/* Copyright 2024 Stanford University, NVIDIA Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "legion.h"
#include "legion/runtime.h"
#include "legion/legion_ops.h"
#include "legion/legion_tasks.h"
#include "legion/legion_trace.h"
#include "legion/legion_utilities.h"
#include "legion/region_tree.h"
#include "legion/legion_auto_trace.h"
#include "legion/legion_spy.h"
#include "legion/legion_profiling.h"
#include "legion/legion_instances.h"
#include "legion/legion_views.h"
#include "legion/legion_context.h"
#include "legion/legion_replication.h"
#include "legion/mapper_manager.h"
#include "legion/garbage_collection.h"
#include "mappers/default_mapper.h"
#include "mappers/test_mapper.h"
#include "mappers/replay_mapper.h"
#include "mappers/debug_mapper.h"
#include "realm/cmdline.h"

#include <algorithm>
#include <stdlib.h>
#include <unistd.h> // sleep for warnings

#ifdef LEGION_TRACE_ALLOCATION
#include <sys/resource.h>
#endif
#include <sys/mman.h> // needed for munlock but should be removed
#ifdef LEGION_USE_CUDA
#include <cuda.h>
#ifdef LEGION_MALLOC_INSTANCES
#include "realm/cuda/cuda_access.h"
#endif
#endif
#ifdef LEGION_USE_HIP
#include <hip/hip_runtime.h>
#ifdef LEGION_MALLOC_INSTANCES
#include "realm/hip/hip_access.h"
#endif
#endif

#define REPORT_DUMMY_CONTEXT(message)                        \
  REPORT_LEGION_ERROR(ERROR_DUMMY_CONTEXT_OPERATION,  message)

namespace Legion {
  namespace Internal {

    // If you add a logger, update the LEGION_EXTERN_LOGGER_DECLARATIONS
    // macro in legion_types.h
    Realm::Logger log_run("runtime");
    Realm::Logger log_task("tasks");
    Realm::Logger log_index("index_spaces");
    Realm::Logger log_field("field_spaces");
    Realm::Logger log_region("regions");
    Realm::Logger log_inst("instances");
    Realm::Logger log_variant("variants");
    Realm::Logger log_allocation("allocation");
    Realm::Logger log_migration("migration");
    Realm::Logger log_prof("legion_prof");
    Realm::Logger log_garbage("legion_gc");
    Realm::Logger log_shutdown("shutdown");
    Realm::Logger log_tracing("tracing");
    Realm::Logger log_auto_trace("auto_trace");
    Realm::Logger log_eager("eager");
    namespace LegionSpy {
      Realm::Logger log_spy("legion_spy");
    };

    thread_local TaskContext *implicit_context = NULL;
    thread_local MappingCallInfo *implicit_mapper_call = NULL;
    thread_local Runtime *implicit_runtime = NULL;
    thread_local LegionProfInstance *implicit_profiler = NULL;
    thread_local AutoLock *local_lock_list = NULL;
    thread_local UniqueID implicit_provenance = 0;
    thread_local LgEvent implicit_fevent = LgEvent::NO_LG_EVENT;
    thread_local unsigned inside_registration_callback=NO_REGISTRATION_CALLBACK;
    thread_local ImplicitReferenceTracker *implicit_reference_tracker = NULL;
#ifdef DEBUG_LEGION_CALLERS
    thread_local LgTaskID implicit_task_kind = LG_SCHEDULER_ID;
    thread_local LgTaskID implicit_task_caller = LG_SCHEDULER_ID;
#endif

    const LgEvent LgEvent::NO_LG_EVENT = {};
    const ApEvent ApEvent::NO_AP_EVENT = {};
    const ApUserEvent ApUserEvent::NO_AP_USER_EVENT = {};
    const ApBarrier ApBarrier::NO_AP_BARRIER = {};
    const RtEvent RtEvent::NO_RT_EVENT = {};
    const RtUserEvent RtUserEvent::NO_RT_USER_EVENT = {};
    const RtBarrier RtBarrier::NO_RT_BARRIER = {};
    const PredEvent PredEvent::NO_PRED_EVENT = {};
    const PredUserEvent PredUserEvent::NO_PRED_USER_EVENT = {};

    //--------------------------------------------------------------------------
    void LgEvent::begin_context_wait(Context ctx, bool from_application) const
    //--------------------------------------------------------------------------
    {
      ctx->begin_wait(*this, from_application);
    }

    //--------------------------------------------------------------------------
    void LgEvent::end_context_wait(Context ctx, bool from_application) const
    //--------------------------------------------------------------------------
    {
      ctx->end_wait(*this, from_application);
    }

    //--------------------------------------------------------------------------
    void LgEvent::record_event_wait(LegionProfInstance *profiler,
                                    Realm::Backtrace &bt) const
    //--------------------------------------------------------------------------
    {
      profiler->record_event_wait(*this, bt);
    }

    //--------------------------------------------------------------------------
    void LgEvent::record_event_trigger(LgEvent precondition) const
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(exists());
      assert(implicit_profiler != NULL);
#endif
      implicit_profiler->record_event_trigger(*this, precondition);
    }

    /////////////////////////////////////////////////////////////
    // Argument Map Impl
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    ArgumentMapImpl::ArgumentMapImpl(void)
      : Collectable(), runtime(implicit_runtime),
        future_map(NULL), point_set(NULL), dimensionality(0), 
        dependent_futures(0), update_point_set(false), equivalent(false)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    ArgumentMapImpl::ArgumentMapImpl(const FutureMap &rhs)
      : Collectable(), runtime(implicit_runtime), future_map(rhs.impl), 
        dependent_futures(0), update_point_set(false), equivalent(false)
    //--------------------------------------------------------------------------
    {
      if (future_map.impl != NULL)
      {
        point_set = future_map.impl->future_map_domain;
        point_set->add_base_expression_reference(RUNTIME_REF);
        dimensionality = point_set->get_num_dims();
      }
      else
      {
        point_set = NULL;
        dimensionality = 0;
      }
    }

    //--------------------------------------------------------------------------
    ArgumentMapImpl::ArgumentMapImpl(const ArgumentMapImpl &impl)
      : Collectable(), runtime(NULL)
    //--------------------------------------------------------------------------
    {
      // This should never ever be called
      assert(false);
    }
    
    //--------------------------------------------------------------------------
    ArgumentMapImpl::~ArgumentMapImpl(void)
    //--------------------------------------------------------------------------
    {
      if ((point_set != NULL) && 
          point_set->remove_base_expression_reference(RUNTIME_REF))
        delete point_set;
    }

    //--------------------------------------------------------------------------
    ArgumentMapImpl& ArgumentMapImpl::operator=(const ArgumentMapImpl &rhs)
    //--------------------------------------------------------------------------
    {
      // This should never ever be called
      assert(false);
      return *this;
    }

    //--------------------------------------------------------------------------
    bool ArgumentMapImpl::has_point(const DomainPoint &point)
    //--------------------------------------------------------------------------
    {
      if (dimensionality > 0)
      {
        const unsigned point_dim = point.get_dim();
        if (point_dim != dimensionality)
          REPORT_LEGION_ERROR(ERROR_ARGUMENT_MAP_DIMENSIONALITY,
              "Mismatch in dimensionality in 'has_point' on ArgumentMap "
              "with %d dimensions and point with %d dimensions. ArgumentMaps "
              "must always contain points of the same dimensionality.",
              dimensionality, point_dim)
      }
      if ((point_set != NULL) && !update_point_set &&
           point_set->contains_point(point))
        return true;
      if (future_map.impl != NULL)
        unfreeze();
      return (arguments.find(point) != arguments.end());
    }

    //--------------------------------------------------------------------------
    void ArgumentMapImpl::set_point(const DomainPoint &point, 
                                    const UntypedBuffer &arg, bool replace)
    //--------------------------------------------------------------------------
    {
      if (dimensionality > 0)
      {
        const unsigned point_dim = point.get_dim();
        if (point_dim != dimensionality)
          REPORT_LEGION_ERROR(ERROR_ARGUMENT_MAP_DIMENSIONALITY,
              "Mismatch in dimensionality in 'set_point' on ArgumentMap "
              "with %d dimensions and point with %d dimensions. ArgumentMaps "
              "must always contain points of the same dimensionality.",
              dimensionality, point_dim)
      }
      else
      {
        dimensionality = point.get_dim();
#ifdef DEBUG_LEGION
        assert(dimensionality > 0);
#endif
      }
      if (!replace and (point_set != NULL) && !update_point_set &&
          point_set->contains_point(point))
        return;
      if (future_map.impl != NULL)
        unfreeze();
      std::map<DomainPoint,Future>::iterator finder = arguments.find(point);
      if (finder != arguments.end())
      {
        // If it already exists and we're not replacing it then we're done
        if (!replace)
          return;
        if (finder->second.impl->producer_op != NULL)
        {
#ifdef DEBUG_LEGION
          assert(dependent_futures > 0);
#endif
          dependent_futures--;
        }
        if (arg.get_size() > 0)
          finder->second = 
            Future::from_untyped_pointer(arg.get_ptr(), arg.get_size());
        else
          finder->second = Future();
      }
      else
      {
        if (arg.get_size() > 0)
          arguments[point] = 
            Future::from_untyped_pointer(arg.get_ptr(), arg.get_size());
        else
          arguments[point] = Future();
        // Had to add a new point so the point set is no longer value
        update_point_set = true;
      }
      // If we modified things then they are no longer equivalent
      if (future_map.impl != NULL)
      {
        equivalent = false;
        future_map = FutureMap();
      }
    }

    //--------------------------------------------------------------------------
    void ArgumentMapImpl::set_point(const DomainPoint &point, 
                                    const Future &f, bool replace)
    //--------------------------------------------------------------------------
    {
      if (dimensionality > 0)
      {
        const unsigned point_dim = point.get_dim();
        if (point_dim != dimensionality)
          REPORT_LEGION_ERROR(ERROR_ARGUMENT_MAP_DIMENSIONALITY,
              "Mismatch in dimensionality in 'set_point' on ArgumentMap "
              "with %d dimensions and point with %d dimensions. ArgumentMaps "
              "must always contain points of the same dimensionality.",
              dimensionality, point_dim)
      }
      else
      {
        dimensionality = point.get_dim();
#ifdef DEBUG_LEGION
        assert(dimensionality > 0);
#endif
      }
      if (!replace and (point_set != NULL) && !update_point_set &&
          point_set->contains_point(point))
        return;
      if (future_map.impl != NULL)
        unfreeze();
      std::map<DomainPoint,Future>::iterator finder = arguments.find(point);
      if (finder != arguments.end())
      {
        // If it already exists and we're not replacing it then we're done
        if (!replace)
          return;
        if (finder->second.impl->producer_op != NULL)
        {
#ifdef DEBUG_LEGION
          assert(dependent_futures > 0);
#endif
          dependent_futures--;
        }
        finder->second = f; 
        
      }
      else
      {
        arguments[point] = f;
        // Had to add a new point so the point set is no longer valid
        update_point_set = true;
      }
      if (f.impl->producer_op != NULL)
          dependent_futures++;
      // If we modified things then they are no longer equivalent
      if (future_map.impl != NULL)
      {
        equivalent = false;
        future_map = FutureMap();
      }
    }

    //--------------------------------------------------------------------------
    bool ArgumentMapImpl::remove_point(const DomainPoint &point)
    //--------------------------------------------------------------------------
    {
      if (dimensionality > 0)
      {
        const unsigned point_dim = point.get_dim();
        if (point_dim != dimensionality)
          REPORT_LEGION_ERROR(ERROR_ARGUMENT_MAP_DIMENSIONALITY,
              "Mismatch in dimensionality in 'remove_point' on ArgumentMap "
              "with %d dimensions and point with %d dimensions. ArgumentMaps "
              "must always contain points of the same dimensionality.",
              dimensionality, point_dim)
      }
      else
      {
        dimensionality = point.get_dim();
#ifdef DEBUG_LEGION
        assert(dimensionality > 0);
#endif
      }
      if ((point_set != NULL) && !update_point_set &&
          !point_set->contains_point(point))
        return false;
      if (future_map.impl != NULL)
        unfreeze();
      std::map<DomainPoint,Future>::iterator finder = arguments.find(point);
      if (finder != arguments.end())
      {
        if (finder->second.impl->producer_op != NULL)
        {
#ifdef DEBUG_LEGION
          assert(dependent_futures > 0);
#endif
          dependent_futures--;
        }
        arguments.erase(finder);
        // If we modified things then they are no longer equivalent
        if (future_map.impl != NULL)
        {
          equivalent = false;
          future_map = FutureMap();
        }
        // We removed a point so the point set is no longer valid
        update_point_set = true;
        return true;
      }
      return false;
    }

    //--------------------------------------------------------------------------
    UntypedBuffer ArgumentMapImpl::get_point(const DomainPoint &point)
    //--------------------------------------------------------------------------
    {
      if (dimensionality > 0)
      {
        const unsigned point_dim = point.get_dim();
        if (point_dim != dimensionality)
          REPORT_LEGION_ERROR(ERROR_ARGUMENT_MAP_DIMENSIONALITY,
              "Mismatch in dimensionality in 'get_point' on ArgumentMap "
              "with %d dimensions and point with %d dimensions. ArgumentMaps "
              "must always contain points of the same dimensionality.",
              dimensionality, point_dim)
      }
      if ((point_set != NULL) && !update_point_set &&
          !point_set->contains_point(point))
        return UntypedBuffer();
      if (future_map.impl != NULL)
        unfreeze();
      std::map<DomainPoint,Future>::const_iterator finder=arguments.find(point);
      if ((finder == arguments.end()) || (finder->second.impl == NULL))
        return UntypedBuffer();
      size_t arg_size = 0;
      const void *ptr = finder->second.impl->get_buffer(
              runtime->runtime_system_memory, &arg_size);
      return UntypedBuffer(ptr, arg_size);
    }

    //--------------------------------------------------------------------------
    FutureMap ArgumentMapImpl::freeze(InnerContext *ctx, Provenance *provenance)
    //--------------------------------------------------------------------------
    {
      // If we already have a future map then we are good
      if (future_map.impl != NULL)
        return future_map;
      // If we have no futures then we can return an empty map
      if (arguments.empty())
        return FutureMap();
      // Compute the point set if needed
      if (update_point_set)
      {
        if ((point_set != NULL) &&
            point_set->remove_base_expression_reference(RUNTIME_REF))
          delete point_set;
        if (!arguments.empty())
        {
          Domain point_domain;
          switch (dimensionality)
          {
#define DIMFUNC(DIM) \
            case DIM: \
            { \
              std::vector<Realm::Point<DIM,coord_t> > points(arguments.size());\
              unsigned index = 0; \
              for (std::map<DomainPoint,Future>::const_iterator it = \
                    arguments.begin(); it != arguments.end(); it++) \
              { \
                const Point<DIM,coord_t> point = it->first; \
                points[index++] = point; \
              } \
              Realm::IndexSpace<DIM,coord_t> space(points); \
              /* Make sure this is tight for determinism */ \
              space = space.tighten(); \
              const DomainT<DIM,coord_t> domaint(space); \
              point_domain = domaint; \
              break; \
            }
            LEGION_FOREACH_N(DIMFUNC)
#undef DIMFUNC
            default:
              assert(false);
          }
          IndexSpace point_space = 
            ctx->find_index_launch_space(point_domain, provenance);
          point_set = runtime->forest->get_node(point_space);
          point_set->add_base_expression_reference(RUNTIME_REF);
        }
        else
          point_set = NULL;
        update_point_set = false;
      }
      // See if we have any dependent future points, if we do then we need
      // to launch an explicit creation operation to ensure we get the right
      // mapping dependences for this future map
      if (point_set == NULL)
        future_map = FutureMap();
      else if (dependent_futures == 0 && !runtime->safe_control_replication)
      {
        // Otherwise we have to make a future map and set all the futures
        // We know that they are already completed 
        DistributedID did = runtime->get_available_distributed_id();
        future_map = FutureMap(new FutureMapImpl(ctx, runtime, point_set, did,
              InnerContext::NO_BLOCKING_INDEX, provenance, true/*reg now*/));
        future_map.impl->set_all_futures(arguments);
      }
      else
        future_map = ctx->construct_future_map(point_set->handle, arguments,
                                               provenance, true/*internal*/);
      equivalent = true; // mark that these are equivalent
      dependent_futures = 0; // reset this for the next unpack 
      return future_map;
    }

    //--------------------------------------------------------------------------
    void ArgumentMapImpl::unfreeze(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(future_map.impl != NULL);
#endif
      // If they are already equivalent then we're done
      if (equivalent)
        return;
      // Otherwise we need to make them equivalent
      std::map<DomainPoint,FutureImpl*> futures;
      future_map.impl->get_all_futures(futures);
      arguments.clear();
      for (std::map<DomainPoint,FutureImpl*>::const_iterator it =
            futures.begin(); it != futures.end(); it++)
        arguments[it->first] = Future(it->second);
      if ((point_set != NULL) && 
          point_set->remove_base_expression_reference(RUNTIME_REF))
        delete point_set;
      point_set = future_map.impl->future_map_domain;
      point_set->add_base_expression_reference(RUNTIME_REF);
      update_point_set = false;
      // Count how many dependent futures we have
#ifdef DEBUG_LEGION
      assert(dependent_futures == 0);
#endif
      for (std::map<DomainPoint,Future>::const_iterator it = 
            arguments.begin(); it != arguments.end(); it++)
        if (it->second.impl->producer_op != NULL)
          dependent_futures++;
      equivalent = true;
    }

    /////////////////////////////////////////////////////////////
    // Field Allocator Impl
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    FieldAllocatorImpl::FieldAllocatorImpl(FieldSpaceNode *n, TaskContext *ctx,
                                           RtEvent ready)
      : field_space(n->handle), node(n), context(ctx), ready_event(ready),
        free_from_application(true)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(node != NULL);
      assert(context != NULL);
#endif
      context->add_base_resource_ref(FIELD_ALLOCATOR_REF);
      node->add_base_resource_ref(FIELD_ALLOCATOR_REF);
    }

    //--------------------------------------------------------------------------
    FieldAllocatorImpl::FieldAllocatorImpl(const FieldAllocatorImpl &rhs)
      : field_space(rhs.field_space), node(rhs.node), context(rhs.context), 
        ready_event(rhs.ready_event)
    //--------------------------------------------------------------------------
    {
      // Should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    FieldAllocatorImpl::~FieldAllocatorImpl(void)
    //--------------------------------------------------------------------------
    {
      context->destroy_field_allocator(node, free_from_application);
      if (context->remove_base_resource_ref(FIELD_ALLOCATOR_REF))
        delete context;
      if (node->remove_base_resource_ref(FIELD_ALLOCATOR_REF))
        delete node;
    }

    //--------------------------------------------------------------------------
    FieldAllocatorImpl& FieldAllocatorImpl::operator=(
                                                  const FieldAllocatorImpl &rhs)
    //--------------------------------------------------------------------------
    {
      // Should never be called
      assert(false);
      return *this;
    }
    
    //--------------------------------------------------------------------------
    FieldID FieldAllocatorImpl::allocate_field(size_t field_size,
                                               FieldID desired_fieldid,
                                               CustomSerdezID serdez_id, 
                                               bool local, Provenance *prov)
    //--------------------------------------------------------------------------
    {
      // Need to wait for this allocator to be ready
      if (ready_event.exists() && !ready_event.has_triggered())
        ready_event.wait();
      return context->allocate_field(field_space, field_size, desired_fieldid,
                                     local, serdez_id, prov);
    }

    //--------------------------------------------------------------------------
    FieldID FieldAllocatorImpl::allocate_field(const Future &field_size,
                                               FieldID desired_fieldid,
                                               CustomSerdezID serdez_id, 
                                               bool local, Provenance *prov)
    //--------------------------------------------------------------------------
    {
      // Need to wait for this allocator to be ready
      if (ready_event.exists() && !ready_event.has_triggered())
        ready_event.wait();
      return context->allocate_field(field_space, field_size, desired_fieldid, 
                                     local, serdez_id, prov);
    }

    //--------------------------------------------------------------------------
    void FieldAllocatorImpl::free_field(FieldID fid, const bool unordered,
                                        Provenance *provenance)
    //--------------------------------------------------------------------------
    {
      // Don't need to wait here since deletion operations catch
      // dependences on the allocator themselves
      context->free_field(this, field_space, fid, unordered, provenance);
    }

    //--------------------------------------------------------------------------
    void FieldAllocatorImpl::allocate_fields(
                                        const std::vector<size_t> &field_sizes,
                                        std::vector<FieldID> &resulting_fields,
                                        CustomSerdezID serdez_id, bool local,
                                        Provenance *provenance)
    //--------------------------------------------------------------------------
    {
      // Need to wait for this allocator to be ready
      if (ready_event.exists() && !ready_event.has_triggered())
        ready_event.wait();
      context->allocate_fields(field_space, field_sizes, resulting_fields,
                               local, serdez_id, provenance);
    }

    //--------------------------------------------------------------------------
    void FieldAllocatorImpl::allocate_fields(
                                        const std::vector<Future> &field_sizes,
                                        std::vector<FieldID> &resulting_fields,
                                        CustomSerdezID serdez_id, bool local,
                                        Provenance *provenance)
    //--------------------------------------------------------------------------
    {
      // Need to wait for this allocator to be ready
      if (ready_event.exists() && !ready_event.has_triggered())
        ready_event.wait();
      context->allocate_fields(field_space, field_sizes, resulting_fields, 
                               local, serdez_id, provenance);
    }

    //--------------------------------------------------------------------------
    void FieldAllocatorImpl::free_fields(const std::set<FieldID> &to_free,
                                   const bool unordered, Provenance *provenance)
    //--------------------------------------------------------------------------
    {
      // Don't need to wait here since deletion operations catch
      // dependences on the allocator themselves
      context->free_fields(this, field_space, to_free, unordered, provenance);
    }

    /////////////////////////////////////////////////////////////
    // Predicate Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    PredicateImpl::PredicateImpl(Operation *op)
      : context(op->get_context()), creator(op),
        creator_gen(op->get_generation()), creator_uid(op->get_unique_op_id()),
        value(-1)
    //--------------------------------------------------------------------------
    {
      context->add_base_resource_ref(APPLICATION_REF);
    }

    //--------------------------------------------------------------------------
    PredicateImpl::~PredicateImpl(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(0 <= value);
#endif 
      if (context->remove_base_resource_ref(APPLICATION_REF))
        delete context;
    }

    //--------------------------------------------------------------------------
    bool PredicateImpl::get_predicate(uint64_t context_index,
                                      PredEvent &true_g, PredEvent &false_g)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(predicate_lock);
      if (0 <= value)
        return (0 < value);
      // Not ready yet, make guards if they don't exist yet
      if (!true_guard.exists())
      {
        true_guard = Runtime::create_pred_event();
        false_guard = Runtime::create_pred_event(); 
      }
      true_g = true_guard;
      false_g = false_guard;
      return false;
    }

    //--------------------------------------------------------------------------
    bool PredicateImpl::get_predicate(RtEvent &ready)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(predicate_lock);
      if (0 <= value)
        return (0 < value);
      if (!ready_event.exists())
        ready_event = Runtime::create_rt_user_event();
      ready = ready_event;
      return false;
    }

    //--------------------------------------------------------------------------
    void PredicateImpl::set_predicate(bool result)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(predicate_lock);
#ifdef DEBUG_LEGION
      assert(value < 0);
#endif
      if (result)
        value = 1;
      else
        value = 0;
      if (ready_event.exists())
        Runtime::trigger_event(ready_event);
      if (true_guard.exists())
      {
        if (result)
        {
          Runtime::trigger_event(true_guard);
          Runtime::poison_event(false_guard);
        }
        else
        {
          Runtime::poison_event(true_guard);
          Runtime::trigger_event(false_guard);
        }
      }
    }

    /////////////////////////////////////////////////////////////
    // Repl Predicate Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    ReplPredicateImpl::ReplPredicateImpl(Operation *op, uint64_t coordinate,
                                         CollectiveID id)
      : PredicateImpl(op), predicate_coordinate(coordinate), collective_id(id),
        max_observed_index(0), collective(NULL)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    ReplPredicateImpl::~ReplPredicateImpl(void)
    //--------------------------------------------------------------------------
    {
      if (collective != NULL)
        delete collective;
    }

    //--------------------------------------------------------------------------
    bool ReplPredicateImpl::get_predicate(uint64_t context_index,
                                          PredEvent &true_g, PredEvent &false_g)
    //--------------------------------------------------------------------------
    {
      bool trigger_guards = false;
      AutoLock p_lock(predicate_lock);
      // If the result is true then we can just return that
      if (0 < value)
        return true;
      if (value == 0)
      {
        // For the false case, check to see if we already got the
        // maximum observed false case
        if (collective != NULL)
          max_observed_index = collective->get_result(); 
        // Can safely return false here since it's later than the 
        // maximum observed index across all the shards so all shards
        // will return the same false decision
        if (max_observed_index < context_index)
          return false;
        // Othewise we fall through and pretend like we don't know that
        // it is false yet so that we align the predication decision
        // across all the shards
        trigger_guards = true;
      }
      // Not ready yet, make guards if they don't exist yet
      if (!true_guard.exists())
      {
        true_guard = Runtime::create_pred_event();
        false_guard = Runtime::create_pred_event(); 
        if (trigger_guards)
        {
          // We're doing the fall-through case where we know its false
          // but we have to make sure that all the shards do the same
          // thing so we're pretending like we don't know the result yet
#ifdef DEBUG_LEGION
          assert(value == 0);
#endif
          Runtime::poison_event(true_guard);
          Runtime::trigger_event(false_guard);
        }
      }
      true_g = true_guard;
      false_g = false_guard;
      if (context_index > max_observed_index)
        max_observed_index = context_index;
      return false;
    }

    //--------------------------------------------------------------------------
    void ReplPredicateImpl::set_predicate(bool result)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(predicate_lock);
#ifdef DEBUG_LEGION
      assert(value < 0);
#endif
      if (!result) // False
      {
        value = 0;
        if (collective_id > 0)
        {
#ifdef DEBUG_LEGION
          ReplicateContext *repl_ctx = dynamic_cast<ReplicateContext*>(context);
          assert(repl_ctx != NULL);
#else
          ReplicateContext *repl_ctx = static_cast<ReplicateContext*>(context);
#endif
          collective = new PredicateCollective(this, repl_ctx, collective_id);
          collective->async_all_reduce(max_observed_index);
        }
      }
      else // True
        value = 1;
      if (ready_event.exists())
        Runtime::trigger_event(ready_event);
      if (true_guard.exists())
      {
        if (result)
        {
          Runtime::trigger_event(true_guard);
          Runtime::poison_event(false_guard);
        }
        else
        {
          Runtime::poison_event(true_guard);
          Runtime::trigger_event(false_guard);
        }
      }
    }

    /////////////////////////////////////////////////////////////
    // Future Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    FutureImpl::FutureImpl(TaskContext *ctx, Runtime *rt, bool register_now,
            DistributedID did, Provenance *prov, Operation *o /*= NULL*/) 
      : DistributedCollectable(rt, 
          LEGION_DISTRIBUTED_HELP_ENCODE(did, FUTURE_DC), 
          register_now), context(ctx),
        producer_op(o), op_gen((o == NULL) ? 0 : o->get_generation()),
        producer_depth((o == NULL) ? -1 : o->get_context()->get_depth()),
        producer_uid((o == NULL) ? 0 : o->get_unique_op_id()),
        coordinate((o == NULL) ?
            ContextCoordinate(InnerContext::NO_BLOCKING_INDEX) :
            ContextCoordinate(o->get_context()->get_next_blocking_index())),
        provenance(prov), local_visible_memory(Memory::NO_MEMORY),
        metadata(NULL), metasize(0), future_size(0), upper_bound_size(SIZE_MAX),
        callback_functor(NULL), own_callback_functor(false),
        future_size_set(false)
    //--------------------------------------------------------------------------
    {
      empty.store(true);
      sampled.store(false);
      if (producer_op != NULL)
        producer_op->add_mapping_reference(op_gen);
      if (provenance != NULL)
        provenance->add_reference();
#ifdef LEGION_GC
      log_garbage.info("GC Future %lld %d", 
          LEGION_DISTRIBUTED_ID_FILTER(did), local_space);
#endif
    }

    //--------------------------------------------------------------------------
    FutureImpl::FutureImpl(TaskContext *ctx, Runtime *rt, bool register_now, 
                           DistributedID did, Operation *o, GenerationID gen,
                           const ContextCoordinate &coord, UniqueID uid,
                           int depth, Provenance *prov, CollectiveMapping *map)
      : DistributedCollectable(rt, 
          LEGION_DISTRIBUTED_HELP_ENCODE(did, FUTURE_DC), 
          register_now, map), context(ctx),
        producer_op(o), op_gen(gen), producer_depth(depth), producer_uid(uid),
        coordinate(coord), provenance(prov), 
        local_visible_memory(Memory::NO_MEMORY), metadata(NULL), metasize(0),
        future_size(0), upper_bound_size(SIZE_MAX), callback_functor(NULL),
        own_callback_functor(false), future_size_set(false)
    //--------------------------------------------------------------------------
    {
      empty.store(true);
      sampled.store(false);
      if (producer_op != NULL)
        producer_op->add_mapping_reference(op_gen);
      if (provenance != NULL)
        provenance->add_reference();
#ifdef LEGION_GC
      log_garbage.info("GC Future %lld %d", 
          LEGION_DISTRIBUTED_ID_FILTER(this->did), local_space);
#endif
    }

    //--------------------------------------------------------------------------
    FutureImpl::~FutureImpl(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!subscription_event.exists());
#endif
      for (std::map<Memory,FutureInstanceTracker>::iterator
            it = instances.begin(); it != instances.end(); it++)
      {
        if (it->second.remote_postcondition.exists())
        {
          // This is a remote instance that we unpacked and nobody
          // used it so we can just clean it up since we don't own it
#ifdef DEBUG_LEGION
          assert(it->second.read_events.empty());
#endif
          Runtime::trigger_event(NULL, it->second.remote_postcondition,
              it->second.ready_event);
          delete it->second.instance;
        }
        else
        {
          // Merge together all the events for destroying this future instance
          ApEvent precondition = it->second.ready_event;
          if (!it->second.read_events.empty())
          {
            if (precondition.exists())
              it->second.read_events.push_back(precondition);
            precondition = Runtime::merge_events(NULL, it->second.read_events);
          }
          if (!it->second.instance->defer_deletion(precondition))
            delete it->second.instance;
        }
      }
      if (producer_op != NULL)
        producer_op->remove_mapping_reference(op_gen);
      if (callback_functor != NULL)
      {
        // Dispatch the deletion functionon the callback processor
        CallbackReleaseArgs args(callback_functor, own_callback_functor); 
        runtime->issue_application_processor_task(args,
              LG_LATENCY_WORK_PRIORITY, callback_proc);
      }
      if (metadata != NULL)
        free(metadata);
      if ((provenance != NULL) && provenance->remove_reference())
        delete provenance;
    }

    //--------------------------------------------------------------------------
    void FutureImpl::prepare_for_shutdown(void)
    //--------------------------------------------------------------------------
    {
      // This future is leaking, so just force delete all our instances
      AutoLock f_lock(future_lock);
      for (std::map<Memory,FutureInstanceTracker>::iterator it =
            instances.begin(); it != instances.end(); it++)
      {
        // Merge together all the events for destroying this future instance
        ApEvent precondition = it->second.ready_event;
        if (!it->second.read_events.empty())
        {
          if (precondition.exists())
            it->second.read_events.push_back(precondition);
          precondition = Runtime::merge_events(NULL, it->second.read_events);
        }
        if (!it->second.instance->defer_deletion(precondition))
          delete it->second.instance;
      }
      instances.clear();
    }

    //--------------------------------------------------------------------------
    bool FutureImpl::is_ready(bool do_subscribe)
    //--------------------------------------------------------------------------
    {
      if (do_subscribe)
        subscribe();
      if (producer_op == NULL)
        return true;
      const int context_depth = (implicit_context == NULL) ? producer_depth :
        implicit_context->get_depth();
#ifdef DEBUG_LEGION
      assert(producer_depth <= context_depth);
#endif
      if (producer_depth < context_depth)
        return true;
      // This is not fully accurate since we might still need to wait across
      // the shards for control replication but it is close enough
      return producer_op->get_commit_event(op_gen).has_triggered();
    }

    //--------------------------------------------------------------------------
    void FutureImpl::wait(bool silence_warnings, const char *warning_string)
    //--------------------------------------------------------------------------
    {
      if (runtime->runtime_warnings && !silence_warnings && 
          (implicit_context != NULL))
      {
        if (!implicit_context->is_leaf_context())
          REPORT_LEGION_WARNING(LEGION_WARNING_WAITING_FUTURE_NONLEAF, 
             "Waiting on a future in non-leaf task %s "
             "(UID %lld) is a violation of Legion's deferred execution model "
             "best practices. You may notice a severe performance "
             "degradation. Warning string: %s",
             implicit_context->get_task_name(), 
             implicit_context->get_unique_id(),
             (warning_string == NULL) ? "" : warning_string)
      }
      mark_sampled();
      // We only need to wait for the commit opertion for this future if we're
      // outside of the task tree or at the same level as the depth of the 
      // context that produced the future (note this handles control
      // replication correctly as well since all the shards will appear to 
      // be at the same depth). It should be impossible to have a depth above
      // the level where the future was created because futures cannot 
      // escape back up the task tree
      if (producer_op == NULL)
        return;
      const int context_depth = (implicit_context == NULL) ? producer_depth :
        implicit_context->get_depth();
#ifdef DEBUG_LEGION
      assert(producer_depth <= context_depth);
#endif
      if (producer_depth < context_depth)
        return;
      context->record_blocking_call(coordinate.context_index);
      context->wait_on_future(this, producer_op->get_commit_event(op_gen));
    }
    
    //--------------------------------------------------------------------------
    const void* FutureImpl::get_buffer(Processor proc, Memory::Kind memkind,
                              size_t *extent_in_bytes, bool check_extent,
                              bool silence_warnings, const char *warning_string)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(proc.exists() ||
          (memkind == runtime->runtime_system_memory.kind()));
#endif
      // Figure out which memory we are looking for
      // If the user passed in a NO_PROC, then use the local system memory
      Memory memory = proc.exists() ? runtime->find_local_memory(proc, memkind)
        : runtime->runtime_system_memory;
      if (!memory.exists())
      {
        if (memkind != Memory::SYSTEM_MEM)
        {
          const char *mem_names[] = {
#define MEM_NAMES(name, desc) desc,
            REALM_MEMORY_KINDS(MEM_NAMES) 
#undef MEM_NAMES
          };
          REPORT_LEGION_ERROR(ERROR_INVALID_FUTURE_MEMORY_KIND,
              "Unable to find a %s memory associated with processor " IDFMT
              " in which to create a future buffer.", 
              mem_names[memkind], proc.id)
        }
        else
          memory = runtime->runtime_system_memory;
      }
      return get_buffer(memory, extent_in_bytes, check_extent,
                        silence_warnings, warning_string);
    }

    //--------------------------------------------------------------------------
    const void* FutureImpl::get_buffer(Memory memory, size_t *extent_in_bytes,
           bool check_extent, bool silence_warnings, const char *warning_string)
    //--------------------------------------------------------------------------
    {
      // Make sure that we've subscribed
      const RtEvent subscribed = subscribe();
      // Wait to make sure that the future is complete first
      wait(silence_warnings, warning_string);
      // Do this wait after everything is ready for pipelining of communication
      subscribed.wait();
      ApEvent inst_ready;
      FutureInstance *instance = find_or_create_instance(memory,
          (implicit_context != NULL) ? implicit_context->owner_task : NULL,
          (implicit_context != NULL) && (implicit_context->owner_task != NULL) ?
           implicit_context->owner_task->get_unique_op_id() : 0, true/*eager*/,
           inst_ready);
      if (extent_in_bytes != NULL)
      {
        if (check_extent)
        {
          if (empty.load())
            REPORT_LEGION_ERROR(ERROR_REQUEST_FOR_EMPTY_FUTURE, 
                                "Accessing empty future! (UID %lld)",
                                (producer_op == NULL) ? 0 :
                                  producer_op->get_unique_op_id())
          else if (instance == NULL)
          {
            if ((*extent_in_bytes) != 0)
              REPORT_LEGION_ERROR(ERROR_FUTURE_SIZE_MISMATCH,
                "Future size mismatch! Expected type of 0 bytes but "
                "requested type is %zd bytes. (UID %lld)", 
                *extent_in_bytes, (producer_op == NULL) ? 0 :
                producer_op->get_unique_op_id())
          }
          else if (future_size != *extent_in_bytes)
            REPORT_LEGION_ERROR(ERROR_FUTURE_SIZE_MISMATCH,
                "Future size mismatch! Expected type of %zd bytes but "
                "requested type is %zd bytes. (UID %lld)", 
                future_size, *extent_in_bytes, (producer_op == NULL) ? 0 :
                producer_op->get_unique_op_id())
        }
        else
          (*extent_in_bytes) = future_size;
      }
      if (instance == NULL)
        return NULL;
      bool poisoned = false;
      if (!inst_ready.has_triggered_faultaware(poisoned))
        inst_ready.wait_faultaware(poisoned);
      if (poisoned && (implicit_context != NULL))
        implicit_context->raise_poison_exception();
      return instance->get_data();
    }

    //--------------------------------------------------------------------------
    void FutureImpl::get_memories(std::set<Memory> &memories,
                              bool silence_warnings, const char *warning_string)
    //--------------------------------------------------------------------------
    {
      // Wait for the future to be ready
      memories.clear();
      wait(silence_warnings, warning_string);
      AutoLock f_lock(future_lock,1,false/*exclusive*/);
      for (std::map<Memory,FutureInstanceTracker>::const_iterator it =
            instances.begin(); it != instances.end(); it++)
        memories.insert(it->first);
    }

    //--------------------------------------------------------------------------
    PhysicalInstance FutureImpl::get_instance(Memory::Kind memkind, 
                              size_t extent_in_bytes, bool check_extent, 
                              bool silence_warnings, const char *warning_string)
    //--------------------------------------------------------------------------
    {
      // Make sure that we've subscribed
      const RtEvent subscribed = subscribe();
      Processor proc = implicit_context->get_executing_processor();
      // A heuristic to help out applications that are unsure of themselves
      if (memkind == Memory::NO_MEMKIND)
        memkind = (proc.kind() == Processor::TOC_PROC) ?
          Memory::GPU_FB_MEM : Memory::SYSTEM_MEM;
      Memory memory = runtime->find_local_memory(proc, memkind);
      if (!memory.exists())
      {
        if (memkind != Memory::SYSTEM_MEM)
        {
          const char *mem_names[] = {
#define MEM_NAMES(name, desc) desc,
            REALM_MEMORY_KINDS(MEM_NAMES) 
#undef MEM_NAMES
          };
          REPORT_LEGION_ERROR(ERROR_INVALID_FUTURE_MEMORY_KIND,
              "Unable to find a %s memory associated with processor " IDFMT
              " in which to create a future buffer.", 
              mem_names[memkind], proc.id)
        }
        else
          memory = runtime->runtime_system_memory;
      }
      // Wait to make sure that the future is complete first
      wait(silence_warnings, warning_string);
      // Do this wait after everything is ready for pipelining of communication
      subscribed.wait();
      ApEvent inst_ready;
      FutureInstance *instance = find_or_create_instance(memory,
          (implicit_context != NULL) ? implicit_context->owner_task : NULL,
          (implicit_context != NULL) && (implicit_context->owner_task != NULL) ?
           implicit_context->owner_task->get_unique_op_id() : 0, true/*eager*/,
           inst_ready);
      if (empty.load())
        REPORT_LEGION_ERROR(ERROR_REQUEST_FOR_EMPTY_FUTURE, 
            "Accessing empty future when making an accessor! (UID %lld)",
            (producer_op == NULL) ? 0 : producer_op->get_unique_op_id())
      else if ((instance == NULL) || (instance->size == 0))
        REPORT_LEGION_ERROR(ERROR_FUTURE_SIZE_MISMATCH,
          "Future size mismatch! Expected non-empty future for making an "
          "accessor but future has a payload of 0 bytes. (UID %lld)", 
          (producer_op == NULL) ? 0 : producer_op->get_unique_op_id())
      if (check_extent && (future_size != extent_in_bytes))
        REPORT_LEGION_ERROR(ERROR_FUTURE_SIZE_MISMATCH,
            "Future size mismatch! Expected type of %zd bytes but "
            "requested type is %zd bytes. (UID %lld)", 
            future_size, extent_in_bytes, (producer_op == NULL) ? 0 :
            producer_op->get_unique_op_id())
      PhysicalInstance result;
      {
        bool dummy_owner = true;
        // Need to hold the lock when creating the instance since 
        // the future instance object is not thread safe
        AutoLock f_lock(future_lock);
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
        LgEvent dummy_event;
        result = instance->get_instance(instance->size,dummy_event,dummy_owner);
#else
        result = instance->get_instance(instance->size, dummy_owner);
#endif
#ifdef DEBUG_LEGION
        // Should never be set to true here
        assert(!dummy_owner);
#endif
      }
      bool poisoned = false;
      if (!inst_ready.has_triggered_faultaware(poisoned))
        inst_ready.wait_faultaware(poisoned);
      if (poisoned && (implicit_context != NULL))
        implicit_context->raise_poison_exception();
      return result;
    }

    //--------------------------------------------------------------------------
    void FutureImpl::report_incompatible_accessor(const char *accessor_kind,
                                                  PhysicalInstance instance)
    //--------------------------------------------------------------------------
    {
      REPORT_LEGION_ERROR(ERROR_ACCESSOR_COMPATIBILITY_CHECK,
          "Unable to create Realm %s for future instance %llx in task %s",
          accessor_kind, instance.id, implicit_context->get_task_name())
    }

    //--------------------------------------------------------------------------
    bool FutureImpl::find_or_create_application_instance(Memory target,
                                                         UniqueID task_uid)
    //--------------------------------------------------------------------------
    {
      const RtEvent ready = request_application_instance(target, NULL, task_uid,
          runtime->address_space, true/*can fail*/);
      if (ready.exists() && !ready.has_triggered())
        ready.wait();
      AutoLock f_lock(future_lock,1,false/*exclusive*/);
      if (target.address_space() == runtime->address_space)
        return (instances.find(target) != instances.end()) ||
          (pending_instances.find(target) != pending_instances.end());
      else
        return (remote_instance_allocations.find(target) !=
                  remote_instance_allocations.end());
    }

    //--------------------------------------------------------------------------
    RtEvent FutureImpl::request_application_instance(Memory target,
      SingleTask *task, UniqueID task_uid, AddressSpaceID source, 
      bool can_fail, size_t known_upper_bound_size)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(target.exists());
#endif
      RtEvent ready_event;
      RtUserEvent send_event;
      bool need_subscribe = false;
      const AddressSpaceID target_space = target.address_space();
      {
        AutoLock f_lock(future_lock);
        // Check first to see if we have such an instance
        std::map<Memory,FutureInstanceTracker>::const_iterator
          inst_finder = instances.find(target);
        if (inst_finder != instances.end())
          return RtEvent::NO_RT_EVENT;
        // We don't have it yet, see if we're on the right node to
        // try to make this instance or not
        if (target_space != runtime->address_space)
        {
          // See if we already have a pending request in flight
          std::map<Memory,RtUserEvent>::iterator finder = 
            remote_instance_allocations.find(target);
          if (finder != remote_instance_allocations.end())
            return finder->second;
          send_event = Runtime::create_rt_user_event();
          remote_instance_allocations[target] = send_event;
        }
        else
        {
          // We're on the right node to make this instance
          // See if we've subscribed yet or not
          if (empty.load())
          {
            std::map<Memory,PendingInstance>::iterator finder =
              pending_instances.find(target);
            if (finder == pending_instances.end())
            {
              // See if we have a size yet that we can use to try
              // to make the allocation, if not we'll need to wait
              if (future_size_set || (known_upper_bound_size < SIZE_MAX))
              {
                // Try to make the instance now
                const size_t pending_size =
                  future_size_set ? future_size : known_upper_bound_size;
                if (pending_size > 0)
                {
                  MemoryManager *manager = runtime->find_memory_manager(target);
                  FutureInstance *instance = manager->create_future_instance(
                      can_fail ? NULL : task, task_uid, 
                       pending_size, false/*eager*/);
                  if (instance == NULL)
                  {
                    if (source != runtime->address_space)
                    {
                      RtUserEvent notified = Runtime::create_rt_user_event();
                      Serializer rez;
                      {
                        RezCheck z(rez);
                        rez.serialize(did);
                        rez.serialize(target);
                        rez.serialize(notified);
                      }
                      runtime->send_future_create_instance_response(source,rez);
                      ready_event = notified;
                    }
                  }
                  else
                    pending_instances[target] = PendingInstance(instance);
                }
              }
              else
              {
                // Defer making this, the subscription we'll send
                // will guarantee that we see the size asap
                const RtUserEvent mapped = Runtime::create_rt_user_event();
                pending_instances.emplace(std::make_pair(target,
                      PendingInstance(task, task_uid, mapped, false/*eager*/)));
                ready_event = mapped;
                if ((source != runtime->address_space) && can_fail)
                  pending_instances[target].can_fail_remote_requests.insert(
                                                                    source);
              }
            }
            else
            {
              if ((source != runtime->address_space) && can_fail)
                finder->second.can_fail_remote_requests.insert(source);
              ready_event = finder->second.alloc_ready;
            }
            need_subscribe = !subscription_event.exists();
          }
          else
          {
            ApEvent inst_ready;
            FutureInstance *instance =
              find_or_create_instance(target, can_fail ? NULL : task, 
                  task_uid, false/*eager*/, inst_ready, false/*need lock*/);
            if (can_fail && (instance == NULL))
            {
              const RtUserEvent notified = Runtime::create_rt_user_event();
              Serializer rez;
              {
                RezCheck z(rez);
                rez.serialize(did);
                rez.serialize(target);
                rez.serialize(notified);
              }
              runtime->send_future_create_instance_response(source, rez);
              return notified;
            }
            return RtEvent::NO_RT_EVENT;
          }
        }
      }
      if (send_event.exists())
      {
        // Send the request to the node that owns the memory
        Serializer rez;
        {
          RezCheck z(rez);
          pack_future(rez, target_space);
          rez.serialize(target);
          rez.serialize(task_uid);
          rez.serialize(send_event);
          rez.serialize(source);
          rez.serialize<bool>(can_fail);
        }
        runtime->send_future_create_instance_request(target_space, rez);
        return send_event;
      }
      else if (need_subscribe)
        subscribe();
      return ready_event;
    }

    //--------------------------------------------------------------------------
    RtEvent FutureImpl::request_runtime_instance(Operation *op, bool eager)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(op != NULL);
#endif
      // Check to see if we have an internal buffer to use already
      // If not record that we need one and do the subscription
      RtEvent ready_event;
      bool need_subscribe = false;
      {
        AutoLock f_lock(future_lock);
        if (!empty.load())
        {
          if (local_visible_memory.exists())
            return RtEvent::NO_RT_EVENT;
          // We don't have one yet, but we can make one since we've got
          // the canonical instance at this point
          ApEvent inst_ready;
          find_or_create_instance(runtime->runtime_system_memory, op,
              op->get_unique_op_id(), eager, inst_ready, false/*need lock*/);
          return RtEvent::NO_RT_EVENT;
        }
        for (std::map<Memory,PendingInstance>::iterator it =
              pending_instances.begin(); it != pending_instances.end(); it++)
        {
          if (it->second.instance == NULL)
          {
            if (FutureInstance::check_meta_visible(it->first))
            {
#ifdef DEBUG_LEGION
              assert(it->second.alloc_ready.exists());
#endif
              // Keep it sticky to eager so that if any requests are eager
              // then we must do an eager allocation
              if (eager)
                it->second.eager = true;
              return it->second.alloc_ready;
            }
          }
          else if (it->second.instance->is_meta_visible)
            return RtEvent::NO_RT_EVENT;
        }
        // No pending instances that are meta visible yet
        if (future_size_set)
        {
          if (future_size > 0)
          {
            MemoryManager *manager = 
              runtime->find_memory_manager(runtime->runtime_system_memory); 
            FutureInstance *instance = manager->create_future_instance(op,
                op->get_unique_op_id(), future_size, eager);
            pending_instances.emplace(std::make_pair(
                  runtime->runtime_system_memory, PendingInstance(instance)));
          }
        }
        else
        {
          const RtUserEvent mapped = Runtime::create_rt_user_event();
          pending_instances[runtime->runtime_system_memory] = PendingInstance(
              op, op->get_unique_op_id(), mapped, eager);
          ready_event = mapped;
        }
        need_subscribe = !subscription_event.exists();
      }
      if (need_subscribe)
        subscribe();
      return ready_event;
    }

    //--------------------------------------------------------------------------
    ApEvent FutureImpl::find_application_instance_ready(Memory target,
                                                        SingleTask *task)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert((target.address_space() == runtime->address_space) ||
              runtime->separate_runtime_instances);
#endif
      // Check to see if we have it
      AutoLock f_lock(future_lock);
      // Handle the case where we have a future with no payload
      if (!empty.load() && instances.empty())
        return future_complete;
      std::map<Memory,FutureInstanceTracker>::const_iterator finder =
        instances.find(target);
      if (finder != instances.end())
        return finder->second.ready_event;
      std::map<Memory,PendingInstance>::iterator pending_finder =
        pending_instances.find(target);
#ifdef DEBUG_LEGION
      assert(pending_finder != pending_instances.end());
#endif
      if (!pending_finder->second.inst_ready.exists())
        pending_finder->second.inst_ready =
          Runtime::create_ap_user_event(NULL);
      return pending_finder->second.inst_ready;
    }

    //--------------------------------------------------------------------------
    RtEvent FutureImpl::find_runtime_instance_ready(void)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_lock);
      if (future_size_set && (future_size == 0))
        return RtEvent::NO_RT_EVENT;
      if (local_visible_memory.exists())
      {
        std::map<Memory,FutureInstanceTracker>::iterator finder =
          instances.find(local_visible_memory);
#ifdef DEBUG_LEGION
        assert(finder != instances.end());
#endif
        if (!finder->second.ready_event.exists())
          return RtEvent::NO_RT_EVENT;
        if (!finder->second.safe_ready_event.exists())
          finder->second.safe_ready_event =
            Runtime::protect_event(finder->second.ready_event);
        return finder->second.safe_ready_event;
      }
      else
      {
        for (std::map<Memory,PendingInstance>::iterator it =
              pending_instances.begin(); it != pending_instances.end(); it++)
        {
          if (!FutureInstance::check_meta_visible(it->first))
            continue;
          if (!it->second.inst_ready.exists())
            it->second.inst_ready = Runtime::create_ap_user_event(NULL);
          if (!it->second.safe_inst_ready.exists())
            it->second.safe_inst_ready = 
              Runtime::protect_event(it->second.inst_ready);
          return it->second.safe_inst_ready;
        }
      }
      // Should never get here because we should have called
      // request_runtime_instance first
      assert(false);
      return RtEvent::NO_RT_EVENT;
    }

    //--------------------------------------------------------------------------
    const void* FutureImpl::find_runtime_buffer(TaskContext *ctx, size_t &size)
    //--------------------------------------------------------------------------
    {
      RtEvent ready_event;
      FutureInstance *instance = NULL;
      {
        AutoLock f_lock(future_lock);
#ifdef DEBUG_LEGION
        assert(future_size_set);
#endif
        if (future_size == 0)
        {
          size = 0;
          return NULL;
        }
#ifdef DEBUG_LEGION
        assert(!empty.load());
#endif
        size = future_size;
        if (local_visible_memory.exists())
        {
          std::map<Memory,FutureInstanceTracker>::iterator finder =
            instances.find(local_visible_memory);
#ifdef DEBUG_LEGION
          assert(finder != instances.end());
#endif
          instance = finder->second.instance;
          if (finder->second.ready_event.exists() &&
              !finder->second.safe_ready_event.exists())
            finder->second.safe_ready_event =
              Runtime::protect_event(finder->second.ready_event);
          ready_event = finder->second.safe_ready_event;
        }
        else
        {
          for (std::map<Memory,PendingInstance>::iterator it =
                pending_instances.begin(); it != pending_instances.end(); it++)
          {
            if (it->second.instance == NULL)
              continue;
            if (!it->second.instance->is_meta_visible)
              continue;
            instance = it->second.instance;
            if (!it->second.inst_ready.exists())
              it->second.inst_ready = Runtime::create_ap_user_event(NULL);
            if (!it->second.safe_inst_ready.exists())
              it->second.safe_inst_ready =
                Runtime::protect_event(it->second.inst_ready);
            ready_event = it->second.safe_inst_ready;
            break;
          }
        }
      }
#ifdef DEBUG_LEGION
      assert(instance != NULL);
#endif
      // Make sure the instance is safe to use
      ready_event.wait();
      return instance->get_data();
    }

    //--------------------------------------------------------------------------
    ApEvent FutureImpl::copy_to(FutureInstance *target, Operation *op, 
                                ApEvent precondition)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_lock);
      Memory source = find_best_source(target->memory);
      FutureInstanceTracker &tracker = instances[source];
#ifdef DEBUG_LEGION
      assert(tracker.instance != NULL);
#endif
      if (tracker.ready_event.exists())
      {
        if (precondition.exists())
          precondition =
            Runtime::merge_events(NULL, precondition, tracker.ready_event);
        else
          precondition = tracker.ready_event;
      }
      const ApEvent ready_event =
        target->copy_from(tracker.instance, op, precondition);
      if (ready_event.exists())
        tracker.read_events.push_back(ready_event);
      return ready_event;
    }

    //--------------------------------------------------------------------------
    ApEvent FutureImpl::reduce_to(FutureInstance *target, AllReduceOp *op,
                         const ReductionOpID redop_id, const ReductionOp *redop,
                         bool exclusive, ApEvent precondition)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_lock);
      Memory source = find_best_source(target->memory);
      FutureInstanceTracker &tracker = instances[source];
#ifdef DEBUG_LEGION
      assert(tracker.instance != NULL);
#endif
      if (tracker.ready_event.exists())
      {
        if (precondition.exists())
          precondition =
            Runtime::merge_events(NULL, precondition, tracker.ready_event);
        else
          precondition = tracker.ready_event;
      }
      const ApEvent ready_event = target->reduce_from(tracker.instance, op,
          redop_id, redop, exclusive, precondition);
      if (ready_event.exists())
        tracker.read_events.push_back(ready_event);
      return ready_event;
    }

    //--------------------------------------------------------------------------
    size_t FutureImpl::get_untyped_size(void)
    //--------------------------------------------------------------------------
    {
      const RtEvent ready_event = subscribe();
      if (ready_event.exists() && !ready_event.has_triggered())
        ready_event.wait();
      return future_size;
    }

    //--------------------------------------------------------------------------
    const void* FutureImpl::get_metadata(size_t *size)
    //--------------------------------------------------------------------------
    {
      const RtEvent ready_event = subscribe();
      if (ready_event.exists() && !ready_event.has_triggered())
        ready_event.wait();
      if (size != NULL)
        *size = metasize;
      return metadata;
    }

    //--------------------------------------------------------------------------
    bool FutureImpl::is_empty(bool block, bool silence_warnings,
                              const char *warning_string, bool internal)
    //--------------------------------------------------------------------------
    {
      if (!internal)
      {
        if (runtime->runtime_warnings && !silence_warnings && 
            (producer_op != NULL))
        {
          TaskContext *context = producer_op->get_context();
          if (!context->is_leaf_context())
            REPORT_LEGION_WARNING(LEGION_WARNING_BLOCKING_EMPTY, 
                "Performing a blocking is_empty test on a "
                "in non-leaf task %s (UID %lld) is a violation of Legion's "
                "deferred execution model best practices. You may notice a "
                "severe performance degradation. Warning string: %s", 
                context->get_task_name(), 
                context->get_unique_id(),
                (warning_string == NULL) ? "" : warning_string)
        }
        if (block && (context != NULL) &&  (implicit_context == context))
          context->record_blocking_call(coordinate.context_index);
      }
      if (block)
      {
        const RtEvent ready_event = subscribe();
        mark_sampled();
        if (ready_event.exists() && !ready_event.has_triggered())
          ready_event.wait();
      }
      return empty.load();
    }

    //--------------------------------------------------------------------------
    void FutureImpl::save_metadata(const void *meta, size_t size)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(size > 0);
      assert(metadata == NULL);
#endif
      metasize = size;
      metadata = malloc(metasize);
      memcpy(metadata, meta, metasize);
    }

    //--------------------------------------------------------------------------
    void FutureImpl::set_result(ApEvent complete, FutureInstance *instance,
                                const void *meta, size_t size)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_lock);
      if (!empty.load() || (callback_functor != NULL))
        REPORT_LEGION_ERROR(ERROR_DUPLICATE_FUTURE_SET,
            "Duplicate future set! This can be either a runtime bug or a "
            "user error. If you have a must epoch launch in this program "
            "please check that all of the point tasks that it creates have "
            "unique index points. If your program has no must epoch launches "
            "then this is likely a runtime bug.")
#ifdef DEBUG_LEGION
      assert(instances.empty());
      assert(metadata == NULL);
#endif
      if (instance != NULL)
      {
        instances.emplace(std::make_pair(instance->memory,
              FutureInstanceTracker(instance, complete)));
        if (instance->is_meta_visible)
          local_visible_memory = instance->memory;
      }
      if (size > 0)
        save_metadata(meta, size);
      finish_set_future(complete);
    }

    //--------------------------------------------------------------------------
    void FutureImpl::set_results(ApEvent complete,
       const std::vector<FutureInstance*> &insts, const void *meta, size_t size)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_lock);
      if (!empty.load() || (callback_functor != NULL))
        REPORT_LEGION_ERROR(ERROR_DUPLICATE_FUTURE_SET,
            "Duplicate future set! This can be either a runtime bug or a "
            "user error. If you have a must epoch launch in this program "
            "please check that all of the point tasks that it creates have "
            "unique index points. If your program has no must epoch launches "
            "then this is likely a runtime bug.")
#ifdef DEBUG_LEGION
      assert(instances.empty());
      assert(!insts.empty());
      assert(metadata == NULL);
#endif
      for (std::vector<FutureInstance*>::const_iterator it =
            insts.begin(); it != insts.end(); it++)
      {
#ifdef DEBUG_LEGION
        assert(instances.find((*it)->memory) == instances.end());
#endif
        instances.emplace(std::make_pair((*it)->memory, 
              FutureInstanceTracker(*it, complete)));
        if (!local_visible_memory.exists() && (*it)->is_meta_visible)
          local_visible_memory = (*it)->memory;
      }
      if (size > 0)
        save_metadata(meta, size);
      finish_set_future(complete);
    }

    //--------------------------------------------------------------------------
    void FutureImpl::set_result(ApEvent complete, FutureFunctor *functor, 
                                bool own, Processor proc)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(proc.kind() != Processor::UTIL_PROC);
#endif
      AutoLock f_lock(future_lock);
      if (!empty.load() || (callback_functor != NULL))
        REPORT_LEGION_ERROR(ERROR_DUPLICATE_FUTURE_SET,
            "Duplicate future set! This can be either a runtime bug or a "
            "user error. If you have a must epoch launch in this program "
            "please check that all of the point tasks that it creates have "
            "unique index points. If your program has no must epoch launches "
            "then this is likely a runtime bug.")
      callback_functor = functor;
      own_callback_functor = own;
      callback_proc = proc;
      finish_set_future(complete);
    }

    //--------------------------------------------------------------------------
    void FutureImpl::set_result(FutureImpl *previous, Operation *op)
    //--------------------------------------------------------------------------
    {
      const RtEvent subscribed = previous->subscribe();
      if (subscribed.exists() && !subscribed.has_triggered())
        subscribed.wait();
      const size_t size = previous->get_untyped_size();
      ApEvent complete = previous->get_complete_event();
      AutoLock f_lock(future_lock);
      if (!empty.load() || (callback_functor != NULL))
        REPORT_LEGION_ERROR(ERROR_DUPLICATE_FUTURE_SET,
            "Duplicate future set! This can be either a runtime bug or a "
            "user error. If you have a must epoch launch in this program "
            "please check that all of the point tasks that it creates have "
            "unique index points. If your program has no must epoch launches "
            "then this is likely a runtime bug.")
#ifdef DEBUG_LEGION
      assert(instances.empty());
      assert(metadata == NULL);
#endif
      if (size > 0)
      {
        MemoryManager *manager = 
          runtime->find_memory_manager(runtime->runtime_system_memory); 
        FutureInstance *instance = manager->create_future_instance(op,
            op->get_unique_op_id(), size, false/*eager*/);
        ApEvent ready = previous->copy_to(instance, op, ApEvent::NO_AP_EVENT);
        instances.emplace(std::make_pair(instance->memory,
              FutureInstanceTracker(instance, ready)));
        local_visible_memory = instance->memory;
      }
      const void *meta = previous->get_metadata(&metasize);
      if (metasize > 0)
        save_metadata(meta, metasize);
      finish_set_future(complete);
    }

    //--------------------------------------------------------------------------
    void FutureImpl::set_local(const void *value, size_t size, bool own)
    //--------------------------------------------------------------------------
    {
      FutureInstance *instance = (size == 0) ? NULL :
        FutureInstance::create_local(value, size, own);
      set_result(ApEvent::NO_AP_EVENT, instance);
    }

    //--------------------------------------------------------------------------
    void FutureImpl::set_future_result_size(size_t size, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_lock);
      if (!empty.load() || future_size_set)
        return;
      upper_bound_size = size;
      future_size = size;
      future_size_set = true;
      if (!is_owner() && (source == local_space))
      {
        // Send the message back to the owner so it can broadcast it out
        // to any subscribers
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(did);
          rez.serialize(size);
        }
        pack_global_ref();
        runtime->send_future_result_size(owner_space, rez);
      }
      if (!subscribers.empty())
      {
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(did);
          rez.serialize(size);
        }
        for (std::set<AddressSpaceID>::const_iterator it =
              subscribers.begin(); it != subscribers.end(); it++)
        {
          if (((*it) == source) || ((*it) == local_space))
            continue;
          pack_global_ref();
          runtime->send_future_result_size(*it, rez);
        }
      }
      // Check to see if there are any pending instances to make now
      if (future_size > 0)
      {
        for (std::map<Memory,PendingInstance>::iterator it = 
              pending_instances.begin(); it != pending_instances.end(); it++)
        {
          if (it->second.instance == NULL)
          {
#ifdef DEBUG_LEGION
            assert(it->second.alloc_ready.exists());
#endif
            MemoryManager *manager = runtime->find_memory_manager(it->first);
            it->second.instance = manager->create_future_instance(
                it->second.op, it->second.uid, future_size, it->second.eager);
            Runtime::trigger_event(it->second.alloc_ready);
          }
#ifdef DEBUG_LEGION
          else
          {
            // This can happend when replaying a trace which already
            // knows exactly how big the future is going to be
            assert(it->second.instance->size <= future_size);
            assert(it->second.inst_ready.exists());
          }
#endif
        }
      }
      else
      {
        for (std::map<Memory,PendingInstance>::iterator it = 
              pending_instances.begin(); it != pending_instances.end(); it++)
        {
          // If we made an instance because we were replaying a trace
          // with a known upper bound then we can delete it now
          if (it->second.instance != NULL)
            delete it->second.instance;
#ifdef DEBUG_LEGION
          assert(it->second.alloc_ready.exists());
#endif
          if (it->second.inst_ready.exists())
            Runtime::trigger_event(NULL, it->second.inst_ready);
          Runtime::trigger_event(it->second.alloc_ready); 
        }
        pending_instances.clear();
      }
    }

    //--------------------------------------------------------------------------
    void FutureImpl::finish_set_future(ApEvent complete)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!future_size_set || ((instances.empty() ? 0 :
              instances.begin()->second.instance->size) <= future_size));
#endif
      // must be called while we are already holding the lock
      future_size =
        instances.empty() ? 0 : instances.begin()->second.instance->size;
      future_size_set = true;
      if (future_complete.exists())
      {
        // If there's already a complete here then we know that it is a 
        // user event that we need to trigger
        ApUserEvent to_trigger;
        to_trigger.id = future_complete.id;
        Runtime::trigger_event(NULL, to_trigger, complete);
      }
      else
        future_complete = complete;
      result_set_space = local_space;
      if (!pending_instances.empty())
        create_pending_instances();
      empty.store(false); 
      if (!is_owner())
        // The owner always needs to be told of the result
        subscribers.insert(owner_space);
      if (!subscribers.empty())
        broadcast_result();
      if (subscription_event.exists())
      {
        Runtime::trigger_event(subscription_event);
        subscription_event = RtUserEvent::NO_RT_USER_EVENT;
      }
    }

    //--------------------------------------------------------------------------
    void FutureImpl::create_pending_instances(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!pending_instances.empty());
#endif
      for (std::map<Memory,PendingInstance>::const_iterator it =
            pending_instances.begin(); it != pending_instances.end(); it++)
      {
        FutureInstance *instance = NULL;
        if (it->second.instance != NULL)
        {
#ifdef DEBUG_LEGION
          assert(!it->second.alloc_ready.exists() ||
              it->second.alloc_ready.has_triggered());
#endif
          // If we already had an allocation then we can try to use
          // it although we might already find we have an instance
          // for this future in that particular memory
          ApEvent inst_ready;
          instance = find_or_create_instance(it->first, it->second.op, 
              it->second.uid, it->second.eager, inst_ready,
              false/*need lock*/, it->second.instance);
          if (instance != it->second.instance)
            delete it->second.instance;
          if (it->second.inst_ready.exists())
            Runtime::trigger_event(NULL, it->second.inst_ready, inst_ready);
        }
        else
        {
#ifdef DEBUG_LEGION
          assert(it->second.alloc_ready.exists());
#endif
          ApEvent inst_ready;
          instance = find_or_create_instance(it->first,
                     it->second.op, it->second.uid, it->second.eager,
                     inst_ready, false/*need lock*/);
          if (instance == NULL)
          {
            std::vector<RtEvent> preconditions;
            preconditions.reserve(it->second.can_fail_remote_requests.size());
            for (std::set<AddressSpaceID>::const_iterator fit =
                  it->second.can_fail_remote_requests.begin(); fit !=
                  it->second.can_fail_remote_requests.end(); fit++)
            {
              const RtUserEvent notified = Runtime::create_rt_user_event();
              Serializer rez;
              {
                RezCheck z(rez);
                rez.serialize(did);
                rez.serialize(it->first);
                rez.serialize(notified);
              }
              runtime->send_future_create_instance_response(*fit, rez);
              preconditions.push_back(notified);
            }
            if (!preconditions.empty())
              Runtime::trigger_event(it->second.alloc_ready,
                  Runtime::merge_events(preconditions));
            else
              Runtime::trigger_event(it->second.alloc_ready);
            if (it->second.inst_ready.exists())
              Runtime::poison_event(it->second.inst_ready);
          }
          else
          {
            Runtime::trigger_event(it->second.alloc_ready);
            if (it->second.inst_ready.exists())
              Runtime::trigger_event(NULL, it->second.inst_ready, inst_ready);
          }
        }
      }
      pending_instances.clear();
    }

    //--------------------------------------------------------------------------
    FutureInstance* FutureImpl::find_or_create_instance(Memory memory,
              Operation *op, UniqueID creator_uid, bool eager,
              ApEvent &ready_event, bool need_lock, FutureInstance *existing)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      // This better be a local memory by the time that we get here
      assert(memory.address_space() == runtime->address_space);
#endif
      if (need_lock)
      {
        AutoLock f_lock(future_lock);
        return find_or_create_instance(memory, op, creator_uid, eager,
                            ready_event, false/*need lock*/, existing);
      }
#ifdef DEBUG_LEGION
      assert((future_size == 0) == instances.empty());
#endif
      // Handle the case where we don't have a payload
      if (instances.empty())
        return NULL;
      // See if we've already got one
      std::map<Memory,FutureInstanceTracker>::const_iterator finder =
        instances.find(memory);
      if (finder != instances.end())
      {
        ready_event = finder->second.ready_event;
        return finder->second.instance;
      }
      // Don't have it so we need to make it
      // Unless we have a pre-existing one
      FutureInstance *instance = existing;
      if (instance == NULL)
      {
        MemoryManager *manager = runtime->find_memory_manager(memory); 
        instance = manager->create_future_instance(op, creator_uid,
                                                  future_size, eager);
      }
      // Can happen if we fail to allocation and op is NULL
      if (instance == NULL)
      {
#ifdef DEBUG_LEGION
        assert(op == NULL);
#endif
        return instance;
      }
      // Initialize the instance from one of the existing instances
      Memory source = find_best_source(memory);
      FutureInstanceTracker &tracker = instances[source];
#ifdef DEBUG_LEGION
      assert(tracker.instance != NULL);
#endif
      ready_event =
        instance->copy_from(tracker.instance, op, tracker.ready_event); 
      if (tracker.remote_postcondition.exists())
      {
        // This is a remote instance that we don't own so once we're
        // done with the copy we can clean it up
        Runtime::trigger_event(NULL, tracker.remote_postcondition, ready_event);
        delete tracker.instance;
        instances.erase(source);
      }
      else if (ready_event.exists())
        tracker.read_events.push_back(ready_event);
      instances.emplace(std::make_pair(memory, 
            FutureInstanceTracker(instance, ready_event)));
      if (!local_visible_memory.exists() && instance->is_meta_visible)
        local_visible_memory = memory;
      return instance;
    }

    //--------------------------------------------------------------------------
    Memory FutureImpl::find_best_source(Memory target) const
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!instances.empty());
#endif
      // Check check to see if there is already an instance in the memory
      // since that will always be fastest if it is already there
      if (instances.find(target) != instances.end())
        return target;
      if (LEGION_MAX_RETURN_SIZE < future_size)
      {
        // Big future so search through to find source with the best affinity
        size_t best_bandwidth = 0;
        Memory best = Memory::NO_MEMORY;
        std::vector<Machine::MemoryMemoryAffinity> affinity;
        for (std::map<Memory,FutureInstanceTracker>::const_iterator it =
              instances.begin(); it != instances.end(); it++)
        {
          affinity.clear();
          runtime->machine.get_mem_mem_affinity(affinity, target, it->first);
          if (affinity.empty())
            continue;
          if (!best.exists() || (best_bandwidth < affinity.front().bandwidth))
          {
            best = it->first;
            best_bandwidth = affinity.front().bandwidth;
          }
        }
        if (best.exists())
          return best;
      }
      // Nothing left to do here other than to potentially pick the local
      // visible memory since we know it is ready to go, otherwise we
      // just randomly pick the first instance in the set
      if (local_visible_memory.exists())
        return local_visible_memory;
      return instances.begin()->first;
    }

    //--------------------------------------------------------------------------
    void FutureImpl::notify_allocation_failure(Memory target)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_lock);
      std::map<Memory,RtUserEvent>::iterator finder =
        remote_instance_allocations.find(target);
#ifdef DEBUG_LEGION
      assert(finder != remote_instance_allocations.end());
#endif
      remote_instance_allocations.erase(finder);
    }

    //--------------------------------------------------------------------------
    RtEvent FutureImpl::invoke_callback(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(callback_functor != NULL);
#endif
      if (!subscription_event.exists())
      {
        subscription_event = Runtime::create_rt_user_event();
        FutureCallbackArgs args(this);    
        runtime->issue_application_processor_task(args, 
            LG_LATENCY_WORK_PRIORITY, callback_proc);
      }
      return subscription_event;
    }

    //--------------------------------------------------------------------------
    void FutureImpl::perform_callback(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(callback_functor != NULL);
      assert(subscription_event.exists());
#endif
      size_t result_size = 0;
      bool owned = false;
      const Realm::ExternalInstanceResource *resource = NULL;
      void (*freefunc)(const Realm::ExternalInstanceResource&) = NULL;
      const void *metaptr = NULL;
      const void *result = callback_functor->callback_get_future(
                    result_size, owned, resource, freefunc, metaptr, metasize);
      FutureInstance *instance;
      if (resource == NULL)
      {
        const Realm::ExternalMemoryResource local(
           reinterpret_cast<uintptr_t>(result), result_size, true/*read only*/);
        instance = new FutureInstance(result, result_size, owned, local.clone(),
            FutureInstance::free_host_memory, callback_proc);
      }
      else
        instance = new FutureInstance(result, result_size, owned,
            resource->clone(), freefunc, callback_proc);
      // If we have any metadata, copy that now
      if (metasize > 0)
      {
#ifdef DEBUG_LEGION
        assert(metadata == NULL);
#endif
        metadata = malloc(metasize);
        memcpy(metadata, metaptr, metasize);
      }
      if (owned)
      {
        // if we took ownership, we can release the functor now
        callback_functor->callback_release_future();
        if (own_callback_functor)
          delete callback_functor;
        callback_functor = NULL;
      }
      // Retake the lock and remove the guards
      AutoLock f_lock(future_lock);
      instances.emplace(std::make_pair(instance->memory,
            FutureInstanceTracker(instance, ApEvent::NO_AP_EVENT)));
      if (!local_visible_memory.exists() && instance->is_meta_visible)
        local_visible_memory = instance->memory;
      if (!pending_instances.empty())
        create_pending_instances();
      Runtime::trigger_event(subscription_event);
      subscription_event = RtUserEvent::NO_RT_USER_EVENT;
      // Check for any subscribers that we need to tell about the result
      if (!subscribers.empty())
        broadcast_result();
    }

    //--------------------------------------------------------------------------
    void FutureImpl::perform_broadcast(void)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_lock);
      broadcast_result();
    }

    //--------------------------------------------------------------------------
    FutureImpl::FutureCallbackArgs::FutureCallbackArgs(FutureImpl *i)
      : LgTaskArgs<FutureCallbackArgs>(implicit_provenance), impl(i)
    //--------------------------------------------------------------------------
    {
      impl->add_base_gc_ref(DEFERRED_TASK_REF);
    }

    //--------------------------------------------------------------------------
    FutureImpl::CallbackReleaseArgs::CallbackReleaseArgs(FutureFunctor *f,
                                                         bool own)
      : LgTaskArgs<CallbackReleaseArgs>(implicit_provenance),
        functor(f), own_functor(own)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    FutureImpl::FutureBroadcastArgs::FutureBroadcastArgs(FutureImpl *i)
      : LgTaskArgs<FutureBroadcastArgs>(implicit_provenance), impl(i)
    //--------------------------------------------------------------------------
    {
      impl->add_base_gc_ref(DEFERRED_TASK_REF);
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureImpl::handle_callback(const void *args)
    //--------------------------------------------------------------------------
    {
      const FutureCallbackArgs *fargs = (const FutureCallbackArgs*)args;
      fargs->impl->perform_callback();
      if (fargs->impl->remove_base_gc_ref(DEFERRED_TASK_REF))
        delete fargs->impl;
    } 

    //--------------------------------------------------------------------------
    /*static*/ void FutureImpl::handle_release(const void *args)
    //--------------------------------------------------------------------------
    {
      const CallbackReleaseArgs *cargs = (const CallbackReleaseArgs*)args;
      cargs->functor->callback_release_future();
      if (cargs->own_functor)
        delete cargs->functor;
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureImpl::handle_broadcast(const void *args)
    //--------------------------------------------------------------------------
    {
      const FutureBroadcastArgs *fargs = (const FutureBroadcastArgs*)args;
      fargs->impl->perform_broadcast();
      if (fargs->impl->remove_base_gc_ref(DEFERRED_TASK_REF))
        delete fargs->impl;
    }

    //--------------------------------------------------------------------------
    void FutureImpl::unpack_future_result(Deserializer &derez)
    //-------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      AutoLock f_lock(future_lock);
#ifdef DEBUG_LEGION
      assert(empty.load());
      assert(subscription_event.exists() || is_owner());
      assert(metadata == NULL);
#endif
      derez.deserialize(future_size);
      future_size_set = true;
      derez.deserialize(result_set_space);
      if (future_size > 0)
      {
        bool has_local = false;
        size_t num_instances;
        derez.deserialize(num_instances);
        for (unsigned idx1 = 0; idx1 < num_instances; idx1++)
        {
          FutureInstance *instance = FutureInstance::unpack_instance(derez);
          if (instance->memory.address_space() == runtime->address_space)
          {
            has_local = true;
            if (!local_visible_memory.exists() && instance->is_meta_visible)
              local_visible_memory = instance->memory;
          }
#ifdef DEBUG_LEGION
          assert(instances.find(instance->memory) == instances.end());
#endif
          ApEvent ready_event;
          derez.deserialize(ready_event);
          FutureInstanceTracker &tracker = 
            instances.emplace(std::make_pair(instance->memory,
                FutureInstanceTracker(instance, ready_event))).first->second;
          size_t num_read_events;
          derez.deserialize(num_read_events);
          tracker.read_events.resize(num_read_events);
          for (unsigned idx2 = 0; idx2 < num_read_events; idx2++)
            derez.deserialize(tracker.read_events[idx2]);
        }
        if (!has_local)
        {
          // If we didn't get a local instance then we'll also get a copy
          // of the future instance from the source
          FutureInstance *instance = FutureInstance::unpack_instance(derez);
          if (instance->is_meta_visible)
          {
            // We unpacked by value if it is meta-visible here
#ifdef DEBUG_LEGION
            assert(!local_visible_memory.exists());
            assert(instances.find(instance->memory) == instances.end());
#endif
            instances.emplace(std::make_pair(instance->memory,
                  FutureInstanceTracker(instance, ApEvent::NO_AP_EVENT)));
            local_visible_memory = instance->memory;
          }
          else
          {
            // The instance is remote from us, we need to copy to one of the
            // pending instances so we can fill in the rest of the results
            ApEvent precondition;
            derez.deserialize(precondition);
            ApUserEvent postcondition;
            derez.deserialize(postcondition);
            if (pending_instances.empty())
            {
              // Save this in the list of instances to consume once 
              // someone tries to read from it
              instances.emplace(std::make_pair(instance->memory,
                FutureInstanceTracker(instance, precondition, postcondition)));
            }
            else
            {
              std::map<Memory,PendingInstance>::iterator pending =
                pending_instances.begin();
              // If we haven't allocated the instance yet then we can do that
              // now because we know the size of the future result
              if (pending->second.instance == NULL)
              {
#ifdef DEBUG_LEGION
                assert(pending->second.alloc_ready.exists());
#endif
                MemoryManager *manager =
                  runtime->find_memory_manager(pending->first);
                pending->second.instance = manager->create_future_instance(
                    pending->second.op, pending->second.uid, future_size,
                    pending->second.eager);
                Runtime::trigger_event(pending->second.alloc_ready);
              }
              // Issue the copy to the pending instance
              ApEvent ready = pending->second.instance->copy_from(instance,
                    pending->second.op, precondition);
              Runtime::trigger_event(NULL, postcondition, ready);
              if (pending->second.inst_ready.exists())
                Runtime::trigger_event(NULL, pending->second.inst_ready, ready);
              instances.emplace(std::make_pair(pending->second.instance->memory,
                    FutureInstanceTracker(pending->second.instance, ready)));
#ifdef DEBUG_LEGION
              assert(!local_visible_memory.exists());
#endif
              if (pending->second.instance->is_meta_visible)
                local_visible_memory = pending->second.instance->memory;
              pending_instances.erase(pending);
              delete instance;
            }
          }
        }
      }
      if (future_complete.exists())
      {
        ApUserEvent to_trigger;
        to_trigger.id = future_complete.id;
        ApEvent precondition;
        derez.deserialize(precondition);
        Runtime::trigger_event(NULL, to_trigger, precondition);
      }
      else
        derez.deserialize(future_complete);
      derez.deserialize(metasize);
      if (metasize > 0)
      {
        save_metadata(derez.get_current_pointer(), metasize);
        derez.advance_pointer(metasize);
      }
      if (!pending_instances.empty())
        create_pending_instances();
      empty.store(false);
      if (subscription_event.exists())
      {
        Runtime::trigger_event(subscription_event);
        subscription_event = RtUserEvent::NO_RT_USER_EVENT;
      }
      if (!subscribers.empty())
        broadcast_result();
    }

    //--------------------------------------------------------------------------
    bool FutureImpl::reset_future(void)
    //--------------------------------------------------------------------------
    {
      // TODO: update this for resilience
      assert(false);
      bool was_sampled = sampled.load();
      sampled.store(false);
      return was_sampled;
    }

    //--------------------------------------------------------------------------
    ApEvent FutureImpl::get_complete_event(void)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_lock);
      if (empty.load())
      {
        if (!future_complete.exists())
          future_complete = Runtime::create_ap_user_event(NULL);
        if (!subscription_event.exists())
          subscribe(false/*need lock*/);
      }
      return future_complete;
    }

    //--------------------------------------------------------------------------
    bool FutureImpl::get_boolean_value(TaskContext *ctx)
    //--------------------------------------------------------------------------
    {
      size_t size = 0;
      const void *result = find_runtime_buffer(ctx, size);
#ifdef DEBUG_LEGION
      assert(sizeof(bool) == size);
#endif
      return *((const bool*)result); 
    }

    //--------------------------------------------------------------------------
    RtEvent FutureImpl::subscribe(bool need_lock)
    //--------------------------------------------------------------------------
    {
      if (!empty.load() && (callback_functor == NULL))
        return RtEvent::NO_RT_EVENT;
      if (need_lock)
      {
        AutoLock f_lock(future_lock);
        return subscribe(false/*need lock*/);
      }
      // See if we lost the race
      if (empty.load())
      {
        if (!subscription_event.exists())
        {
          subscription_event = Runtime::create_rt_user_event();
          if (!is_owner())
          {
            // Send a request to the owner node to subscribe
            Serializer rez;
            rez.serialize(did);
            pack_global_ref();
            if ((collective_mapping != NULL) && 
                collective_mapping->contains(local_space))
              runtime->send_future_subscription(
                 collective_mapping->get_parent(owner_space, local_space), rez);
            else
              runtime->send_future_subscription(owner_space, rez);
          }
          else
            record_subscription(local_space, false/*need lock*/);
        }
        return subscription_event;
      }
      else
      {
        if (callback_functor != NULL)
          return invoke_callback();
        return RtEvent::NO_RT_EVENT;
      }
    }

    //--------------------------------------------------------------------------
    size_t FutureImpl::get_upper_bound_size(void)
    //--------------------------------------------------------------------------
    {
      {
        AutoLock f_lock(future_lock,1,false/*exclusive*/);
        if (!empty.load() || future_size_set)
          return upper_bound_size;
      }
      const RtEvent subscribed = subscribe();
      if (subscribed.exists() && !subscribed.has_triggered())
        subscribed.wait();
      AutoLock f_lock(future_lock,1,false/*exclusive*/);
#ifdef DEBUG_LEGION
      assert(!empty.load() || future_size_set);
#endif
      return upper_bound_size;
    }

    //--------------------------------------------------------------------------
    bool FutureImpl::get_context_coordinate(const TaskContext *ctx,
                                            ContextCoordinate &coord) const
    //--------------------------------------------------------------------------
    {
      // If contexts don't match then we don't return the coordinate
      if (ctx != context)
        return false;
      // No coordinates if we are an application-generated future
      if (coordinate.context_index == InnerContext::NO_BLOCKING_INDEX)
        return false;
      coord = coordinate;
      return true;
    }

    //--------------------------------------------------------------------------
    void FutureImpl::pack_future(Serializer &rez, AddressSpaceID target)
    //--------------------------------------------------------------------------
    {
      pack_global_ref();
      rez.serialize<DistributedID>(did);
      if ((collective_mapping != NULL) && collective_mapping->contains(target))
      {
        rez.serialize<bool>(true); // collective
        return;
      }
      else
        rez.serialize<bool>(false); // collective
      rez.serialize(context->did);
      coordinate.serialize(rez);
      if (collective_mapping != NULL)
        collective_mapping->pack(rez);
      else
        rez.serialize<size_t>(0); // no collective mapping
      if (provenance != NULL)
        provenance->serialize(rez);
      else
        Provenance::serialize_null(rez);
    }

    //--------------------------------------------------------------------------
    /*static*/ Future FutureImpl::unpack_future(Runtime *runtime, 
                                Deserializer &derez,
                                Operation *op, GenerationID op_gen,
                                UniqueID op_uid, int op_depth)
    //--------------------------------------------------------------------------
    {
      DistributedID future_did, ctx_did;
      derez.deserialize(future_did);
      if (future_did == 0)
        return Future();
      bool collective;
      derez.deserialize(collective);
      if (collective)
      {
        // Wait until we find it here
        Future result(static_cast<FutureImpl*>(
              runtime->find_distributed_collectable(future_did)));
        result.impl->unpack_global_ref();
        return result;
      }
      derez.deserialize(ctx_did);
      ContextCoordinate coordinate;
      coordinate.deserialize(derez);
      size_t collective_spaces;
      derez.deserialize(collective_spaces);
      CollectiveMapping *collective_mapping = (collective_spaces == 0) ? NULL :
        new CollectiveMapping(derez, collective_spaces);
      if (collective_mapping != NULL)
        collective_mapping->add_reference();
      AutoProvenance provenance(Provenance::deserialize(derez));
      Future result(runtime->find_or_create_future(future_did, ctx_did,
                                            coordinate, provenance,
                                            op, op_gen, op_uid, op_depth,
                                            collective_mapping));
      result.impl->unpack_global_ref();
      if ((collective_mapping != NULL) && 
          collective_mapping->remove_reference())
        delete collective_mapping;
      return result;
    }

    //--------------------------------------------------------------------------
    void FutureImpl::notify_local(void)
    //--------------------------------------------------------------------------
    {
      // Nothing to do
    }

    //--------------------------------------------------------------------------
    void FutureImpl::register_dependence(Operation *consumer_op)
    //--------------------------------------------------------------------------
    {
      if (producer_op != NULL)
      {
        // Only record dependences on things from the same context
        // We know futures can never flow up the task tree so the
        // only way they have the same depth is if they are from 
        // the same parent context
        TaskContext *consumer_context = consumer_op->get_context();
        if (consumer_context == context)
        {
          consumer_op->register_dependence(producer_op, op_gen);
#ifdef LEGION_SPY
          LegionSpy::log_mapping_dependence(
              context->get_unique_id(), producer_uid, 0,
              consumer_op->get_unique_op_id(), 0, TRUE_DEPENDENCE);
#endif
        }
        else
        {
          // Check that the consumer is contained within the task
          // sub-tree of the producer task
          TaskTreeCoordinates prod_coords, con_coords;
          context->compute_task_tree_coordinates(prod_coords);
          consumer_context->compute_task_tree_coordinates(con_coords);
          bool contained = (prod_coords.size() <= con_coords.size());
          if (contained)
          {
            for (unsigned idx = 0; idx < prod_coords.size(); idx++)
            {
              if (prod_coords[idx] == con_coords[idx])
                continue;
              contained = false;
              break;
            }
          }
          if (!contained)
          {
            Provenance *provenance = consumer_op->get_provenance();
            REPORT_LEGION_ERROR(ERROR_ILLEGAL_FUTURE_USE,
                "Illegal use of future produced in context %s (UID %lld) "
                "but consumed in context %s (UID %lld) by operation %s "
                "(UID %lld) launched from %s. Futures are only permitted "
                "to be used in the task sub-tree rooted by the context "
                "that produced the future.", context->get_task_name(),
                context->get_unique_id(), consumer_context->get_task_name(), 
                consumer_context->get_unique_id(),
                consumer_op->get_logging_name(),
                consumer_op->get_unique_op_id(), provenance->human_str())
          }
        }
      }
#ifdef DEBUG_LEGION
      else
        assert(!empty.load()); // better not be empty if it doesn't have an op
#endif
    }

    //--------------------------------------------------------------------------
    void FutureImpl::mark_sampled(void)
    //--------------------------------------------------------------------------
    {
      sampled.store(true);
    }

    //--------------------------------------------------------------------------
    void FutureImpl::broadcast_result(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!empty.load());
#endif
      if (callback_functor != NULL)
      {
        // Handle the special case where the only subscriber is the local
        // node so we can lazily defer this until later and the user
        // actually asks us for the result
        if (!subscribers.empty() && ((subscribers.size() > 1) ||
              (subscribers.find(local_space) == subscribers.end())))
        {
          // If we still have a callback to perform do
          // that now to get it in flight, it will send
          // out any updates to subscribers
          invoke_callback();
        }
        return;
      }
      // If this is a small future, we need to have a local visible
      // instance that we can use for packing this by value
      if ((0 < future_size) && (future_size <= LEGION_MAX_RETURN_SIZE))
      {
        ApEvent inst_ready;
        if (!local_visible_memory.exists())
        {
          // Check to see if we have targets for all the subscribers
          // if so then we don't need to make a local copy
          std::set<AddressSpaceID> subscribers_without_instances = subscribers;
          for (std::map<Memory,FutureInstanceTracker>::const_iterator it =
                instances.begin(); it != instances.end(); it++)
          {
            subscribers_without_instances.erase(it->first.address_space());
            if (subscribers_without_instances.empty())
              break;
          }
          if (!subscribers_without_instances.empty())
          {
            find_or_create_instance(runtime->runtime_system_memory, NULL/*op*/,
                producer_uid, true/*eager*/, inst_ready, false/*need lock*/);
#ifdef DEBUG_LEGION
            assert(local_visible_memory.exists());
#endif
          }
        }
        else
          inst_ready = instances[local_visible_memory].ready_event;
        if (inst_ready.exists() && !inst_ready.has_triggered_faultignorant())
        {
          // Defer until the instance can be packed by value
          const RtEvent precondition = Runtime::protect_event(inst_ready);
          FutureBroadcastArgs args(this);
          runtime->issue_runtime_meta_task(args, 
              LG_LATENCY_WORK_PRIORITY, precondition);
          return;
        }
      }
      for (std::set<AddressSpaceID>::const_iterator it = 
            subscribers.begin(); it != subscribers.end(); it++)
      {
        if (((*it) == local_space) || ((*it) == result_set_space))
          continue;
        // Need to pack each of these separately in case we need to make
        // events for each future instance being packed
        Serializer rez;
        pack_future_result(rez, *it);
        pack_global_ref();
        runtime->send_future_result(*it, rez);
      }
      subscribers.clear();
    }

    //--------------------------------------------------------------------------
    void FutureImpl::record_subscription(AddressSpaceID subscriber, 
                                         bool need_lock)
    //--------------------------------------------------------------------------
    {
      if (need_lock)
      {
        AutoLock f_lock(future_lock);
        record_subscription(subscriber, false/*need lock*/);
        return;
      }
      if (empty.load())
      {
        // Send the future size back to the subscriber so they
        // can have it to be able to create instances
        if (future_size_set && (subscriber != local_space))
        {
          Serializer rez;
          {
            RezCheck z(rez);
            rez.serialize(did);
            rez.serialize(future_size);
          }
          pack_global_ref();
          runtime->send_future_result_size(subscriber, rez);
        }
#ifdef DEBUG_LEGION
        assert(subscribers.find(subscriber) == subscribers.end());
#endif
        subscribers.insert(subscriber);
        if (!is_owner())
        {
          // Not the owner, we should be in a collective future
#ifdef DEBUG_LEGION
          assert(collective_mapping != NULL);
          assert(collective_mapping->contains(local_space));
#endif
          subscribe(false/*needs lock*/);
        }
      }
      else
      {
        // Handle the race where the subscription from the node that
        // ultimately set the future result arrives after the future
        // result makes it here
        if ((subscriber == result_set_space) && (subscriber != local_space))
          return;
        if (callback_functor != NULL)
        {
          invoke_callback();
          // If we still have a callback to be done, make sure
          // it is in flight and that the subscriber is there
          // for it to be messaged when the callback is done
          subscribers.insert(subscriber);
        }
        else if (!instances.empty() && (future_size <= LEGION_MAX_RETURN_SIZE))
        {
          // Check to see if we have any instances to send directly
          bool has_local_target = false;
          for (std::map<Memory,FutureInstanceTracker>::const_iterator it =
                instances.begin(); it != instances.end(); it++)
          {
            if (it->first.address_space() != subscriber)
              continue;
            has_local_target = true;
            break;
          }
          ApEvent local_visible_ready;
          if (!has_local_target)
          {
            // If we don't see if we need to make a local visible
            if (!local_visible_memory.exists())
            {
              find_or_create_instance(runtime->runtime_system_memory,
                  NULL/*op*/, producer_uid, true/*eager*/, 
                  local_visible_ready, false/*need lock*/);
#ifdef DEBUG_LEGION
              assert(local_visible_memory.exists());
#endif
            }
            else
              local_visible_ready = instances[local_visible_memory].ready_event;
          }
          if (local_visible_ready.exists() && 
              !local_visible_ready.has_triggered_faultignorant())
          {
            // Save the subscriber and launch a broadcast task
            // if one is not already in flight to broadcast the
            // result to the subscriptions once it is ready
            if (subscribers.empty())
            {
              // First one so launch the broadcast task
              FutureBroadcastArgs args(this);
              runtime->issue_runtime_meta_task(args, 
                  LG_LATENCY_WORK_PRIORITY, 
                  Runtime::protect_event(local_visible_ready));
            }
            subscribers.insert(subscriber);
          }
          else
          {
            // We can send the result right now
            Serializer rez;
            pack_future_result(rez, subscriber);
            pack_global_ref();
            runtime->send_future_result(subscriber, rez);
          }
        }
        else
        {
          // Send the result back to the subscriber since right away
          Serializer rez;
          pack_future_result(rez, subscriber);
          pack_global_ref();
          runtime->send_future_result(subscriber, rez);
        }
      }
    }

    //--------------------------------------------------------------------------
    void FutureImpl::pack_future_result(Serializer &rez, AddressSpaceID target)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert((future_size == 0) == instances.empty());
#endif
      rez.serialize(did);
      RezCheck z(rez);
      rez.serialize(future_size);
      rez.serialize(result_set_space);
      if (!instances.empty())
      {
        // Find any target instances to pack up to send to the subscriber
        bool has_exact_target = false;
        std::vector<Memory> target_memories;
        for (std::map<Memory,FutureInstanceTracker>::const_iterator it =
              instances.begin(); it != instances.end(); it++)
        {
          AddressSpaceID inst_space = it->first.address_space();
          if (inst_space == target)
          {
            has_exact_target = true;
            target_memories.push_back(it->first);
          }
          else if ((collective_mapping != NULL) &&
              collective_mapping->contains(inst_space) && 
              (subscribers.find(inst_space) == subscribers.end()))
          {
            // If there is a collective mapping we need to check whether
            // we should send the instance to the target because the 
            // actual subscriber will come through the collective mapping
            // subscriber tree to the target.
            while ((inst_space != owner_space) && (inst_space != target) &&
                    (inst_space != local_space) &&
                    (subscribers.find(inst_space) == subscribers.end()))
              inst_space =
                collective_mapping->get_parent(owner_space, inst_space);
            if (inst_space == target)
              target_memories.push_back(it->first);
            else if ((inst_space == owner_space) && (target == owner_space))
              target_memories.push_back(it->first);
          }
        }
        if (!target_memories.empty())
        {
          // Check to see if we're packing all our instances to send away.
          // If we are we still need to keep one of them around to be able
          // to copy from it if we need to
          const Memory keep = (target_memories.size() < instances.size()) ?
           Memory::NO_MEMORY : find_best_source(runtime->runtime_system_memory);
          // Send the instances to the future impl that should own them
          rez.serialize<size_t>(target_memories.size());
          for (std::vector<Memory>::const_iterator mit =
                target_memories.begin(); mit != target_memories.end(); mit++)
          {
            std::map<Memory,FutureInstanceTracker>::iterator finder =
              instances.find(*mit);
#ifdef DEBUG_LEGION
            assert(finder != instances.end());
#endif
            // Don't allow this to be packed by value
            finder->second.instance->pack_instance(rez, ApEvent::NO_AP_EVENT,
                true/*move ownership*/, false/*allow by value*/);
            rez.serialize(finder->second.ready_event);
            if ((*mit) == keep)
            {
              finder->second.remote_postcondition = 
                Runtime::create_ap_user_event(NULL);
              finder->second.read_events.push_back(
                  finder->second.remote_postcondition);
            }
            rez.serialize<size_t>(finder->second.read_events.size());
            for (std::vector<ApEvent>::const_iterator it =
                  finder->second.read_events.begin(); it !=
                  finder->second.read_events.end(); it++)
              rez.serialize(*it);
            if ((*mit) != keep)
            {
              // Now we can delete the instance remove it from the entry
              delete finder->second.instance;
              instances.erase(finder);
            }
            else
              finder->second.read_events.clear();
          }
        }
        else
          rez.serialize<size_t>(0);
        if (!has_exact_target)
        {
          // Pack our local visible copy by value so that the subscriber
          // will have it's own local copy of the data
          std::map<Memory,FutureInstanceTracker>::iterator finder =
            local_visible_memory.exists() ?
              instances.find(local_visible_memory) : instances.begin();
#ifdef DEBUG_LEGION
          assert(finder != instances.end());
#endif
          if (!finder->second.instance->pack_instance(rez,
                finder->second.ready_event, false/*move ownership*/))
          {
            // Couldn't pack this by value so we need to pack up events
            rez.serialize(finder->second.ready_event);
            const ApUserEvent read_done = Runtime::create_ap_user_event(NULL);
            rez.serialize(read_done);
            finder->second.read_events.push_back(read_done);
          }
        }
      }
      rez.serialize(future_complete);
      rez.serialize(metasize);
      if (metasize > 0)
        rez.serialize(metadata, metasize); 
    }

    //--------------------------------------------------------------------------
    RtEvent FutureImpl::record_future_registered(void)
    //--------------------------------------------------------------------------
    {
      // Similar to DistributedCollectable::register_with_runtime but
      // we don't actually need to do the registration since we know
      // it has already been done
#ifdef DEBUG_LEGION
      assert(!registered_with_runtime);
#endif
      registered_with_runtime = true;
      RtEvent result;
      if (!is_owner())
        result = send_remote_registration();
      return result;
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureImpl::handle_future_result(Deserializer &derez,
                                                 Runtime *runtime)
    //--------------------------------------------------------------------------
    {
      DistributedID did;
      derez.deserialize(did);
      DistributedCollectable *dc = runtime->find_distributed_collectable(did);
#ifdef DEBUG_LEGION
      FutureImpl *future = dynamic_cast<FutureImpl*>(dc);
      assert(future != NULL);
#else
      FutureImpl *future = static_cast<FutureImpl*>(dc);
#endif
      future->unpack_future_result(derez);
      future->unpack_global_ref();
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureImpl::handle_future_result_size(Deserializer &derez,
                                        Runtime *runtime, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      DistributedID did;
      derez.deserialize(did);
      // The future might be a collective future so wait for it if 
      // it hasn't been registered yet
      DistributedCollectable *dc = runtime->find_distributed_collectable(did);
#ifdef DEBUG_LEGION
      FutureImpl *future = dynamic_cast<FutureImpl*>(dc);
      assert(future != NULL);
#else
      FutureImpl *future = static_cast<FutureImpl*>(dc);
#endif
      size_t future_size;
      derez.deserialize(future_size);
      future->set_future_result_size(future_size, source);
      future->unpack_global_ref();
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureImpl::handle_future_subscription(
                   Deserializer &derez, Runtime *runtime, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DistributedID did;
      derez.deserialize(did);
      DistributedCollectable *dc = runtime->find_distributed_collectable(did);
#ifdef DEBUG_LEGION
      FutureImpl *future = dynamic_cast<FutureImpl*>(dc);
      assert(future != NULL);
#else
      FutureImpl *future = static_cast<FutureImpl*>(dc);
#endif
      future->record_subscription(source, true/*need lock*/);
      future->unpack_global_ref();
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureImpl::handle_future_create_instance_request(
                                          Deserializer &derez, Runtime *runtime)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Future f = FutureImpl::unpack_future(runtime, derez);
      Memory target;
      derez.deserialize(target);
      UniqueID creator_uid;
      derez.deserialize(creator_uid);
      RtUserEvent mapped_event;
      derez.deserialize(mapped_event);
      AddressSpaceID source;
      derez.deserialize(source);
      bool can_fail;
      derez.deserialize<bool>(can_fail);
      const RtEvent mapped = f.impl->request_application_instance(target, 
          NULL/*task*/, creator_uid, source, can_fail);
      Runtime::trigger_event(mapped_event, mapped);
    }

    //--------------------------------------------------------------------------
    void FutureImpl::handle_future_create_instance_response(
                                          Deserializer &derez, Runtime *runtime)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      DistributedID did;
      derez.deserialize(did);
      DistributedCollectable *dc = runtime->find_distributed_collectable(did);
#ifdef DEBUG_LEGION
      FutureImpl *future = dynamic_cast<FutureImpl*>(dc);
      assert(future != NULL);
#else
      FutureImpl *future = static_cast<FutureImpl*>(dc);
#endif
      Memory target;
      derez.deserialize(target);
      future->notify_allocation_failure(target); 
      RtUserEvent notified;
      derez.deserialize(notified);
      Runtime::trigger_event(notified);
    } 

    //--------------------------------------------------------------------------
    void FutureImpl::contribute_to_collective(const DynamicCollective &dc, 
                                              unsigned count)
    //--------------------------------------------------------------------------
    {
      const RtEvent ready = subscribe();
      if (ready.exists() && !ready.has_triggered())
      {
        // If we're not done then defer the operation until we are triggerd
        // First add a garbage collection reference so we don't get
        // collected while we are waiting for the contribution task to run
        add_base_gc_ref(PENDING_COLLECTIVE_REF);
        ContributeCollectiveArgs args(this, dc, count);
        // Spawn the task dependent on the future being ready
        runtime->issue_runtime_meta_task(args, LG_LATENCY_WORK_PRIORITY, ready);
      }
      else // If we've already triggered, then we can do the arrival now
      {
        size_t result_size = 0;
        const void *result = get_buffer(runtime->runtime_system_memory,
            &result_size, false/*check size*/, true/*silence warnings*/);
        runtime->phase_barrier_arrive(dc, count, ApEvent::NO_AP_EVENT,
                                      result, result_size);
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureImpl::handle_contribute_to_collective(
                                                               const void *args)
    //--------------------------------------------------------------------------
    {
      const ContributeCollectiveArgs *cargs = (ContributeCollectiveArgs*)args;
      cargs->impl->contribute_to_collective(cargs->dc, cargs->count);
      // Now remote the garbage collection reference and see if we can 
      // reclaim the future
      if (cargs->impl->remove_base_gc_ref(PENDING_COLLECTIVE_REF))
        delete cargs->impl;
    }

    /////////////////////////////////////////////////////////////
    // Future Instance
    /////////////////////////////////////////////////////////////
      
    //--------------------------------------------------------------------------
    FutureInstance::FutureInstance(const void *d, size_t s,
                              bool eager, bool external, bool own,
                              LgEvent unique, PhysicalInstance inst,
                              Processor p, RtEvent use)
      : size(s), memory(inst.exists() ? inst.get_location() : 
          implicit_runtime->runtime_system_memory),
        resource(inst.exists() ? NULL : 
            new Realm::ExternalMemoryResource(reinterpret_cast<uintptr_t>(d),
              s, false/*read only*/)), freefunc(inst.exists() || !p.exists() ? 
              NULL : free_host_memory), freeproc(p),
        eager_allocation(eager), external_allocation(external),
        is_meta_visible(check_meta_visible(memory)),
        own_allocation(own), data(d), instance(inst), use_event(use),
        unique_event(unique), own_instance(own && inst.exists())
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(size > 0);
      assert(memory.exists());
      assert((freefunc == NULL) || freeproc.exists());
      assert((freefunc == NULL) || external_allocation);
      assert(!freeproc.exists() || (freeproc.kind() != Processor::UTIL_PROC));
      assert(instance.exists() || external_allocation);
      assert((data != NULL) || instance.exists());
      assert(unique_event.exists() || !instance.exists() || 
          (implicit_runtime->profiler == NULL));
#endif
    }

    //--------------------------------------------------------------------------
    FutureInstance::FutureInstance(const void *d, size_t s, bool own,
                          const Realm::ExternalInstanceResource *allocation,
                          void (*func)(const Realm::ExternalInstanceResource&),
                          Processor proc, LgEvent unique, PhysicalInstance inst,
                          RtEvent use)
      : size(s), memory(inst.exists() ?
          inst.get_location() : allocation->suggested_memory()),
        resource(allocation), freefunc(func), freeproc(proc),
        eager_allocation(false), external_allocation(true),
        is_meta_visible(check_meta_visible(memory)), 
        own_allocation(own), data(d), instance(inst), use_event(use),
        unique_event(unique), own_instance(own && inst.exists())
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(size > 0);
      assert(memory.exists());
      assert((freefunc == NULL) || freeproc.exists());
      assert((freefunc == NULL) || external_allocation);
      assert(!freeproc.exists() || (freeproc.kind() != Processor::UTIL_PROC));
      assert(instance.exists() || external_allocation);
      assert((data != NULL) || instance.exists());
      assert((resource != NULL) || inst.exists());
      assert(unique_event.exists() || !instance.exists() || 
          (implicit_runtime->profiler == NULL));
#endif
    }

    //--------------------------------------------------------------------------
    FutureInstance::~FutureInstance(void)
    //--------------------------------------------------------------------------
    {
      // Make sure our instance is valid before we try to delete it
      if (instance.exists() && use_event.exists() && !use_event.has_triggered())
        use_event.wait();
      bool free_resource = true;
      // Only need to free resources if we own the allocation
      if (own_allocation)
      {
        if (external_allocation)
        {
          const AddressSpaceID target_space = memory.address_space();
          if (target_space != implicit_runtime->address_space)
          {
#ifdef DEBUG_LEGION
            assert(!freeproc.exists() || 
                freeproc.address_space() == target_space);
#endif
            // Send the message to the remote node to do the free
            Serializer rez;
            {
              RezCheck z(rez);
              rez.serialize(freeproc);
              rez.serialize(freefunc);
              rez.serialize(instance);
            }
            implicit_runtime->send_free_external_allocation(target_space, rez);
          }
          else
          {
            // We're already local, see if we need to launch a task
            if (freeproc.exists())
            {
              FreeExternalArgs args(resource, 
                  (freefunc != NULL) ? freefunc : free_host_memory, instance);
              if (freeproc.exists())
                implicit_runtime->issue_application_processor_task(args,
                    LG_THROUGHPUT_WORK_PRIORITY, freeproc); 
              else
                implicit_runtime->issue_runtime_meta_task(args,
                    LG_THROUGHPUT_WORK_PRIORITY);
              // No longer safe to free the resource since that is going
              // to be done by the free external args task
              free_resource = false;
            }
            else
            {
              // We can do the free now
              free(const_cast<void*>(data.load()));
              if (instance.exists())
                instance.destroy();
            }
          }
        }
        else
        {
#ifdef DEBUG_LEGION
          assert(instance.exists());
          assert(own_instance);
#endif
          // Free the future instance through the memory manager
          MemoryManager *manager =
            implicit_runtime->find_memory_manager(memory);
          manager->free_future_instance(instance, size, 
                RtEvent::NO_RT_EVENT, eager_allocation);
        }
      }
      else if (own_instance)
      {
#ifdef DEBUG_LEGION
        assert(instance.exists());
#endif
        instance.destroy();
      }
      if ((resource != NULL) && free_resource)
        delete resource;
    }

    //--------------------------------------------------------------------------
    ApEvent FutureInstance::initialize(const ReductionOp *redop, Operation *op,
                                       ApEvent precondition)
    //--------------------------------------------------------------------------
    {
      // Check to see if this is visible or not
      if (!is_meta_visible || (precondition.exists() && 
           !precondition.has_triggered_faultignorant()))
      {
        Realm::CopySrcDstField src, dst;
        src.set_fill(redop->identity, redop->sizeof_rhs);
        bool own_inst = false;
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
        LgEvent inst_event;
        PhysicalInstance dst_inst = 
          get_instance(redop->sizeof_rhs, inst_event, own_inst);
#else
        PhysicalInstance dst_inst = get_instance(redop->sizeof_rhs, own_inst);
#endif
#ifdef DEBUG_LEGION
        // Should only be writing to instances that this future instance owns
        assert(own_instance);
#endif
        dst.set_field(dst_inst, 0/*field id*/, size);
        std::vector<Realm::CopySrcDstField> srcs(1, src);
        std::vector<Realm::CopySrcDstField> dsts(1, dst);
        Realm::ProfilingRequestSet requests;
        if (implicit_runtime->profiler != NULL)
        {
          SmallNameClosure<1> *closure = new SmallNameClosure<1>();
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
          closure->record_instance_name(dst_inst, inst_event);
#else
          closure->record_instance_name(dst_inst, unique_event);
#endif
          implicit_runtime->profiler->add_fill_request(
              requests, closure, op, precondition);
        }
        const Point<1,coord_t> zero(0);
        const Rect<1,coord_t> rect(zero, zero);
        const ApEvent result(rect.copy(srcs, dsts, requests, precondition));
        if (own_inst)
        {
          if (result.exists())
            dst_inst.destroy(Runtime::protect_event(result));
          else
            dst_inst.destroy();
        }
        return result;
      }
      else
      {
        memcpy(const_cast<void*>(get_data()),redop->identity,redop->sizeof_rhs);
        return ApEvent::NO_AP_EVENT;
      }
    }

    //--------------------------------------------------------------------------
    ApEvent FutureInstance::copy_from(FutureInstance *source, Operation *op,
                                      ApEvent precondition)
    //--------------------------------------------------------------------------
    {
      // Only copying the minimum size between the two, this is not very
      // safe, but it's how we deal with upper bound instances so we're
      // just trusing that the caller code is correct
      const size_t copy_size = std::min(size, source->size);
      if (!is_meta_visible || !source->is_meta_visible ||
          (precondition.exists() && 
           !precondition.has_triggered_faultignorant()))
      {
        // We need to offload this to realm
        bool own_src = false, own_dst = false;
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
        LgEvent src_event, dst_event;
        PhysicalInstance src_inst = 
          source->get_instance(copy_size, src_event, own_src);
        PhysicalInstance dst_inst = get_instance(copy_size, dst_event, own_dst);
#else
        PhysicalInstance src_inst = source->get_instance(copy_size, own_src);
        PhysicalInstance dst_inst = get_instance(copy_size, own_dst);
#endif
#ifdef DEBUG_LEGION
        // Should only be writing to instances that this future instance owns
        // Might also happen if we have an "external" (not really external but
        // made-using-malloc instance) that is bigger than the copy and we 
        // make an intermediate instance to handle that.
        assert(own_instance || 
            (own_dst && external_allocation && (copy_size < size)));
#endif
        std::vector<Realm::CopySrcDstField> srcs(1);
        std::vector<Realm::CopySrcDstField> dsts(1);
        srcs.back().set_field(src_inst, 0/*field id*/, copy_size);
        dsts.back().set_field(dst_inst, 0/*field id*/, copy_size);
        Realm::ProfilingRequestSet requests;
        if (implicit_runtime->profiler != NULL)
        {
          SmallNameClosure<2> *closure = new SmallNameClosure<2>();
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
          closure->record_instance_name(src_inst, src_event);
          closure->record_instance_name(dst_inst, dst_event);
#else
          closure->record_instance_name(src_inst, source->unique_event);
          closure->record_instance_name(dst_inst, unique_event);
#endif
          implicit_runtime->profiler->add_copy_request(
              requests, closure, op, precondition);
        }
        const Point<1,coord_t> zero(0);
        const Rect<1,coord_t> rect(zero, zero);
        const ApEvent result(rect.copy(srcs, dsts, requests, precondition));
        RtEvent protect;
        if (own_src)
        {
          if (result.exists())
          {
            protect = Runtime::protect_event(result);
            src_inst.destroy(protect);
          }
          else
            src_inst.destroy();
        }
        if (own_dst)
        {
          if (result.exists())
          {
            if (!protect.exists())
              protect = Runtime::protect_event(result);
            dst_inst.destroy(protect);
          }
          else
            dst_inst.destroy();
        }
        return result;
      }
      else
      {
        // We can do this as a straight memcpy, no need to offload to realm
        memcpy(const_cast<void*>(get_data()), source->get_data(), copy_size);
        return ApEvent::NO_AP_EVENT;
      }
    } 

    //--------------------------------------------------------------------------
    ApEvent FutureInstance::reduce_from(FutureInstance *source, Operation *op,
                       const ReductionOpID redop_id, const ReductionOp *redop, 
                       bool exclusive, ApEvent precondition)
    //--------------------------------------------------------------------------
    {
      if (!is_meta_visible || !source->is_meta_visible || 
          (precondition.exists() && 
           !precondition.has_triggered_faultignorant()))
      {
        // We need to offload this to realm
        bool own_src = false, own_dst = false;
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
        LgEvent src_event, dst_event;
        PhysicalInstance src_inst =
          source->get_instance(redop->sizeof_rhs, src_event, own_src);
        PhysicalInstance dst_inst =
          get_instance(redop->sizeof_rhs, dst_event, own_dst);
#else
        PhysicalInstance src_inst =
          source->get_instance(redop->sizeof_rhs, own_src);
        PhysicalInstance dst_inst = get_instance(redop->sizeof_rhs, own_dst);
#endif
#ifdef DEBUG_LEGION
        // Should only be reducing to instances that this future instance owns
        // Might also happen if we have an "external" (not really external but
        // made-using-malloc instance) that is bigger than the copy and we 
        // make an intermediate instance to handle that.
        assert(own_instance ||
            (own_dst && external_allocation && (redop->sizeof_rhs < size)));
#endif
        std::vector<Realm::CopySrcDstField> srcs(1);
        std::vector<Realm::CopySrcDstField> dsts(1);
        srcs.back().set_field(src_inst, 0/*field id*/, size);
        dsts.back().set_field(dst_inst, 0/*field id*/, size);
        dsts.back().set_redop(redop_id, true/*fold*/, exclusive);
        Realm::ProfilingRequestSet requests;
        if (implicit_runtime->profiler != NULL)
        {
          SmallNameClosure<2> *closure = new SmallNameClosure<2>();
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
          closure->record_instance_name(src_inst, src_event);
          closure->record_instance_name(dst_inst, dst_event);
#else
          closure->record_instance_name(src_inst, source->unique_event);
          closure->record_instance_name(dst_inst, unique_event);
#endif
          implicit_runtime->profiler->add_copy_request(
              requests, closure, op, precondition);
        }
        const Point<1,coord_t> zero(0);
        const Rect<1,coord_t> rect(zero, zero);
        const ApEvent result(rect.copy(srcs, dsts, requests, precondition));
        RtEvent protect;
        if (own_src)
        {
          if (result.exists())
          {
            protect = Runtime::protect_event(result);
            src_inst.destroy(protect);
          }
          else
            src_inst.destroy();
        }
        if (own_dst)
        {
          if (result.exists())
          {
            if (!protect.exists())
              protect = Runtime::protect_event(result);
            dst_inst.destroy(protect);
          }
          else
            dst_inst.destroy();
        }
        return result;
      }
      else
      {
        // We can do this as a straight fold, no need to offload to realm
        if (exclusive)
        {
#ifdef DEBUG_LEGION
          assert(redop->cpu_fold_excl_fn);
#endif
          (redop->cpu_fold_excl_fn)(const_cast<void*>(get_data()), 0/*stride*/,
                  source->get_data(), 0/*stride*/, 1/*count*/, redop->userdata);
        }
        else
        {
#ifdef DEBUG_LEGION
          assert(redop->cpu_fold_nonexcl_fn);
#endif
          (redop->cpu_fold_nonexcl_fn)(const_cast<void*>(get_data()), 
              0/*stride*/, source->get_data(), 0/*stride*/,
              1/*count*/, redop->userdata);
        }
        return ApEvent::NO_AP_EVENT;
      }
    }

    //--------------------------------------------------------------------------
    const void* FutureInstance::get_data(void)
    //--------------------------------------------------------------------------
    {
      if (size == 0)
        return NULL;
      const void *result = data.load();
      if (result != NULL)
        return result;
      if (use_event.exists() && !use_event.has_triggered())
      {
        use_event.wait();
        use_event = RtEvent::NO_RT_EVENT;
      }
#ifdef DEBUG_LEGION
      assert(instance.exists());
#endif
      result = instance.pointer_untyped(0, size);
      data.store(result);
      return result;
    }

    //--------------------------------------------------------------------------
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
    PhysicalInstance FutureInstance::get_instance(size_t needed, 
                                            LgEvent &inst_event, bool &own_inst)
#else
    PhysicalInstance FutureInstance::get_instance(size_t needed, bool &own_inst)
#endif
    //--------------------------------------------------------------------------
    {
      if (needed != size)
      {
        // The unusual case where we need to make a new instance to reflect
        // a different size than the original
#ifdef DEBUG_LEGION
        assert(needed < size);
#endif
        const Point<1,coord_t> zero(0);
        const Realm::IndexSpace<1,coord_t> rect_space(
                      Realm::Rect<1,coord_t>(zero, zero));
        const Realm::ExternalInstanceResource *alt_resource = resource;
        // Check to see if we already have a resource or not
        if (alt_resource == NULL)
        {
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
          const PhysicalInstance inst = get_instance(size, inst_event,own_inst);
#else
          const PhysicalInstance inst = get_instance(size, own_inst); 
#endif
          alt_resource =
            inst.generate_resource_info(rect_space,0/*fid*/,false/*read only*/);
#ifdef DEBUG_LEGION
          // Note that if you hit this then that likely means that Realm 
          // doesn't support 'generate_resource_info' yet for that kind of
          // memory and it probably just needs to be implemented
          assert(alt_resource != NULL);
#endif
        }
        const std::vector<Realm::FieldID> fids(1, 0/*field id*/);
        const std::vector<size_t> sizes(1, needed);
        const int dim_order[1] = { 0 };
        const Realm::InstanceLayoutConstraints constraints(fids, sizes, 1);
        Realm::InstanceLayoutGeneric *ilg =
            Realm::InstanceLayoutGeneric::choose_instance_layout<1,coord_t>(
                rect_space, constraints, dim_order);
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
        const RtUserEvent temp_unique_event = Runtime::create_rt_user_event();        
        Runtime::trigger_event(temp_unique_event);
#endif
        // If it is not an external allocation then ignore suggested_memory
        // because we know we're making this on top of an existing instance
        Realm::ProfilingRequestSet requests;
        if (implicit_runtime->profiler != NULL)
          implicit_runtime->profiler->add_inst_request(requests, 
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
                      implicit_provenance, temp_unique_event);
#else
                      implicit_provenance, unique_event);
#endif
        PhysicalInstance result;
        const RtEvent inst_ready(PhysicalInstance::create_external_instance(
              result, alt_resource->suggested_memory(), ilg,
              *alt_resource, requests));
        if (inst_ready.exists() && (implicit_profiler != NULL))
          implicit_profiler->record_instance_ready(inst_ready, unique_event);
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
        inst_event = temp_unique_event; 
#endif
        own_inst = true;
        if (resource == NULL)
          delete alt_resource;
        if (inst_ready.exists() && !inst_ready.has_triggered())
          inst_ready.wait();
        return result;
      }
      else if (!instance.exists())
      {
#ifdef DEBUG_LEGION
        assert(!own_instance);
        assert(external_allocation);
        assert(resource != NULL);
        assert(!unique_event.exists());
#endif
        RtEvent wait_on;
        // Make our instance and see if we lost the race
        const std::vector<Realm::FieldID> fids(1, 0/*field id*/);
        const std::vector<size_t> sizes(1, size);
        const int dim_order[1] = { 0 };
        const Realm::InstanceLayoutConstraints constraints(fids, sizes, 1);
        const Point<1,coord_t> zero(0);
        const Realm::IndexSpace<1,coord_t> rect_space(
                      Realm::Rect<1,coord_t>(zero, zero));
        Realm::InstanceLayoutGeneric *ilg =
          Realm::InstanceLayoutGeneric::choose_instance_layout<1,coord_t>(
              rect_space, constraints, dim_order);
        Realm::ProfilingRequestSet requests;
        if (implicit_runtime->profiler != NULL)
        {
          // Need to try to make a unique event
          RtUserEvent unique = Runtime::create_rt_user_event();
          Runtime::trigger_event(unique);
          unique_event = unique;
          implicit_runtime->profiler->add_inst_request(requests,
                      implicit_provenance, unique_event);
        }
        // If it is not an external allocation then ignore suggested_memory
        // because we know we're making this on top of an existing instance
        use_event = RtEvent(PhysicalInstance::create_external_instance(instance,
              resource->suggested_memory(), ilg, *resource, requests));
        own_instance = true;
        if (use_event.exists() && (implicit_profiler != NULL))
          implicit_profiler->record_instance_ready(use_event, unique_event);
      }
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
      inst_event = unique_event;
#endif
      own_inst = false;
      if (use_event.exists() && !use_event.has_triggered())
      {
        use_event.wait();
        use_event = RtEvent::NO_RT_EVENT;
      }
      return instance;
    }

    //--------------------------------------------------------------------------
    bool FutureInstance::defer_deletion(ApEvent precondition)
    //--------------------------------------------------------------------------
    {
      if (own_allocation)
      {
        if (precondition.exists() && 
            !precondition.has_triggered_faultignorant())
        {
          DeferDeleteFutureInstanceArgs args(this);
          implicit_runtime->issue_runtime_meta_task(args,
            LG_THROUGHPUT_WORK_PRIORITY, Runtime::protect_event(precondition));
          return true;
        }
      }
      else if (own_instance)
      {
#ifdef DEBUG_LEGION
        assert(instance.exists());
#endif
        if (precondition.exists() && 
            !precondition.has_triggered_faultignorant())
        {
          instance.destroy(Runtime::protect_event(precondition));
          own_instance = false;
        }
      }
      return false;
    }

    //--------------------------------------------------------------------------
    bool FutureInstance::can_pack_by_value(void) const
    //--------------------------------------------------------------------------
    {
      return (is_meta_visible && (size <= LEGION_MAX_RETURN_SIZE));
    }

    //--------------------------------------------------------------------------
    bool FutureInstance::pack_instance(Serializer &rez, ApEvent ready_event,
        bool pack_ownership, bool allow_value)
    //--------------------------------------------------------------------------
    {
      rez.serialize(size);
      // Check to see if we can just pass this future instance by value
      if (allow_value && is_meta_visible && (size <= LEGION_MAX_RETURN_SIZE) &&
          (!ready_event.exists() || ready_event.has_triggered_faultignorant()))
      {
        // We can just pass this future by value because we can
        // see it here, it's tiny, and it's ready to be read
        rez.serialize<bool>(true); // by value
        rez.serialize(data.load(), size);
        // We packed this by value so return true
        return true;
      }
      else
      {
        rez.serialize<bool>(false); // by value
        rez.serialize(data.load());
        bool dummy_owner = true;
#ifndef LEGION_UNDO_FUTURE_INSTANCE_HACK
        LgEvent dummy_event;
        rez.serialize(get_instance(size, dummy_event, dummy_owner));
#else
        rez.serialize(get_instance(size, dummy_owner));
#endif
        rez.serialize(unique_event);
#ifdef DEBUG_LEGION
        // should never end up owning this instance
        assert(!dummy_owner);
#endif
        if (pack_ownership)
        {
#ifdef DEBUG_LEGION
          assert(own_instance);
          assert(own_allocation);
#endif
          rez.serialize<bool>(true); // own the allocation on the destination
          own_allocation = false;
          // we no longer own this instance either
          own_instance = false;
        }
        else
          rez.serialize<bool>(false); // do not own allocation on destination
        if (external_allocation)
        {
          rez.serialize<bool>(true); // external allocation
          rez.serialize(freefunc);
          rez.serialize(freeproc);
        }
        else
        {
          rez.serialize<bool>(false); // external allocation
          rez.serialize<bool>(eager_allocation);
        }
        // Not packed by value
        return false;
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ FutureInstance* FutureInstance::unpack_instance(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      size_t size;
      derez.deserialize(size);
      if (size == 0)
        return NULL;
      bool pass_by_value;
      derez.deserialize<bool>(pass_by_value);
      if (pass_by_value)
      {
        void *data = malloc(size);
        derez.deserialize(data, size);
        return new FutureInstance(data, size, false/*eager*/, true/*external*/);
      }
      void *data;
      derez.deserialize(data);
      PhysicalInstance instance;
      derez.deserialize(instance);
      LgEvent unique_event;
      derez.deserialize(unique_event);
      RtEvent use_event;
      if (instance.exists())
        use_event = RtEvent(instance.fetch_metadata(
              Processor::get_executing_processor()));
      bool own_allocation, external_allocation;
      derez.deserialize<bool>(own_allocation);
      derez.deserialize<bool>(external_allocation);
      if (external_allocation)
      {
        void (*freefunc)(const Realm::ExternalInstanceResource&);
        derez.deserialize(freefunc);
        Processor proc;
        derez.deserialize(proc);
        return new FutureInstance(data, size, own_allocation,
           NULL/*resource*/, freefunc, proc, unique_event, instance, use_event);
      }
      else
      {
        bool eager_alloc;
        derez.deserialize<bool>(eager_alloc);
        return new FutureInstance(data, size, eager_alloc,
                    false/*external*/, own_allocation, unique_event,
                    instance, Processor::NO_PROC, use_event);
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ bool FutureInstance::check_meta_visible(Memory memory)
    //--------------------------------------------------------------------------
    {
      // Common case, if it is the local system memory, we can see it
      if (implicit_runtime->runtime_system_memory == memory)
        return true;
      // If it's not in the local process, we definitely can't see it
      if (memory.address_space() != implicit_runtime->address_space)
        return false;
      // switch on the memory kind and see if there are any we support
      switch (memory.kind())
      {
        case Memory::GLOBAL_MEM:
        case Memory::SYSTEM_MEM:
        case Memory::REGDMA_MEM:
        case Memory::SOCKET_MEM:
        case Memory::Z_COPY_MEM:
          return true;
        default:
          break;
      }
      return false;
    }

    //--------------------------------------------------------------------------
    /*static*/ FutureInstance* FutureInstance::create_local(const void *value,
                                                          size_t size, bool own)
    //--------------------------------------------------------------------------
    {
      // Copy the data into a buffer we own if we don't already
      if (!own)
      {
        void *buffer = malloc(size);
        memcpy(buffer, value, size);
        value = buffer;
        own = true;
      }
      return new FutureInstance(value, size, false/*eager*/, true/*external*/);
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureInstance::handle_free_external(Deserializer &derez,
                                                         Runtime *runtime)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Processor freeproc;
      derez.deserialize(freeproc);
      void (*freefunc)(const Realm::ExternalInstanceResource&);
      derez.deserialize(freefunc);
      if (freefunc == NULL)
        freefunc = free_host_memory;
      PhysicalInstance instance;
      derez.deserialize(instance);
      const RtEvent use_event(instance.fetch_metadata(freeproc));
      FreeExternalArgs args(NULL/*no resource*/, freefunc, instance);
      if (freeproc.exists())
        runtime->issue_application_processor_task(args,
            LG_THROUGHPUT_WORK_PRIORITY, freeproc, use_event);
      else
        runtime->issue_runtime_meta_task(args,
            LG_THROUGHPUT_WORK_PRIORITY, use_event);
    }

    //--------------------------------------------------------------------------
    FutureInstance::FreeExternalArgs::FreeExternalArgs(
                          const Realm::ExternalInstanceResource *r,
                          void (*func)(const Realm::ExternalInstanceResource&),
                          PhysicalInstance inst)
      : LgTaskArgs<FreeExternalArgs>(implicit_provenance),
        resource((r == NULL) ? r : r->clone()), freefunc(func), instance(inst)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert((resource != NULL) || instance.exists());
#endif
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureInstance::handle_free_external(const void *args)
    //--------------------------------------------------------------------------
    {
      const FreeExternalArgs *fargs = (const FreeExternalArgs*)args;
      const Realm::ExternalInstanceResource *resource = fargs->resource;
      if (resource == NULL)
      {
        const Point<1,coord_t> zero(0);
        const Realm::IndexSpace<1,coord_t> rect_space(
                      Realm::Rect<1,coord_t>(zero, zero));
        resource = fargs->instance.generate_resource_info(rect_space,
                                          0/*fid*/, true/*read only*/);
      }
      (*(fargs->freefunc))(*resource);
      if (fargs->instance.exists())
        fargs->instance.destroy();
      delete resource;
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureInstance::free_host_memory(
                                const Realm::ExternalInstanceResource &resource)
    //--------------------------------------------------------------------------
    {
      const Realm::ExternalMemoryResource &allocation =
        static_cast<const Realm::ExternalMemoryResource&>(resource);
      free(reinterpret_cast<void*>(allocation.base));
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureInstance::handle_defer_deletion(const void *args)
    //--------------------------------------------------------------------------
    {
      const DeferDeleteFutureInstanceArgs *dargs = 
        (const DeferDeleteFutureInstanceArgs*)args;
      delete dargs->instance;
    }

    /////////////////////////////////////////////////////////////
    // Future Map Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    FutureMapImpl::FutureMapImpl(TaskContext *ctx, Operation *o,
                                 IndexSpaceNode *domain, Runtime *rt,
                                 DistributedID did, Provenance *prov,
                                 bool register_now, CollectiveMapping *mapping)
      : DistributedCollectable(rt, 
          LEGION_DISTRIBUTED_HELP_ENCODE(did, FUTURE_MAP_DC),
          register_now, mapping),
        context(ctx), op(o), op_gen(o->get_generation()),
        op_depth(o->get_context()->get_depth()), op_uid(o->get_unique_op_id()),
        blocking_index(o->get_context()->get_next_blocking_index()),
        provenance(prov), future_map_domain(domain)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(future_map_domain != NULL);
#endif
      future_map_domain->add_nested_valid_ref(did);
      if (provenance != NULL)
        provenance->add_reference();
#ifdef LEGION_GC
      log_garbage.info("GC Future Map %lld %d", 
          LEGION_DISTRIBUTED_ID_FILTER(this->did), local_space);
#endif
    }

    //--------------------------------------------------------------------------
    FutureMapImpl::FutureMapImpl(TaskContext *ctx,Runtime *rt,IndexSpaceNode *d,
                                 DistributedID did, uint64_t blocking,
                                 Provenance *prov,
                                 bool register_now, CollectiveMapping *mapping)
      : DistributedCollectable(rt, 
          LEGION_DISTRIBUTED_HELP_ENCODE(did, FUTURE_MAP_DC),
          register_now, mapping),
        context(ctx), op(NULL), op_gen(0), op_depth(0), op_uid(0),
        blocking_index(blocking), provenance(prov), future_map_domain(d)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(future_map_domain != NULL);
#endif
      future_map_domain->add_nested_valid_ref(did);
      if (provenance != NULL)
        provenance->add_reference();
#ifdef LEGION_GC
      log_garbage.info("GC Future Map %lld %d", 
          LEGION_DISTRIBUTED_ID_FILTER(this->did), local_space);
#endif
    }

    //--------------------------------------------------------------------------
    FutureMapImpl::FutureMapImpl(TaskContext *ctx, Operation *o, uint64_t index,
                                 GenerationID gen, int depth, UniqueID uid,
                                 IndexSpaceNode *domain, Runtime *rt,
                                 DistributedID did, Provenance *prov)
      : DistributedCollectable(rt, 
          LEGION_DISTRIBUTED_HELP_ENCODE(did, FUTURE_MAP_DC)), 
        context(ctx), op(o), op_gen(gen), op_depth(depth), op_uid(uid),
        blocking_index(index), provenance(prov), future_map_domain(domain)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(future_map_domain != NULL);
#endif
      future_map_domain->add_nested_valid_ref(did);
      if (provenance != NULL)
        provenance->add_reference();
#ifdef LEGION_GC
      log_garbage.info("GC Future Map %lld %d", 
          LEGION_DISTRIBUTED_ID_FILTER(this->did), local_space);
#endif
    }

    //--------------------------------------------------------------------------
    FutureMapImpl::~FutureMapImpl(void)
    //--------------------------------------------------------------------------
    {
      for (std::map<DomainPoint,FutureImpl*>::const_iterator it =
            futures.begin(); it != futures.end(); it++)
        if (it->second->remove_nested_resource_ref(did))
          delete it->second;
      futures.clear();
      if (future_map_domain->remove_nested_valid_ref(did))
        delete future_map_domain;
      if ((provenance != NULL) && provenance->remove_reference())
        delete provenance;
    }

    //--------------------------------------------------------------------------
    void FutureMapImpl::notify_local(void)
    //--------------------------------------------------------------------------
    {
      for (std::map<DomainPoint,FutureImpl*>::const_iterator it =
            futures.begin(); it != futures.end(); it++)
        it->second->remove_nested_gc_ref(did);
    }

    //--------------------------------------------------------------------------
    Domain FutureMapImpl::get_domain(void) const
    //--------------------------------------------------------------------------
    {
      Domain result;
      future_map_domain->get_domain(result);
      return result;
    }

    //--------------------------------------------------------------------------
    Future FutureMapImpl::get_future(const DomainPoint &point, 
                                     bool internal, RtEvent *wait_on)
    //--------------------------------------------------------------------------
    {
#ifndef DEBUG_LEGION
      if (!internal)
#endif
      {
        if (!future_map_domain->contains_point(point))
          REPORT_LEGION_ERROR(ERROR_INVALID_FUTURE_MAP_POINT,
              "Invalid request for a point not contained in the "
              "domain of a future map in task %s (UID %lld).",
              context->get_task_name(), context->get_unique_id())
      }
      if (!is_owner())
      {
        // See if we already have it
        {
          AutoLock fm_lock(future_map_lock,1,false/*exlusive*/);
          std::map<DomainPoint,FutureImpl*>::const_iterator finder = 
                                                futures.find(point);
          if (finder != futures.end())
            return Future(finder->second);
        }
        // Make an event for when we have the answer
        RtUserEvent future_ready_event = Runtime::create_rt_user_event();
        // If not send a message to get it
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(did);
          rez.serialize(point);
          rez.serialize(future_ready_event);
          rez.serialize<bool>(internal);
        }
        runtime->send_future_map_request_future(owner_space, rez);
        if (wait_on != NULL)
        {
          *wait_on = future_ready_event;
          return Future();
        }
        future_ready_event.wait(); 
        // When we wake up it should be here
        AutoLock fm_lock(future_map_lock,1,false/*exlusive*/);
        std::map<DomainPoint,FutureImpl*>::const_iterator finder = 
                                              futures.find(point);
#ifdef DEBUG_LEGION
        assert(finder != futures.end());
#endif
        return Future(finder->second);
      }
      else
      {
        AutoLock fm_lock(future_map_lock);
        // Check to see if we already have a future for the point
        std::map<DomainPoint,FutureImpl*>::const_iterator finder = 
                                              futures.find(point);
        if (finder != futures.end())
          return Future(finder->second);
        // Otherwise we need a future from the context to use for
        // the point that we will fill in later
        FutureImpl *result = new FutureImpl(context, runtime, true/*register*/,
              runtime->get_available_distributed_id(), op, op_gen, 
              ContextCoordinate(blocking_index, point),
              op_uid, op_depth, provenance);
        result->add_nested_gc_ref(did);
        result->add_nested_resource_ref(did);
        futures[point] = result;
        if (runtime->legion_spy_enabled)
          LegionSpy::log_future_creation(op_uid, result->did, point);
        return Future(result);
      }
    }

    //--------------------------------------------------------------------------
    void FutureMapImpl::set_future(const DomainPoint &point, FutureImpl *impl)
    //--------------------------------------------------------------------------
    {
      // Add the reference first and then set the future
      impl->add_nested_gc_ref(did);
      impl->add_nested_resource_ref(did);
      AutoLock fm_lock(future_map_lock);
#ifdef DEBUG_LEGION
      assert(futures.find(point) == futures.end());
#endif
      futures[point] = impl;
    }

    //--------------------------------------------------------------------------
    void FutureMapImpl::get_void_result(const DomainPoint &point,
                                        bool silence_warnings,
                                        const char *warning_string)
    //--------------------------------------------------------------------------
    {
      Future f = get_future(point, false/*internal*/);
      f.get_void_result(silence_warnings, warning_string);
    }

    //--------------------------------------------------------------------------
    void FutureMapImpl::wait_all_results(bool silence_warnings,
                                         const char *warning_string)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(implicit_context != NULL);
      assert(implicit_context == context);
#endif
      if (runtime->runtime_warnings && !silence_warnings && 
          (context != NULL) && !context->is_leaf_context())
        REPORT_LEGION_WARNING(LEGION_WARNING_WAITING_ALL_FUTURES, 
            "Waiting for all futures in a future map in "
            "non-leaf task %s (UID %lld) is a violation of Legion's deferred "
            "execution model best practices. You may notice a severe "
            "performance degredation. Warning string: %s", 
            context->get_task_name(),
            context->get_unique_id(),
            (warning_string == NULL) ? "" : warning_string)
      context->record_blocking_call(blocking_index);
      if (op != NULL)
        context->wait_on_future_map(this, op->get_commit_event(op_gen));
    }

    //--------------------------------------------------------------------------
    bool FutureMapImpl::reset_all_futures(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner());
#endif
      // TODO: send messages to all the remote copies of this
      assert(false);
      bool result = false;
      AutoLock fm_lock(future_map_lock);
      for (std::map<DomainPoint,FutureImpl*>::const_iterator it = 
            futures.begin(); it != futures.end(); it++)
        if (it->second->reset_future())
          result = true;
      return result;
    }

    //--------------------------------------------------------------------------
    void FutureMapImpl::pack_future_map(Serializer &rez, AddressSpaceID target)
    //--------------------------------------------------------------------------
    {
      rez.serialize(did);
      if ((collective_mapping == NULL) || !collective_mapping->contains(target))
      {
        rez.serialize<bool>(true); // can create
        rez.serialize(future_map_domain->handle);
        rez.serialize(blocking_index);
        if (provenance != NULL)
          provenance->serialize(rez);
        else
          Provenance::serialize_null(rez);
      }
      else
        rez.serialize<bool>(false); // cannot make it, need to wait
      pack_global_ref();
    }

    //--------------------------------------------------------------------------
    /*static*/ FutureMap FutureMapImpl::unpack_future_map(Runtime *runtime,
                                          Deserializer &derez, TaskContext *ctx)
    //--------------------------------------------------------------------------
    {
      DistributedID future_map_did;
      derez.deserialize(future_map_did);
      if (future_map_did == 0)
        return FutureMap();
      bool can_create;
      derez.deserialize<bool>(can_create);
      if (!can_create)
      {
        // Have to wait to find this one since it is created collectively
        FutureMap result(static_cast<FutureMapImpl*>(
          runtime->find_distributed_collectable(future_map_did)));
        result.impl->unpack_global_ref();
        return result;
      }
      IndexSpace future_map_domain;
      derez.deserialize(future_map_domain);
      uint64_t coordinate;
      derez.deserialize(coordinate);
      AutoProvenance provenance(Provenance::deserialize(derez));
      FutureMap result(runtime->find_or_create_future_map(future_map_did, ctx, 
                      coordinate, future_map_domain, provenance));
      result.impl->unpack_global_ref();
      return result;
    }

    //--------------------------------------------------------------------------
    void FutureMapImpl::get_all_futures(
                                     std::map<DomainPoint,FutureImpl*> &others)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner());
#endif
      Domain domain;
      future_map_domain->get_domain(domain);
      const size_t needed = domain.get_volume();
      AutoLock fm_lock(future_map_lock);
#ifdef DEBUG_LEGION
      assert(futures.size() <= needed);
#endif
      if (futures.size() < needed)
      {
        fm_lock.release();
        std::vector<RtEvent> ready_events;
        for (Domain::DomainPointIterator itr(domain); itr; itr++)
        {
          RtEvent ready;
          get_future(itr.p, true/*internal only*/, &ready);
          if (ready.exists())
            ready_events.push_back(ready);
        }
        if (!ready_events.empty())
        {
          const RtEvent wait_on = Runtime::merge_events(ready_events);
          if (wait_on.exists() && !wait_on.has_triggered())
            wait_on.wait();
        }
        fm_lock.reacquire();
      }
      others = futures;
    }

    //--------------------------------------------------------------------------
    void FutureMapImpl::set_all_futures(
                                     const std::map<DomainPoint,Future> &others)
    //--------------------------------------------------------------------------
    {
      // No need for the lock here since we're initializing
      for (std::map<DomainPoint,FutureImpl*>::const_iterator it =
            futures.begin(); it != futures.end(); it++)
      {
        it->second->remove_nested_gc_ref(did);
        if (it->second->remove_nested_resource_ref(did))
          delete it->second;
      }
      futures.clear();
      for (std::map<DomainPoint,Future>::const_iterator it =
            others.begin(); it != others.end(); it++)
      {
        FutureImpl *impl = it->second.impl;
        impl->add_nested_resource_ref(did);
        impl->add_nested_gc_ref(did);
        futures[it->first] = impl;
      }
    }

    //--------------------------------------------------------------------------
    FutureImpl* FutureMapImpl::find_local_future(const DomainPoint &point)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(future_map_domain->contains_point(point));
#endif
      Future result = get_future(point, true/*internal only*/);
      return result.impl;
    }

    //--------------------------------------------------------------------------
    void FutureMapImpl::get_shard_local_futures(ShardID shard,
                                      std::map<DomainPoint,FutureImpl*> &others)
    //--------------------------------------------------------------------------
    {
      // This is only called on this kind of future map when we know we
      // already have all the futures so there's no need to wait or lock
      others = futures;
    }

    //--------------------------------------------------------------------------
    void FutureMapImpl::register_dependence(Operation *consumer_op)
    //--------------------------------------------------------------------------
    {
      if (op == NULL)
        return;
      // Only record dependences on things from the same context
      // We know futures can never flow up the task tree so the
      // only way they have the same depth is if they are from 
      // the same parent context
      TaskContext *context = consumer_op->get_context();
      const int consumer_depth = context->get_depth();
#ifdef DEBUG_LEGION
      assert(consumer_depth >= op_depth);
#endif
      if (consumer_depth == op_depth)
      {
        consumer_op->register_dependence(op, op_gen);
#ifdef LEGION_SPY
        LegionSpy::log_mapping_dependence(
            context->get_unique_id(), op_uid, 0,
            consumer_op->get_unique_op_id(), 0, TRUE_DEPENDENCE);
#endif
      }
    }

    //--------------------------------------------------------------------------
    RtEvent FutureMapImpl::record_future_map_registered(void)
    //--------------------------------------------------------------------------
    {
      // Similar to DistributedCollectable::register_with_runtime but
      // we don't actually need to do the registration since we know
      // it has already been done
#ifdef DEBUG_LEGION
      assert(!registered_with_runtime);
#endif
      registered_with_runtime = true;
      RtEvent result;
      if (!is_owner())
        result = send_remote_registration();
      return result;
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureMapImpl::handle_future_map_future_request(
                   Deserializer &derez, Runtime *runtime, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      DistributedID did;
      derez.deserialize(did);
      DomainPoint point;
      derez.deserialize(point);
      RtUserEvent done;
      derez.deserialize(done);
      bool internal;
      derez.deserialize(internal);
      
      // Should always find it since this is the owner node except in the 
      // replicated case in which case a shard on this node might not have
      // actually made it yet, so wait in that case
      DistributedCollectable *dc = runtime->find_distributed_collectable(did);
#ifdef DEBUG_LEGION
      FutureMapImpl *impl = dynamic_cast<FutureMapImpl*>(dc);
      assert(impl != NULL);
#else
      FutureMapImpl *impl = static_cast<FutureMapImpl*>(dc);
#endif
      Future f = impl->get_future(point, internal);
      Serializer rez;
      {
        RezCheck z2(rez);
        rez.serialize(did);
        rez.serialize(point);
        rez.serialize(f.impl->did);
        f.impl->pack_global_ref();
        rez.serialize(done);
      }
      runtime->send_future_map_response_future(source, rez);
    }

    //--------------------------------------------------------------------------
    void FutureMapImpl::process_future_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ContextCoordinate coordinate(blocking_index);
      derez.deserialize(coordinate.index_point);
      DistributedID future_did;
      derez.deserialize(future_did);
      FutureImpl *impl = runtime->find_or_create_future(future_did,
                                    context->did, coordinate,
                                    provenance, op, op_gen,
#ifdef LEGION_SPY
                                    op_uid,
#endif
                                    op_depth);
      set_future(coordinate.index_point, impl);
      impl->unpack_global_ref();
    }

    //--------------------------------------------------------------------------
    /*static*/ void FutureMapImpl::handle_future_map_future_response(
                                          Deserializer &derez, Runtime *runtime)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      DistributedID did;
      derez.deserialize(did);
      // Should always find it since this is the source node
      DistributedCollectable *dc = runtime->find_distributed_collectable(did);
#ifdef DEBUG_LEGION
      FutureMapImpl *impl = dynamic_cast<FutureMapImpl*>(dc);
      assert(impl != NULL);
#else
      FutureMapImpl *impl = static_cast<FutureMapImpl*>(dc);
#endif
      // Add it to the map
      impl->process_future_response(derez);
      // Trigger the done event
      RtUserEvent done;
      derez.deserialize(done);
      Runtime::trigger_event(done);
    }

    /////////////////////////////////////////////////////////////
    // Transform Future Map Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    TransformFutureMapImpl::TransformFutureMapImpl(FutureMapImpl *prev,
                              IndexSpaceNode *domain, PointTransformFnptr fnptr,
                              Provenance *prov)
      : FutureMapImpl(prev->context, prev->op, prev->blocking_index,
          prev->op_gen, prev->op_depth, prev->op_uid,
          domain, prev->runtime, prev->runtime->get_available_distributed_id(),
          prov),
        previous(prev), own_functor(false), is_functor(false)
    //--------------------------------------------------------------------------
    {
      prev->add_nested_gc_ref(did);
      transform.fnptr = fnptr;
    }

    //--------------------------------------------------------------------------
    TransformFutureMapImpl::TransformFutureMapImpl(FutureMapImpl *prev,
          IndexSpaceNode *domain, PointTransformFunctor *functor, bool own_func,
          Provenance *prov)
      : FutureMapImpl(prev->context, prev->op, prev->blocking_index,
          prev->op_gen, prev->op_depth, prev->op_uid,
          domain, prev->runtime, prev->runtime->get_available_distributed_id(),
          prov),
        previous(prev), own_functor(own_func), is_functor(true)
    //--------------------------------------------------------------------------
    {
      prev->add_nested_gc_ref(did);
      transform.functor = functor;
    }

    //--------------------------------------------------------------------------
    TransformFutureMapImpl::~TransformFutureMapImpl(void)
    //--------------------------------------------------------------------------
    {
      if (previous->remove_nested_gc_ref(did))
        delete previous;
      if (own_functor)
        delete transform.functor;
    }

    //--------------------------------------------------------------------------
    bool TransformFutureMapImpl::is_replicate_future_map(void) const
    //--------------------------------------------------------------------------
    {
      return previous->is_replicate_future_map();
    }

    //--------------------------------------------------------------------------
    Future TransformFutureMapImpl::get_future(const DomainPoint &point, 
                                           bool internal_only, RtEvent *wait_on)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(future_map_domain->contains_point(point));
#endif
      Domain domain, range;
      future_map_domain->get_domain(domain);
      previous->future_map_domain->get_domain(range);
      if (is_functor)
      {
        const DomainPoint transformed = 
          transform.functor->transform_point(point, domain, range);
#ifdef DEBUG_LEGION
        assert(previous->future_map_domain->contains_point(transformed));
#endif
        return previous->get_future(transformed, internal_only, wait_on);
      }
      else
      {
        const DomainPoint transformed = (*transform.fnptr)(point,domain,range);
#ifdef DEBUG_LEGION
        assert(previous->future_map_domain->contains_point(transformed));
#endif
        return previous->get_future(transformed, internal_only, wait_on);
      }
    }

    //--------------------------------------------------------------------------
    void TransformFutureMapImpl::get_all_futures(
                                     std::map<DomainPoint,FutureImpl*> &futures)
    //--------------------------------------------------------------------------
    {
      std::map<DomainPoint,FutureImpl*> previous_futures;
      previous->get_all_futures(previous_futures);
      Domain domain, range;
      future_map_domain->get_domain(domain);
      previous->future_map_domain->get_domain(range);
      if (is_functor)
      {
        for (Domain::DomainPointIterator itr(domain); itr; itr++)
        {
          const DomainPoint transformed = 
            transform.functor->transform_point(itr.p, domain, range);
#ifdef DEBUG_LEGION
          assert(previous->future_map_domain->contains_point(transformed));
#endif 
          std::map<DomainPoint,FutureImpl*>::const_iterator finder =
            previous_futures.find(transformed);
#ifdef DEBUG_LEGION
          assert(finder != previous_futures.end());
#endif
          futures[itr.p] = finder->second;
        }
      }
      else
      {
        for (Domain::DomainPointIterator itr(domain); itr; itr++)
        {
          const DomainPoint transformed = 
            (*transform.fnptr)(itr.p, domain, range);
#ifdef DEBUG_LEGION
          assert(previous->future_map_domain->contains_point(transformed));
#endif 
          std::map<DomainPoint,FutureImpl*>::const_iterator finder =
            previous_futures.find(transformed);
#ifdef DEBUG_LEGION
          assert(finder != previous_futures.end());
#endif
          futures[itr.p] = finder->second;
        }
      }
    }

    //--------------------------------------------------------------------------
    void TransformFutureMapImpl::wait_all_results(bool silence_warnings,
                                                  const char *warning_string)
    //--------------------------------------------------------------------------
    {
      previous->wait_all_results(silence_warnings, warning_string);
    }

    //--------------------------------------------------------------------------
    FutureImpl* TransformFutureMapImpl::find_local_future(
                                                       const DomainPoint &point)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(future_map_domain->contains_point(point));
#endif
      Domain domain, range;
      future_map_domain->get_domain(domain);
      previous->future_map_domain->get_domain(range);
      if (is_functor)
      {
        const DomainPoint transformed = 
          transform.functor->transform_point(point, domain, range);
#ifdef DEBUG_LEGION
        assert(previous->future_map_domain->contains_point(transformed));
#endif
        return previous->find_local_future(transformed);
      }
      else
      {
        const DomainPoint transformed = (*transform.fnptr)(point,domain,range);
#ifdef DEBUG_LEGION
        assert(previous->future_map_domain->contains_point(transformed));
#endif
        return previous->find_local_future(transformed);
      } 
    }

    //--------------------------------------------------------------------------
    void TransformFutureMapImpl::get_shard_local_futures(ShardID shard,
                                     std::map<DomainPoint,FutureImpl*> &futures)
    //--------------------------------------------------------------------------
    {
      std::map<DomainPoint,FutureImpl*> previous_futures;
      previous->get_shard_local_futures(shard, previous_futures);
      Domain domain, range;
      future_map_domain->get_domain(domain);
      previous->future_map_domain->get_domain(range);
      if (is_functor)
      {
        if (transform.functor->is_invertible())
        {
          for (std::map<DomainPoint,FutureImpl*>::const_iterator it =
                previous_futures.begin(); it != previous_futures.end(); it++)
          {
            const DomainPoint inverted =
              transform.functor->invert_point(it->first, domain, range);
#ifdef DEBUG_LEGION
            assert(future_map_domain->contains_point(inverted));
#endif
            futures[inverted] = it->second;
          }
        }
        else
        {
          // Not invertible so do it the hard way by enumerating all
          // the points and seeing which ones we find
          for (Domain::DomainPointIterator itr(domain); itr; itr++)
          {
            const DomainPoint transformed = 
              transform.functor->transform_point(itr.p, domain, range);
#ifdef DEBUG_LEGION
            assert(previous->future_map_domain->contains_point(transformed));
#endif 
            std::map<DomainPoint,FutureImpl*>::const_iterator finder =
              previous_futures.find(transformed);
            if (finder != previous_futures.end())
              futures[itr.p] = finder->second;
          }
        }
      }
      else
      {
        // No easy way to invert a function pointer, so we iterate all
        // the points and just take the ones that we find
        for (Domain::DomainPointIterator itr(domain); itr; itr++)
        {
          const DomainPoint transformed = 
            (*transform.fnptr)(itr.p, domain, range);
#ifdef DEBUG_LEGION
          assert(previous->future_map_domain->contains_point(transformed));
#endif 
          std::map<DomainPoint,FutureImpl*>::const_iterator finder =
            previous_futures.find(transformed);
          if (finder != previous_futures.end())
            futures[itr.p] = finder->second;
        }
      }
    }

    /////////////////////////////////////////////////////////////
    // Repl Future Map Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    ReplFutureMapImpl::ReplFutureMapImpl(TaskContext *ctx, ShardManager *man,
                                         Operation *op, IndexSpaceNode *domain,
                                         IndexSpaceNode *shard_dom, Runtime *rt, 
                                         DistributedID did, Provenance *prov,
                                         CollectiveMapping *mapping)
      : FutureMapImpl(ctx, op, domain, rt, did, prov,
                      false/*register now*/, mapping),
        shard_manager(man), shard_domain(shard_dom),
        op_depth(ctx->get_depth()), sharding_function(NULL), 
        own_sharding_function(false), collective_performed(false)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(shard_domain != NULL);
#endif
      shard_domain->add_nested_valid_ref(did);
      shard_manager->add_nested_gc_ref(did);
    }

    //--------------------------------------------------------------------------
    ReplFutureMapImpl::ReplFutureMapImpl(TaskContext *ctx, ShardManager *man,
                            Runtime *rt, IndexSpaceNode *domain,
                            IndexSpaceNode *shard_dom, DistributedID did, 
                            uint64_t coord,
                            Provenance *prov, CollectiveMapping *mapping)
      : FutureMapImpl(ctx, rt, domain, did, coord, prov, 
                      false/*register now*/, mapping),
        shard_manager(man), shard_domain(shard_dom),
        op_depth(ctx->get_depth()), sharding_function(NULL),
        own_sharding_function(false), collective_performed(false)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(shard_domain != NULL);
#endif
      shard_domain->add_nested_valid_ref(did);
      shard_manager->add_nested_gc_ref(did);
    }

    //--------------------------------------------------------------------------
    ReplFutureMapImpl::~ReplFutureMapImpl(void)
    //--------------------------------------------------------------------------
    { 
      if (shard_domain->remove_nested_valid_ref(did))
        delete shard_domain;
      if (shard_manager->remove_nested_gc_ref(did))
        delete shard_manager;
      if (own_sharding_function)
        delete sharding_function.load();
    }

    //--------------------------------------------------------------------------
    Future ReplFutureMapImpl::get_future(const DomainPoint &point,
                                         bool internal, RtEvent *wait_on)
    //--------------------------------------------------------------------------
    {
      // Do a quick check to see if we've already got it
      {
        AutoLock f_lock(future_map_lock,1,false/*exclusive*/);
        std::map<DomainPoint,FutureImpl*>::const_iterator finder = 
          futures.find(point);
        if (finder != futures.end())
          return Future(finder->second);
      }
      // Now we need to figure out which shard we're on, see if we know
      // the sharding function yet, if not we have to wait
      if (sharding_function == NULL)
      {
        RtEvent wait_on = get_sharding_function_ready();
        if (wait_on.exists() && !wait_on.has_triggered())
          wait_on.wait();
      }
      Domain domain;
      shard_domain->get_domain(domain);
      const ShardID owner_shard = 
        sharding_function.load()->find_owner(point, domain);
      // Figure out which node has this future
      const AddressSpaceID space = shard_manager->get_shard_space(owner_shard); 
      if (space != runtime->address_space)
      {
        // Make an event for when we have the answer
        RtUserEvent future_ready_event = Runtime::create_rt_user_event();
        // If not send a message to get it
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(did);
          rez.serialize(point);
          rez.serialize(future_ready_event);
          rez.serialize<bool>(internal);
        }
        runtime->send_future_map_request_future(space, rez);
        if (wait_on != NULL)
        {
          *wait_on = future_ready_event;
          return Future();
        }
        future_ready_event.wait();
        // Now we can wake up see if we found it
        AutoLock f_lock(future_map_lock,1,false/*exclusive*/);
        std::map<DomainPoint,FutureImpl*>::const_iterator finder = 
          futures.find(point);
#ifdef DEBUG_LEGION
        assert(finder != futures.end());
#endif
        return Future(finder->second);
      }
      else // If we're the owner shard we can just do the normal thing
      {
        AutoLock fm_lock(future_map_lock);
        // Check to see if we already have a future for the point
        std::map<DomainPoint,FutureImpl*>::const_iterator finder = 
                                              futures.find(point);
        if (finder != futures.end())
          return Future(finder->second);
        // Otherwise we need a future from the context to use for
        // the point that we will fill in later
        FutureImpl *result = new FutureImpl(context, runtime, true/*register*/,
              runtime->get_available_distributed_id(), op, op_gen, 
              ContextCoordinate(blocking_index, point),
              op_uid, op_depth, provenance);
        result->add_nested_gc_ref(did);
        result->add_nested_resource_ref(did);
        futures[point] = result;
        if (runtime->legion_spy_enabled)
          LegionSpy::log_future_creation(op_uid, result->did, point);
        return Future(result);
      }
    }

    //--------------------------------------------------------------------------
    void ReplFutureMapImpl::get_all_futures(
                                      std::map<DomainPoint,FutureImpl*> &others)
    //--------------------------------------------------------------------------
    {
      // We know this call only comes from the application so we don't
      // need to worry about thread safety
      if (!collective_performed)
      {
#ifdef DEBUG_LEGION
        ReplicateContext *repl_ctx =
          dynamic_cast<ReplicateContext*>(implicit_context);
        assert(repl_ctx != NULL);
#else
        ReplicateContext *repl_ctx =
          static_cast<ReplicateContext*>(implicit_context);
#endif
        for (int i = 0; runtime->safe_control_replication && (i < 2); i++)
        {
          ReplicateContext::HashVerifier hasher(repl_ctx, 
              runtime->safe_control_replication > 1, i > 0);
          hasher.hash(
              ReplicateContext::REPLICATE_FUTURE_MAP_GET_ALL_FUTURES, __func__);
          repl_ctx->hash_future_map(hasher, FutureMap(this), "future map");
          if (hasher.verify(__func__))
            break;
        }
        std::map<DomainPoint,FutureImpl*> local_futures;
        get_shard_local_futures(repl_ctx->owner_shard->shard_id, local_futures);
        FutureNameExchange collective(repl_ctx, COLLECTIVE_LOC_32);
        collective.exchange_future_names(local_futures);
        AutoLock f_lock(future_map_lock);
        for (std::map<DomainPoint,FutureImpl*>::const_iterator it =
              local_futures.begin(); it != local_futures.end(); it++)
        {
          if (futures.insert(*it).second)
          {
            it->second->add_nested_resource_ref(did);
            it->second->add_nested_gc_ref(did);
          }
        }
        collective_performed = true; 
      }
      // No need for the lock now that we know that we have all of them
      others = futures;
    }

    //--------------------------------------------------------------------------
    void ReplFutureMapImpl::get_shard_local_futures(ShardID local_shard,
                                      std::map<DomainPoint,FutureImpl*> &others)
    //--------------------------------------------------------------------------
    {
      Domain sharding_domain;
      shard_domain->get_domain(sharding_domain);
      if (sharding_function == NULL)
      {
        RtEvent wait_on = get_sharding_function_ready();
        if (wait_on.exists() && !wait_on.has_triggered())
          wait_on.wait();
      }
      ShardingFunction *function = sharding_function.load();
      IndexSpace local_space = function->find_shard_space(
          local_shard, future_map_domain, shard_domain->handle, provenance);
      // Handle the case where there are no points for the local shard
      if (!local_space.exists())
        return;
      IndexSpaceNode *local_points = runtime->forest->get_node(local_space);
      Domain domain;
      local_points->get_domain(domain);
      std::vector<RtEvent> ready_events;
      for (Domain::DomainPointIterator itr(domain); itr; itr++)
      {
        const ShardID shard = function->find_owner(itr.p, sharding_domain);
        if (shard == local_shard)
        {
          RtEvent ready;
          others[itr.p] = get_future(itr.p, true/*internal*/, &ready).impl;
          if (ready.exists())
            ready_events.push_back(ready);
        }
      }
      if (!ready_events.empty())
      {
        const RtEvent wait_on = Runtime::merge_events(ready_events);
        if (wait_on.exists() && !wait_on.has_triggered())
          wait_on.wait();
      }
    }

    //--------------------------------------------------------------------------
    bool ReplFutureMapImpl::set_sharding_function(ShardingFunction *function,
                                                  bool own_function)
    //--------------------------------------------------------------------------
    {
      // Deduplicate sharding function sets across multiple shards
      RtUserEvent to_trigger;
      {
        AutoLock fm_lock(future_map_lock);
        if (sharding_function == NULL)
        {
          sharding_function = function;
          own_sharding_function = own_function;
          to_trigger = sharding_function_ready;
        }
        else 
          return false;
      }
      if (to_trigger.exists())
        Runtime::trigger_event(to_trigger);
      return true;
    }

    //--------------------------------------------------------------------------
    RtEvent ReplFutureMapImpl::get_sharding_function_ready(void)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_map_lock);
      if (sharding_function == NULL)
      {
        if (!sharding_function_ready.exists())
          sharding_function_ready = Runtime::create_rt_user_event();
        return sharding_function_ready;
      }
      else
        return RtEvent::NO_RT_EVENT;
    }

    /////////////////////////////////////////////////////////////
    // Physical Region Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    PhysicalRegionImpl::PhysicalRegionImpl(const RegionRequirement &r, 
      RtEvent mapped, ApEvent ready, ApUserEvent term, bool m, TaskContext *ctx, 
      MapperID mid, MappingTagID t, bool leaf, bool virt, bool col,
      uint64_t blocking, Runtime *rt)
      : Collectable(), runtime(rt), context(ctx), map_id(mid), tag(t),
        leaf_region(leaf), virtual_mapped(virt), collective(col),
        replaying((ctx != NULL) ? ctx->owner_task->is_replaying() : false),
        req(r),mapped_event(mapped),ready_event(ready),termination_event(term),
        blocking_index(blocking), mapped(m), valid(false), made_accessor(false)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    PhysicalRegionImpl::~PhysicalRegionImpl(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!termination_event.exists());
#endif
      if (!references.empty() && !replaying)
      {
        if (leaf_region)
          references.remove_resource_references(PHYSICAL_REGION_REF);
        else
          references.remove_valid_references(PHYSICAL_REGION_REF);
      }
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::wait_until_valid(bool silence_warnings, 
                                              const char *warning_string,
                                              bool warn, const char *source)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(implicit_context != NULL);
      assert(implicit_context == context);
#endif
      context->record_blocking_call(blocking_index);
      if (runtime->runtime_warnings && !silence_warnings &&
          (context != NULL) && !context->is_leaf_context())
      {
        if (source != NULL)
          REPORT_LEGION_WARNING(LEGION_WARNING_WAITING_REGION, 
              "Waiting for a physical region to be valid "
              "for call %s in non-leaf task %s (UID %lld) is a violation of "
              "Legion's deferred execution model best practices. You may "
              "notice a severe performance degradation. Warning string: %s", 
              source, context->get_task_name(), context->get_unique_id(),
              (warning_string == NULL) ? "" : warning_string)
        else
          REPORT_LEGION_WARNING(LEGION_WARNING_WAITING_REGION, 
              "Waiting for a physical region to be valid "
              "in non-leaf task %s (UID %lld) is a violation of Legion's "
              "deferred execution model best practices. You may notice a "
              "severe performance degradation. Warning string: %s", 
              context->get_task_name(), context->get_unique_id(),
              (warning_string == NULL) ? "" : warning_string)
      }
      if (mapped_event.exists() && !mapped_event.has_triggered())
      {
        if (warn && !silence_warnings && (source != NULL))
          REPORT_LEGION_WARNING(LEGION_WARNING_MISSING_REGION_WAIT, 
              "Request for %s was performed on a "
              "physical region in task %s (ID %lld) without first waiting "
              "for the physical region to be valid. Legion is performing "
              "the wait for you. Warning string: %s", source, 
              context->get_task_name(), context->get_unique_id(),
              (warning_string == NULL) ? "" : warning_string)
        mapped_event.wait();
      }
      // If we've already gone through this process we're good
      if (valid)
        return;
      // Now wait for the reference to be ready
      bool poisoned = false;
      if (!ready_event.has_triggered_faultaware(poisoned))
      {
        if (!poisoned)
          ready_event.wait_faultaware(poisoned);
      }
      if (poisoned)
        context->raise_poison_exception();
      valid = true;
    }

    //--------------------------------------------------------------------------
    bool PhysicalRegionImpl::is_valid(void) const
    //--------------------------------------------------------------------------
    {
      if (valid)
        return true;
      if (!mapped_event.exists() || mapped_event.has_triggered())
      {
        bool poisoned = false;
        if (ready_event.has_triggered_faultaware(poisoned))
          return true;
        if (poisoned)
          implicit_context->raise_poison_exception();
      }
      return false;
    }

    //--------------------------------------------------------------------------
    bool PhysicalRegionImpl::is_mapped(void) const
    //--------------------------------------------------------------------------
    {
      return mapped;
    }

    //--------------------------------------------------------------------------
    LogicalRegion PhysicalRegionImpl::get_logical_region(void) const
    //--------------------------------------------------------------------------
    {
      return req.region;
    }

    //--------------------------------------------------------------------------
    PrivilegeMode PhysicalRegionImpl::get_privilege(void) const
    //--------------------------------------------------------------------------
    {
      return req.privilege;
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::unmap_region(void)
    //--------------------------------------------------------------------------
    {
      if (!mapped)
        return;
#ifdef DEBUG_LEGION
      assert(termination_event.exists());
#endif
      // trigger the termination event conditional upon the ready event
      Runtime::trigger_event(NULL, termination_event, ready_event);
#ifdef LEGION_SPY
      // This is a really mind-bending corner case so be prepared 
      // If we're doing a trace replay and we actually end up replaying a 
      // physical template, we need to make it look to Legion Spy like the
      // fence at the beginning of the trace depends on any mapped physical 
      // regions in the context that will be unmapped during the execution 
      // of the trace otherwise Legion Spy will be unhappy with its validation.
      // We can fake this because it is already safe by definition, but just
      // in a way that Legion Spy can't actually see with its analysis. There
      // are two different sceanrios in the case where unmapping of physical
      // region occurs inside of the trace:
      // 1. the application doesn't unmap before launching a task or other
      //    operation that uses an interfering region requirement and the
      //    runtime has to insert unmap/remap operations which by definition
      //    will prevent a physical template from being captured because
      //    inline mapping operations are not (and never will be) memoizable
      //    so on all future traces we can only do logical analysis
      // 2. the application does its own unmap before a conflicting use of 
      //    the logical region which creates an implicit happens-before
      //    relationship between the unmap and any uses by the template 
      //    because operations can't be replayed before they are launched
      // There we can see this is trivially safe, but we need to create this
      // explicit event relationship for Legion Spy here to keep it happy
      const ApEvent tracing_replay_event = context->get_tracing_replay_event();
      if (tracing_replay_event.exists())
        LegionSpy::log_event_dependence(termination_event,tracing_replay_event);
#endif
#ifdef DEBUG_LEGION
      termination_event = ApUserEvent::NO_AP_USER_EVENT;
#endif
      mapped = false;
      valid = false;
    }

    //--------------------------------------------------------------------------
    ApEvent PhysicalRegionImpl::remap_region(ApEvent new_ready,
                                             uint64_t blocking)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!mapped);
      assert(!termination_event.exists());
#endif
      blocking_index = blocking;
      termination_event = Runtime::create_ap_user_event(NULL);
      ready_event = new_ready;
      mapped = true;
      return termination_event;
    }

    //--------------------------------------------------------------------------
    const RegionRequirement& PhysicalRegionImpl::get_requirement(void) const
    //--------------------------------------------------------------------------
    {
      return req;
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::add_padded_field(FieldID fid)
    //--------------------------------------------------------------------------
    {
      padded_fields.push_back(fid);
      // Resort to keep things in order
      if (padded_fields.size() > 1)
        std::sort(padded_fields.begin(), padded_fields.end());
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::set_reference(const InstanceRef &ref, bool safe)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(ref.has_ref());
      assert(references.empty());
      assert(safe || (mapped_event.exists() && !mapped_event.has_triggered()));
#endif
      references.add_instance(ref);
      if (!replaying)
      {
        if (leaf_region)
          ref.add_resource_reference(PHYSICAL_REGION_REF);
        else
          ref.add_valid_reference(PHYSICAL_REGION_REF);
      }
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::set_references(const InstanceSet &refs, bool safe)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(references.empty());
      assert(safe || (mapped_event.exists() && !mapped_event.has_triggered()));
#endif
      references = refs;
      if (!references.empty() && !replaying)
      {
        if (leaf_region)
          references.add_resource_references(PHYSICAL_REGION_REF);
        else
          references.add_valid_references(PHYSICAL_REGION_REF);
      }
    }

    //--------------------------------------------------------------------------
    bool PhysicalRegionImpl::has_references(void) const
    //--------------------------------------------------------------------------
    {
      return !references.empty();
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::get_references(InstanceSet &instances) const
    //--------------------------------------------------------------------------
    {
      if (mapped_event.exists() && !mapped_event.has_triggered())
        mapped_event.wait();
      instances = references;
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::get_memories(std::set<Memory>& memories,
                        bool silence_warnings, const char *warning_string) const
    //--------------------------------------------------------------------------
    {
      if (mapped_event.exists() && !mapped_event.has_triggered())
      {
        if (runtime->runtime_warnings && !silence_warnings)
          REPORT_LEGION_WARNING(LEGION_WARNING_MISSING_REGION_WAIT, 
              "Request for 'get_memories' was performed on a "
              "physical region in task %s (ID %lld) without first waiting "
              "for the physical region to be valid. Legion is performing "
              "the wait for you. Warning string: %s", context->get_task_name(), 
              context->get_unique_id(), (warning_string == NULL) ? 
              "" : warning_string)
        mapped_event.wait();
      }
      const InstanceSet &instances = references;
      for (unsigned idx = 0; idx < instances.size(); idx++)
        memories.insert(instances[idx].get_memory());
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::get_fields(std::vector<FieldID>& fields) const
    //--------------------------------------------------------------------------
    {
      // Just get these from the region requirement
      fields.insert(fields.end(), req.privilege_fields.begin(),
                    req.privilege_fields.end());
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::get_bounds(void *realm_is, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      runtime->get_index_space_domain(req.region.get_index_space(),
                                      realm_is, type_tag);
    }

    //--------------------------------------------------------------------------
    PieceIteratorImpl* PhysicalRegionImpl::get_piece_iterator(FieldID fid,
         bool privilege_only, bool silence_warnings, const char *warning_string)
    //--------------------------------------------------------------------------
    {
      if (req.privilege_fields.find(fid) == req.privilege_fields.end())
        REPORT_LEGION_ERROR(ERROR_INVALID_FIELD_PRIVILEGES, 
                       "Piece iterator construction in task %s on "
                       "PhysicalRegion that does not contain field %d!", 
                       context->get_task_name(), fid)
      if (mapped_event.exists() && !mapped_event.has_triggered())
      {
        if (runtime->runtime_warnings && !silence_warnings)
          REPORT_LEGION_WARNING(LEGION_WARNING_MISSING_REGION_WAIT, 
              "Request for 'get_piece_iterator' was performed on a "
              "physical region in task %s (ID %lld) without first waiting "
              "for the physical region to be valid. Legion is performing "
              "the wait for you. Warning string: %s", context->get_task_name(), 
              context->get_unique_id(), (warning_string == NULL) ? 
              "" : warning_string)
        mapped_event.wait();
      }
      const InstanceSet &instances = references;
      for (unsigned idx = 0; idx < instances.size(); idx++)
      {
        const InstanceRef &ref = instances[idx];
        if (ref.is_field_set(fid))
        {
          PhysicalManager *manager = ref.get_physical_manager();
          if (privilege_only)
          {
            IndexSpaceNode *privilege_node =
              runtime->forest->get_node(req.region.get_index_space());
            return manager->create_piece_iterator(privilege_node);
          }
          else
            return manager->create_piece_iterator(NULL);
        }
      }
      assert(false);
      return NULL;
    }
    
    //--------------------------------------------------------------------------
    PhysicalInstance PhysicalRegionImpl::get_instance_info(PrivilegeMode mode, 
                                              FieldID fid, size_t field_size, 
                                              void *realm_is, TypeTag type_tag,
                                              const char *warning_string,
                                              bool silence_warnings, 
                                              bool generic_accessor,
                                              bool check_field_size,
                                              ReductionOpID redop)
    //--------------------------------------------------------------------------
    { 
      // Check the privilege mode first
      switch (mode)
      {
        case LEGION_READ_ONLY:
          {
            if (!(LEGION_READ_ONLY & req.privilege))
              REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                            "Error creating read-only field accessor without "
                            "read-only privileges on field %d in task %s",
                            fid, context->get_task_name())
            break;
          }
        case LEGION_READ_WRITE:
          {
            if (req.privilege == LEGION_WRITE_DISCARD)
            {
              if (!silence_warnings)
                REPORT_LEGION_WARNING(LEGION_WARNING_READ_DISCARD, 
                                "creating read-write accessor for "
                                "field %d in task %s which only has "
                                "WRITE_DISCARD privileges. You may be "
                                "accessing uninitialized data. "
                                "Warning string: %s",
                                fid, context->get_task_name(),
                                (warning_string == NULL) ? "" : warning_string)
            }
            else if (req.privilege != LEGION_READ_WRITE)
              REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                            "Error creating read-write field accessor without "
                            "read-write privileges on field %d in task %s",
                            fid, context->get_task_name())
            break;
          }
        case LEGION_WRITE_ONLY:
        case LEGION_WRITE_DISCARD:
          {
            if (!(LEGION_WRITE_ONLY & req.privilege))
              REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                            "Error creating write-discard field accessor "
                            "without write privileges on field %d in task %s",
                            fid, context->get_task_name())
            break;
          }
        case LEGION_REDUCE:
          {
            if ((LEGION_REDUCE != req.privilege) || (redop != req.redop))
            {
              if (!(LEGION_REDUCE & req.privilege))
                REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                              "Error creating reduction field accessor "
                              "without reduction privileges on field %d in "
                              "task %s", fid, context->get_task_name())
              else if ((redop != req.redop) && 
                       (req.privilege != LEGION_READ_WRITE))
                REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                              "Error creating reduction field accessor "
                              "with mismatched reduction operators %d and %d "
                              "on field %d in task %s", redop, req.redop,
                              fid, context->get_task_name())
#ifdef DEBUG_LEGION
              assert(req.privilege == LEGION_READ_WRITE);
#endif
            }
            break;
          }
        default: // rest of the privileges don't matter
          break;
      }
      if (context != NULL)
      {
        if (context->is_inner_context())
          REPORT_LEGION_ERROR(ERROR_INNER_TASK_VIOLATION, 
            "Illegal accessor construction inside "
            "task %s (UID %lld) for a variant that was labeled as an 'inner' "
            "variant.", context->get_task_name(), context->get_unique_id())
        else if (runtime->runtime_warnings && !silence_warnings &&
                  !context->is_leaf_context())
          REPORT_LEGION_WARNING(LEGION_WARNING_NONLEAF_ACCESSOR, 
              "Accessor construction in non-leaf "
              "task %s (UID %lld) is a blocking operation in violation of "
              "Legion's deferred execution model best practices. You may "
              "notice a severe performance degradation. Warning string: %s",
              context->get_task_name(), context->get_unique_id(),
              (warning_string == NULL) ? "" : warning_string)
      }
      // If this physical region isn't mapped, then we have to
      // map it before we can return an accessor
      if (!mapped)
      {
        if (virtual_mapped)
          REPORT_LEGION_ERROR(ERROR_ILLEGAL_IMPLICIT_MAPPING, 
                        "Illegal implicit mapping of a virtual mapped region "
                        "in task %s (UID %lld)", context->get_task_name(),
                        context->get_unique_id())
        if (runtime->runtime_warnings && !silence_warnings)
          REPORT_LEGION_WARNING(LEGION_WARNING_UNMAPPED_ACCESSOR, 
                          "Accessor construction was "
                          "performed on an unmapped region in task %s "
                          "(UID %lld). Legion is mapping it for you. "
                          "Please try to be more careful. Warning string: %s",
                          context->get_task_name(), context->get_unique_id(),
                          (warning_string == NULL) ? "" : warning_string)
        runtime->remap_region(context, PhysicalRegion(this));
        // At this point we should have a new ready event
        // and be mapped
#ifdef DEBUG_LEGION
        assert(mapped);
#endif 
      }
      if (req.privilege_fields.find(fid) == req.privilege_fields.end())
        REPORT_LEGION_ERROR(ERROR_INVALID_FIELD_PRIVILEGES, 
                       "Accessor construction for field %d in task %s "
                       "without privileges!", fid, context->get_task_name())
      if (generic_accessor && runtime->runtime_warnings && !silence_warnings)
        REPORT_LEGION_WARNING(LEGION_WARNING_GENERIC_ACCESSOR,
                              "Using a generic accessor for accessing a "
                              "physical instance of task %s (UID %lld). "
                              "Generic accessors are very slow and are "
                              "strongly discouraged for use in high "
                              "performance code. Warning string: %s", 
                              context->get_task_name(),
                              context->get_unique_id(),
                              (warning_string == NULL) ? "" : warning_string)
      // Get the index space to use for the accessor
      IndexSpaceNode *bounds = 
        runtime->forest->get_node(req.region.get_index_space());
      // Check to see if this is a padded field, if it is then we need to 
      // merge the padding into the resulting domain that is allowed
      // to be accessed by the accessor for bounds checks
      bool need_padded_bounds = false;
      if (!std::binary_search(padded_fields.begin(), padded_fields.end(), fid))
        bounds->get_index_space_domain(realm_is, type_tag);
      else
        need_padded_bounds = true;
      // Wait until we are valid before returning the accessor
      wait_until_valid(silence_warnings, warning_string,
                       runtime->runtime_warnings, "Accessor Construction");
      made_accessor = true;
      const InstanceSet &instances = references;
      for (unsigned idx = 0; idx < instances.size(); idx++)
      {
        const InstanceRef &ref = instances[idx];
        if (ref.is_field_set(fid))
        {
          PhysicalManager *manager = ref.get_physical_manager();
          if (check_field_size)
          {
            const size_t actual_size = 
              manager->field_space_node->get_field_size(fid);
            if (actual_size != field_size)
              REPORT_LEGION_ERROR(ERROR_ACCESSOR_FIELD_SIZE_CHECK,
                            "Error creating accessor for field %d with a "
                            "type of size %zd bytes when the field was "
                            "originally allocated with a size of %zd bytes "
                            "in task %s (UID %lld)",
                            fid, field_size, actual_size, 
                            context->get_task_name(), context->get_unique_id()) 
          }
          if (need_padded_bounds)
          {
            Domain domain;
            bounds->get_domain(domain);
#ifdef DEBUG_LEGION
            assert(domain.dense());
#endif
            // Do not add padding to empty domains
            if (!domain.empty())
            {
              // Now we can compute the bounds on this instance
              const Domain &delta= 
                manager->layout->constraints->padding_constraint.delta;
#ifdef DEBUG_LEGION
              assert(domain.get_dim() == delta.get_dim());
#endif
              const Domain padded_bounds =
                Domain(domain.lo() - delta.lo(), domain.hi() + delta.hi());
              switch (domain.get_dim())
              {
#define DIMFUNC(DIM) \
                case DIM: \
                  { \
                    RealmSpaceConverter<DIM,Realm::DIMTYPES>::convert_to( \
                      padded_bounds, realm_is, type_tag, "get_instance_info"); \
                    break; \
                  }
                LEGION_FOREACH_N(DIMFUNC)
#undef DIMFUNC
                default:
                  assert(false);
              }
            }
            else
              bounds->get_index_space_domain(realm_is, type_tag);
          }
          return manager->get_instance();
        }
      }
      // should never get here at worst there should have been an
      // error raised earlier in this function
      assert(false);
      return PhysicalInstance::NO_INST;
    }

    //--------------------------------------------------------------------------
    PhysicalInstance PhysicalRegionImpl::get_padding_info(FieldID fid,
                              size_t field_size, Domain *inner, Domain &outer,
                              const char *warning_string, bool silence_warnings,
                              bool generic_accessor, bool check_field_size)
    //--------------------------------------------------------------------------
    {
      if (!std::binary_search(padded_fields.begin(), padded_fields.end(), fid))
        REPORT_LEGION_ERROR(ERROR_INVALID_PADDED_ACCESSOR,
            "Illegal request to create a padded accessor for field %d in "
            "parent task %s (UID %lld) which does not have padded privileges. "
            "You must record a layout constraint with an explicit for padding "
            "constraint when registering this task variant in order to be able "
            "to access the padded space on this instance.",
            fid, context->get_task_name(), context->get_unique_id())
      if (context != NULL)
      {
        if (context->is_inner_context())
          REPORT_LEGION_ERROR(ERROR_INNER_TASK_VIOLATION, 
            "Illegal padding accessor construction inside "
            "task %s (UID %lld) for a variant that was labeled as an 'inner' "
            "variant.", context->get_task_name(), context->get_unique_id())
        else if (runtime->runtime_warnings && !silence_warnings &&
                  !context->is_leaf_context())
          REPORT_LEGION_WARNING(LEGION_WARNING_NONLEAF_ACCESSOR, 
              "Padding ccessor construction in non-leaf "
              "task %s (UID %lld) is a blocking operation in violation of "
              "Legion's deferred execution model best practices. You may "
              "notice a severe performance degradation. Warning string: %s",
              context->get_task_name(), context->get_unique_id(),
              (warning_string == NULL) ? "" : warning_string)
      }
      if (req.privilege_fields.find(fid) == req.privilege_fields.end())
        REPORT_LEGION_ERROR(ERROR_INVALID_FIELD_PRIVILEGES, 
                       "Padding accessor construction for field %d in task %s "
                       "without privileges!", fid, context->get_task_name())
      if (generic_accessor && runtime->runtime_warnings && !silence_warnings)
        REPORT_LEGION_WARNING(LEGION_WARNING_GENERIC_ACCESSOR,
                              "Using a generic accessor for accessing a "
                              "physical instance of task %s (UID %lld). "
                              "Generic accessors are very slow and are "
                              "strongly discouraged for use in high "
                              "performance code. Warning string: %s", 
                              context->get_task_name(),
                              context->get_unique_id(),
                              (warning_string == NULL) ? "" : warning_string)
      const InstanceSet &instances = references;
      for (unsigned idx = 0; idx < instances.size(); idx++)
      {
        const InstanceRef &ref = instances[idx];
        if (ref.is_field_set(fid))
        {
          PhysicalManager *manager = ref.get_physical_manager();
          if (check_field_size)
          {
            const size_t actual_size = 
              manager->field_space_node->get_field_size(fid);
            if (actual_size != field_size)
              REPORT_LEGION_ERROR(ERROR_ACCESSOR_FIELD_SIZE_CHECK,
                            "Error creating accessor for field %d with a "
                            "type of size %zd bytes when the field was "
                            "originally allocated with a size of %zd bytes "
                            "in task %s (UID %lld)",
                            fid, field_size, actual_size, 
                            context->get_task_name(), context->get_unique_id()) 
          }
          // If this is a padded instance, then we know that this is an affine
          // instance so we can get it's index space expression and it should
          // be dense so then we can just add the offsets
          Domain bounds;
          manager->instance_domain->get_domain(bounds);
#ifdef DEBUG_LEGION
          assert(bounds.dense());
#endif
          if (inner != NULL)
            *inner = bounds;
          if (!bounds.empty())
          {
            // Now we can compute the bounds on this instance
            const Domain &delta= 
              manager->layout->constraints->padding_constraint.delta;
#ifdef DEBUG_LEGION
            assert(bounds.get_dim() == delta.get_dim());
#endif
            outer = Domain(bounds.lo() - delta.lo(), bounds.hi() + delta.hi());
          }
          else
            outer = bounds;
          return manager->get_instance();
        }
      }
      // should never get here at worst there should have been an
      // error raised earlier in this function
      assert(false);
      return PhysicalInstance::NO_INST;
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::report_incompatible_accessor(
              const char *accessor_kind, PhysicalInstance instance, FieldID fid)
    //--------------------------------------------------------------------------
    {
      REPORT_LEGION_ERROR(ERROR_ACCESSOR_COMPATIBILITY_CHECK,
          "Unable to create Realm %s for field %d of instance %llx in task %s",
          accessor_kind, fid, instance.id, context->get_task_name())
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::report_incompatible_multi_accessor(unsigned index,
                    FieldID fid, PhysicalInstance inst1, PhysicalInstance inst2)
    //--------------------------------------------------------------------------
    {
      REPORT_LEGION_ERROR(ERROR_ACCESSOR_COMPATIBILITY_CHECK,
          "Unable to create multi-region accessor for field %d because "
          "instances " IDFMT " (index 0) and " IDFMT " (index %d) are "
          "differnt. Multi-region accessors must always be for region "
          "requirements with the same physical instance.", 
          fid, inst1.id, inst2.id, index)
    }

    //--------------------------------------------------------------------------
    void PhysicalRegionImpl::report_colocation_violation(
            const char *accessor_kind, FieldID fid, PhysicalInstance inst1,
            PhysicalInstance inst2, const PhysicalRegion &other, bool reduction)
    //--------------------------------------------------------------------------
    {
      REPORT_LEGION_ERROR(ERROR_COLOCATION_VIOLATION,
          "Unable to create co-location %s<%s> from multiple physical regions "
          "for field %d in task %s because regions have different physical "
          "instances " IDFMT " and  " IDFMT, reduction ? "ReductionAccessor" :
            "FieldAccessor", accessor_kind, fid, context->get_task_name(),
            inst1.id, inst2.id)
    }

    //--------------------------------------------------------------------------
    /*static*/ void PhysicalRegionImpl::empty_colocation_regions(
                         const char *accessor_kind, FieldID fid, bool reduction)
    //--------------------------------------------------------------------------
    {
      REPORT_LEGION_ERROR(ERROR_COLOCATION_VIOLATION,
          "Attempt to create colocation %s<%s> with no physical regions for "
          "field %d task %s. Must provide a non-empty set of regions.",
          reduction ? "ReductionAccessor" : "FieldAccessor", accessor_kind,
          fid, implicit_context->get_task_name())
    }

    //--------------------------------------------------------------------------
    /*static*/ void PhysicalRegionImpl::fail_bounds_check(DomainPoint p, 
                                    FieldID fid, PrivilegeMode mode, bool multi)
    //--------------------------------------------------------------------------
    {
      char point_string[128];
      snprintf(point_string, sizeof point_string, " (");
      for (int d = 0; d < p.get_dim(); d++)
      {
        char buffer[32];
        if (d == 0)
          snprintf(buffer, sizeof buffer, "%lld", p[0]);
        else
          snprintf(buffer, sizeof buffer, ",%lld", p[d]);
        strcat(point_string, buffer);
      }
      strcat(point_string,")");
      switch (mode)
      {
        case LEGION_READ_ONLY:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_BOUNDS_CHECK, 
                          "Bounds check failure reading point %s from "
                          "field %d in task %s%s\n", point_string, fid,
                          implicit_context->get_task_name(),
                          multi ? " for multi-region accessor" : "")
            break;
          }
        case LEGION_READ_WRITE:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_BOUNDS_CHECK, 
                          "Bounds check failure geting a reference to point %s "
                          "from field %d in task %s%s\n", point_string, fid,
                          implicit_context->get_task_name(),
                          multi ? " for multi-region accessor" : "")
            break;
          }
        case LEGION_WRITE_ONLY:
        case LEGION_WRITE_DISCARD:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_BOUNDS_CHECK, 
                          "Bounds check failure writing to point %s in "
                          "field %d in task %s%s\n", point_string, fid,
                          implicit_context->get_task_name(),
                          multi ? " for multi-region accessor" : "")
            break;
          }
        case LEGION_REDUCE:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_BOUNDS_CHECK, 
                          "Bounds check failure reducing to point %s in "
                          "field %d in task %s%s\n", point_string, fid,
                          implicit_context->get_task_name(),
                          multi ? " for multi-region accessor" : "")
            break;
          }
        default:
          assert(false);
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ void PhysicalRegionImpl::fail_bounds_check(Domain dom, 
                                    FieldID fid, PrivilegeMode mode, bool multi)
    //--------------------------------------------------------------------------
    {
      char rect_string[256];
      snprintf(rect_string, sizeof rect_string, " (");
      for (int d = 0; d < dom.get_dim(); d++)
      {
        char buffer[32];
        if (d == 0)
          snprintf(buffer, sizeof buffer, "%lld", dom.lo()[0]);
        else
          snprintf(buffer, sizeof buffer, ",%lld", dom.lo()[d]);
        strcat(rect_string, buffer);
      }
      strcat(rect_string,") - (");
      for (int d = 0; d < dom.get_dim(); d++)
      {
        char buffer[32];
        if (d == 0)
          snprintf(buffer, sizeof buffer, "%lld", dom.hi()[0]);
        else
          snprintf(buffer, sizeof buffer, ",%lld", dom.hi()[d]);
        strcat(rect_string, buffer);
      }
      strcat(rect_string,")");
      switch (mode)
      {
        case LEGION_READ_ONLY:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_BOUNDS_CHECK, 
                          "Bounds check failure getting a read-only reference "
                          "to rect %s from field %d in task %s%s\n", 
                          rect_string, fid, implicit_context->get_task_name(),
                          multi ? " for multi-region accessor" : "")
            break;
          }
        case LEGION_READ_WRITE:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_BOUNDS_CHECK, 
                          "Bounds check failure geting a reference to rect %s "
                          "from field %d in task %s%s\n", rect_string, fid,
                          implicit_context->get_task_name(),
                          multi ? " for multi-region accessor" : "")
            break;
          }
        default:
          assert(false);
      }
    } 

    //--------------------------------------------------------------------------
    /*static*/ void PhysicalRegionImpl::fail_privilege_check(DomainPoint p, 
                                                FieldID fid, PrivilegeMode mode)
    //--------------------------------------------------------------------------
    {
      char point_string[128];
      snprintf(point_string, sizeof point_string, " (");
      for (int d = 0; d < p.get_dim(); d++)
      {
        char buffer[32];
        if (d == 0)
          snprintf(buffer, sizeof buffer, "%lld", p[0]);
        else
          snprintf(buffer, sizeof buffer, ",%lld", p[d]);
        strcat(point_string, buffer);
      }
      strcat(point_string,")");
      switch (mode)
      {
        case LEGION_READ_ONLY:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                          "Privilege check failure reading point %s from "
                          "field %d in task %s\n", point_string, fid,
                          implicit_context->get_task_name())
            break;
          }
        case LEGION_READ_WRITE:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                          "Privilege check failure geting a reference to point "
                          "%s from field %d in task %s\n", point_string, fid,
                          implicit_context->get_task_name())
            break;
          }
        case LEGION_WRITE_ONLY:
        case LEGION_WRITE_DISCARD:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                          "Privilege check failure writing to point %s in "
                          "field %d in task %s\n", point_string, fid,
                          implicit_context->get_task_name())
            break;
          }
        case LEGION_REDUCE:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                          "Privilege check failure reducing to point %s in "
                          "field %d in task %s\n", point_string, fid,
                          implicit_context->get_task_name())
            break;
          }
        default:
          assert(false);
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ void PhysicalRegionImpl::fail_privilege_check(Domain dom, 
                                                FieldID fid, PrivilegeMode mode)
    //--------------------------------------------------------------------------
    {
      char rect_string[256];
      snprintf(rect_string, sizeof rect_string, " (");
      for (int d = 0; d < dom.get_dim(); d++)
      {
        char buffer[32];
        if (d == 0)
          snprintf(buffer, sizeof buffer, "%lld", dom.lo()[0]);
        else
          snprintf(buffer, sizeof buffer, ",%lld", dom.lo()[d]);
        strcat(rect_string, buffer);
      }
      strcat(rect_string,") - (");
      for (int d = 0; d < dom.get_dim(); d++)
      {
        char buffer[32];
        if (d == 0)
          snprintf(buffer, sizeof buffer, "%lld", dom.hi()[0]);
        else
          snprintf(buffer, sizeof buffer, ",%lld", dom.hi()[d]);
        strcat(rect_string, buffer);
      }
      strcat(rect_string,")");
      switch (mode)
      {
        case LEGION_READ_ONLY:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                          "Privilege check failure getting a read-only "
                          "reference to rect %s from field %d in task %s\n", 
                          rect_string, fid, implicit_context->get_task_name())
            break;
          }
        case LEGION_READ_WRITE:
          {
            REPORT_LEGION_ERROR(ERROR_ACCESSOR_PRIVILEGE_CHECK, 
                          "Privilege check failure geting a reference to rect "
                          "%s from field %d in task %s\n", rect_string, fid,
                          implicit_context->get_task_name())
            break;
          }
        default:
          assert(false);
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ void PhysicalRegionImpl::fail_padding_check(DomainPoint p,
                                                           FieldID fid)
    //--------------------------------------------------------------------------
    {
      char point_string[128];
      snprintf(point_string, sizeof point_string, " (");
      for (int d = 0; d < p.get_dim(); d++)
      {
        char buffer[32];
        if (d == 0)
          snprintf(buffer, sizeof buffer, "%lld", p[0]);
        else
          snprintf(buffer, sizeof buffer, ",%lld", p[d]);
        strcat(point_string, buffer);
      }
      strcat(point_string,")");
      REPORT_LEGION_ERROR(ERROR_ACCESSOR_BOUNDS_CHECK, 
                          "Bounds check failure accessing padded point %s from "
                          "field %d in task %s\n", point_string, fid,
                          implicit_context->get_task_name())
    }

    /////////////////////////////////////////////////////////////
    // Output Region Impl
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    OutputRegionImpl::OutputRegionImpl(unsigned idx,
                                       const OutputRequirement &r,
                                       const InstanceSet &instances,
                                       TaskContext *ctx, Runtime *rt,
                                       const bool global,
                                       const bool valid)
      : Collectable(), runtime(rt), context(ctx), req(r), 
        region(runtime->forest->get_node(req.region)), index(idx),
        created_region(
          (req.flags & LEGION_CREATED_OUTPUT_REQUIREMENT_FLAG) && !valid),
        global_indexing(global)
    //--------------------------------------------------------------------------
    {
      region->add_base_gc_ref(OUTPUT_REGION_REF);
      context->add_base_gc_ref(OUTPUT_REGION_REF);
      
      managers.resize(req.instance_fields.size(), NULL);
      for (unsigned idx = 0; idx < instances.size(); idx++)
      {
        const InstanceRef &ref = instances[idx];
        std::vector<FieldID> fields;
        region->column_source->get_field_set(ref.get_valid_fields(),
                                             context, fields);
        PhysicalManager *manager = ref.get_physical_manager();
        for (std::vector<FieldID>::const_iterator it =
              fields.begin(); it != fields.end(); it++)
        {
          std::vector<FieldID>::const_iterator finder =
            std::find(req.instance_fields.begin(), 
                      req.instance_fields.end(), *it);
#ifdef DEBUG_LEGION
          assert(finder != req.instance_fields.end());
#endif
          const unsigned offset = 
            std::distance(req.instance_fields.begin(), finder);
#ifdef DEBUG_LEGION
          assert(offset < managers.size());
          assert(managers[offset] == NULL);
#endif
          managers[offset] = manager;
          manager->add_base_gc_ref(OUTPUT_REGION_REF);
        }
      }
    }

    //--------------------------------------------------------------------------
    OutputRegionImpl::~OutputRegionImpl(void)
    //--------------------------------------------------------------------------
    {
      if (region->remove_base_gc_ref(OUTPUT_REGION_REF))
        delete region;
      if (context->remove_base_gc_ref(OUTPUT_REGION_REF))
        delete context;
      for (std::vector<PhysicalManager*>::const_iterator it =
            managers.begin(); it != managers.end(); it++)
        if ((*it)->remove_base_gc_ref(OUTPUT_REGION_REF))
          delete (*it);
    }

    //--------------------------------------------------------------------------
    Memory OutputRegionImpl::target_memory(void) const
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!managers.empty());
#endif
      return managers.front()->get_memory();
    }

    //--------------------------------------------------------------------------
    LogicalRegion OutputRegionImpl::get_logical_region(void) const
    //--------------------------------------------------------------------------
    {
      if (!is_valid_output_region())
        REPORT_LEGION_ERROR(ERROR_LOGICAL_REGION_FROM_INVALID_OUTPUT_REGION,
          "Logical region cannot be retrieved from output region %u of task %s "
          "(UID: %lld) whose index space is yet to be determined.",
          index, context->owner_task->get_task_name(), 
          context->owner_task->get_unique_op_id());

      return req.region;
    }

    //--------------------------------------------------------------------------
    bool OutputRegionImpl::is_valid_output_region(void) const
    //--------------------------------------------------------------------------
    {
      return !created_region;
    }

    //--------------------------------------------------------------------------
    void OutputRegionImpl::check_type_tag(TypeTag type_tag) const
    //--------------------------------------------------------------------------
    {
      if (type_tag == req.type_tag) return;

      REPORT_LEGION_ERROR(ERROR_INVALID_OUTPUT_REGION_RETURN,
        "The deferred buffer passed to output region %u of task %s (UID: %lld) "
        "is incompatible with the output region. Make sure the deferred buffer "
        "has the right dimension and the coordinate type.",
        index, context->owner_task->get_task_name(), 
        context->owner_task->get_unique_op_id());
    }

    //--------------------------------------------------------------------------
    void OutputRegionImpl::check_field_size(
                                      FieldID field_id, size_t field_size) const
    //--------------------------------------------------------------------------
    {
      size_t impl_field_size = get_field_size(field_id);
      if (field_size == impl_field_size) return;

      REPORT_LEGION_ERROR(ERROR_INVALID_OUTPUT_REGION_RETURN,
        "The deferred buffer passed to field %u of output region %u of task %s "
        "(UID: %lld) has elements of %zd bytes each, but the field size is "
        "%zd bytes. Make sure you pass a buffer of the right element type.",
        field_id, index, context->owner_task->get_task_name(),
        context->owner_task->get_unique_op_id(), field_size, impl_field_size);
    }

    //--------------------------------------------------------------------------
    void OutputRegionImpl::get_layout(FieldID field_id,
                                      std::vector<DimensionKind> &ordering,
                                      size_t &alignment) const
    //--------------------------------------------------------------------------
    {
      PhysicalManager *manager = get_manager(field_id);
      LayoutConstraints *cons = manager->layout->constraints;

#ifdef DEBUG_LEGION
      assert(cons->ordering_constraint.ordering.size() > 1);
      assert(cons->ordering_constraint.ordering.back() == LEGION_DIM_F);
#endif
      int32_t ndim = NT_TemplateHelper::get_dim(req.type_tag);
      DimensionKind max_dim =
        static_cast<DimensionKind>(static_cast<int32_t>(LEGION_DIM_X) + ndim);
      ordering.resize(ndim);
      uint32_t idx = 0;
      for (std::vector<DimensionKind>::const_iterator it =
           cons->ordering_constraint.ordering.begin(); it !=
           cons->ordering_constraint.ordering.end(); ++it)
      {
        if (*it < max_dim) ordering[idx++] = *it;
      }

      for (std::vector<AlignmentConstraint>::const_iterator it =
           cons->alignment_constraints.begin(); it !=
           cons->alignment_constraints.end(); ++it)
      {
        if (it->fid == field_id && it->eqk == LEGION_EQ_EK)
        {
          alignment = it->alignment;
          return;
        }
      }

      // If no alignment constraint was given, use the field size
      // for alignment
      alignment = get_field_size(field_id);
    }

    //--------------------------------------------------------------------------
    size_t OutputRegionImpl::get_field_size(FieldID field_id) const
    //--------------------------------------------------------------------------
    {
      std::vector<FieldID>::const_iterator finder = std::find(
          req.instance_fields.begin(), req.instance_fields.end(), field_id);
      if (finder == req.instance_fields.end())
      {
        REPORT_LEGION_ERROR(ERROR_INVALID_OUTPUT_REGION_FIELD,
          "Field %u does not exist in output region %u of task %s "
          "(UID: %lld).",
          field_id, index, context->owner_task->get_task_name(),
          context->owner_task->get_unique_op_id());
      }
      return region->column_source->get_field_size(field_id);
    }

    //--------------------------------------------------------------------------
    void OutputRegionImpl::return_data(const DomainPoint &new_extents,
                                       FieldID field_id,
                                       uintptr_t ptr,
                                       size_t alignment)
    //--------------------------------------------------------------------------
    {
      if (req.privilege_fields.find(field_id) == req.privilege_fields.end())
      {
          REPORT_LEGION_ERROR(ERROR_INVALID_OUTPUT_FIELD,
            "Output region %u of task %s (UID: %lld) does not have privilege "
            "on field %u.", index, context->owner_task->get_task_name(),
            context->owner_task->get_unique_op_id(), field_id);
      }
      std::map<FieldID,ReturnedInstanceInfo>::iterator finder =
        returned_instances.find(field_id);
      if (finder != returned_instances.end())
      {
        REPORT_LEGION_ERROR(ERROR_INVALID_OUTPUT_SIZE,
          "Data has already been set to field %u of output region %u of "
          "task %s (UID: %lld). You can return data for each field of an "
          "output region only once.",
          field_id, index, context->owner_task->get_task_name(),
          context->owner_task->get_unique_op_id());
      }

      if (extents.dim == 0)
      {
        extents = new_extents;
        if (created_region)
        {
          // We now know the extent so we can report it back
          // Set the result if we're not doing global indexing with a parent
          if (region->parent == NULL)
          {
            DomainPoint lo; lo.dim = extents.dim;
            Domain domain(lo, extents - 1);
            if (region->row_source->set_domain(domain, true/*broadcast*/))
              assert(false); // should never end up deleting this
          }
          else
          {
            DomainPoint color = region->row_source->get_domain_point_color();
            if (!global_indexing)
            {
              Domain domain;
              domain.dim = color.dim + extents.dim;
#ifdef DEBUG_LEGION
              assert(domain.dim <= LEGION_MAX_DIM);
#endif
              for (int idx = 0; idx < color.dim; ++idx)
              {
                domain.rect_data[idx] = color[idx];
                domain.rect_data[idx + domain.dim] = color[idx];
              }
              for (int idx = 0; idx < extents.dim; ++idx)
              {
                int off = color.dim + idx;
                domain.rect_data[off] = 0;
                domain.rect_data[domain.dim + off] = extents[idx] - 1;
              }
              if (region->row_source->set_domain(domain, true/*broadcast*/))
                assert(false); // should never end up deleting this
            }
            context->owner_task->record_output_extent(index, color, extents);
          }
        }
      }
      else if (new_extents != extents)
      {
        std::stringstream ss;
        ss << "Output region " << index << " of task "
           << context->owner_task->get_task_name() << " (UID: "
           << context->owner_task->get_unique_op_id() << ") has already been "
           << "initialized to extents " << extents << ", but the new output "
           << "has extents " << new_extents << ". You must return data having "
           << "the same extents to all the fields in the same output region.";
        REPORT_LEGION_ERROR(ERROR_INVALID_OUTPUT_SIZE, "%s", ss.str().c_str());
      }

      // Here we simply queue up the output data, rather than eagerly
      // creating and setting an instance to the output region.
      ReturnedInstanceInfo &info = returned_instances[field_id];
      // Sanitize the pointer when the size is 0
      size_t num_elements = 1;
      for (int32_t dim = 0; dim < extents.dim; ++dim)
        num_elements *= extents[dim];
      info.ptr = num_elements != 0 ? ptr : 0;
      info.alignment = alignment;
    }

    //--------------------------------------------------------------------------
    void OutputRegionImpl::return_data(
                              const DomainPoint &extents,
                              FieldID field_id,
                              PhysicalInstance instance,
                              const LayoutConstraintSet *constraints,
                              bool check_constraints)
    //--------------------------------------------------------------------------
    {
      PhysicalManager *manager = get_manager(field_id);
      if (instance.get_location() != manager->get_memory())
        REPORT_LEGION_ERROR(ERROR_INVALID_OUTPUT_SIZE,
          "Field %u of output region %u of task %s (UID: %lld) is requested "
          "to have an instance on memory " IDFMT ", but the returned instance "
          "is allocated on memory " IDFMT ".",
          field_id, index, context->owner_task->get_task_name(),
          context->owner_task->get_unique_op_id(),
          manager->get_memory().id, instance.get_location().id);

      if (!context->is_task_local_instance(instance))
        REPORT_LEGION_ERROR(ERROR_DUPLICATE_RETURN_REQUESTS,
          "Instance passed to field %u of output region %u of task %s "
          "(UID: %lld) is already bound to this field or some other fields. "
          "You cannot assign a buffer to more than one output region field. ",
          field_id, index, context->owner_task->get_task_name(),
          context->owner_task->get_unique_op_id());

      // The realm instance backing a deferred buffer is currently tagged as
      // a task local instance, so we need to tell the runtime that the instance
      // now escapes the context.
      context->escape_task_local_instance(instance);
      const uintptr_t ptr = 
        reinterpret_cast<uintptr_t>(instance.pointer_untyped(0,0)); 

      if (check_constraints && constraints != NULL)
      {
        bool has_conflict = false;

        LayoutConstraints *manager_cons = manager->layout->constraints;
        if (!req.global_indexing && context->owner_task->is_index_space)
        {
          // Unfortunately, for local indexing, the ordering constraint
          // prescribes the ordering of dimensions that the returned
          // buffer does not contain. (those dimensions are added
          // by the runtime and invisible to the point task.) So, here
          // we filter out the dimensions that would otherwise fail
          // the constraint check innocuously.
          LayoutConstraintSet copied;
          copied.alignment_constraints = manager_cons->alignment_constraints;
          std::vector<DimensionKind> ordering;
          int32_t ndim = NT_TemplateHelper::get_dim(req.type_tag);
          for (std::vector<DimensionKind>::const_iterator it =
               manager_cons->ordering_constraint.ordering.begin(); it !=
               manager_cons->ordering_constraint.ordering.end(); ++it)
          {
            int32_t dim = *it;
            if (dim - LEGION_DIM_X < ndim || dim == LEGION_DIM_F)
              ordering.push_back(static_cast<DimensionKind>(dim));
          }
          copied.ordering_constraint =
            OrderingConstraint(
              ordering, manager_cons->ordering_constraint.contiguous);

          has_conflict = constraints->conflicts(copied);
        }
        else
          has_conflict = constraints->conflicts(*manager_cons);

        if (has_conflict)
          REPORT_LEGION_FATAL(LEGION_FATAL_UNIMPLEMENTED_FEATURE,
            "The returned instance for field %u of output region %u of "
            "task %s (UID: %lld) does not satisfy the layout constraints "
            "chosen by the mapper. This is an illegal usage right now. "
            "In the future, the runtime will copy this returned instance "
            "into a fresh one with the correct layout.",
            field_id, index, context->owner_task->get_task_name(),
            context->owner_task->get_unique_op_id());
      }
      else if (check_constraints)
      {
        REPORT_LEGION_FATAL(LEGION_FATAL_UNIMPLEMENTED_FEATURE,
          "Currently the constraint checks need to be turned off to pass "
          "naked instances to output regions. In the future, layout "
          "constraints will be inferred from the instances and used for "
          "the checks.");
      }

      return_data(
          extents, field_id, ptr, instance.get_layout()->alignment_reqd);

      // This instance was escaped so the context is no longer responsible
      // for destroying it when the task is done, we take that responsibility
      escaped_instances.push_back(instance);
    }

    //--------------------------------------------------------------------------
    void OutputRegionImpl::finalize(void)
    //--------------------------------------------------------------------------
    {
      Domain domain;
      region->row_source->get_domain(domain);
      // Create a Realm instance and update the physical manager
      // for each output field
      for (std::map<FieldID,ReturnedInstanceInfo>::iterator it =
           returned_instances.begin(); it !=
           returned_instances.end(); ++it)
      {
        FieldID field_id = it->first;
        PhysicalManager *manager = get_manager(field_id);

        // Create a Realm layout
        LayoutConstraints *manager_cons = manager->layout->constraints;

        // Extract the order of dimensions from the ordering constraint
        const std::vector<DimensionKind> &ordering =
          manager_cons->ordering_constraint.ordering;
        std::vector<int> dim_order;
        for (size_t idx = 0; idx < ordering.size(); ++idx)
          if (ordering[idx] != LEGION_DIM_F)
            dim_order.push_back(ordering[idx] - static_cast<int>(LEGION_DIM_X));

        std::map<Realm::FieldID,size_t> field_sizes;
        size_t field_size = get_field_size(field_id);
        field_sizes[field_id] = field_size;
        Realm::InstanceLayoutConstraints constraints(field_sizes,
                                                     0 /*block_size*/);

        // Make a Realm layout descriptor of the right type using demux
        Realm::InstanceLayoutGeneric *layout = NULL;
        LayoutCreator creator(layout, domain, constraints, dim_order);
        NT_TemplateHelper::demux<LayoutCreator>(req.region.get_type_tag(),
                                                &creator);
#ifdef DEBUG_LEGION
        assert(layout != NULL);
#endif

        // Extract the alignment info from the alignment constraints
        // if there is one
        size_t alignment = 0;
        if (!manager_cons->alignment_constraints.empty())
        {
#ifdef DEBUG_LEGION
          assert(manager_cons->alignment_constraints.size() == 1);
          assert(manager_cons->alignment_constraints[0].fid == field_id);
#endif
          alignment = manager_cons->alignment_constraints[0].alignment;
        }
        // If no alignment is given, set it to the field size
        if (alignment == 0) alignment = field_size;

        size_t volume = 1;
        for (int32_t dim = 0; dim < extents.dim; ++dim) volume *= extents[dim];

        size_t bytes_used =
          field_size > 0
          ? (volume * field_size + alignment - 1) / alignment * alignment
          : 0;
        layout->bytes_used = bytes_used;

        if (!manager_cons->offset_constraints.empty())
        {
#ifdef DEBUG_LEGION
          assert(manager_cons->offset_constraints.size() == 1);
          assert(manager_cons->offset_constraints[0].fid == field_id);
#endif
          Realm::InstanceLayoutGeneric::FieldLayout &fl =
            layout->fields[field_id];
          fl.rel_offset = manager_cons->offset_constraints[0].offset;
        }

        // Create an external Realm instance
        Realm::RegionInstance instance;
        Realm::ProfilingRequestSet no_requests;
        ReturnedInstanceInfo &info = it->second;

        MemoryManager* memory_manager =
          runtime->find_memory_manager(manager->get_memory());
        RtEvent wait_on = memory_manager->create_sub_eager_instance(instance,
            info.ptr, bytes_used, layout, manager->get_unique_event());
        if (wait_on.exists())
          wait_on.wait();
#ifdef DEBUG_LEGION
        assert(instance.exists());
#endif
        // Finally we set the instance to the physical manager
        const bool delete_now = manager->update_physical_instance(instance,
                                          bytes_used, info.ptr);
        if (delete_now)
          delete manager;
      }
      // Lasty destroy our physical instance objects since the task is done
      for (std::vector<PhysicalInstance>::const_iterator it =
            escaped_instances.begin(); it != escaped_instances.end(); it++)
        it->destroy();
    }

    //--------------------------------------------------------------------------
    /*static*/ void OutputRegionImpl::handle_finalize_output(const void *args)
    //--------------------------------------------------------------------------
    {
      const FinalizeOutputArgs *finalize_args = (const FinalizeOutputArgs*)args;
      OutputRegionImpl *region = finalize_args->region;
      region->finalize();
      if (region->remove_reference())
        delete region;
    }

    //--------------------------------------------------------------------------
    bool OutputRegionImpl::is_complete(FieldID &unbound_field) const
    //--------------------------------------------------------------------------
    {
      for (std::vector<FieldID>::const_iterator it =
           req.instance_fields.begin(); it !=
           req.instance_fields.end(); ++it)
      {
        if (returned_instances.find(*it) == returned_instances.end())
        {
          unbound_field = *it;
          return false;
        }
      }
      return true;
    }

    //--------------------------------------------------------------------------
    PhysicalManager *OutputRegionImpl::get_manager(FieldID field_id) const
    //--------------------------------------------------------------------------
    {
      std::vector<FieldID>::const_iterator finder = std::find(
          req.instance_fields.begin(), req.instance_fields.end(), field_id);
      if (finder == req.instance_fields.end())
      {
        REPORT_LEGION_ERROR(ERROR_INVALID_OUTPUT_REGION_FIELD,
          "Field %u does not exist in output region %u of task %s "
          "(UID: %lld).",
          field_id, index, context->owner_task->get_task_name(),
          context->owner_task->get_unique_op_id());
      }
      return managers[std::distance(req.instance_fields.begin(), finder)];
    }

    /////////////////////////////////////////////////////////////
    // ExternalResourcesImpl
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    ExternalResourcesImpl::ExternalResourcesImpl(InnerContext *ctx,
        size_t num_regions, RegionTreeNode *upper, IndexSpaceNode *launch,
        LogicalRegion par, const std::set<FieldID> &fields)
      : context(ctx), upper_bound(upper), launch_bounds(launch),
        privilege_fields(fields.begin(), fields.end()), parent(par),
        pid(0), detached(false)
    //--------------------------------------------------------------------------
    {
      regions.resize(num_regions);
      upper_bound->add_base_resource_ref(PHYSICAL_REGION_REF);
      launch_bounds->add_base_resource_ref(PHYSICAL_REGION_REF);
    }

    //--------------------------------------------------------------------------
    ExternalResourcesImpl::ExternalResourcesImpl(
                                               const ExternalResourcesImpl &rhs)
      : context(rhs.context), upper_bound(rhs.upper_bound),
        launch_bounds(rhs.launch_bounds), 
        privilege_fields(rhs.privilege_fields), parent(rhs.parent)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    ExternalResourcesImpl::~ExternalResourcesImpl(void)
    //--------------------------------------------------------------------------
    {
      if (upper_bound->remove_base_resource_ref(PHYSICAL_REGION_REF))
        delete upper_bound;
      if (launch_bounds->remove_base_resource_ref(PHYSICAL_REGION_REF))
        delete launch_bounds;
    }

    //--------------------------------------------------------------------------
    ExternalResourcesImpl& ExternalResourcesImpl::operator=(
                                               const ExternalResourcesImpl &rhs)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
      return *this;
    }

    //--------------------------------------------------------------------------
    size_t ExternalResourcesImpl::size(void) const
    //--------------------------------------------------------------------------
    {
      return regions.size();
    }

    //--------------------------------------------------------------------------
    void ExternalResourcesImpl::set_region(unsigned index, 
                                           PhysicalRegionImpl *region)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(index < regions.size());
      assert(regions[index].impl == NULL);
#endif
      regions[index] = PhysicalRegion(region);
    }

    //--------------------------------------------------------------------------
    PhysicalRegion ExternalResourcesImpl::get_region(unsigned index) const
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(index < regions.size());
#endif
      return regions[index];
    }

    //--------------------------------------------------------------------------
    void ExternalResourcesImpl::set_projection(ProjectionID id)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(pid == 0);
#endif
      pid = id;
    }

    //--------------------------------------------------------------------------
    Future ExternalResourcesImpl::detach(InnerContext *ctx, IndexDetachOp *op,
                 const bool flush, const bool unordered, Provenance *provenance)
    //--------------------------------------------------------------------------
    {
      if (ctx != context)
        REPORT_LEGION_ERROR(ERROR_INDEX_SPACE_DETACH,
            "Attempted detach of external resources in context of task %s "
            "(UID %lld). Detach of external resources must always be performed "
            "in the the context of the task in which they are attached.",
            ctx->get_task_name(), ctx->get_unique_id())
      if (detached)
        REPORT_LEGION_ERROR(ERROR_INDEX_SPACE_DETACH,
            "Duplicate detach of external resources performed in task %s "
            "(UID %lld). External resources should only be detached once.",
            ctx->get_task_name(), ctx->get_unique_id())
      detached = true;
      // Unmap any mapped regions
      for (std::vector<PhysicalRegion>::iterator it =
            regions.begin(); it != regions.end(); it++)
      {
        if (!it->impl->is_mapped())
          continue;
        it->impl->unmap_region();
        ctx->unregister_inline_mapped_region(*it);
      }
      // Now initialize the detach operation
      return op->initialize_detach(ctx, parent, upper_bound, launch_bounds,
            this, privilege_fields, regions, flush, unordered, provenance);
    }

    /////////////////////////////////////////////////////////////
    // Grant Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    GrantImpl::GrantImpl(void)
      : acquired(false)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    GrantImpl::GrantImpl(const std::vector<ReservationRequest> &reqs)
      : requests(reqs), acquired(false)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    GrantImpl::GrantImpl(const GrantImpl &rhs)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    GrantImpl::~GrantImpl(void)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    GrantImpl& GrantImpl::operator=(const GrantImpl &rhs)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
      return *this;
    }

    //--------------------------------------------------------------------------
    void GrantImpl::register_operation(ApEvent completion_event)
    //--------------------------------------------------------------------------
    {
      AutoLock g_lock(grant_lock);
      completion_events.insert(completion_event);
    }

    //--------------------------------------------------------------------------
    ApEvent GrantImpl::acquire_grant(void)
    //--------------------------------------------------------------------------
    {
      AutoLock g_lock(grant_lock);
      if (!acquired)
      {
        grant_event = ApEvent::NO_AP_EVENT;
        for (std::vector<ReservationRequest>::const_iterator it = 
              requests.begin(); it != requests.end(); it++)
        {
          grant_event = ApEvent(it->reservation.acquire(it->mode, 
                                                it->exclusive, grant_event));
        }
        acquired = true;
      }
      return grant_event;
    }

    //--------------------------------------------------------------------------
    void GrantImpl::release_grant(void)
    //--------------------------------------------------------------------------
    {
      AutoLock g_lock(grant_lock);
      ApEvent deferred_release = Runtime::merge_events(NULL, completion_events);
      for (std::vector<ReservationRequest>::const_iterator it = 
            requests.begin(); it != requests.end(); it++)
      {
        it->reservation.release(deferred_release);
      }
    }

    //--------------------------------------------------------------------------
    void GrantImpl::pack_grant(Serializer &rez)
    //--------------------------------------------------------------------------
    {
      ApEvent pack_event = acquire_grant();
      rez.serialize(pack_event);
    }

    //--------------------------------------------------------------------------
    void GrantImpl::unpack_grant(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ApEvent unpack_event;
      derez.deserialize(unpack_event);
      AutoLock g_lock(grant_lock);
#ifdef DEBUG_LEGION
      assert(!acquired);
#endif
      grant_event = unpack_event;
      acquired = true;
    }

    /////////////////////////////////////////////////////////////
    // Legion Handshake Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    LegionHandshakeImpl::LegionHandshakeImpl(bool init_ext, int ext_parts,
                                                   int legion_parts)
      : init_in_ext(init_ext), ext_participants(ext_parts), 
        legion_participants(legion_parts), runtime(NULL)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    LegionHandshakeImpl::LegionHandshakeImpl(const LegionHandshakeImpl &rhs)
      : init_in_ext(false), ext_participants(-1), legion_participants(-1)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    LegionHandshakeImpl::~LegionHandshakeImpl(void)
    //--------------------------------------------------------------------------
    {
      ext_wait_barrier.get_barrier().destroy_barrier();
      legion_wait_barrier.get_barrier().destroy_barrier();
    }

    //--------------------------------------------------------------------------
    LegionHandshakeImpl& LegionHandshakeImpl::operator=(
                                                 const LegionHandshakeImpl &rhs)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
      return *this;
    }

    //--------------------------------------------------------------------------
    void LegionHandshakeImpl::initialize(Runtime *rt)
    //--------------------------------------------------------------------------
    {
      runtime = rt;
      ext_wait_barrier = PhaseBarrier(
          runtime->create_ap_barrier(legion_participants));
      legion_wait_barrier = PhaseBarrier(
          runtime->create_ap_barrier(ext_participants));
      ext_arrive_barrier = legion_wait_barrier;
      legion_arrive_barrier = ext_wait_barrier;
      // Advance the two wait barriers
      Runtime::advance_barrier(ext_wait_barrier);
      Runtime::advance_barrier(legion_wait_barrier);
      // Whoever is waiting first, we have to advance their arrive barriers
      if (init_in_ext)
      {
        runtime->phase_barrier_arrive(legion_arrive_barrier,
                                      legion_participants);
        Runtime::advance_barrier(ext_wait_barrier);
      }
      else
      {
        runtime->phase_barrier_arrive(ext_arrive_barrier, ext_participants);
        Runtime::advance_barrier(legion_wait_barrier);
      }
    }

    //--------------------------------------------------------------------------
    void LegionHandshakeImpl::ext_handoff_to_legion(void)
    //--------------------------------------------------------------------------
    {
      // Just have to do our arrival
      runtime->phase_barrier_arrive(ext_arrive_barrier, 1);
    }

    //--------------------------------------------------------------------------
    void LegionHandshakeImpl::ext_wait_on_legion(void)
    //--------------------------------------------------------------------------
    {
      // When we get this call, we know we have done 
      // all the arrivals so we can advance it
      Runtime::advance_barrier(ext_arrive_barrier);
      // Wait for ext  to be ready to run
      // Note we use the external wait to be sure 
      // we don't get drafted by the Realm runtime
      ApBarrier previous = Runtime::get_previous_phase(ext_wait_barrier);
      if (!previous.has_triggered_faultignorant())
      {
        // We can't call external wait directly on the barrier
        // right now, so as a work-around we'll make an event
        // and then wait on that
        ApUserEvent wait_on = Runtime::create_ap_user_event(NULL);
        Runtime::trigger_event(NULL, wait_on, previous);
        wait_on.external_wait();
      }
      // Now we can advance our wait barrier
      Runtime::advance_barrier(ext_wait_barrier);
    }

    //--------------------------------------------------------------------------
    void LegionHandshakeImpl::legion_handoff_to_ext(void)
    //--------------------------------------------------------------------------
    {
      // Just have to do our arrival
      runtime->phase_barrier_arrive(legion_arrive_barrier, 1);
    }

    //--------------------------------------------------------------------------
    void LegionHandshakeImpl::legion_wait_on_ext(void)
    //--------------------------------------------------------------------------
    {
      Runtime::advance_barrier(legion_arrive_barrier);
      // Wait for Legion to be ready to run
      // No need to avoid being drafted by the
      // Realm runtime here
      legion_wait_barrier.wait();
      // Now we can advance our wait barrier
      Runtime::advance_barrier(legion_wait_barrier);
    }

    //--------------------------------------------------------------------------
    PhaseBarrier LegionHandshakeImpl::get_legion_wait_phase_barrier(void)
    //--------------------------------------------------------------------------
    {
      return legion_wait_barrier;
    }

    //--------------------------------------------------------------------------
    PhaseBarrier LegionHandshakeImpl::get_legion_arrive_phase_barrier(void)
    //--------------------------------------------------------------------------
    {
      return legion_arrive_barrier;
    }

    //--------------------------------------------------------------------------
    void LegionHandshakeImpl::advance_legion_handshake(void)
    //--------------------------------------------------------------------------
    {
      Runtime::advance_barrier(legion_wait_barrier);
      Runtime::advance_barrier(legion_arrive_barrier);
    }

    /////////////////////////////////////////////////////////////
    // MPI Rank Table
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    MPIRankTable::MPIRankTable(Runtime *rt)
      : runtime(rt), collective_radix(rt->legion_collective_radix),
        done_triggered(false)
    //--------------------------------------------------------------------------
    {
      if (runtime->total_address_spaces > 1)
      {
        configure_collective_settings(runtime->total_address_spaces,
            runtime->address_space, collective_radix, collective_log_radix,
            collective_stages, collective_participating_spaces, 
            collective_last_radix);
        participating = 
          (int(runtime->address_space) < collective_participating_spaces);
        // We already have our contributions for each stage so
        // we can set the inditial participants to 1
        if (participating)
        {
          sent_stages.resize(collective_stages, false);
#ifdef DEBUG_LEGION
          assert(collective_stages > 0);
#endif
          stage_notifications.resize(collective_stages, 1);
          // Stage 0 always starts with 0 notifications since we'll 
          // explictcly arrive on it
          stage_notifications[0] = 0;
        }
        done_event = Runtime::create_rt_user_event();
      }
      // Add ourselves to the set before any exchanges start
#ifdef DEBUG_LEGION
      assert(Runtime::mpi_rank >= 0);
#endif
      forward_mapping[Runtime::mpi_rank] = runtime->address_space;
    }
    
    //--------------------------------------------------------------------------
    MPIRankTable::MPIRankTable(const MPIRankTable &rhs)
      : runtime(NULL), participating(false)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    MPIRankTable::~MPIRankTable(void)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    MPIRankTable& MPIRankTable::operator=(const MPIRankTable &rhs)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
      return *this;
    }

    //--------------------------------------------------------------------------
    void MPIRankTable::perform_rank_exchange(void)
    //--------------------------------------------------------------------------
    {
      // We can skip this part if there are not multiple nodes
      if (runtime->total_address_spaces > 1)
      {
        // See if we are participating node or not
        if (participating)
        {
          // We are a participating node
          // See if we are waiting for an initial notification
          // if not we can just send our message now
          if ((int(runtime->total_address_spaces) ==
                collective_participating_spaces) ||
              (runtime->address_space >= (runtime->total_address_spaces -
                collective_participating_spaces)))
          {
            const bool all_stages_done = initiate_exchange();
            if (all_stages_done)
              complete_exchange();
          }
        }
        else
        {
          // We are not a participating node
          // so we just have to send notification to one node
          send_remainder_stage();
        }
        // Wait for our done event to be ready
        done_event.wait();
      }
#ifdef DEBUG_LEGION
      assert(forward_mapping.size() == runtime->total_address_spaces);
#endif
      // Reverse the mapping
      for (std::map<int,AddressSpace>::const_iterator it = 
            forward_mapping.begin(); it != forward_mapping.end(); it++)
        reverse_mapping[it->second] = it->first;
    }

    //--------------------------------------------------------------------------
    bool MPIRankTable::initiate_exchange(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(participating); // should only get this for participating shards
#endif
      {
        AutoLock r_lock(reservation);
#ifdef DEBUG_LEGION
        assert(!sent_stages.empty());
        assert(!sent_stages[0]); // stage 0 shouldn't be sent yet
        assert(!stage_notifications.empty());
        if (collective_stages == 1)
          assert(stage_notifications[0] < collective_last_radix); 
        else
          assert(stage_notifications[0] < collective_radix);
#endif
        stage_notifications[0]++;
      }
      return send_ready_stages(0/*start stage*/);
    }

    //--------------------------------------------------------------------------
    void MPIRankTable::send_remainder_stage(void)
    //--------------------------------------------------------------------------
    {
      Serializer rez;
      {
        RezCheck z(rez);
        rez.serialize(-1);
        AutoLock r_lock(reservation, 1, false/*exclusive*/);
        rez.serialize<size_t>(forward_mapping.size());
        for (std::map<int,AddressSpace>::const_iterator it = 
              forward_mapping.begin(); it != forward_mapping.end(); it++)
        {
          rez.serialize(it->first);
          rez.serialize(it->second);
        }
      }
      if (participating)
      {
        // Send back to the nodes that are not participating
        AddressSpaceID target = runtime->address_space +
          collective_participating_spaces;
#ifdef DEBUG_LEGION
        assert(target < runtime->total_address_spaces);
#endif
        runtime->send_mpi_rank_exchange(target, rez);
      }
      else
      {
        // Sent to a node that is participating
        AddressSpaceID target = runtime->address_space % 
          collective_participating_spaces;
        runtime->send_mpi_rank_exchange(target, rez);
      }
    }

    //--------------------------------------------------------------------------
    bool MPIRankTable::send_ready_stages(const int start_stage) 
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(participating);
#endif
      // Iterate through the stages and send any that are ready
      // Remember that stages have to be done in order
      for (int stage = start_stage; stage < collective_stages; stage++)
      {
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(stage);
          AutoLock r_lock(reservation);
          // If this stage has already been sent then we can keep going
          if (sent_stages[stage])
            continue;
          // Check to see if we're sending this stage
          // We need all the notifications from the previous stage before
          // we can send this stage
          if ((stage > 0) && (stage_notifications[stage-1] < collective_radix))
            return false;
          // If we get here then we can send the stage
          sent_stages[stage] = true;
#ifdef DEBUG_LEGION
          {
            size_t expected_size = 1;
            for (int idx = 0; idx < stage; idx++)
              expected_size *= collective_radix;
            assert(expected_size <= forward_mapping.size());
          }
#endif
          rez.serialize<size_t>(forward_mapping.size());
          for (std::map<int,AddressSpace>::const_iterator it = 
                forward_mapping.begin(); it != forward_mapping.end(); it++)
          {
            rez.serialize(it->first);
            rez.serialize(it->second);
          }
        }
        // Now we can do the send
        if (stage == (collective_stages-1))
        {
          for (int r = 1; r < collective_last_radix; r++)
          {
            AddressSpaceID target = runtime->address_space ^
              (r << (stage * collective_log_radix));
#ifdef DEBUG_LEGION
            assert(int(target) < collective_participating_spaces);
#endif
            runtime->send_mpi_rank_exchange(target, rez);
          }
        }
        else
        {
          for (int r = 1; r < collective_radix; r++)
          {
            AddressSpaceID target = runtime->address_space ^
              (r << (stage * collective_log_radix));
#ifdef DEBUG_LEGION
            assert(int(target) < collective_participating_spaces);
#endif
            runtime->send_mpi_rank_exchange(target, rez);
          }
        }
      }
      // If we make it here, then we sent the last stage, check to see
      // if we've seen all the notifications for it
      AutoLock r_lock(reservation);
      if ((stage_notifications.back() == collective_last_radix)
          && !done_triggered)
      {
        done_triggered = true;
        return true;
      }
      else
        return false;
    }

    //--------------------------------------------------------------------------
    void MPIRankTable::handle_mpi_rank_exchange(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      int stage;
      derez.deserialize(stage);
#ifdef DEBUG_LEGION
      assert(participating || (stage == -1));
#endif
      unpack_exchange(stage, derez);
      bool all_stages_done = false;
      if (stage == -1)
      {
        if (!participating)
          all_stages_done = true;
        else // we can now send our stage 0
          all_stages_done = initiate_exchange();
      }
      else
        all_stages_done = send_ready_stages();
      if (all_stages_done)
        complete_exchange();
    }

    //--------------------------------------------------------------------------
    void MPIRankTable::unpack_exchange(int stage, Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      size_t num_entries;
      derez.deserialize(num_entries);
      AutoLock r_lock(reservation);
      for (unsigned idx = 0; idx < num_entries; idx++)
      {
        int rank;
        derez.deserialize(rank);
	unsigned space;
	derez.deserialize(space);
#ifdef DEBUG_LEGION
	// Duplicates are possible because later messages aren't "held", but
	// they should be exact matches
	assert ((forward_mapping.count(rank) == 0) ||
		(forward_mapping[rank] == space));
#endif
	forward_mapping[rank] = space;
      }
      if (stage >= 0)
      {
#ifdef DEBUG_LEGION
	assert(stage < int(stage_notifications.size()));
        if (stage < (collective_stages-1))
          assert(stage_notifications[stage] < collective_radix);
        else
          assert(stage_notifications[stage] < collective_last_radix);
#endif
        stage_notifications[stage]++;
      }
    }

    //--------------------------------------------------------------------------
    void MPIRankTable::complete_exchange(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(forward_mapping.size() == runtime->total_address_spaces);
#endif
      // See if we have to send a message back to a
      // non-participating node
      if ((int(runtime->total_address_spaces) > 
           collective_participating_spaces) &&
          (int(runtime->address_space) < int(runtime->total_address_spaces -
            collective_participating_spaces)))
        send_remainder_stage();
      // We are done
      Runtime::trigger_event(done_event);
    }

    /////////////////////////////////////////////////////////////
    // Implicit Shard Manager
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    ImplicitShardManager::ImplicitShardManager(Runtime *rt, TaskID tid,
                     MapperID mid, Processor::Kind k, unsigned shards_per_space)
      : Collectable(), runtime(rt), task_id(tid), mapper_id(mid), kind(k), 
        shards_per_address_space(shards_per_space), 
        remaining_local_arrivals(shards_per_space),
        local_shard_id(0), top_context(NULL), shard_manager(NULL),
        collective_mapping(NULL), local_task_name(NULL)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(runtime->total_address_spaces > 0);
#endif
      std::vector<AddressSpaceID> spaces(runtime->total_address_spaces);
      for (unsigned idx = 0; idx < spaces.size(); idx++)
        spaces[idx] = idx;
      collective_mapping =
        new CollectiveMapping(spaces, runtime->legion_collective_radix);
      collective_mapping->add_reference();
      remaining_remote_arrivals = 
        collective_mapping->count_children(0, runtime->address_space);
    }

    //--------------------------------------------------------------------------
    ImplicitShardManager::~ImplicitShardManager(void)
    //--------------------------------------------------------------------------
    {
      runtime->unregister_implicit_shard_manager(task_id);
      if (collective_mapping->remove_reference())
        delete collective_mapping;
    }

    //--------------------------------------------------------------------------
    ShardTask* ImplicitShardManager::create_shard(int shard_id,
               const DomainPoint &point, Processor proxy, const char *task_name)
    //--------------------------------------------------------------------------
    {
      // Do our registrations and then wait for the shard manager to be ready
      ShardTask *task = NULL;
      {
        AutoLock m_lock(manager_lock);
#ifdef DEBUG_LEGION
        assert(local_shard_id < shards_per_address_space);
#endif
        local_proxy = proxy;
        local_task_name = task_name;
        const ShardID shard = (shard_id < 0) ? (runtime->address_space * 
            shards_per_address_space + local_shard_id++) : shard_id;
        const size_t total_shards = 
          shards_per_address_space * runtime->total_address_spaces;
        if (total_shards <= shard)
          REPORT_LEGION_ERROR(ERROR_IMPLICIT_REPLICATED_SHARDING,
              "All shard IDs must be contained within [0,%zd) for implicit "
              "control replicated task %s", total_shards, task_name)
        const DomainPoint shard_point = 
          (point.get_dim() > 0) ? point : DomainPoint(shard);
        const bool result = shard_points.emplace(std::make_pair(shard_point,
              std::make_pair(shard, proxy))).second;
        if (!result)
          REPORT_LEGION_ERROR(ERROR_IMPLICIT_REPLICATED_SHARDING,
              "Discovered multiple ranks with the same implicit shard point "
              "for implicit control replicated task %s", task_name)
        if (remaining_local_arrivals == 0)
          REPORT_LEGION_ERROR(ERROR_IMPLICIT_REPLICATED_SHARDING,
              "Too many arrivals for implicit control replicated task %s. "
              "Only %d are permitted.", task_name, shards_per_address_space)
        if ((--remaining_local_arrivals == 0) &&
            (remaining_remote_arrivals == 0))
        {
          if (runtime->address_space > 0)
            request_shard_manager();
          else
            create_shard_manager();
        }
        if (shard_manager == NULL)
        {
          if (!manager_ready.exists())
            manager_ready = Runtime::create_rt_user_event();
          const RtEvent wait_on = manager_ready;
          m_lock.release();
          wait_on.wait();
          m_lock.reacquire();
        }
#ifdef DEBUG_LEGION
        assert(top_context != NULL);
        assert(shard_manager != NULL);
#endif
        task = shard_manager->create_shard(shard, proxy, 0/*variant id*/,
                                           top_context, NULL/*source*/);
      }
      top_context->increment_pending();
      implicit_context = top_context;
      task->initialize_implicit_task(task_id, mapper_id, proxy);
      return task;
    }

    //--------------------------------------------------------------------------
    void ImplicitShardManager::create_shard_manager(void)
    //--------------------------------------------------------------------------
    {
      const size_t total_shards = 
        runtime->total_address_spaces * shards_per_address_space;
#ifdef DEBUG_LEGION
      assert(runtime->address_space == 0);
      assert(top_context == NULL);
      assert(shard_manager == NULL);
      assert(shard_points.size() == total_shards);
#endif
      IndividualTask *implicit_top = runtime->create_implicit_top_level(
          task_id, mapper_id, local_proxy, local_task_name, collective_mapping);
#ifdef DEBUG_LEGION
      top_context = dynamic_cast<TopLevelContext*>(implicit_top->get_context());
      assert(top_context != NULL);
#else
      top_context = static_cast<TopLevelContext*>(implicit_top->get_context());
#endif
      // Now we need to make the shard manager
      const DistributedID repl_context = 
        runtime->get_available_distributed_id();
      // Fill in the shard points
      std::vector<DomainPoint> points(total_shards);
      std::vector<DomainPoint> sorted_points;
      sorted_points.reserve(total_shards);
      std::vector<ShardID> shard_lookup;
      shard_lookup.reserve(total_shards);
      bool isomorphic_points = true;
      // Should not be any duplicate shard domains
      if (shard_points.size() != total_shards)
        REPORT_LEGION_ERROR(ERROR_IMPLICIT_REPLICATED_SHARDING,
              "Discovered multiple ranks with the same implicit shard point "
              "for implicit control replicated task %s", local_task_name)
      std::vector<Processor> shard_mapping(total_shards);
      for (std::map<DomainPoint,std::pair<ShardID,Processor> >::const_iterator
            it = shard_points.begin(); it != shard_points.end(); it++)
      {
        if (isomorphic_points && ((it->first.get_dim() != 1) ||
            (it->first[0] != it->second.first)))
          isomorphic_points = false;
        sorted_points.push_back(it->first);
        shard_lookup.push_back(it->second.first);
#ifdef DEBUG_LEGION
        assert(it->second.first < points.size());
#endif
        // Should not be any duplicate shard IDs
        if (points[it->second.first].get_dim() > 0)
          REPORT_LEGION_ERROR(ERROR_IMPLICIT_REPLICATED_SHARDING,
              "Discovered multiple ranks with the same implicit shard ID "
              "for implicit control replicated task %s", local_task_name)
        points[it->second.first] = it->first;
        shard_mapping[it->second.first] = it->second.second;
      }
      Domain shard_domain;
      if (isomorphic_points)
        shard_domain = Domain(DomainPoint(0),DomainPoint(total_shards-1));
      Mapper::ContextConfigOutput configuration;
      implicit_top->configure_execution_context(configuration);
      // The shard manager will take ownership of this
      ShardManager *manager = new ShardManager(runtime, repl_context,
          collective_mapping, shards_per_address_space, configuration,
          true/*top level*/, isomorphic_points, true/*control replicated*/,
          shard_domain, std::move(points), std::move(sorted_points),
          std::move(shard_lookup), implicit_top);
      shard_manager = manager;
      implicit_top->set_shard_manager(manager);
      manager->set_shard_mapping(shard_mapping);
      if (runtime->legion_spy_enabled)
        LegionSpy::log_replication(implicit_top->get_unique_id(), repl_context,
                                   true/*control replication*/);
      manager->distribute_implicit(task_id, mapper_id, kind,
          shards_per_address_space, top_context); 
      if (manager_ready.exists())
        Runtime::trigger_event(manager_ready);
    }

    //--------------------------------------------------------------------------
    void ImplicitShardManager::request_shard_manager(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(shard_manager == NULL);
      assert(runtime->address_space > 0);
#endif
      Serializer rez;
      {
        RezCheck z(rez);
        rez.serialize(task_id);
        rez.serialize(mapper_id);
        rez.serialize(kind);
        rez.serialize(shards_per_address_space);
        rez.serialize<size_t>(shard_points.size());
        for (std::map<DomainPoint,std::pair<ShardID,Processor> >::const_iterator
              it = shard_points.begin(); it != shard_points.end(); it++)
        {
          rez.serialize(it->first);
          rez.serialize(it->second.first);
          rez.serialize(it->second.second);
        }
      }
      runtime->send_control_replicate_implicit_rendezvous(
          collective_mapping->get_parent(0, runtime->address_space), rez);
    }

    //--------------------------------------------------------------------------
    void ImplicitShardManager::process_implicit_rendezvous(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      AutoLock m_lock(manager_lock);
      size_t num_points = 0;
      derez.deserialize(num_points);
      for (unsigned idx = 0; idx < num_points; idx++)
      {
        DomainPoint point;
        derez.deserialize(point);
#ifdef DEBUG_LEGION
        assert(shard_points.find(point) == shard_points.end());
#endif
        std::pair<ShardID,Processor> &pair = shard_points[point];
        derez.deserialize(pair.first);
        derez.deserialize(pair.second);
      }
#ifdef DEBUG_LEGION
      assert(remaining_remote_arrivals > 0);
#endif
      if ((--remaining_remote_arrivals == 0) &&
          (remaining_local_arrivals == 0))
      {
        if (runtime->address_space > 0)
          request_shard_manager();
        else
          create_shard_manager();
      }
    }
    
    //--------------------------------------------------------------------------
    RtUserEvent ImplicitShardManager::set_shard_manager(ShardManager *m,
                                                        TopLevelContext *c)
    //--------------------------------------------------------------------------
    {
      AutoLock m_lock(manager_lock);
#ifdef DEBUG_LEGION
      assert(top_context == NULL);
      assert(shard_manager == NULL);
      assert(manager_ready.exists());
#endif
      top_context = c;
      shard_manager = m;
      RtUserEvent to_trigger = manager_ready;
      manager_ready = RtUserEvent::NO_RT_USER_EVENT;
      return to_trigger;
    }

    //--------------------------------------------------------------------------
    /*static*/ void ImplicitShardManager::handle_remote_rendezvous(
                                          Deserializer &derez, Runtime *runtime)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      TaskID task_id;
      derez.deserialize(task_id);
      MapperID mapper_id;
      derez.deserialize(mapper_id);
      Processor::Kind kind;
      derez.deserialize(kind);
      unsigned shards_per_address_space;
      derez.deserialize(shards_per_address_space); 
      ImplicitShardManager *manager = runtime->find_implicit_shard_manager(
          task_id, mapper_id, kind, shards_per_address_space);
      manager->process_implicit_rendezvous(derez);
    }

    /////////////////////////////////////////////////////////////
    // Processor Manager 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    ProcessorManager::ProcessorManager(Processor proc, Processor::Kind kind,
                                       Runtime *rt, unsigned def_mappers,
                                       bool no_steal, bool replay)
      : runtime(rt), local_proc(proc), proc_kind(kind), 
        stealing_disabled(no_steal), replay_execution(replay), 
        next_local_index(0), task_scheduler_enabled(false), 
        outstanding_task_scheduler(false),
        total_active_contexts(0), total_active_mappers(0), 
        total_progress_tasks(0), concurrent_lamport_clock(0),
        ready_concurrent_tasks(0), outstanding_concurrent_task(false)
    //--------------------------------------------------------------------------
    {
      context_states.resize(LEGION_DEFAULT_CONTEXTS);
      // Find our set of visible memories
      Machine::MemoryQuery vis_mems(runtime->machine);
      vis_mems.has_affinity_to(proc);
      vis_mems.has_capacity(1/*at least one byte*/);
      for (Machine::MemoryQuery::iterator it = vis_mems.begin();
            it != vis_mems.end(); it++)
      {
        Realm::Machine::AffinityDetails affinity;
        runtime->machine.has_affinity(proc, *it, &affinity);
        visible_memories[*it] = affinity.bandwidth;
      }
    }

    //--------------------------------------------------------------------------
    ProcessorManager::~ProcessorManager(void)
    //--------------------------------------------------------------------------
    {
      mapper_states.clear();
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::prepare_for_shutdown(void)
    //--------------------------------------------------------------------------
    {
      for (std::map<MapperID,std::pair<MapperManager*,bool> >::iterator it = 
            mappers.begin(); it != mappers.end(); it++)
      {
        if (it->second.second)
          delete it->second.first;
      }
      mappers.clear();
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::add_mapper(MapperID mid, MapperManager *m, 
                                      bool check, bool own, bool skip_replay)
    //--------------------------------------------------------------------------
    {
      // Don't do this if we are doing replay execution
      if (!skip_replay && replay_execution)
        return;
      log_run.spew("Adding mapper %d on processor " IDFMT "", 
                          mid, local_proc.id);
      if (check && (mid == 0))
        REPORT_LEGION_ERROR(ERROR_RESERVED_MAPPING_ID, 
                            "Invalid mapping ID. ID 0 is reserved.");
      if (check && !inside_registration_callback)
          REPORT_LEGION_WARNING(LEGION_WARNING_NON_CALLBACK_REGISTRATION,
            "Mapper %s (ID %d) was dynamically registered outside of a "
            "registration callback invocation. In the near future this will " 
            "become an error in order to support task subprocesses. Please "
            "use 'perform_registration_callback' to generate a callback "
            "where it will be safe to perform dynamic registrations.", 
            m->get_mapper_name(), mid)
      AutoLock m_lock(mapper_lock);
      std::map<MapperID,std::pair<MapperManager*,bool> >::iterator finder = 
        mappers.find(mid);
      if (finder != mappers.end())
      {
        if (finder->second.second)
          delete finder->second.first;
        finder->second = std::pair<MapperManager*,bool>(m, own);
      }
      else
      {
        mappers[mid] = std::pair<MapperManager*,bool>(m, own); 
        AutoLock q_lock(queue_lock);
        mapper_states[mid] = MapperState();
      }
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::replace_default_mapper(MapperManager *m, bool own)
    //--------------------------------------------------------------------------
    {
      // Don't do this if we are doing replay execution
      if (replay_execution)
        return;
      if (!inside_registration_callback)
          REPORT_LEGION_WARNING(LEGION_WARNING_NON_CALLBACK_REGISTRATION,
            "Replacing default mapper with %s was dynamically performed "
            "outside of a registration callback invocation. In the near "
            "future this will become an error in order to support task "
            "subprocesses. Please use 'perform_registration_callback' to "
            "generate a callback where it will be safe to perform dynamic " 
            "registrations.", m->get_mapper_name())
      AutoLock m_lock(mapper_lock);
      std::map<MapperID,std::pair<MapperManager*,bool> >::iterator finder = 
        mappers.find(0);
      if (finder != mappers.end())
      {
        if (finder->second.second)
          delete finder->second.first;
        finder->second = std::pair<MapperManager*,bool>(m, own);
      }
      else
      {
        mappers[0] = std::pair<MapperManager*,bool>(m, own);
        AutoLock q_lock(queue_lock);
        mapper_states[0] = MapperState();
      }
    }

    //--------------------------------------------------------------------------
    MapperManager* ProcessorManager::find_mapper(MapperID mid) const 
    //--------------------------------------------------------------------------
    {
      // Easy case if we are doing replay execution
      if (replay_execution)
      {
        std::map<MapperID,std::pair<MapperManager*,bool> >::const_iterator
          finder = mappers.find(0);
#ifdef DEBUG_LEGION
        assert(finder != mappers.end());
#endif
        return finder->second.first;
      }
      AutoLock m_lock(mapper_lock, 0/*mode*/, false/*exclusive*/);
      MapperManager *result = NULL;
      // We've got the lock, so do the operation
      std::map<MapperID,std::pair<MapperManager*,bool> >::const_iterator
        finder = mappers.find(mid);
      if (finder != mappers.end())
        result = finder->second.first;
      return result;
    }

    //--------------------------------------------------------------------------
    bool ProcessorManager::has_non_default_mapper(void) const
    //--------------------------------------------------------------------------
    {
      AutoLock m_lock(mapper_lock, 0/*mode*/, false/*exclusive*/);
      for (std::map<MapperID,std::pair<MapperManager*,bool> >::const_iterator
            it = mappers.begin(); it != mappers.end(); it++)
        if (!it->second.first->is_default_mapper)
          return true;
      return false;
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::perform_scheduling(void)
    //--------------------------------------------------------------------------
    {
      perform_mapping_operations(); 
      // Now re-take the lock and re-check the condition to see 
      // if the next scheduling task should be launched
      AutoLock q_lock(queue_lock);
#ifdef DEBUG_LEGION
      assert(outstanding_task_scheduler);
#endif
      // If the task scheduler is enabled launch ourselves again
      if (task_scheduler_enabled)
      {
        SchedulerArgs sched_args(local_proc);
        // If we need to recursively run the scheduler then we do so with
        // a lower priority than other meta-tasks to ensure that those other
        // meta tasks can continue to make forward progress and the scheduler
        // cannot starve other tasks.
        runtime->issue_runtime_meta_task(sched_args,
            LG_THROUGHPUT_WORK_PRIORITY);
      }
      else
        outstanding_task_scheduler = false;
    } 

    //--------------------------------------------------------------------------
    void ProcessorManager::launch_task_scheduler(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!outstanding_task_scheduler);
#endif
      outstanding_task_scheduler = true;
      SchedulerArgs sched_args(local_proc);
      // This is waking the scheduler up so give it higher priority in
      // order to ensure that we can get tasks mapped and running sooner
      runtime->issue_runtime_meta_task(sched_args, LG_LATENCY_WORK_PRIORITY);
    } 

    //--------------------------------------------------------------------------
    void ProcessorManager::notify_deferred_mapper(MapperID map_id,
                                                  RtEvent deferred_event)
    //--------------------------------------------------------------------------
    {
      AutoLock q_lock(queue_lock);
      MapperState &state = mapper_states[map_id];
      // Check to see if the deferral event matches the one that we have
      if (state.deferral_event == deferred_event)
      {
        // Now we can clear it
        state.deferral_event = RtEvent::NO_RT_EVENT;
        // And if we still have tasks, reactivate the mapper
        if (!state.ready_queue.empty())
          increment_active_mappers();
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ void ProcessorManager::handle_defer_mapper(const void *args)
    //--------------------------------------------------------------------------
    {
      const DeferMapperSchedulerArgs *dargs = 
        (const DeferMapperSchedulerArgs*)args; 
      dargs->proxy_this->notify_deferred_mapper(dargs->map_id, 
                                                dargs->deferral_event);
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::activate_context(InnerContext *context)
    //--------------------------------------------------------------------------
    {
      ContextID ctx_id = context->get_logical_tree_context();
      AutoLock q_lock(queue_lock); 
      ContextState &state = context_states[ctx_id];
#ifdef DEBUG_LEGION
      assert(!state.active);
#endif
      state.active = true;
      if (state.owned_tasks > 0)
        increment_active_contexts();
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::deactivate_context(InnerContext *context)
    //--------------------------------------------------------------------------
    {
      ContextID ctx_id = context->get_logical_tree_context();
      // We can do this without holding the lock because we know
      // the size of this vector is fixed
      AutoLock q_lock(queue_lock); 
      ContextState &state = context_states[ctx_id];
#ifdef DEBUG_LEGION
      assert(state.active);
#endif
      state.active = false;
      if (state.owned_tasks > 0)
        decrement_active_contexts();
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::update_max_context_count(unsigned max_contexts)
    //--------------------------------------------------------------------------
    {
      AutoLock q_lock(queue_lock);
      context_states.resize(max_contexts);
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::increment_active_contexts(void)
    //--------------------------------------------------------------------------
    {
      // Better be called while holding the queue lock
      if (!task_scheduler_enabled && (total_active_contexts == 0) &&
          (total_progress_tasks == 0) && (total_active_mappers > 0))
      {
        task_scheduler_enabled = true;
        if (!outstanding_task_scheduler)
          launch_task_scheduler();
      }
      total_active_contexts++;
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::decrement_active_contexts(void)
    //--------------------------------------------------------------------------
    {
      // Better be called while holding the queue lock
#ifdef DEBUG_LEGION
      assert(total_active_contexts > 0);
#endif
      total_active_contexts--;
      if ((total_active_contexts == 0) && (total_progress_tasks == 0))
        task_scheduler_enabled = false;
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::increment_active_mappers(void)
    //--------------------------------------------------------------------------
    {
      // Better be called while holding the queue lock
      if (!task_scheduler_enabled && (total_active_mappers == 0) &&
          ((total_active_contexts > 0) || (total_progress_tasks > 0)))
      {
        task_scheduler_enabled = true;
        if (!outstanding_task_scheduler)
          launch_task_scheduler();
      }
      total_active_mappers++;
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::decrement_active_mappers(void)
    //--------------------------------------------------------------------------
    {
      // Better be called while holding the queue lock
#ifdef DEBUG_LEGION
      assert(total_active_mappers > 0);
#endif
      total_active_mappers--;
      if (total_active_mappers == 0)
        task_scheduler_enabled = false;
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::increment_progress_tasks(void)
    //--------------------------------------------------------------------------
    {
      // Better be called while holding the queue lock
      if (!task_scheduler_enabled && (total_active_contexts == 0) &&
          (total_progress_tasks == 0) && (total_active_mappers > 0))
      {
        task_scheduler_enabled = true;
        if (!outstanding_task_scheduler)
          launch_task_scheduler();
      }
      total_progress_tasks++;
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::decrement_progress_tasks(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(total_progress_tasks > 0);
#endif
      total_progress_tasks--;
      if ((total_active_contexts == 0) && (total_progress_tasks == 0))
        task_scheduler_enabled = false;
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::process_steal_request(Processor thief,
                                           const std::vector<MapperID> &thieves)
    //--------------------------------------------------------------------------
    {
      log_run.spew("handling a steal request on processor " IDFMT " "
                         "from processor " IDFMT "", local_proc.id,thief.id);
      // Iterate over the task descriptions, asking the appropriate mapper
      // whether we can steal the task
      std::set<TaskOp*> stolen;
      std::vector<MapperID> successful_thiefs;
      for (std::vector<MapperID>::const_iterator steal_it = thieves.begin();
            steal_it != thieves.end(); steal_it++)
      {
        const MapperID stealer = *steal_it;
        // Handle a race condition here where some processors can 
        // issue steal requests to another processor before the mappers 
        // have been initialized on that processor.  There's no 
        // correctness problem for ignoring a steal request so just do that.
        MapperManager *mapper = find_mapper(stealer);
        if (mapper == NULL)
          continue;
        Mapper::StealRequestInput input;
        {
          // Wait until we can exclusive access to the ready queue
          RtEvent queue_copy_ready;
          // Pull out the current tasks for this mapping operation
          // Need to iterate until we get access to the queue
          do
          {
            if (queue_copy_ready.exists() && !queue_copy_ready.has_triggered())
            {
              queue_copy_ready.wait();
              queue_copy_ready = RtEvent::NO_RT_EVENT;
            }
            AutoLock q_lock(queue_lock);
            MapperState &map_state = mapper_states[*steal_it];
            if (!map_state.queue_guard)
            {
              // If we don't have a deferral event then grab our
              // ready queue of tasks so we can try to map them
              // this will also prevent them from being stolen
              if (!map_state.ready_queue.empty())
              {
                for (std::list<TaskOp*>::const_iterator it =
                      map_state.ready_queue.begin(); it !=
                      map_state.ready_queue.end(); it++)
                  if ((*it)->is_stealable() && !(*it)->is_origin_mapped())
                    input.stealable_tasks.push_back(*it);
                // Set the queue guard so no one else tries to
                // read the ready queue while we've checked it out
                if (!input.stealable_tasks.empty())
                  map_state.queue_guard = true;
              }
            }
            else
            {
              // Make an event if necessary
              if (!map_state.queue_waiter.exists())
                map_state.queue_waiter = Runtime::create_rt_user_event();
              // Record that we need to wait on it
              queue_copy_ready = map_state.queue_waiter;
            }
          } while (queue_copy_ready.exists());
        }
        if (input.stealable_tasks.empty())
          continue;
        input.thief_proc = thief;
        Mapper::StealRequestOutput output;
        // Ask the mapper what it wants to allow be stolen
        if (!input.stealable_tasks.empty())
          mapper->invoke_permit_steal_request(input, output);
        // See which tasks we can succesfully steal
        std::vector<TaskOp*> local_stolen;
        {
          // Retake the lock, put any tasks still in the ready queue
          // back into the queue and remove the queue guard
          AutoLock q_lock(queue_lock);
          MapperState &map_state = mapper_states[*steal_it];
#ifdef DEBUG_LEGION
          assert(map_state.queue_guard);
#endif
          std::list<TaskOp*> &rqueue = map_state.ready_queue;
          for (std::list<TaskOp*>::iterator it =
                rqueue.begin(); it != rqueue.end(); /*nothing*/)
          {
            if (output.stolen_tasks.find(*it) != output.stolen_tasks.end())
            {
              const ContextID ctx_id = 
                (*it)->get_context()->get_logical_tree_context();
              ContextState &state = context_states[ctx_id];
#ifdef DEBUG_LEGION
              assert(state.owned_tasks > 0);
#endif
              state.owned_tasks--;
              if (state.active && (state.owned_tasks == 0))
                decrement_active_contexts();
              if ((*it)->is_forward_progress_task())
                decrement_progress_tasks();
              (*it)->mark_stolen();
              local_stolen.push_back(*it);
              it = rqueue.erase(it);
            }
            else
              it++;
          }
          if (rqueue.empty())
          {
            if (map_state.deferral_event.exists())
              map_state.deferral_event = RtEvent::NO_RT_EVENT;
            else
              decrement_active_mappers();
          }
          // Remove the queue guard
          map_state.queue_guard = false;
          if (map_state.queue_waiter.exists())
          {
            Runtime::trigger_event(map_state.queue_waiter);
            map_state.queue_waiter = RtUserEvent::NO_RT_USER_EVENT;
          }
        }
        if (!local_stolen.empty())
        {
          successful_thiefs.push_back(stealer);
          for (std::vector<TaskOp*>::const_iterator it = 
                local_stolen.begin(); it != local_stolen.end(); it++)
          {
            (*it)->deactivate_outstanding_task();
            stolen.insert(*it);
          }
        }
        else
          mapper->process_failed_steal(thief);
      }
      if (!stolen.empty())
      {
#ifdef DEBUG_LEGION
        for (std::set<TaskOp*>::const_iterator it = stolen.begin();
              it != stolen.end(); it++)
        {
          log_task.debug("task %s (ID %lld) stolen from processor " IDFMT
                         " by processor " IDFMT "", (*it)->get_task_name(), 
                         (*it)->get_unique_id(), local_proc.id, thief.id);
        }
#endif
        runtime->send_tasks(thief, stolen);
        // Also have to send advertisements to the mappers that 
        // successfully stole so they know that they can try again
        std::set<Processor> thief_set;
        thief_set.insert(thief);
        for (std::vector<MapperID>::const_iterator it = 
              successful_thiefs.begin(); it != successful_thiefs.end(); it++)
          runtime->send_advertisements(thief_set, *it, local_proc);
      }
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::process_advertisement(Processor advertiser,
                                                 MapperID mid)
    //--------------------------------------------------------------------------
    {
      MapperManager *mapper = find_mapper(mid);
      mapper->process_advertisement(advertiser);
      // See if this mapper would like to try stealing again
      std::multimap<Processor,MapperID> stealing_targets;
      mapper->perform_stealing(stealing_targets);
      if (!stealing_targets.empty())
        runtime->send_steal_request(stealing_targets, local_proc);
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::add_to_ready_queue(TaskOp *task)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(task != NULL);
#endif
      // have to do this when we are not holding the lock
      task->activate_outstanding_task();
      // Check to see if this task is a task that must map in order to
      // guarantee forward progress
      const bool forward_progress_task = task->is_forward_progress_task();
      // We can do this without holding the lock because the
      // vector is of a fixed size
      ContextID ctx_id = task->get_context()->get_logical_tree_context();
      AutoLock q_lock(queue_lock);
#ifdef DEBUG_LEGION
      assert(mapper_states.find(task->map_id) != mapper_states.end());
#endif
      // Update the state for the context
      ContextState &state = context_states[ctx_id];
      if (state.active && (state.owned_tasks == 0))
        increment_active_contexts();
      state.owned_tasks++;
      // Also update the queue for the mapper
      MapperState &map_state = mapper_states[task->map_id];
      if (map_state.ready_queue.empty() || map_state.deferral_event.exists())
      {
        // Clear our deferral event since we are changing state
        map_state.deferral_event = RtEvent::NO_RT_EVENT;
        increment_active_mappers();
      }
      map_state.ready_queue.push_back(task);
      // Finally if this is a progress task increment it
      if (forward_progress_task)
        increment_progress_tasks();
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::find_visible_memories(std::set<Memory> &visible)const
    //--------------------------------------------------------------------------
    {
      for (std::map<Memory,size_t>::const_iterator it =
            visible_memories.begin(); it != visible_memories.end(); it++)
        visible.insert(it->first);
    }

    //--------------------------------------------------------------------------
    Memory ProcessorManager::find_best_visible_memory(Memory::Kind kind) const
    //--------------------------------------------------------------------------
    {
      size_t affinity = 0;
      Memory result = Memory::NO_MEMORY;
      for (std::map<Memory,size_t>::const_iterator it =
            visible_memories.begin(); it != visible_memories.end(); it++)
      {
        if (it->first.kind() != kind)
          continue;
        if (it->second < affinity)
          continue;
        result = it->first;
        affinity = it->second;
      }
      return result;
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::order_concurrent_task_launch(SingleTask *task,
                    ApEvent precondition, ApUserEvent ready, VariantID vid)
    //--------------------------------------------------------------------------
    {
      uint64_t lamport_clock = 0;
      {
        AutoLock c_lock(concurrent_lock);
#ifdef DEBUG_LEGION
        assert(concurrent_tasks.find(task) == concurrent_tasks.end());
#endif
        lamport_clock = concurrent_lamport_clock++;
        concurrent_tasks.insert(std::make_pair(task,
              ConcurrentState(lamport_clock, precondition, ready)));
      }
      // Check to see if the precondition event was poisoned
      bool poisoned = false;
#ifdef DEBUG_LEGION
#ifndef NDEBUG
      bool triggered =
#endif
#endif
        precondition.has_triggered_faultaware(poisoned);
#ifdef DEBUG_LEGION
      assert(triggered);
#endif
      // Tell the task to compute the max all-reduce of lamport clocks
      task->concurrent_allreduce(this, lamport_clock, vid, poisoned);
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::finalize_concurrent_task_order(SingleTask *task,
                                          uint64_t lamport_clock, bool poisoned)
    //--------------------------------------------------------------------------
    {
      AutoLock c_lock(concurrent_lock);
      std::map<SingleTask*,ConcurrentState>::iterator finder = 
        concurrent_tasks.find(task);
#ifdef DEBUG_LEGION
      assert(finder != concurrent_tasks.end());
      assert(!finder->second.max);
      assert(finder->second.lamport_clock <= lamport_clock);
#endif
      if (concurrent_lamport_clock <= lamport_clock)
        concurrent_lamport_clock = lamport_clock + 1;
      if (poisoned)
      {
        Runtime::poison_event(finder->second.ready);
        concurrent_tasks.erase(finder);
      }
      else
      {
        finder->second.lamport_clock = lamport_clock;
        finder->second.max = true;
        ready_concurrent_tasks++;
        if (!outstanding_concurrent_task)
          start_next_concurrent_task();
      }
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::end_concurrent_task(void)
    //--------------------------------------------------------------------------
    {
      AutoLock c_lock(concurrent_lock);
#ifdef DEBUG_LEGION
      assert(outstanding_concurrent_task);
#endif
      outstanding_concurrent_task = false;
      if (ready_concurrent_tasks > 0)
        start_next_concurrent_task();
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::start_next_concurrent_task(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!concurrent_tasks.empty());
      assert(!outstanding_concurrent_task);
      assert(ready_concurrent_tasks > 0);
#endif
      // See if we can prove that there is a task that is safe to start
      uint64_t min_next = std::numeric_limits<uint64_t>::max();
      uint64_t min_pending = std::numeric_limits<uint64_t>::max();
      SingleTask *next = NULL;
      TaskTreeCoordinates next_coords;
      for (std::map<SingleTask*,ConcurrentState>::const_iterator it =
            concurrent_tasks.begin(); it != concurrent_tasks.end(); it++)
      {
        if (it->second.max)
        {
          if (next != NULL)
          {
            // Compare the lamport clocks
            if (it->second.lamport_clock < min_next)
            {
              next = it->first;
              next_coords.clear();
              min_next = it->second.lamport_clock;
            }
            else if (min_next == it->second.lamport_clock)
            {
              // Very bad case, same min of max all-reduce of clocks
              // Resolve this conflict based on task tree coordinates
              TaskTreeCoordinates it_coords;
              if (next_coords.empty())
                next->compute_task_tree_coordinates(next_coords);
              it->first->compute_task_tree_coordinates(it_coords);
              const size_t lower_bound =
                std::min(next_coords.size(), it_coords.size());
              bool equal = true;
              for (unsigned idx = 0; idx < lower_bound; idx++)
              {
                const ContextCoordinate &c1 = next_coords[idx];
                const ContextCoordinate &c2 = it_coords[idx];
                if (c1.context_index == c2.context_index)
                {
                  if (c2.index_point < c1.index_point)
                  {
                    next = it->first;
                    next_coords.swap(it_coords);
                  }
                  else if (c1.index_point == c2.index_point)
                    continue;
                }
                else if (c2.context_index < c1.context_index)
                {
                  next = it->first;
                  next_coords.swap(it_coords);
                }
                equal = false;
                break;
              }
              if (equal)
              {
#ifdef DEBUG_LEGION
                assert(next_coords.size() != it_coords.size());
#endif
                if (it_coords.size() < next_coords.size())
                {
                  next = it->first;
                  next_coords.swap(it_coords);
                }
              }
            }
          }
          else
          {
            next = it->first;
            min_next = it->second.lamport_clock;
          }
        }
        else if (it->second.lamport_clock < min_pending)
          min_pending = it->second.lamport_clock;
      }
      // If all the pending tasks with lamport clocks are
      // larger than our max lamport clock of the next task
      // to launch then we know they won't ever come before it
      // so we can issue our next task now, otherwise we'll need
      // to wait until those pending lamport clocks are done
      if (min_next < min_pending)
      {
        std::map<SingleTask*,ConcurrentState>::iterator finder =
          concurrent_tasks.find(next);
#ifdef DEBUG_LEGION
        assert(finder != concurrent_tasks.end());
#endif
        // Trigger the ready event with the precondition to keep
        // tools like Legion Spy happy even though we know that
        // the precondition event has already triggered
        Runtime::trigger_event(NULL, finder->second.ready, 
            finder->second.precondition);
        concurrent_tasks.erase(finder);
        ready_concurrent_tasks--;
        outstanding_concurrent_task = true;
      }
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::perform_mapping_operations(void)
    //--------------------------------------------------------------------------
    {
      std::multimap<Processor,MapperID> stealing_targets;
      std::vector<MapperID> mappers_with_stealable_work;
      std::vector<std::pair<MapperID,MapperManager*> > current_mappers;
      // Take a snapshot of our current mappers
      {
        AutoLock m_lock(mapper_lock,1,false/*exclusive*/);
        // Fast path for no deferred mappers
        current_mappers.resize(mappers.size());
        unsigned idx = 0;
        for (std::map<MapperID,std::pair<MapperManager*,bool> >::
              const_iterator it = mappers.begin(); it != 
              mappers.end(); it++, idx++)
          current_mappers[idx] = 
            std::pair<MapperID,MapperManager*>(it->first, it->second.first);
      }
      for (std::vector<std::pair<MapperID,MapperManager*> >::const_iterator
            it = current_mappers.begin(); it != current_mappers.end(); it++)
      {
        const MapperID map_id = it->first;
        MapperManager *const mapper = it->second;
        Mapper::SelectMappingInput input;
        {
          RtEvent input_ready;
          // Pull out the current tasks for this mapping operation
          // Need to iterate until we get access to the queue
          do
          {
            if (input_ready.exists() && !input_ready.has_triggered())
            {
              input_ready.wait();
              input_ready = RtEvent::NO_RT_EVENT;
            }
            AutoLock q_lock(queue_lock);
            MapperState &map_state = mapper_states[map_id];
            if (!map_state.queue_guard)
            {
              // If we don't have a deferral event then grab our
              // ready queue of tasks so we can try to map them
              // this will also prevent them from being stolen
              if (!map_state.deferral_event.exists() &&
                  !map_state.ready_queue.empty())
              {
                // Only ask the mapper about ready tasks that have
                // active contexts that we should keep mapping
                for (std::list<TaskOp*>::const_iterator it =
                      map_state.ready_queue.begin(); it != 
                      map_state.ready_queue.end(); it++)
                {
                  const ContextID ctx =
                    (*it)->get_context()->get_logical_tree_context();
                  const ContextState &ctx_state = context_states[ctx];
                  if (ctx_state.active || (*it)->is_forward_progress_task())
                    input.ready_tasks.push_back(*it);
                }
                // Set the queue guard so no one else tries to
                // read the ready queue while we've checked it out
                if (!input.ready_tasks.empty())
                  map_state.queue_guard = true;
              }
            }
            else
            {
              // Make an event if necessary
              if (!map_state.queue_waiter.exists())
                map_state.queue_waiter = Runtime::create_rt_user_event();
              // Record that we need to wait on it
              input_ready = map_state.queue_waiter;
            }
          } while (input_ready.exists());
        }
        // Do this before anything else in case we don't have any tasks
        if (!stealing_disabled)
          mapper->perform_stealing(stealing_targets);
        // Nothing to do if there are no tasks on the queue
        if (input.ready_tasks.empty())
          continue;
        // Ask the mapper which tasks it would like to schedule
        Mapper::SelectMappingOutput output;
        mapper->invoke_select_tasks_to_map(input, output);
        // If we had no entry then we better have gotten a mapper event
        if (output.map_tasks.empty() && output.relocate_tasks.empty())
        {
          const RtEvent wait_on = output.deferral_event.impl;
          if (wait_on.exists())
          {
            // Put this on the list of the deferred mappers
            AutoLock q_lock(queue_lock);
            MapperState &map_state = mapper_states[map_id];
            // We have to check to see if any new tasks were added to 
            // the ready queue while we were doing our mapper call, if 
            // they were then we need to invoke select_tasks_to_map again
            if (map_state.ready_queue.empty())
            {
#ifdef DEBUG_LEGION
              assert(!map_state.deferral_event.exists());
              assert(map_state.queue_guard);
#endif
              map_state.deferral_event = wait_on;
              // Decrement the number of active mappers
              decrement_active_mappers();
              // Clear the queue guard
              map_state.queue_guard = false;
              if (map_state.queue_waiter.exists())
              {
                Runtime::trigger_event(map_state.queue_waiter);
                map_state.queue_waiter = RtUserEvent::NO_RT_USER_EVENT;
              }
              // Launch a task to remove the deferred mapper 
              // event when it triggers
              DeferMapperSchedulerArgs args(this, map_id, wait_on);
              // If we need to recursively run the scheduler then we do so with
              // a lower priority than other meta-tasks to ensure that those 
              // other meta tasks can continue to make forward progress and the
              // scheduler cannot starve other tasks
              runtime->issue_runtime_meta_task(args,
                  LG_THROUGHPUT_WORK_PRIORITY, wait_on);
              // We can continue because there is nothing 
              // left to do for this mapper
              continue;
            }
            // Otherwise we fall through to put our tasks back on the queue 
            // which will lead to select_tasks_to_map being called again
          }
          else // Very bad, error message
            REPORT_LEGION_ERROR(ERROR_INVALID_MAPPER_OUTPUT,
                          "Mapper %s failed to specify an output MapperEvent "
                          "when returning from a call to 'select_tasks_to_map' "
                          "that performed no other actions. Specifying a "
                          "MapperEvent in such situation is necessary to avoid "
                          "livelock conditions. Please return a "
                          "'deferral_event' in the 'output' struct.",
                          mapper->get_mapper_name())
        }
        else if (!output.relocate_tasks.empty())
        {
          for (std::map<const Task*,Processor>::const_iterator it = 
                output.relocate_tasks.begin(); it != 
                output.relocate_tasks.end(); it++)
            if (it->second.kind() == Processor::UTIL_PROC)
              REPORT_LEGION_ERROR(ERROR_INVALID_MAPPER_OUTPUT,
                  "Invalid mapper output. Mapper %s requested that task %s "
                  "(UID %lld) be relocated to a utility processor in "
                  "'select_tasks_to_map.' Only application processor kinds "
                  "are permitted to be the target processor for tasks.",
                  mapper->get_mapper_name(), it->first->get_task_name(),
                  it->first->get_unique_id())
        }
        // Figure out which tasks are to be triggered
        std::vector<TaskOp*> to_trigger;
        {
          // Retake the lock, put any tasks that the mapper didn't select
          // back on the queue and update the context states for any
          // that were selected 
          AutoLock q_lock(queue_lock);
          MapperState &map_state = mapper_states[map_id];
#ifdef DEBUG_LEGION
          assert(map_state.queue_guard);
#endif
          std::list<TaskOp*> &rqueue = map_state.ready_queue;
          // Iterate over the list and find any items to remove
          for (std::list<TaskOp*>::iterator it =
                rqueue.begin(); it != rqueue.end(); /*nothing*/)
          {
            if ((output.map_tasks.find(*it) != output.map_tasks.end()) ||
                (output.relocate_tasks.find(*it) != 
                 output.relocate_tasks.end()))
            {
              // Remove it from our set of local tasks
              const ContextID ctx_id = 
                (*it)->get_context()->get_logical_tree_context(); 
              ContextState &state = context_states[ctx_id];
#ifdef DEBUG_LEGION
              assert(state.owned_tasks > 0);
#endif
              state.owned_tasks--;
              if (state.active && (state.owned_tasks == 0))
                decrement_active_contexts();
              if ((*it)->is_forward_progress_task())
                decrement_progress_tasks();
              to_trigger.push_back(*it);
              it = rqueue.erase(it);
            }
            else
              it++;
          }
          if (rqueue.empty())
          {
            if (map_state.deferral_event.exists())
              map_state.deferral_event = RtEvent::NO_RT_EVENT;
            else
              decrement_active_mappers();
          }
          else if (!stealing_disabled)
          {
            for (std::list<TaskOp*>::const_iterator it =
                  rqueue.begin(); it != rqueue.end(); it++)
            {
              if ((*it)->is_stealable())
              {
                mappers_with_stealable_work.push_back(map_id);
                break;
              }
            }
          }
          // Remove the queue guard
          map_state.queue_guard = false;
          if (map_state.queue_waiter.exists())
          {
            Runtime::trigger_event(map_state.queue_waiter);
            map_state.queue_waiter = RtUserEvent::NO_RT_USER_EVENT;
          }
        }
        // Now we can trigger our tasks that the mapper selected
        for (std::vector<TaskOp*>::const_iterator it = 
              to_trigger.begin(); it != to_trigger.end(); it++)
        {
          // Update the target processor for this task if necessary
          std::map<const Task*,Processor>::const_iterator finder = 
            output.relocate_tasks.find(*it);
          const bool send_remotely = (finder != output.relocate_tasks.end());
          if (send_remotely)
            (*it)->set_target_proc(finder->second);
          // Mark that this task is no longer outstanding
          (*it)->deactivate_outstanding_task();
          TaskOp::TriggerTaskArgs trigger_args(*it);
          runtime->issue_runtime_meta_task(trigger_args,
                                           LG_THROUGHPUT_WORK_PRIORITY);
        }
      }

      // Advertise any work that we have
      if (!stealing_disabled && !mappers_with_stealable_work.empty())
      {
        for (std::vector<MapperID>::const_iterator it = 
              mappers_with_stealable_work.begin(); it !=
              mappers_with_stealable_work.end(); it++)
          issue_advertisements(*it);
      }

      // Finally issue any steal requeusts
      if (!stealing_disabled && !stealing_targets.empty())
        runtime->send_steal_request(stealing_targets, local_proc);
    }

    //--------------------------------------------------------------------------
    void ProcessorManager::issue_advertisements(MapperID map_id)
    //--------------------------------------------------------------------------
    {
      // Create a clone of the processors we want to advertise so that
      // we don't call into the high level runtime holding a lock
      std::set<Processor> failed_waiters;
      MapperManager *mapper = find_mapper(map_id);
      mapper->perform_advertisements(failed_waiters);
      if (!failed_waiters.empty())
        runtime->send_advertisements(failed_waiters, map_id, local_proc);
    }

    /////////////////////////////////////////////////////////////
    // Memory Manager 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    MemoryManager::MemoryManager(Memory m, Runtime *rt)
      : memory(m), owner_space(m.address_space()), 
        is_owner(is_owner_memory(m, rt->address_space)),
        capacity(m.capacity()), remaining_capacity(capacity), runtime(rt),
        eager_pool_instance(PhysicalInstance::NO_INST), eager_pool(0),
        eager_allocator(NULL), eager_remaining_capacity(0),
        next_allocation_id(0)
    //--------------------------------------------------------------------------
    {
#if defined(LEGION_USE_CUDA) || defined(LEGION_USE_HIP)
      if ((memory.kind() == Memory::GPU_FB_MEM) || 
          (memory.kind() == Memory::GPU_MANAGED_MEM) ||
          (memory.kind() == Memory::GPU_DYNAMIC_MEM))
      {
        Machine::ProcessorQuery finder(runtime->machine);
        finder.best_affinity_to(memory);
        finder.only_kind(Processor::TOC_PROC);
        assert(finder.count() > 0);
        local_gpu = finder.first();
      }
      else if (memory.kind() == Memory::Z_COPY_MEM)
      {
        Machine::ProcessorQuery finder(runtime->machine);
        finder.has_affinity_to(memory);
        finder.only_kind(Processor::TOC_PROC);
        assert(finder.count() > 0);
        local_gpu = finder.first();
      }
#endif
      // We do not make eager pool instances if we are not the owner or if the
      // memory has capacity zero (e.g. disk memory) where the creation of any 
      // instances that are not external instances are disallowed
      if (!is_owner || (capacity == 0)) 
        return;

      // Override the eager allocation percentage if we were
      // requested to do so for a particular memory kind.
      auto alloc_percentage = runtime->eager_alloc_percentage;
      auto override = runtime->eager_alloc_percentage_overrides.find(memory.kind());
      if (override != runtime->eager_alloc_percentage_overrides.end()) {
        alloc_percentage = override->second;
      }

      // Allocate eager pool
      const coord_t eager_pool_size = capacity * alloc_percentage / 100;
      log_eager.info("create an eager pool of size %lld on memory " IDFMT,
                     eager_pool_size, memory.id);
      const DomainT<1,coord_t> bounds(Rect<1>(0,Point<1>(eager_pool_size - 1)));
      const std::vector<Realm::FieldID> field_ids(1,0/*fid*/);
      const std::vector<size_t> field_sizes(1,sizeof(char));
      Realm::InstanceLayoutConstraints constraints(field_ids, field_sizes, 
                                                   0/*blocking*/);
      int dim_order[] = {0};
      Realm::InstanceLayoutGeneric *layout =
        Realm::InstanceLayoutGeneric::choose_instance_layout(bounds,
                                                             constraints,
                                                             dim_order);
      Realm::ProfilingRequestSet no_requests;
      Realm::RegionInstance::create_instance(eager_pool_instance,
                                             memory,
                                             layout,
                                             no_requests);

      if (eager_pool_size > 0)
      {
        Realm::AffineAccessor<char,1,coord_t> accessor(eager_pool_instance,
                                                       0/*field id*/);
        eager_pool = reinterpret_cast<uintptr_t>(accessor.ptr(0));

        eager_allocator = new EagerAllocator();
        eager_allocator->add_range(0, eager_pool_size - 1);
        eager_remaining_capacity = eager_pool_size;
      }
    }

    //--------------------------------------------------------------------------
    MemoryManager::~MemoryManager(void)
    //--------------------------------------------------------------------------
    {
      if (eager_pool_instance.exists())
        eager_pool_instance.destroy();
      delete eager_allocator;
    }

    //--------------------------------------------------------------------------
    void MemoryManager::find_shutdown_preconditions(
                                               std::set<ApEvent> &preconditions)
    //--------------------------------------------------------------------------
    {
      // We only need to check this on the owner node instances and 
      // in fact it's only safe for us to do it on the owner node
      // instance because we only are guaranteed to have references
      // to the owner node objects
      if (!is_owner)
        return;
      std::vector<PhysicalManager*> to_check;
      {
        AutoLock m_lock(manager_lock,1,false/*exclusive*/);
        for (std::map<RegionTreeID,TreeInstances>::const_iterator cit = 
              current_instances.begin(); cit != current_instances.end(); cit++)
          for (TreeInstances::const_iterator it = 
                cit->second.begin(); it != cit->second.end(); it++)
          {
            it->first->add_base_resource_ref(MEMORY_MANAGER_REF);
            to_check.push_back(it->first);
          }
      }
      for (std::vector<PhysicalManager*>::const_iterator it = 
            to_check.begin(); it != to_check.end(); it++)
      {
        (*it)->find_shutdown_preconditions(preconditions);
        if ((*it)->remove_base_resource_ref(MEMORY_MANAGER_REF))
          delete (*it);
      }
    }

    //--------------------------------------------------------------------------
    void MemoryManager::prepare_for_shutdown(void)
    //--------------------------------------------------------------------------
    {
      // Only need to do things if we are the owner memory
      if (!is_owner)
        return;
      // This is a kind of deletion so make sure it is ordered
      AutoLock c_lock(collection_lock);
      // This a collection so make sure we're ordered with other collections
      std::vector<PhysicalManager*> to_delete;
      {
        AutoLock m_lock(manager_lock);
        for (std::map<RegionTreeID,TreeInstances>::iterator cit =
              current_instances.begin(); cit != 
              current_instances.end(); cit++)
        {
          for (TreeInstances::iterator it =
                cit->second.begin(); it != cit->second.end(); it++)
          {
            if (it->first->is_external_instance())
              continue;
            if ((it->second == LEGION_GC_NEVER_PRIORITY) && 
                it->first->is_owner())
            {
              it->first->remove_base_valid_ref(NEVER_GC_REF);
              it->second = 0;
            }
            bool already_collected = false;
            if (it->first->can_collect(already_collected))
            {
              it->first->add_base_gc_ref(MEMORY_MANAGER_REF);
              to_delete.push_back(it->first);
            }
            else if (already_collected)
              remove_collectable(it->second, it->first);
          }
        }
      }
      if (!to_delete.empty())
        check_instance_deletions(to_delete);
    }

    //--------------------------------------------------------------------------
    void MemoryManager::check_instance_deletions(
                                 const std::vector<PhysicalManager*> &to_delete)
    //--------------------------------------------------------------------------
    {
      for (std::vector<PhysicalManager*>::const_iterator it =
            to_delete.begin(); it != to_delete.end(); it++)
      {
#ifdef DEBUG_LEGION
        assert(!(*it)->is_external_instance());
#endif
        RtEvent deletion_done;
        (*it)->collect(deletion_done);
        if ((*it)->remove_base_gc_ref(MEMORY_MANAGER_REF))
          delete (*it);
      }
    }

    //--------------------------------------------------------------------------
    void MemoryManager::remove_collectable(GCPriority priority,
                                           PhysicalManager *manager)
    //--------------------------------------------------------------------------
    {
      if (priority != LEGION_GC_NEVER_PRIORITY)
      {
        std::map<GCPriority,std::set<PhysicalManager*> >::iterator finder =
          collectable_instances.find(priority);
        if (finder != collectable_instances.end())
        {
          finder->second.erase(manager);
          if (finder->second.empty())
            collectable_instances.erase(finder);
        }
      }
    }

    //--------------------------------------------------------------------------
    void MemoryManager::finalize(void)
    //--------------------------------------------------------------------------
    {
      if (!is_owner)
        return;
      // No need for the lock, no one should be doing anything at this point
      // The only instances that are left here are the ones that were not
      // collected since we already waited for any pending collections to 
      // finish and their meta tasks to run to prune them out of the
      // current_instances data structure
      for (std::map<RegionTreeID,TreeInstances>::const_iterator cit = 
            current_instances.begin(); cit != current_instances.end(); cit++)
        for (TreeInstances::const_iterator it = 
              cit->second.begin(); it != cit->second.end(); it++)
          it->first->force_deletion();
      current_instances.clear();
#ifdef LEGION_MALLOC_INSTANCES
      for (std::map<RtEvent,PhysicalInstance>::const_iterator it = 
            pending_collectables.begin(); it != 
            pending_collectables.end(); it++)
        free_legion_instance(it->first, it->second);
      pending_collectables.clear();
#endif
    }
    
    //--------------------------------------------------------------------------
    void MemoryManager::register_remote_instance(PhysicalManager *manager)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!is_owner);
#endif
      AutoLock m_lock(manager_lock);
      TreeInstances &insts = current_instances[manager->tree_id];
#ifdef DEBUG_LEGION
      assert(insts.find(manager) == insts.end());
#endif
      insts[manager] = LEGION_GC_NEVER_PRIORITY;
    }

    //--------------------------------------------------------------------------
    void MemoryManager::unregister_remote_instance(PhysicalManager *manager)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!is_owner);
#endif
      AutoLock m_lock(manager_lock);
      std::map<RegionTreeID,TreeInstances>::iterator finder = 
        current_instances.find(manager->tree_id);
 #ifdef DEBUG_LEGION
      assert(finder != current_instances.end());
      assert(finder->second.find(manager) != finder->second.end());
#endif     
      finder->second.erase(manager);
      if (finder->second.empty())
        current_instances.erase(finder);
    }

    //--------------------------------------------------------------------------
    void MemoryManager::unregister_deleted_instance(PhysicalManager *manager)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner);
#endif
      {
        AutoLock m_lock(manager_lock);
        std::map<RegionTreeID,TreeInstances>::iterator tree_finder =
          current_instances.find(manager->tree_id);
#ifdef DEBUG_LEGION
        assert(tree_finder != current_instances.end());
#endif
        TreeInstances::iterator finder = tree_finder->second.find(manager);
#ifdef DEBUG_LEGION
        assert(finder != tree_finder->second.end());
#endif
        remove_collectable(finder->second, finder->first);
        tree_finder->second.erase(finder);
        if (tree_finder->second.empty())
          current_instances.erase(tree_finder);
      }
      if (manager->is_external_instance())
      {
        if (manager->remove_base_resource_ref(MEMORY_MANAGER_REF))
          delete manager;
      }
      else
      {
        if (manager->remove_base_gc_ref(MEMORY_MANAGER_REF))
          delete manager;
      }
    }

    //--------------------------------------------------------------------------
    bool MemoryManager::create_physical_instance(
                                const LayoutConstraintSet &constraints,
                                const std::vector<LogicalRegion> &regions,
                                MappingInstance &result,
                                Processor processor, bool acquire, 
                                GCPriority priority, bool tight_bounds,
                                LayoutConstraintKind *unsat_kind,
                                unsigned *unsat_index, size_t *footprint, 
                                UniqueID creator_id, bool remote)
    //--------------------------------------------------------------------------
    {
      if (!is_owner)
      {
        // Not the owner, send a meessage to the owner to request the creation
        Serializer rez;
        std::atomic<bool> success(false);
        std::atomic<PhysicalManager*> remote_manager(NULL);
        RtUserEvent ready_event = Runtime::create_rt_user_event();
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(CREATE_INSTANCE_CONSTRAINTS);
          rez.serialize(ready_event);
          rez.serialize<size_t>(regions.size());
          for (unsigned idx = 0; idx < regions.size(); idx++)
            rez.serialize(regions[idx]);
          constraints.serialize(rez);
          rez.serialize(processor);
          rez.serialize(priority);
          rez.serialize<bool>(tight_bounds);
          rez.serialize(unsat_kind);
          rez.serialize(unsat_index);
          rez.serialize(footprint);
          rez.serialize(creator_id);
          rez.serialize(&remote_manager);
          rez.serialize(&success);
        }
        runtime->send_instance_request(owner_space, rez);
        ready_event.wait();
        PhysicalManager *manager = remote_manager.load();
        if (manager != NULL)
        {
          result = MappingInstance(manager);
          manager->unpack_global_ref();
          if (acquire && !manager->acquire_instance(MAPPING_ACQUIRE_REF))
            return false;
          else
            return true;
        }
        return success.load();
      }
      else
      {
        // Create the builder and initialize it before getting
        // the allocation privilege to avoid deadlock scenario
        InstanceBuilder builder(regions, constraints, runtime, this,creator_id);
        builder.initialize(runtime->forest);
        // Acquire allocation privilege before doing anything
        const RtEvent wait_on = acquire_allocation_privilege();
        if (wait_on.exists())
          wait_on.wait();
        // Try to make the result
        PhysicalManager *manager = allocate_physical_instance(builder, 
                                    footprint, unsat_kind, unsat_index);
        bool success = false;
        if (manager != NULL)
        {
          if (runtime->legion_spy_enabled)
            manager->log_instance_creation(creator_id, processor, regions);
          // Do this first to add a resource reference
          result = MappingInstance(manager);
          record_created_instance(manager, acquire, priority);
          success = true;
        }
        // Release our allocation privilege after doing the record
        release_allocation_privilege();
        return success;
      }
    }

    //--------------------------------------------------------------------------
    bool MemoryManager::create_physical_instance(LayoutConstraints *constraints,
                                     const std::vector<LogicalRegion> &regions,
                                     MappingInstance &result,
                                     Processor processor, bool acquire, 
                                     GCPriority priority, bool tight_bounds,
                                     LayoutConstraintKind *unsat_kind,
                                     unsigned *unsat_index, size_t *footprint, 
                                     UniqueID creator_id, bool remote)
    //--------------------------------------------------------------------------
    {
      if (!is_owner)
      {
        // Not the owner, send a meessage to the owner to request the creation
        Serializer rez;
        std::atomic<bool> success(false);
        std::atomic<PhysicalManager*> remote_manager(NULL);
        RtUserEvent ready_event = Runtime::create_rt_user_event();
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(CREATE_INSTANCE_LAYOUT);
          rez.serialize(ready_event);
          rez.serialize<size_t>(regions.size());
          for (unsigned idx = 0; idx < regions.size(); idx++)
            rez.serialize(regions[idx]);
          rez.serialize(constraints->layout_id);
          rez.serialize(processor);
          rez.serialize(priority);
          rez.serialize<bool>(tight_bounds);
          rez.serialize(unsat_kind);
          rez.serialize(unsat_index);
          rez.serialize(footprint);
          rez.serialize(creator_id);
          rez.serialize(&remote_manager);
          rez.serialize(&success);
        }
        runtime->send_instance_request(owner_space, rez);
        ready_event.wait();
        PhysicalManager *manager = remote_manager.load();
        if (manager != NULL)
        {
          result = MappingInstance(manager);
          manager->unpack_global_ref();
          if (acquire && !manager->acquire_instance(MAPPING_ACQUIRE_REF))
            return false;
          else
            return true;
        }
        return success.load();
      }
      else
      {
        // Create the builder and initialize it before getting
        // the allocation privilege to avoid deadlock scenario
        InstanceBuilder builder(regions,*constraints, runtime, this,creator_id);
        builder.initialize(runtime->forest);
        // Acquire allocation privilege before doing anything
        const RtEvent wait_on = acquire_allocation_privilege();
        if (wait_on.exists())
          wait_on.wait();
        // Try to make the instance
        PhysicalManager *manager = allocate_physical_instance(builder, 
                                    footprint, unsat_kind, unsat_index);
        bool success = false;
        if (manager != NULL)
        {
          if (runtime->legion_spy_enabled)
            manager->log_instance_creation(creator_id, processor, regions);
          // Do this first to add a resource reference
          result = MappingInstance(manager);
          record_created_instance(manager, acquire, priority);
          success = true;
        }
        // Release our allocation privilege after doing the record
        release_allocation_privilege();
        return success;
      }
    }

    //--------------------------------------------------------------------------
    bool MemoryManager::find_or_create_physical_instance(
                                  const LayoutConstraintSet &constraints,
                                  const std::vector<LogicalRegion> &regions,
                                  MappingInstance &result, bool &created, 
                                  Processor processor,
                                  bool acquire, GCPriority priority,
                                  bool tight_region_bounds, 
                                  LayoutConstraintKind *unsat_kind,
                                  unsigned *unsat_index, size_t *footprint, 
                                  UniqueID creator_id, bool remote)
    //--------------------------------------------------------------------------
    {
      // Set created to default to false
      created = false;
      if (!is_owner)
      {
        // See if we can find a locally valid instance first
        if (find_valid_instance(constraints, regions, result, acquire,
                                tight_region_bounds, remote))
          return true;
        // Not the owner, send a message to the owner to request creation
        Serializer rez;
        std::atomic<bool> remote_created(created);
        std::atomic<PhysicalManager*> remote_manager(NULL);
        RtUserEvent ready_event = Runtime::create_rt_user_event();
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(FIND_OR_CREATE_CONSTRAINTS);
          rez.serialize(ready_event);
          rez.serialize<size_t>(regions.size());
          for (unsigned idx = 0; idx < regions.size(); idx++)
            rez.serialize(regions[idx]);
          constraints.serialize(rez);
          rez.serialize(processor);
          rez.serialize(priority);
          rez.serialize<bool>(tight_region_bounds);
          rez.serialize(unsat_kind);
          rez.serialize(unsat_index);
          rez.serialize(footprint);
          rez.serialize(creator_id);
          rez.serialize(&remote_manager);
          rez.serialize(&remote_created);
        }
        runtime->send_instance_request(owner_space, rez);
        ready_event.wait();
        PhysicalManager *manager = remote_manager.load();
        if (manager != NULL)
        {
          result = MappingInstance(manager);
          manager->unpack_global_ref();
          created = remote_created.load();
          if (acquire && !manager->acquire_instance(MAPPING_ACQUIRE_REF))
            return false;
          else
            return true;
        }
        else
          return false;
      }
      else
      {
        // Create the builder and initialize it before getting
        // the allocation privilege to avoid deadlock scenario
        InstanceBuilder builder(regions, constraints, runtime, this,creator_id);
        builder.initialize(runtime->forest); 
        // First get our allocation privileges so we're the only
        // one trying to do any allocations
        const RtEvent wait_on = acquire_allocation_privilege();
        if (wait_on.exists())
          wait_on.wait();
        // Since this is find or acquire, first see if we can find
        // an instance that has already been makde that satisfies 
        // our layout constraints
        bool success = find_satisfying_instance(constraints, regions,
                        result, acquire, tight_region_bounds, remote);
        if (!success)
        {
          // If we couldn't find it, we have to make it
          PhysicalManager *manager = allocate_physical_instance(builder, 
              footprint, unsat_kind, unsat_index);
          if (manager != NULL)
          {
            success = true;
            if (runtime->legion_spy_enabled)
              manager->log_instance_creation(creator_id, processor, regions);
            // Do this first to add a resource reference
            result = MappingInstance(manager);
            record_created_instance(manager, acquire, priority);
            // We made this instance so mark that it was created
            created = true;
          }
        }
        else if (footprint != NULL)
          *footprint = result.get_instance_size();
        // Release our allocation privilege after doing the record
        release_allocation_privilege();
        return success;
      }
    }

    //--------------------------------------------------------------------------
    bool MemoryManager::find_or_create_physical_instance(
                                LayoutConstraints *constraints, 
                                const std::vector<LogicalRegion> &regions,
                                MappingInstance &result, bool &created,
                                Processor processor,
                                bool acquire, GCPriority priority, 
                                bool tight_region_bounds, 
                                LayoutConstraintKind *unsat_kind,
                                unsigned *unsat_index, size_t *footprint, 
                                UniqueID creator_id, bool remote)
    //--------------------------------------------------------------------------
    {
      // Set created to false in case we fail
      created = false;
      if (!is_owner)
      {
        // See if we can find it locally
        if (find_valid_instance(*constraints, regions, result, acquire,
                                tight_region_bounds, remote))
          return true;
        // Not the owner, send a message to the owner to request creation
        Serializer rez;
        std::atomic<bool> remote_created(created);
        std::atomic<PhysicalManager*> remote_manager(NULL);
        RtUserEvent ready_event = Runtime::create_rt_user_event();
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(FIND_OR_CREATE_LAYOUT);
          rez.serialize(ready_event);
          rez.serialize<size_t>(regions.size());
          for (unsigned idx = 0; idx < regions.size(); idx++)
            rez.serialize(regions[idx]);
          rez.serialize(constraints->layout_id);
          rez.serialize(processor);
          rez.serialize(priority);
          rez.serialize<bool>(tight_region_bounds);
          rez.serialize(unsat_kind);
          rez.serialize(unsat_index);
          rez.serialize(footprint);
          rez.serialize(creator_id);
          rez.serialize(&remote_manager);
          rez.serialize(&remote_created);
        }
        runtime->send_instance_request(owner_space, rez);
        ready_event.wait();
        PhysicalManager *manager = remote_manager.load();
        if (manager != NULL)
        {
          result = MappingInstance(manager);
          manager->unpack_global_ref();
          created = remote_created.load();
          if (acquire && !manager->acquire_instance(MAPPING_ACQUIRE_REF))
            return false;
          else
            return true;
        }
        else
          return false;
      }
      else
      {
        // Create the builder and initialize it before getting
        // the allocation privilege to avoid deadlock scenario
        InstanceBuilder builder(regions,*constraints, runtime, this,creator_id);
        builder.initialize(runtime->forest);
        // First get our allocation privileges so we're the only
        // one trying to do any allocations
        const RtEvent wait_on = acquire_allocation_privilege();
        if (wait_on.exists())
          wait_on.wait();
        // Since this is find or acquire, first see if we can find
        // an instance that has already been makde that satisfies 
        // our layout constraints
        // Try to find an instance first and then make one
        bool success = find_satisfying_instance(*constraints, regions,
                        result, acquire, tight_region_bounds, remote);
        if (!success)
        {
          // If we couldn't find it, we have to make it
          PhysicalManager *manager = allocate_physical_instance(builder, 
              footprint, unsat_kind, unsat_index);
          if (manager != NULL)
          {
            success = true;
            if (runtime->legion_spy_enabled)
              manager->log_instance_creation(creator_id, processor, regions);
            // Do this first to add a resource reference
            result = MappingInstance(manager);
            record_created_instance(manager, acquire, priority);
            // We made this instance so mark that it was created
            created = true;
          }
        }
        else if (footprint != NULL)
          *footprint = result.get_instance_size();
        // Release our allocation privilege after doing the record
        release_allocation_privilege();
        return success;
      }
    }

    //--------------------------------------------------------------------------
    bool MemoryManager::find_physical_instance(
                                     const LayoutConstraintSet &constraints,
                                     const std::vector<LogicalRegion> &regions,
                                     MappingInstance &result, bool acquire, 
                                     bool tight_region_bounds, bool remote)
    //--------------------------------------------------------------------------
    {
      if (!is_owner)
      {
        // See if we can find it locally 
        if (find_valid_instance(constraints, regions, result, acquire,
                                tight_region_bounds, remote))
          return true;
        // Not the owner, send a message to the owner to try and find it
        Serializer rez;
        std::atomic<PhysicalManager*> remote_manager(NULL);
        RtUserEvent ready_event = Runtime::create_rt_user_event();
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(FIND_ONLY_CONSTRAINTS);
          rez.serialize(ready_event);
          rez.serialize(regions.size());
          for (unsigned idx = 0; idx < regions.size(); idx++)
            rez.serialize(regions[idx]);
          constraints.serialize(rez);
          rez.serialize<bool>(tight_region_bounds);
          rez.serialize(&remote_manager);
        }
        runtime->send_instance_request(owner_space, rez);
        ready_event.wait();
        PhysicalManager *manager = remote_manager.load();
        if (manager != NULL)
        {
          result = MappingInstance(manager);
          manager->unpack_global_ref();
          if (acquire && !manager->acquire_instance(MAPPING_ACQUIRE_REF))
            return false;
          else
            return true;
        }
        else
          return false;
      }
      else
      {
        // Try to find an instance
        return find_satisfying_instance(constraints, regions, result, acquire,
                                        tight_region_bounds, remote);
      }
    }

    //--------------------------------------------------------------------------
    bool MemoryManager::find_physical_instance(LayoutConstraints *constraints,
                                      const std::vector<LogicalRegion> &regions,
                                      MappingInstance &result, bool acquire, 
                                      bool tight_region_bounds, bool remote)
    //--------------------------------------------------------------------------
    {
      if (!is_owner)
      {
        // See if we can find a persistent instance
        if (find_valid_instance(*constraints, regions, result, acquire,
                                tight_region_bounds, remote))
          return true;
        Serializer rez;
        std::atomic<PhysicalManager*> remote_manager(NULL);
        RtUserEvent ready_event = Runtime::create_rt_user_event();
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(FIND_ONLY_LAYOUT);
          rez.serialize(ready_event);
          rez.serialize<size_t>(regions.size());
          for (unsigned idx = 0; idx < regions.size(); idx++)
            rez.serialize(regions[idx]);
          rez.serialize(constraints->layout_id);
          rez.serialize<bool>(tight_region_bounds);
          rez.serialize(&remote_manager);
        }
        runtime->send_instance_request(owner_space, rez);
        ready_event.wait();
        PhysicalManager *manager = remote_manager.load();
        if (manager != NULL)
        {
          result = MappingInstance(manager);
          manager->unpack_global_ref();
          if (acquire && !manager->acquire_instance(MAPPING_ACQUIRE_REF))
            return false;
          else
            return true;
        }
        else
          return false;
      }
      else
      {
        // Try to find an instance
        return find_satisfying_instance(*constraints, regions, result, acquire,
                                        tight_region_bounds, remote);
      }
    }

    //--------------------------------------------------------------------------
    void MemoryManager::find_physical_instances(
                            const LayoutConstraintSet &constraints,
                            const std::vector<LogicalRegion> &regions,
                            std::vector<MappingInstance> &results, 
                            bool acquire, bool tight_region_bounds, bool remote)
    //--------------------------------------------------------------------------
    {
      if (!is_owner)
      {
        // Not the owner, send a message to the owner to try and find it
        Serializer rez;
        std::atomic<std::vector<PhysicalManager*>*> remote_managers(NULL);
        RtUserEvent ready_event = Runtime::create_rt_user_event();
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(FIND_MANY_CONSTRAINTS);
          rez.serialize(ready_event);
          rez.serialize(regions.size());
          for (unsigned idx = 0; idx < regions.size(); idx++)
            rez.serialize(regions[idx]);
          constraints.serialize(rez);
          rez.serialize<bool>(tight_region_bounds);
          rez.serialize(&remote_managers);
        }
        runtime->send_instance_request(owner_space, rez);
        ready_event.wait();
        std::vector<PhysicalManager*> *managers = remote_managers.load();
        if (managers != NULL)
        {
          for (unsigned idx = 0; idx < managers->size(); idx++)
          {
            PhysicalManager *manager = managers->at(idx);
#ifdef DEBUG_LEGION
            assert(manager != NULL);
#endif
            results.emplace_back(MappingInstance(manager));
            manager->unpack_global_ref();
            if (acquire && !manager->acquire_instance(MAPPING_ACQUIRE_REF))
              results.pop_back();
          }
          delete managers;
        }
      }
      else
        find_satisfying_instances(constraints, regions, results, acquire,
                                  tight_region_bounds, remote);
    }

    //--------------------------------------------------------------------------
    void MemoryManager::find_physical_instances(LayoutConstraints *constraints,
                            const std::vector<LogicalRegion> &regions,
                            std::vector<MappingInstance> &results, 
                            bool acquire, bool tight_region_bounds, bool remote)
    //--------------------------------------------------------------------------
    {
      if (!is_owner)
      {
        Serializer rez;
        std::atomic<std::vector<PhysicalManager*>*> remote_managers(NULL);
        RtUserEvent ready_event = Runtime::create_rt_user_event();
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(FIND_MANY_LAYOUT);
          rez.serialize(ready_event);
          rez.serialize<size_t>(regions.size());
          for (unsigned idx = 0; idx < regions.size(); idx++)
            rez.serialize(regions[idx]);
          rez.serialize(constraints->layout_id);
          rez.serialize<bool>(tight_region_bounds);
          rez.serialize(&remote_managers);
        }
        runtime->send_instance_request(owner_space, rez);
        ready_event.wait();
        std::vector<PhysicalManager*> *managers = remote_managers.load();
        if (managers != NULL)
        {
          for (unsigned idx = 0; idx < managers->size(); idx++)
          {
            PhysicalManager *manager = managers->at(idx);
#ifdef DEBUG_LEGION
            assert(manager != NULL);
#endif
            results.emplace_back(MappingInstance(manager));
            manager->unpack_global_ref();
            if (acquire && !manager->acquire_instance(MAPPING_ACQUIRE_REF))
              results.pop_back();
          }
          delete managers;
        }
      }
      else
        find_satisfying_instances(*constraints, regions, results, acquire,
                                  tight_region_bounds, remote);
    }

    //--------------------------------------------------------------------------
    void MemoryManager::release_tree_instances(RegionTreeID tree_id)
    //--------------------------------------------------------------------------
    {
      // If we're not the owner, then there is nothing to do
      if (!is_owner)
        return;
      // Try to delete all the instances in the region tree
      // If any of them cannot be deleted yet, they'll have to 
      // wait until we do a garbage collection
      // This is a collection so we need to order it with respect to
      // to other collections
      AutoLock c_lock(collection_lock);
      std::vector<PhysicalManager*> to_delete;
      {
        AutoLock m_lock(manager_lock);
        std::map<RegionTreeID,TreeInstances>::iterator finder = 
          current_instances.find(tree_id);
        if (finder != current_instances.end())
        {
          for (TreeInstances::iterator it =
                finder->second.begin(); it != finder->second.end(); it++)
          {
            if (it->first->is_external_instance())
              continue;
            if ((it->second == LEGION_GC_NEVER_PRIORITY) && 
                it->first->is_owner())
            {
              it->first->remove_base_valid_ref(NEVER_GC_REF);
              it->second = 0;
            }
            bool already_collected = false;
            if (it->first->can_collect(already_collected))
            {
              it->first->add_base_gc_ref(MEMORY_MANAGER_REF);
              to_delete.push_back(it->first);
            }
            else if (already_collected)
              remove_collectable(it->second, it->first);
          }
        }
      }
      if (!to_delete.empty())
        check_instance_deletions(to_delete);
    }

    //--------------------------------------------------------------------------
    void MemoryManager::set_garbage_collection_priority(
                                  PhysicalManager *manager, GCPriority priority)
    //--------------------------------------------------------------------------
    { 
#ifdef DEBUG_LEGION
      assert(is_owner);
#endif
      AutoLock m_lock(manager_lock);
      std::map<RegionTreeID,TreeInstances>::iterator tree_finder =
        current_instances.find(manager->tree_id);
#ifdef DEBUG_LEGION
      assert(tree_finder != current_instances.end());
#endif
      TreeInstances::iterator finder = tree_finder->second.find(manager);
#ifdef DEBUG_LEGION
      assert(finder != tree_finder->second.end());
#endif
      remove_collectable(finder->second, manager);
      finder->second = priority;
      if (priority != LEGION_GC_NEVER_PRIORITY)
        collectable_instances[priority].insert(manager);
    }

    //--------------------------------------------------------------------------
    void MemoryManager::process_instance_request(Deserializer &derez,
                                                 AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner);
#endif
      RequestKind kind;
      derez.deserialize(kind);
      RtUserEvent to_trigger;
      derez.deserialize(to_trigger);
      size_t num_regions;
      derez.deserialize(num_regions);
      std::vector<LogicalRegion> regions(num_regions);
      for (unsigned idx = 0; idx < num_regions; idx++)
        derez.deserialize(regions[idx]);
      switch (kind)
      {
        case CREATE_INSTANCE_CONSTRAINTS:
          {
            LayoutConstraintSet constraints;
            constraints.deserialize(derez);
            Processor processor;
            derez.deserialize(processor);
            GCPriority priority;
            derez.deserialize(priority);
            bool tight_region_bounds;
            derez.deserialize<bool>(tight_region_bounds);
            LayoutConstraintKind *remote_kind;
            derez.deserialize(remote_kind);
            unsigned *remote_index;
            derez.deserialize(remote_index);
            size_t *remote_footprint; // warning: remote pointer
            derez.deserialize(remote_footprint);
            UniqueID creator_id;
            derez.deserialize(creator_id);
            std::atomic<PhysicalManager*> *remote_target;
            derez.deserialize(remote_target);
            std::atomic<bool> *remote_success;
            derez.deserialize(remote_success);
            MappingInstance result;
            size_t local_footprint;
            LayoutConstraintKind local_kind;
            unsigned local_index;
            bool success = create_physical_instance(constraints, regions, 
                                 result, processor, false/*acquire*/,
                                 priority, tight_region_bounds,
                                 &local_kind, &local_index, &local_footprint,
                                 creator_id, true/*remote*/);
            if (success || (remote_footprint != NULL) || 
                (remote_kind != NULL) || (remote_index != NULL))
            {
              // Send back the response starting with the instance
              Serializer rez;
              {
                RezCheck z(rez);
                rez.serialize(memory);
                rez.serialize(to_trigger);
                rez.serialize(kind);
                rez.serialize<bool>(success);
                if (success)
                {
                  InstanceManager *manager = result.impl;
                  manager->pack_global_ref();
                  rez.serialize(manager->did);
                  rez.serialize(remote_target);
                  rez.serialize(remote_success);
                }
                rez.serialize(remote_kind);
                rez.serialize(local_kind);
                rez.serialize(remote_index);
                rez.serialize(local_index);
                rez.serialize(remote_footprint);
                rez.serialize(local_footprint);
              }
              runtime->send_instance_response(source, rez);
            }
            else // we can just trigger the done event since we failed
              Runtime::trigger_event(to_trigger);
            break;
          }
        case CREATE_INSTANCE_LAYOUT:
          {
            LayoutConstraintID layout_id;
            derez.deserialize(layout_id);
            Processor processor;
            derez.deserialize(processor);
            GCPriority priority;
            derez.deserialize(priority);
            bool tight_region_bounds;
            derez.deserialize<bool>(tight_region_bounds);
            LayoutConstraintKind *remote_kind;
            derez.deserialize(remote_kind);
            unsigned *remote_index;
            derez.deserialize(remote_index);
            size_t *remote_footprint; // warning: remote pointer
            derez.deserialize(remote_footprint);
            UniqueID creator_id;
            derez.deserialize(creator_id);
            std::atomic<PhysicalManager*> *remote_target;
            derez.deserialize(remote_target);
            std::atomic<bool> *remote_success;
            derez.deserialize(remote_success);
            LayoutConstraints *constraints = 
              runtime->find_layout_constraints(layout_id);
            MappingInstance result;
            size_t local_footprint;
            LayoutConstraintKind local_kind;
            unsigned local_index;
            bool success = create_physical_instance(constraints, regions, 
                                 result, processor, false/*acquire*/,
                                 priority, tight_region_bounds,
                                 &local_kind, &local_index, &local_footprint,
                                 creator_id, true/*remote*/);
            if (success || (remote_footprint != NULL) ||
                (remote_kind != NULL) || (remote_index != NULL))
            {
              Serializer rez;
              {
                RezCheck z(rez);
                rez.serialize(memory);
                rez.serialize(to_trigger);
                rez.serialize(kind);
                rez.serialize<bool>(success);
                if (success)
                {
                  InstanceManager *manager = result.impl;
                  manager->pack_global_ref();
                  rez.serialize(manager->did);
                  rez.serialize(remote_target);
                  rez.serialize(remote_success);
                }
                rez.serialize(remote_kind);
                rez.serialize(local_kind);
                rez.serialize(remote_index);
                rez.serialize(local_index);
                rez.serialize(remote_footprint);
                rez.serialize(local_footprint);
              }
              runtime->send_instance_response(source, rez);
            }
            else // if we failed, we can just trigger the response
              Runtime::trigger_event(to_trigger);
            break;
          }
        case FIND_OR_CREATE_CONSTRAINTS:
          {
            LayoutConstraintSet constraints;
            constraints.deserialize(derez);
            Processor processor;
            derez.deserialize(processor);
            GCPriority priority;
            derez.deserialize(priority);
            bool tight_bounds;
            derez.deserialize(tight_bounds);
            LayoutConstraintKind *remote_kind;
            derez.deserialize(remote_kind);
            unsigned *remote_index;
            derez.deserialize(remote_index);
            size_t *remote_footprint; // warning: remote pointer
            derez.deserialize(remote_footprint);
            UniqueID creator_id;
            derez.deserialize(creator_id);
            std::atomic<PhysicalManager*> *remote_target;
            derez.deserialize(remote_target);
            std::atomic<bool> *remote_created;
            derez.deserialize(remote_created);
            MappingInstance result;
            size_t local_footprint;
            LayoutConstraintKind local_kind;
            unsigned local_index;
            bool created;
            bool success = find_or_create_physical_instance(constraints, 
                                regions, result, created, processor,
                                false/*acquire*/, priority, tight_bounds,
                                &local_kind, &local_index,
                                &local_footprint, creator_id, true/*remote*/);
            if (success || (remote_footprint != NULL) ||
                (remote_kind != NULL) || (remote_index != NULL))
            {
              Serializer rez;
              {
                RezCheck z(rez);
                rez.serialize(memory);
                rez.serialize(to_trigger);
                rez.serialize(kind);
                rez.serialize<bool>(success);
                if (success)
                {
                  InstanceManager *manager = result.impl;
                  manager->pack_global_ref();
                  rez.serialize(manager->did);
                  rez.serialize(remote_target);
                  rez.serialize(remote_created);
                  rez.serialize<bool>(created);
                }
                rez.serialize(remote_kind);
                rez.serialize(local_kind);
                rez.serialize(remote_index);
                rez.serialize(local_index);
                rez.serialize(remote_footprint);
                rez.serialize(local_footprint);
              }
              runtime->send_instance_response(source, rez);
            }
            else // if we failed, we can just trigger the response
              Runtime::trigger_event(to_trigger);
            break;
          }
        case FIND_OR_CREATE_LAYOUT:
          {
            LayoutConstraintID layout_id;
            derez.deserialize(layout_id);
            Processor processor;
            derez.deserialize(processor);
            GCPriority priority;
            derez.deserialize(priority);
            bool tight_bounds;
            derez.deserialize(tight_bounds);
            LayoutConstraintKind *remote_kind;
            derez.deserialize(remote_kind);
            unsigned *remote_index;
            derez.deserialize(remote_index);
            size_t *remote_footprint; // warning: remote pointer
            derez.deserialize(remote_footprint);
            UniqueID creator_id;
            derez.deserialize(creator_id);
            std::atomic<PhysicalManager*> *remote_target;
            derez.deserialize(remote_target);
            std::atomic<bool> *remote_created;
            derez.deserialize(remote_created);
            LayoutConstraints *constraints = 
              runtime->find_layout_constraints(layout_id);
            MappingInstance result;
            size_t local_footprint;
            LayoutConstraintKind local_kind;
            unsigned local_index;
            bool created;
            bool success = find_or_create_physical_instance(constraints, 
                                 regions, result, created, processor,
                                 false/*acquire*/, priority, tight_bounds,
                                 &local_kind, &local_index,
                                 &local_footprint, creator_id, true/*remote*/);
            if (success || (remote_footprint != NULL) ||
                (remote_kind != NULL) || (remote_index != NULL))
            {
              Serializer rez;
              {
                RezCheck z(rez);
                rez.serialize(memory);
                rez.serialize(to_trigger);
                rez.serialize(kind);
                rez.serialize<bool>(success);
                if (success)
                {
                  InstanceManager *manager = result.impl;
                  manager->pack_global_ref();
                  rez.serialize(manager->did);
                  rez.serialize(remote_target);
                  rez.serialize(remote_created);
                  rez.serialize<bool>(created);
                }
                rez.serialize(remote_kind);
                rez.serialize(local_kind);
                rez.serialize(remote_index);
                rez.serialize(local_index);
                rez.serialize(remote_footprint);
                rez.serialize(local_footprint);
              }
              runtime->send_instance_response(source, rez);
            }
            else // we failed so just trigger the response
              Runtime::trigger_event(to_trigger);
            break;
          }
        case FIND_ONLY_CONSTRAINTS:
          {
            LayoutConstraintSet constraints; 
            constraints.deserialize(derez);
            bool tight_bounds;
            derez.deserialize(tight_bounds);
            std::atomic<PhysicalManager*> *remote_target;
            derez.deserialize(remote_target);
            MappingInstance result;
            bool success = find_physical_instance(constraints, regions,
                        result, false/*acquire*/, tight_bounds, true/*remote*/);
            if (success)
            {
              InstanceManager *manager = result.impl;
              manager->pack_global_ref();
              Serializer rez;
              {
                RezCheck z(rez);
                rez.serialize(memory);
                rez.serialize(to_trigger);
                rez.serialize(kind);
                rez.serialize<bool>(true); // success
                rez.serialize(manager->did);
                rez.serialize(remote_target);
                // No things for us to pass back here
                rez.serialize<LayoutConstraintKind*>(NULL);
                rez.serialize(LEGION_SPECIALIZED_CONSTRAINT);
                rez.serialize<unsigned*>(NULL);
                rez.serialize<unsigned>(0);
                rez.serialize<size_t*>(NULL);
                rez.serialize<size_t>(0);
              }
              runtime->send_instance_response(source, rez);
            }
            else // we failed so we can just trigger the response
              Runtime::trigger_event(to_trigger);
            break;
          }
        case FIND_ONLY_LAYOUT:
          {
            LayoutConstraintID layout_id;
            derez.deserialize(layout_id);
            bool tight_bounds;
            derez.deserialize(tight_bounds);
            std::atomic<PhysicalManager*> *remote_target;
            derez.deserialize(remote_target);
            LayoutConstraints *constraints = 
              runtime->find_layout_constraints(layout_id);
            MappingInstance result;
            bool success = find_physical_instance(constraints, regions,
                        result, false/*acquire*/, tight_bounds, true/*remote*/);
            if (success)
            {
              InstanceManager *manager = result.impl;
              manager->pack_global_ref();
              Serializer rez;
              {
                RezCheck z(rez);
                rez.serialize(memory);
                rez.serialize(to_trigger);
                rez.serialize(kind);
                rez.serialize<bool>(true); // success
                rez.serialize(manager->did);
                rez.serialize(remote_target);
                // No things for us to pass back here
                rez.serialize<LayoutConstraintKind*>(NULL);
                rez.serialize(LEGION_SPECIALIZED_CONSTRAINT);
                rez.serialize<unsigned*>(NULL);
                rez.serialize<unsigned>(0);
                rez.serialize<size_t*>(NULL);
                rez.serialize<size_t>(0);
              }
              runtime->send_instance_response(source, rez);
            }
            else // we failed so just trigger
              Runtime::trigger_event(to_trigger);
            break;
          }
        case FIND_MANY_CONSTRAINTS:
          {
            LayoutConstraintSet constraints; 
            constraints.deserialize(derez);
            bool tight_bounds;
            derez.deserialize(tight_bounds);
            std::atomic<std::vector<PhysicalManager*>*> *remote_target;
            derez.deserialize(remote_target);
            std::vector<MappingInstance> results;
            find_physical_instances(constraints, regions, results,
                false/*acquire*/, tight_bounds, true/*remote*/);
            if (!results.empty())
            {
              Serializer rez;
              {
                RezCheck z(rez);
                rez.serialize(memory);
                rez.serialize(to_trigger);
                rez.serialize(kind);
                rez.serialize<bool>(false); // success
                rez.serialize(remote_target);
                rez.serialize<size_t>(results.size());
                for (unsigned idx = 0; idx < results.size(); idx++)
                {
                  InstanceManager *manager = results[idx].impl;
                  manager->pack_global_ref();
                  rez.serialize(manager->did);
                }
                // No things for us to pass back here
                rez.serialize<LayoutConstraintKind*>(NULL);
                rez.serialize(LEGION_SPECIALIZED_CONSTRAINT);
                rez.serialize<unsigned*>(NULL);
                rez.serialize<unsigned>(0);
                rez.serialize<size_t*>(NULL);
                rez.serialize<size_t>(0);
              }
              runtime->send_instance_response(source, rez);
            }
            else // we failed so we can just trigger the response
              Runtime::trigger_event(to_trigger);
            break;
          }
        case FIND_MANY_LAYOUT:
          {
            LayoutConstraintID layout_id;
            derez.deserialize(layout_id);
            bool tight_bounds;
            derez.deserialize(tight_bounds);
            std::atomic<std::vector<PhysicalManager*>*> *remote_target;
            derez.deserialize(remote_target);
            LayoutConstraints *constraints = 
              runtime->find_layout_constraints(layout_id);
            std::vector<MappingInstance> results;
            find_physical_instances(constraints, regions, results,
                false/*acquire*/, tight_bounds, true/*remote*/);
            if (!results.empty())
            {
              Serializer rez;
              {
                RezCheck z(rez);
                rez.serialize(memory);
                rez.serialize(to_trigger);
                rez.serialize(kind);
                rez.serialize<bool>(false); // success
                rez.serialize(remote_target);
                rez.serialize<size_t>(results.size());
                for (unsigned idx = 0; idx < results.size(); idx++)
                {
                  InstanceManager *manager = results[idx].impl;
                  manager->pack_global_ref();
                  rez.serialize(manager->did);
                }
                // No things for us to pass back here
                rez.serialize<LayoutConstraintKind*>(NULL);
                rez.serialize(LEGION_SPECIALIZED_CONSTRAINT);
                rez.serialize<unsigned*>(NULL);
                rez.serialize<unsigned>(0);
                rez.serialize<size_t*>(NULL);
                rez.serialize<size_t>(0);
              }
              runtime->send_instance_response(source, rez);
            }
            else // we failed so just trigger
              Runtime::trigger_event(to_trigger);
            break;
          }
        default:
          assert(false);
      }
    }

    //--------------------------------------------------------------------------
    void MemoryManager::process_instance_response(Deserializer &derez,
                                                  AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      RtUserEvent to_trigger;
      derez.deserialize(to_trigger);
      RequestKind kind;
      derez.deserialize(kind);
      bool success;
      derez.deserialize<bool>(success);
      std::vector<RtEvent> preconditions;
      if (success)
      {
        DistributedID did;
        derez.deserialize(did);
        std::atomic<PhysicalManager*> *target;
        derez.deserialize(target);
#ifdef DEBUG_LEGION
        assert((CREATE_INSTANCE_CONSTRAINTS <= kind) &&
               (kind <= FIND_ONLY_LAYOUT));
#endif
        if (did > 0)
        {
          RtEvent manager_ready = RtEvent::NO_RT_EVENT;
          PhysicalManager *manager = 
            runtime->find_or_request_instance_manager(did, manager_ready);
          // If the manager isn't ready yet, then we need to wait for it
          if (manager_ready.exists())
            preconditions.push_back(manager_ready);
          target->store(manager);
        }
        if ((kind == CREATE_INSTANCE_CONSTRAINTS) ||
            (kind == CREATE_INSTANCE_LAYOUT))
        {
          std::atomic<bool> *remote_success;
          derez.deserialize(remote_success);
          remote_success->store(true);
        }
        else if ((kind == FIND_OR_CREATE_CONSTRAINTS) || 
                 (kind == FIND_OR_CREATE_LAYOUT))
        {
          std::atomic<bool> *created_ptr;
          derez.deserialize(created_ptr);
          bool created;
          derez.deserialize(created);
          created_ptr->store(created);
        }
      }
      else
      {
        if ((kind == FIND_MANY_CONSTRAINTS) || (kind == FIND_MANY_LAYOUT))
        {
          std::atomic<std::vector<PhysicalManager*>*> *target;
          derez.deserialize(target);
          size_t num_insts;
          derez.deserialize(num_insts);
          std::vector<PhysicalManager*> *results = 
            new std::vector<PhysicalManager*>();
          results->reserve(num_insts);
          for (unsigned idx = 0; idx < num_insts; idx++)
          {
            DistributedID did;
            derez.deserialize(did);
            RtEvent manager_ready = RtEvent::NO_RT_EVENT;
            PhysicalManager *manager = 
              runtime->find_or_request_instance_manager(did, manager_ready);
            // If the manager isn't ready yet, then we need to wait for it
            if (manager_ready.exists())
              preconditions.push_back(manager_ready);
            results->push_back(manager);
          }
          target->store(results);
        }
      }
      // Unpack the constraint responses
      LayoutConstraintKind *local_kind;
      derez.deserialize(local_kind);
      LayoutConstraintKind constraint_kind;
      derez.deserialize(constraint_kind);
      if (local_kind != NULL)
        *local_kind = constraint_kind;
      unsigned *local_index;
      derez.deserialize(local_index);
      unsigned index;
      derez.deserialize(index);
      if (local_index != NULL)
        *local_index = index;
      // Unpack the footprint and asign it if necessary
      size_t *local_footprint;
      derez.deserialize(local_footprint);
      size_t footprint;
      derez.deserialize(footprint);
      if (local_footprint != NULL)
        *local_footprint = footprint;
      // Trigger that we are done
      if (!preconditions.empty())
        Runtime::trigger_event(to_trigger,Runtime::merge_events(preconditions));
      else
        Runtime::trigger_event(to_trigger);
    }

    //--------------------------------------------------------------------------
    bool MemoryManager::find_satisfying_instance(
                                const LayoutConstraintSet &constraints,
                                const std::vector<LogicalRegion> &regions,
                                MappingInstance &result, bool acquire, 
                                bool tight_region_bounds, bool remote)
    //--------------------------------------------------------------------------
    {
      RegionTreeID tree_id = 0;
      for (std::vector<LogicalRegion>::const_iterator it =
            regions.begin(); it != regions.end(); it++)
      {
        if (!it->exists())
          continue;
        tree_id = it->get_tree_id();
        break;
      }
      std::deque<PhysicalManager*> candidates;
      if (tree_id != 0)
      {
        // Hold the lock while searching here
        AutoLock m_lock(manager_lock, 1, false/*exclusive*/);
        std::map<RegionTreeID,TreeInstances>::const_iterator finder = 
          current_instances.find(tree_id);
        if (finder == current_instances.end())
          return false;
        for (TreeInstances::const_iterator it = 
              finder->second.begin(); it != finder->second.end(); it++)
        {
          if (it->first->is_collected())
            continue;
          it->first->add_base_resource_ref(MEMORY_MANAGER_REF);
          candidates.push_back(it->first);
        }
      }
      else
      {
        // Just get all the instances since we don't care about regions
        AutoLock m_lock(manager_lock, 1, false/*exclusive*/);
        for (std::map<RegionTreeID,TreeInstances>::const_iterator rit =
              current_instances.begin(); rit != current_instances.end(); rit++)
        {
          for (TreeInstances::const_iterator it =
                rit->second.begin(); it != rit->second.end(); it++)
          {
            if (it->first->is_collected())
              continue;
            it->first->add_base_resource_ref(MEMORY_MANAGER_REF);
            candidates.push_back(it->first);
          }
        }
      }
      // If we have any candidates check their constraints
      bool found = false;
      if (!candidates.empty())
      {
        if (tree_id != 0)
        {
          std::set<IndexSpaceExpression*> region_exprs;
          RegionTreeForest *forest = runtime->forest;
          for (std::vector<LogicalRegion>::const_iterator it = 
                regions.begin(); it != regions.end(); it++)
          {
            // If the region tree IDs don't match that is bad
            if (tree_id != it->get_tree_id())
              return false;
            RegionNode *node = forest->get_node(*it);
            region_exprs.insert(node->row_source);
          }
          IndexSpaceExpression *space_expr = (region_exprs.size() == 1) ?
            *(region_exprs.begin()) : forest->union_index_spaces(region_exprs);
          for (std::deque<PhysicalManager*>::const_iterator it =
                candidates.begin(); it != candidates.end(); it++)
          {
            if (!(*it)->meets_expression(space_expr, tight_region_bounds,
                  &constraints.padding_constraint.delta))
              continue;
            if ((*it)->entails(constraints, NULL))
            {
              // Check to see if we need to acquire
              // If we fail to acquire then keep going
              if (acquire && !(*it)->acquire_instance(MAPPING_ACQUIRE_REF))
                continue;
              // If we make it here, we succeeded
              result = MappingInstance(*it);
              found = true;
              break;
            }
          }
        }
        else
        {
          // No region constraints, just check the base constraints
          for (std::deque<PhysicalManager*>::const_iterator it =
                candidates.begin(); it != candidates.end(); it++)
          {
            if ((*it)->entails(constraints, NULL))
            {
              // Check to see if we need to acquire
              // If we fail to acquire then keep going
              if (acquire && !(*it)->acquire_instance(MAPPING_ACQUIRE_REF))
                continue;
              // If we make it here, we succeeded
              result = MappingInstance(*it);
              found = true;
              break;
            }
          }
        }
        release_candidate_references(candidates);
      }
      return found;
    }

    //--------------------------------------------------------------------------
    void MemoryManager::find_satisfying_instances(
                            const LayoutConstraintSet &constraints,
                            const std::vector<LogicalRegion> &regions,
                            std::vector<MappingInstance> &results, 
                            bool acquire, bool tight_region_bounds, bool remote)
    //--------------------------------------------------------------------------
    {
      RegionTreeID tree_id = 0;
      for (std::vector<LogicalRegion>::const_iterator it =
            regions.begin(); it != regions.end(); it++)
      {
        if (!it->exists())
          continue;
        tree_id = it->get_tree_id();
        break;
      }
      std::deque<PhysicalManager*> candidates;
      if (tree_id != 0)
      {
        // Hold the lock while searching here
        AutoLock m_lock(manager_lock, 1, false/*exclusive*/);
        std::map<RegionTreeID,TreeInstances>::const_iterator finder = 
          current_instances.find(tree_id);
        if (finder == current_instances.end())
          return;
        for (TreeInstances::const_iterator it = 
              finder->second.begin(); it != finder->second.end(); it++)
        {
          if (it->first->is_collected())
            continue;
          it->first->add_base_resource_ref(MEMORY_MANAGER_REF);
          candidates.push_back(it->first);
        }
      }
      else
      {
        // Just get all the instances since we don't care about regions
        AutoLock m_lock(manager_lock, 1, false/*exclusive*/);
        for (std::map<RegionTreeID,TreeInstances>::const_iterator rit =
              current_instances.begin(); rit != current_instances.end(); rit++)
        {
          for (TreeInstances::const_iterator it =
                rit->second.begin(); it != rit->second.end(); it++)
          {
            if (it->first->is_collected())
              continue;
            it->first->add_base_resource_ref(MEMORY_MANAGER_REF);
            candidates.push_back(it->first);
          }
        }
      }
      // If we have any candidates check their constraints
      if (!candidates.empty())
      {
        if (tree_id != 0)
        {
          std::set<IndexSpaceExpression*> region_exprs;
          RegionTreeForest *forest = runtime->forest;
          for (std::vector<LogicalRegion>::const_iterator it = 
                regions.begin(); it != regions.end(); it++)
          {
            // If the region tree IDs don't match that is bad
            if (tree_id != it->get_tree_id())
              return;
            RegionNode *node = forest->get_node(*it);
            region_exprs.insert(node->row_source);
          }
          IndexSpaceExpression *space_expr = (region_exprs.size() == 1) ?
            *(region_exprs.begin()) : forest->union_index_spaces(region_exprs);
          for (std::deque<PhysicalManager*>::const_iterator it = 
                candidates.begin(); it != candidates.end(); it++)
          {
            if (!(*it)->meets_expression(space_expr, tight_region_bounds,
                  &constraints.padding_constraint.delta))
              continue;
            if ((*it)->entails(constraints, NULL))
            {
              // Check to see if we need to acquire
              // If we fail to acquire then keep going
              if (acquire && !(*it)->acquire_instance(MAPPING_ACQUIRE_REF))
                continue;
              // If we make it here, we succeeded
              results.push_back(MappingInstance(*it));
            }
          }
        }
        else
        {
          // No regions to care about here, just check constraints
          for (std::deque<PhysicalManager*>::const_iterator it = 
                candidates.begin(); it != candidates.end(); it++)
          {
            if ((*it)->entails(constraints, NULL))
            {
              // Check to see if we need to acquire
              // If we fail to acquire then keep going
              if (acquire && !(*it)->acquire_instance(MAPPING_ACQUIRE_REF))
                continue;
              // If we make it here, we succeeded
              results.push_back(MappingInstance(*it));
            }
          }
        }
        release_candidate_references(candidates);
      }
    }

    //--------------------------------------------------------------------------
    bool MemoryManager::find_valid_instance(
                                     const LayoutConstraintSet &constraints,
                                     const std::vector<LogicalRegion> &regions,
                                     MappingInstance &result, bool acquire, 
                                     bool tight_region_bounds, bool remote)
    //--------------------------------------------------------------------------
    {
      if (regions.empty())
        return false;
      RegionTreeID tree_id = 0;
      for (std::vector<LogicalRegion>::const_iterator it =
            regions.begin(); it != regions.end(); it++)
      {
        if (!it->exists())
          continue;
        tree_id = it->get_tree_id();
        break;
      }
      if (tree_id == 0)
        return false;
      std::deque<PhysicalManager*> candidates;
      {
        // Hold the lock while searching here
        AutoLock m_lock(manager_lock, 1, false/*exclusive*/);
        std::map<RegionTreeID,TreeInstances>::const_iterator finder = 
          current_instances.find(tree_id);
        if (finder == current_instances.end())
          return false;
        for (TreeInstances::const_iterator it = 
              finder->second.begin(); it != finder->second.end(); it++)
        {
          if (it->first->is_collected())
            continue;
          it->first->add_base_resource_ref(MEMORY_MANAGER_REF);
          candidates.push_back(it->first);
        }
      }
      // If we have any candidates check their constraints
      bool found = false;
      if (!candidates.empty())
      {
        std::set<IndexSpaceExpression*> region_exprs;
        RegionTreeForest *forest = runtime->forest;
        for (std::vector<LogicalRegion>::const_iterator it = 
              regions.begin(); it != regions.end(); it++)
        {
          // If the region tree IDs don't match that is bad
          if (tree_id != it->get_tree_id())
            return false;
          RegionNode *node = forest->get_node(*it);
          region_exprs.insert(node->row_source);
        }
        IndexSpaceExpression *space_expr = (region_exprs.size() == 1) ?
          *(region_exprs.begin()) : forest->union_index_spaces(region_exprs);
        for (std::deque<PhysicalManager*>::const_iterator it = 
              candidates.begin(); it != candidates.end(); it++)
        {
          if (!(*it)->meets_expression(space_expr, tight_region_bounds,
                &constraints.padding_constraint.delta))
            continue;
          if ((*it)->entails(constraints, NULL))
          {
            // Check to see if we need to acquire
            // If we fail to acquire then keep going
            if (acquire && !(*it)->acquire_instance(MAPPING_ACQUIRE_REF))
              continue;
            // If we make it here, we succeeded
            result = MappingInstance(*it);
            found = true;
            break;
          }
        }
        release_candidate_references(candidates);
      }
      return found;
    }
    
    //--------------------------------------------------------------------------
    void MemoryManager::release_candidate_references(
                           const std::deque<PhysicalManager*> &candidates) const
    //--------------------------------------------------------------------------
    {
      for (std::deque<PhysicalManager*>::const_iterator it = 
            candidates.begin(); it != candidates.end(); it++)
      {
        if ((*it)->remove_base_resource_ref(MEMORY_MANAGER_REF))
          delete (*it);
      }
    }

    //--------------------------------------------------------------------------
    PhysicalManager* MemoryManager::create_unbound_instance(
                                               LogicalRegion region,
                                               LayoutConstraintSet &constraints,
                                               ApEvent producer_event,
                                               MapperID mapper_id,
                                               Processor target_proc,
                                               GCPriority priority)
    //--------------------------------------------------------------------------
    {
      // We don't need to acquire allocation privilege as this function
      // doesn't eagerly perform any instance collections.

      RegionNode *node = runtime->forest->get_node(region);
      FieldSpaceNode *fspace_node = node->get_column_source();

      const std::vector<FieldID> &fields =
        constraints.field_constraint.field_set;
      FieldMask instance_mask;
      std::vector<size_t> field_sizes(fields.size());
      std::vector<unsigned> mask_index_map(fields.size());
      std::vector<CustomSerdezID> serdez(fields.size());
      fspace_node->compute_field_layout(
          fields, field_sizes, mask_index_map, serdez, instance_mask);

      LayoutDescription *layout =
        fspace_node->find_layout_description(instance_mask, 1, constraints);
      if (layout == NULL)
      {
        LayoutConstraints *internal_constraints =
          runtime->register_layout(
              fspace_node->handle, constraints, true/*internal*/);
        layout = fspace_node->create_layout_description(
            instance_mask, 1, internal_constraints,
            mask_index_map, fields, field_sizes, serdez);
      }

      // Create an individual manager with a null instance
      DistributedID did = runtime->get_available_distributed_id();

      LgEvent unique_event;
      if (runtime->legion_spy_enabled || (runtime->profiler != NULL))
      {
        // When Legion Spy is enabled, we want the ready event to be unique.
        // So we create a fresh event and trigger it with the producer event
        RtUserEvent unique = Runtime::create_rt_user_event();
        Runtime::trigger_event(unique);
        unique_event = unique;
      }

      PhysicalManager *manager =
        new PhysicalManager(runtime->forest, did,
                            this,
                            PhysicalInstance::NO_INST,
                            node->get_row_source()->as_index_space_node(),
                            NULL/*piece_list*/,
                            0/*piece_list_size*/,
                            fspace_node,
                            region.get_tree_id(),
                            layout,
                            0/*redop id*/, true/*register now*/,
                            -1U/*instance_footprint*/,
                            producer_event, unique_event,
                            PhysicalManager::UNBOUND_INSTANCE_KIND,
                            NULL/*op*/,
                            NULL/*collective mapping*/,
                            producer_event);

      // Register the instance to make it visible to downstream tasks
      record_created_instance(manager,
                              true/*acquire*/,
                              priority);
      return manager;
    }

    //--------------------------------------------------------------------------
    RtEvent MemoryManager::acquire_allocation_privilege(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner); // should only happen on the owner
#endif
      const RtUserEvent our_event = Runtime::create_rt_user_event();
      AutoLock m_lock(manager_lock);
      // Wait for the previous allocation if there is one
      const RtEvent wait_on = pending_allocation_attempts.empty() ? 
        RtEvent::NO_RT_EVENT : pending_allocation_attempts.back();
      pending_allocation_attempts.push_back(our_event);
      return wait_on;
    }

    //--------------------------------------------------------------------------
    void MemoryManager::release_allocation_privilege(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner); // should only happen on the owner
#endif
      RtUserEvent to_trigger;
      {
        AutoLock m_lock(manager_lock);
#ifdef DEBUG_LEGION
        assert(!pending_allocation_attempts.empty());
#endif
        to_trigger = pending_allocation_attempts.front();
        pending_allocation_attempts.pop_front();
      }
      Runtime::trigger_event(to_trigger);
    }

    //--------------------------------------------------------------------------
    MemoryManager::GarbageCollector::GarbageCollector(LocalLock &c_lock,
                                LocalLock &m_lock, AddressSpaceID local,
                                Memory mem, size_t needed, 
                                std::map<GCPriority,std::set<PhysicalManager*>,
                                       std::greater<GCPriority> > &collectables)
      : collection_lock(c_lock), manager_lock(m_lock), 
        collectable_instances(collectables), memory(mem), local_space(local),
        needed_size(needed)
    //--------------------------------------------------------------------------
    {
      AutoLock man_lock(manager_lock);
      if (!collectable_instances.empty())
      {
        current_priority = collectable_instances.begin()->first;
        sort_next_priority_holes(false/*advance*/);
      }
      else
        current_priority = LEGION_GC_NEVER_PRIORITY;
    }

    //--------------------------------------------------------------------------
    MemoryManager::GarbageCollector::~GarbageCollector(void)
    //--------------------------------------------------------------------------
    {
      // Remove any references to any holes that we are still holding
      for (std::vector<PhysicalManager*>::const_iterator it =
            small_holes.begin(); it != small_holes.end(); it++)
        if ((*it)->remove_base_gc_ref(MEMORY_MANAGER_REF))
          delete (*it);
      for (std::vector<PhysicalManager*>::const_iterator it =
            perfect_holes.begin(); it != perfect_holes.end(); it++)
        if ((*it)->remove_base_gc_ref(MEMORY_MANAGER_REF))
          delete (*it);
      for (std::map<size_t,std::vector<PhysicalManager*> >::const_iterator lit =
            large_holes.begin(); lit != large_holes.end(); lit++)
        for (std::vector<PhysicalManager*>::const_iterator it =
              lit->second.begin(); it != lit->second.end(); it++)
          if ((*it)->remove_base_gc_ref(MEMORY_MANAGER_REF))
            delete (*it);
      for (std::map<uintptr_t,Range>::const_iterator rit =
            ranges.begin(); rit != ranges.end(); rit++)
        for (std::vector<PhysicalManager*>::const_iterator it =
              rit->second.managers.begin(); it != 
              rit->second.managers.end(); it++)
          if ((*it)->remove_base_gc_ref(MEMORY_MANAGER_REF))
            delete (*it);
    }

    //--------------------------------------------------------------------------
    MemoryManager::GarbageCollector::Range::Range(PhysicalManager *m)
      : size(m->instance_footprint)
    //--------------------------------------------------------------------------
    {
      managers.push_back(m);
    }

    //--------------------------------------------------------------------------
    void MemoryManager::GarbageCollector::sort_next_priority_holes(bool advance)
    //--------------------------------------------------------------------------
    {
      if (!collectable_instances.empty())
      {
        std::map<GCPriority,std::set<PhysicalManager*>,
          std::greater<GCPriority> >::iterator next =
            collectable_instances.lower_bound(current_priority);
        if ((next->first == current_priority) && advance)
          next = std::next(next);
        if (next != collectable_instances.end())
        {
          current_priority = next->first;
          for (std::set<PhysicalManager*>::iterator it = 
                next->second.begin(); it != next->second.end(); /*nothing*/)
          {
            bool already_collected = false;
            if ((*it)->can_collect(already_collected))
            {
              // Add a reference that ensures that this manager
              // won't be deleted out from under us when we do
              // the call to 'collect'
              (*it)->add_base_gc_ref(MEMORY_MANAGER_REF);
              if ((*it)->instance_footprint == needed_size)
                perfect_holes.push_back(*it);
              else if ((*it)->instance_footprint < needed_size)
                small_holes.push_back(*it);
              else
                large_holes[(*it)->instance_footprint].push_back(*it);
            }
            else if (already_collected)
            {
              // We can prune this out of the collected set immediately
              // since it has already been deleted so there is no need
              // to consider it again
              std::set<PhysicalManager*>::iterator to_delete = it++;
              next->second.erase(to_delete);
              continue;
            }
            it++;
          }
          if (next->second.empty())
            collectable_instances.erase(next);
        }
        else
          current_priority = LEGION_GC_NEVER_PRIORITY;
      }
      else
        current_priority = LEGION_GC_NEVER_PRIORITY;
    }

    //--------------------------------------------------------------------------
    RtEvent MemoryManager::GarbageCollector::perform_collection(void)
    //--------------------------------------------------------------------------
    {
      while (!collection_complete())
      {
        // If we've run out of stuff for this priority then go on to the next
        if (small_holes.empty() && perfect_holes.empty() &&
            large_holes.empty() && ranges.empty())
        {
          AutoLock m_lock(manager_lock);
          sort_next_priority_holes();
          continue;
        }
        // Try to use any other perfectly sized instances first
        while (!perfect_holes.empty())
        {
          PhysicalManager *manager = perfect_holes.back();
          perfect_holes.pop_back();
          RtEvent collected;
          if (manager->collect(collected))
          {
            if (manager->remove_base_gc_ref(MEMORY_MANAGER_REF))
              delete manager;
            return collected;
          }
          else if (manager->remove_base_gc_ref(MEMORY_MANAGER_REF))
            delete manager;
        }
        // If that didn't work try to use any large holes starting from
        // the ones that are closest in size to the largest
        while (!large_holes.empty())
        {
          std::map<size_t,std::vector<PhysicalManager*> >::iterator sit = 
            large_holes.begin();
          while (!sit->second.empty())
          {
            PhysicalManager *manager = sit->second.back();
            sit->second.pop_back();
            RtEvent collected;
            if (manager->collect(collected))
            {
              if (manager->remove_base_gc_ref(MEMORY_MANAGER_REF))
                delete manager;
              return collected;
            }
            else if (manager->remove_base_gc_ref(MEMORY_MANAGER_REF))
              delete manager;
          }
          large_holes.erase(sit);
        }
        // If we're down to just holes that are smaller than our desired
        // size then try grouping the small holes together into chunks that 
        // are either as big as possible or as big as the hole we need and 
        // try deleting them
        while (!small_holes.empty())
        {
          PhysicalManager *small_manager = small_holes.back();
          small_holes.pop_back();
          uintptr_t ptr = small_manager->get_instance_pointer();
          // Insert our range
          std::map<uintptr_t,Range>::iterator rit = 
            ranges.insert(std::make_pair(ptr, Range(small_manager))).first;
          // Check if we can join it with the one before or after
          if (rit != ranges.begin())
          {
            std::map<uintptr_t,Range>::iterator prev = std::prev(rit);
            if ((prev->first + prev->second.size) == rit->first)
            {
              // Merge rit into prev
              prev->second.size += rit->second.size;
              prev->second.managers.insert(prev->second.managers.end(),
                  rit->second.managers.begin(), rit->second.managers.end());
              ranges.erase(rit);
              rit = prev;
            }
          }
          std::map<uintptr_t,Range>::iterator next = std::next(rit);
          if (next != ranges.end())
          {
            if ((rit->first + rit->second.size) == next->first)
            {
              // Merge next into rit
              rit->second.size += next->second.size;
              rit->second.managers.insert(rit->second.managers.end(),
                next->second.managers.begin(), next->second.managers.end());
              ranges.erase(next);
            }
          }
          // See if it is is big enough to try an allocation
          if (needed_size <= rit->second.size)
          {
            std::vector<RtEvent> collected_events;
            for (std::vector<PhysicalManager*>::const_iterator it =
                  rit->second.managers.begin(); it != 
                  rit->second.managers.end(); it++)
            {
              RtEvent collected;
              if ((*it)->collect(collected) && collected.exists())
                collected_events.push_back(collected);
              if ((*it)->remove_base_gc_ref(MEMORY_MANAGER_REF))
                delete (*it);
            }
            ranges.erase(rit);
            if (!collected_events.empty())
              return Runtime::merge_events(collected_events);
            else
              return RtEvent::NO_RT_EVENT;
          }
        }
        // At this point, things look pretty hopeless, so just
        // go through and start deleting ranges until we've freed
        // up enough memory for the needed size until we run out
        // of stuff to delete
        size_t freed_size = 0;
        std::vector<RtEvent> collected_events;
        while (!ranges.empty())
        {
          std::map<uintptr_t,Range>::iterator rit = ranges.begin(); 
          for (std::vector<PhysicalManager*>::const_iterator it =
                rit->second.managers.begin(); it != 
                rit->second.managers.end(); it++)
          {
            RtEvent collected;
            if ((*it)->collect(collected) && collected.exists())
              collected_events.push_back(collected);
            freed_size += (*it)->instance_footprint;
            if ((*it)->remove_base_gc_ref(MEMORY_MANAGER_REF))
              delete (*it);
          }
          ranges.erase(rit);
          if (needed_size <= freed_size)
          {
            if (!collected_events.empty())
              return Runtime::merge_events(collected_events);
            else
              return RtEvent::NO_RT_EVENT;
          }
        }
        // Can try one more collection at this level before going to the next
        if (freed_size > 0)
        {
          if (!collected_events.empty())
            return Runtime::merge_events(collected_events);
          else
            return RtEvent::NO_RT_EVENT;
        }
      }
      return RtEvent::NO_RT_EVENT;
    }

    //--------------------------------------------------------------------------
    PhysicalManager* MemoryManager::allocate_physical_instance(
                       InstanceBuilder &builder, size_t *footprint,
                       LayoutConstraintKind *unsat_kind, unsigned *unsat_index)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner);
#endif
      // First, just try to make the instance as is, if it works we are done 
      size_t needed_size;
      PhysicalManager *result = builder.create_physical_instance(
          runtime->forest, unsat_kind, unsat_index, &needed_size);
      if (footprint != NULL)
        *footprint = needed_size;
      if ((result != NULL) || (needed_size == 0))
        return result;
      GarbageCollector collector(collection_lock, manager_lock, 
                                 runtime->address_space, memory, needed_size, 
                                 collectable_instances);
      while (!collector.collection_complete())
      {
        const RtEvent collection_done = collector.perform_collection(); 
        result = builder.create_physical_instance(runtime->forest,
                  unsat_kind, unsat_index, NULL, collection_done);
        if (result != NULL)
          break;
      }
      return result;
    }

    //--------------------------------------------------------------------------
    void MemoryManager::record_created_instance(PhysicalManager *manager,
                                              bool acquire, GCPriority priority)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner);
#endif
      // Add references first to prevent races with collection
      if (acquire)
      {
#ifdef DEBUG_LEGION
#ifndef NDEBUG
        const bool result =
#endif
#endif
        manager->acquire_instance(MAPPING_ACQUIRE_REF);
#ifdef DEBUG_LEGION
        assert(result);
#endif
      }
      // Since we're going to put this in the table add a gc reference 
      // which will keep this manager eligible for acquires until the 
      // point where we actually end up deleting it
      manager->add_base_gc_ref(MEMORY_MANAGER_REF);
      // If we're setting the priority to min priority and this is the
      // owner then add the reference for the manager
      if ((priority == LEGION_GC_NEVER_PRIORITY) && manager->is_owner())
        manager->add_base_valid_ref(NEVER_GC_REF);
      // Record the manager here as being eligible for collection
      {
        AutoLock m_lock(manager_lock);
        TreeInstances &insts = current_instances[manager->tree_id];
#ifdef DEBUG_LEGION
        assert(insts.find(manager) == insts.end());
#endif
        insts[manager] = priority;
        if (priority != LEGION_GC_NEVER_PRIORITY)
          collectable_instances[priority].insert(manager);
      }
    }

    //--------------------------------------------------------------------------
    void MemoryManager::notify_collected_instances(
                                 const std::vector<PhysicalManager*> &instances)
    //--------------------------------------------------------------------------
    {
      if (is_owner)
      {
        AutoLock m_lock(manager_lock);
        for (std::vector<PhysicalManager*>::const_iterator it =
              instances.begin(); it != instances.end(); it++)
        {
          std::map<RegionTreeID,TreeInstances>::iterator current_finder =
            current_instances.find((*it)->tree_id);
          if (current_finder == current_instances.end())
            continue;
          TreeInstances::iterator finder = current_finder->second.find(*it);
          if (finder == current_finder->second.end())
            continue;
          current_finder->second.erase(finder);
          if (current_finder->second.empty())
            current_instances.erase(current_finder);
          if ((*it)->remove_base_gc_ref(MEMORY_MANAGER_REF))
            delete (*it);
        }
      }
      else
      {
        // Send the managers to the owner node to nodify them of the deletion
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize<size_t>(instances.size());
          for (std::vector<PhysicalManager*>::const_iterator it =
                instances.begin(); it != instances.end(); it++)
          {
            rez.serialize((*it)->did);
            (*it)->pack_global_ref();
          }
        }
        runtime->send_notify_collected_instances(owner_space, rez);
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ void MemoryManager::handle_notify_collected_instances(
                                          Deserializer &derez, Runtime *runtime)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Memory memory;
      derez.deserialize(memory);
      size_t num_instances;
      derez.deserialize(num_instances);
      std::vector<PhysicalManager*> instances(num_instances);
      std::vector<RtEvent> wait_for;
      for (unsigned idx = 0; idx < num_instances; idx++)
      {
        DistributedID did;
        derez.deserialize(did);
        RtEvent ready;
        instances[idx] = runtime->find_or_request_instance_manager(did, ready);
        if (ready.exists())
          wait_for.push_back(ready);
      }
      MemoryManager *manager = runtime->find_memory_manager(memory);
      if (!wait_for.empty())
      {
        const RtEvent wait_on = Runtime::merge_events(wait_for);
        wait_on.wait();
      }
      manager->notify_collected_instances(instances);
      for (unsigned idx = 0; idx < num_instances; idx++)
        instances[idx]->unpack_global_ref();
    }

    //--------------------------------------------------------------------------
    FutureInstance* MemoryManager::create_future_instance(Operation *op,
                                  UniqueID creator_uid, size_t size, bool eager)
    //--------------------------------------------------------------------------
    {
      if (!is_owner)
      {
        std::atomic<FutureInstance*> result(NULL);
        // Send a message to the owner to do this and wait for the result
        const RtUserEvent wait_on = Runtime::create_rt_user_event();
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(&result);
          rez.serialize(wait_on);
          rez.serialize(creator_uid);
          rez.serialize(size);
          rez.serialize<bool>(eager);
        }
        runtime->send_create_future_instance_request(owner_space, rez);
        wait_on.wait();
        FutureInstance *inst = result.load();
        if (inst == NULL)
        {
          if (op != NULL)
          {
            const char *mem_names[] = {
#define MEM_NAMES(name, desc) desc,
              REALM_MEMORY_KINDS(MEM_NAMES) 
#undef MEM_NAMES
            };
            if (op->get_operation_kind() == Operation::TASK_OP_KIND)
            {
              TaskOp *task = static_cast<TaskOp*>(op);
              REPORT_LEGION_ERROR(ERROR_DEFERRED_ALLOCATION_FAILURE,
                  "Failed to allocate eager future buffer for task %s "
                  "(UID %lld) because %s memory " IDFMT " is full. This is "
                  "an eager allocation so you must adjust the percentage of "
                  "this mememory dedicated for eager allocations with "
                  "'-lg:eager_alloc_percentage' flag on the command line.",
                  task->get_task_name(), op->get_unique_op_id(),
                  mem_names[memory.kind()], memory.id)
            }
            else
              REPORT_LEGION_ERROR(ERROR_DEFERRED_ALLOCATION_FAILURE,
                  "Failed to allocate eager future buffer for %s (UID %lld) "
                  "in parent task %s (UID %lld) because %s memory " IDFMT 
                  " is full. This is an eager allocation so you must adjust "
                  "the percentage of this mememory dedicated for eager "
                  "jallocations with '-lg:eager_alloc_percentage' flag on the "
                  "command line.", op->get_logging_name(),
                  op->get_unique_op_id(), op->get_context()->get_task_name(),
                  op->get_context()->get_unique_id(),
                  mem_names[memory.kind()], memory.id)
          }
        }
        return inst;
      }
      // Do a quick check to see if we can handle the easy case
      if ((size <= LEGION_MAX_RETURN_SIZE) &&
          (memory == runtime->runtime_system_memory))
      {
#ifdef __GNUC__
#if __GNUC__ >= 11
          // GCC is dumb and thinks we need to initialize the malloc buffer
          // before we pass it into the create local call, which we
          // obviously don't need to do, so tell the compiler to shut up
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wmaybe-uninitialized"
#endif
#endif
        // Special case where we can just allocate the buffer locally
        return new FutureInstance(malloc(size), size,
            false/*eager*/, true/*external*/, true/*own allocation*/);
#ifdef __GNUC__
#if __GNUC__ >= 11
#pragma GCC diagnostic pop
#endif
#endif
      }
      // Create the layout description for this instance
      const std::vector<Realm::FieldID> fids(1, 0/*field id*/);
      const std::vector<size_t> sizes(1, size);
      const int dim_order[1] = { 0 };
      const Realm::Point<1,coord_t> zero(0);
      const Realm::InstanceLayoutConstraints constraints(fids, sizes, 1);
      const Realm::IndexSpace<1,coord_t> rect_space(
                                     Realm::Rect<1,coord_t>(zero, zero));
      Realm::InstanceLayoutGeneric *ilg =
        Realm::InstanceLayoutGeneric::choose_instance_layout<1,coord_t>(
            rect_space, constraints, dim_order);
      RtEvent use_event;
      LgEvent unique_event;
      PhysicalInstance instance = PhysicalInstance::NO_INST;
      if (runtime->legion_spy_enabled || (runtime->profiler != NULL))
      {
        RtUserEvent unique = Runtime::create_rt_user_event();
        Runtime::trigger_event(unique);
        unique_event = unique;
      }
      if (eager)
      {
        use_event = create_eager_instance(instance, unique_event, ilg);
        if (!instance.exists())
        {
          if (op != NULL)
          {
            const char *mem_names[] = {
#define MEM_NAMES(name, desc) desc,
              REALM_MEMORY_KINDS(MEM_NAMES) 
#undef MEM_NAMES
            };
            if (op->get_operation_kind() == Operation::TASK_OP_KIND)
            {
              TaskOp *task = static_cast<TaskOp*>(op);
              REPORT_LEGION_ERROR(ERROR_DEFERRED_ALLOCATION_FAILURE,
                  "Failed to allocate eager future buffer for task %s "
                  "(UID %lld) because %s memory " IDFMT " is full. This is "
                  "an eager allocation so you must adjust the percentage of "
                  "this mememory dedicated for eager allocations with "
                  "'-lg:eager_alloc_percentage' flag on the command line.",
                  task->get_task_name(), op->get_unique_op_id(),
                  mem_names[memory.kind()], memory.id)
            }
            else
              REPORT_LEGION_ERROR(ERROR_DEFERRED_ALLOCATION_FAILURE,
                  "Failed to allocate eager future buffer for %s (UID %lld) "
                  "in parent task %s (UID %lld) because %s memory " IDFMT 
                  " is full. This is an eager allocation so you must adjust "
                  "the percentage of this mememory dedicated for eager "
                  "jallocations with '-lg:eager_alloc_percentage' flag on the "
                  "command line.", op->get_logging_name(),
                  op->get_unique_op_id(), op->get_context()->get_task_name(),
                  op->get_context()->get_unique_id(),
                  mem_names[memory.kind()], memory.id)
          }
          return NULL;
        } 
      }
      else
      {
        // deferred allocation case
        // no need to serialize this with respect to the other allocations
        // because this is not subject to find_and_create calls
        GarbageCollector *collector = NULL;
        do {
          RtEvent alloc_precondition;
          if (collector != NULL)
            alloc_precondition = collector->perform_collection();;
          Realm::ProfilingRequestSet requests;
#ifdef DEBUG_LEGION
          assert(!instance.exists());
#endif
#ifndef LEGION_MALLOC_INSTANCES
          FutureInstanceAllocator allocator(unique_event);
          ProfilingResponseBase base(&allocator, creator_uid,
                                     false/*completion*/);
          Realm::ProfilingRequest &req = requests.add_request(
              runtime->find_utility_group(), LG_LEGION_PROFILING_ID,
              &base, sizeof(base), LG_RESOURCE_PRIORITY);
          req.add_measurement<
            Realm::ProfilingMeasurements::InstanceAllocResult>(); 
          if (runtime->profiler != NULL)
            runtime->profiler->add_inst_request(requests, 
                                                creator_uid, unique_event);
          use_event = RtEvent(PhysicalInstance::create_instance(instance,
                    memory, ilg->clone(), requests, alloc_precondition));
          if (use_event.exists() && (implicit_profiler != NULL))
            implicit_profiler->record_instance_ready(use_event, unique_event,
                                                     alloc_precondition);
          if (allocator.succeeded())
          {
            AutoLock m_lock(manager_lock);
#ifdef DEBUG_LEGION
            assert(remaining_capacity >= size);
#endif
            remaining_capacity -= size;
            break;
          }
          else if (instance.exists())
          {
            instance.destroy();
            instance = PhysicalInstance::NO_INST;
          }
#else
          use_event = allocate_legion_instance(ilg->clone(), requests,
              instance, unique_event);
          if (instance.exists())
          {
            AutoLock m_lock(manager_lock);
#ifdef DEBUG_LEGION
            assert(remaining_capacity >= size);
#endif
            remaining_capacity -= size;
            break;
          }
#endif
          if (collector == NULL)
            collector = new GarbageCollector(collection_lock, manager_lock,
                runtime->address_space, memory, size, collectable_instances);
        } while (!collector->collection_complete());
        if (collector != NULL)
          delete collector;
        delete ilg;
        if (!instance.exists())
        {
          if (op != NULL)
          {
            const char *mem_names[] = {
#define MEM_NAMES(name, desc) desc,
              REALM_MEMORY_KINDS(MEM_NAMES) 
#undef MEM_NAMES
            };
            if (op->get_operation_kind() == Operation::TASK_OP_KIND)
            {
              TaskOp *task = static_cast<TaskOp*>(op);
              REPORT_LEGION_ERROR(ERROR_DEFERRED_ALLOCATION_FAILURE,
                  "Failed to allocate future for task %s "
                  "(UID %lld) because %s memory " IDFMT " is full.", 
                  task->get_task_name(), op->get_unique_op_id(),
                  mem_names[memory.kind()], memory.id)
            }
            else
              REPORT_LEGION_ERROR(ERROR_DEFERRED_ALLOCATION_FAILURE,
                  "Failed to allocate future for %s (UID %lld) "
                  "in parent task %s (UID %lld) because %s memory " IDFMT 
                  " is full.", op->get_logging_name(), op->get_unique_op_id(),
                  op->get_context()->get_task_name(),
                  op->get_context()->get_unique_id(),
                  mem_names[memory.kind()], memory.id)
          }
          return NULL;
        }
      }
      return new FutureInstance(NULL/*data*/, size,
              eager, false/*external*/, true/*own allocation*/, unique_event,
              instance, Processor::NO_PROC, use_event);
    }

    //--------------------------------------------------------------------------
    void MemoryManager::free_future_instance(PhysicalInstance inst, size_t size, 
                                             RtEvent free_event, bool eager)
    //--------------------------------------------------------------------------
    {
      if (!is_owner)
      {
        // Send this to the owner node
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(inst);
          rez.serialize(size);
          rez.serialize(free_event);
          rez.serialize<bool>(eager);
        }
        runtime->send_free_future_instance(owner_space, rez); 
        return;
      }
      if (!eager)
      {
        // perform the deferred deletion on this instance
        inst.destroy(free_event);
        AutoLock m_lock(manager_lock);
        remaining_capacity += size;
      }
      else
        free_eager_instance(inst, free_event);
    }

    //--------------------------------------------------------------------------
    MemoryManager::FutureInstanceAllocator::FutureInstanceAllocator(LgEvent u)
      : ready(Runtime::create_rt_user_event()), unique_event(u)
    //--------------------------------------------------------------------------
    {
      success.store(false);
    }

    //--------------------------------------------------------------------------
    bool MemoryManager::FutureInstanceAllocator::handle_profiling_response(
        const Realm::ProfilingResponse &response, const void *orig, 
        size_t orig_length, LgEvent &fevent)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(response.has_measurement<
          Realm::ProfilingMeasurements::InstanceAllocResult>());
#endif
      Realm::ProfilingMeasurements::InstanceAllocResult result;
      result.success = false; // Need this to avoid compiler warnings
#ifdef DEBUG_LEGION
#ifndef NDEBUG
      const bool measured =  
#endif
#endif
        response.get_measurement<
              Realm::ProfilingMeasurements::InstanceAllocResult>(result);
#ifdef DEBUG_LEGION
      assert(measured);
#endif
      success.store(result.success);
      fevent = unique_event;
      // Can't read anything after trigger the event as the object
      // might be deleted after we do that
      Runtime::trigger_event(ready);
      return true;
    }

    //--------------------------------------------------------------------------
    RtEvent MemoryManager::attach_external_instance(PhysicalManager *manager)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(manager->is_external_instance());
#endif
      if (!is_owner)
      {
        // Send a message to the owner node to do the record
        RtUserEvent result = Runtime::create_rt_user_event();
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(manager->did);
          rez.serialize(result);
        }
        runtime->send_external_attach(manager->owner_space, rez);
        return result;
      }
#ifdef DEBUG_LEGION
      assert(is_owner);
#endif
      // Since we're going to put this in the table add a reference
      manager->add_base_resource_ref(MEMORY_MANAGER_REF);
      {
        AutoLock m_lock(manager_lock);
        TreeInstances &insts = current_instances[manager->tree_id];
#ifdef DEBUG_LEGION
        assert(insts.find(manager) == insts.end());
#endif
        insts[manager] = LEGION_GC_NEVER_PRIORITY;
      }
      return RtEvent::NO_RT_EVENT;
    }

    //--------------------------------------------------------------------------
    void MemoryManager::detach_external_instance(PhysicalManager *manager)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(manager->is_external_instance());
#endif
      if (!is_owner)
      {
        // Send a message to the owner node to do the deletion
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(memory);
          rez.serialize(manager->did);
        }
        manager->pack_valid_ref();
        runtime->send_external_detach(manager->owner_space, rez);
      }
      else
      {
        // Tell the manager that it can perform its deletion
        manager->perform_deletion(runtime->address_space);
      }
    }

    //--------------------------------------------------------------------------
    bool MemoryManager::is_visible_memory(Memory other)
    //--------------------------------------------------------------------------
    {
      if (other == memory)
        return true;
      {
        AutoLock m_lock(manager_lock,1,false);
        if (!visible_memories.empty())
          return (visible_memories.find(other) != visible_memories.end());
      }
      // Do the query while not holding the lock
      Machine::MemoryQuery vis_mems(runtime->machine);
      vis_mems.has_affinity_to(memory);
      AutoLock m_lock(manager_lock);
      if (visible_memories.empty())
        for (Machine::MemoryQuery::iterator it = vis_mems.begin();
              it != vis_mems.end(); it++)
          visible_memories.insert(*it);
      return (visible_memories.find(other) != visible_memories.end());
    }

    //--------------------------------------------------------------------------
    size_t MemoryManager::query_available_eager_memory(void)
    //--------------------------------------------------------------------------
    {
      AutoLock m_lock(manager_lock,1,false/*exclusive*/);
      return eager_remaining_capacity;
    }

    //--------------------------------------------------------------------------
    RtEvent MemoryManager::create_eager_instance(PhysicalInstance &instance,
                     LgEvent unique_event, Realm::InstanceLayoutGeneric *layout)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner);
#endif
      RtEvent wait_on;
      instance = PhysicalInstance::NO_INST;
      if (eager_allocator == NULL) 
        return wait_on;
      const size_t allocation_id = next_allocation_id.fetch_add(1);

      const size_t size = layout->bytes_used;
      bool allocated = (size == 0);
      size_t offset = 0;

      if (!allocated)
      {
        AutoLock m_lock(manager_lock);
        allocated = eager_allocator->allocate(
            allocation_id, size, layout->alignment_reqd, offset);
        if (allocated)
        {
          eager_remaining_capacity -= size;
          const uintptr_t ptr = eager_pool + offset;
#ifdef DEBUG_LEGION
          assert(eager_allocations.find(ptr) == eager_allocations.end());
#endif
          eager_allocations[ptr] = allocation_id;
        }
      }

      if (allocated)
      {
        wait_on = create_sub_eager_instance(
            instance, eager_pool + offset, size, layout, unique_event);
        log_eager.debug("allocate instance " IDFMT
                      " (%p+%zd, %zd) on memory " IDFMT ", %zd bytes left",
                      instance.id,
                      reinterpret_cast<void*>(eager_pool),
                      offset,
                      size,
                      memory.id,
                      eager_remaining_capacity);
      }
      else
      {
        log_eager.debug("failed to allocate an instance of size %zd on memory "
                        IDFMT " (%zd bytes left)",
                        size, memory.id, eager_remaining_capacity);
        if (runtime->dump_free_ranges)
        {
          AutoLock m_lock(manager_lock);
          eager_allocator->dump_all_free_ranges(log_eager);
        }
      }

      return wait_on;
    }

    //--------------------------------------------------------------------------
    RtEvent MemoryManager::create_sub_eager_instance(PhysicalInstance &instance,
                                                     uintptr_t ptr, size_t size,
                                           Realm::InstanceLayoutGeneric *layout,
                                                     LgEvent unique_event)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert((ptr >= eager_pool) || ((size == 0) && (ptr == 0)));
#endif
      Realm::ProfilingRequestSet requests;
      if (runtime->profiler != NULL)
      {
#ifdef DEBUG_LEGION
        assert(unique_event.exists());
#endif
        runtime->profiler->add_inst_request(requests, 
                  implicit_provenance, unique_event);
      }
      if (size > 0)
      {
        int64_t offset = ptr - eager_pool;
        const Point<1> start(offset);
        const Point<1> stop(offset + size - 1);
        const Rect<1> bounds(start, stop);
        Realm::ExternalInstanceResource *external_resource =
          eager_pool_instance.generate_resource_info(
              Realm::IndexSpaceGeneric(bounds), 0/*fid*/, false/*read only*/);
#ifdef DEBUG_LEGION
        // Note that if you hit this then that likely means that Realm 
        // doesn't support 'generate_resource_info' yet for that kind of
        // memory and it probably just needs to be implemented
        assert(external_resource != NULL);
#endif
        const RtEvent wait_on(Realm::RegionInstance::create_external_instance(
              instance, memory, layout, *external_resource, requests));
        delete external_resource;
        if (wait_on.exists() && (implicit_profiler != NULL))
          implicit_profiler->record_instance_ready(wait_on, unique_event);
        return wait_on;
      }
      else
      {
        const RtEvent wait_on(
            Realm::RegionInstance::create_instance(instance, memory, 
                                                   layout, requests));
        if (wait_on.exists() && (implicit_profiler != NULL))
          implicit_profiler->record_instance_ready(wait_on, unique_event);
        return wait_on;
      }
    }

    //--------------------------------------------------------------------------
    void MemoryManager::free_eager_instance(
                                       PhysicalInstance instance, RtEvent defer)
    //--------------------------------------------------------------------------
    {
      if (defer.exists() && !defer.has_triggered())
      {
        log_eager.debug("defer deallocation of instance " IDFMT
                        " on memory " IDFMT ": wait for " IDFMT,
                        instance.id, memory.id, defer.id);
        FreeEagerInstanceArgs args(this, instance);
        runtime->issue_runtime_meta_task(args, LG_LOW_PRIORITY, defer);
      }
      else
      {
        if (instance.get_layout()->bytes_used > 0)
        {
          void *base = instance.pointer_untyped(0,0);
#ifdef DEBUG_LEGION
          // Technically realm could return us a null pointer here if the
          // instance is not directly accessible on this node, but that
          // should never happen because all eager allocations are done
          // locally and to memories for which loads and stores are safe
          assert(base != NULL);
#endif
          const uintptr_t ptr = reinterpret_cast<uintptr_t>(base);
          AutoLock lock(manager_lock);
          std::map<uintptr_t,size_t>::iterator finder = 
            eager_allocations.find(ptr);

          size_t size = 0;
          // empty allocations are not created by the eager allocator,
          // so we don't need to deallocate them
          if (finder != eager_allocations.end())
          {
            size = eager_allocator->get_size(finder->second);
            eager_remaining_capacity += size;
            eager_allocator->deallocate(finder->second);
            eager_allocations.erase(finder);
          }
          log_eager.debug(
            "deallocate instance " IDFMT " of size %zd on memory " IDFMT
            ", %zd bytes left", instance.id, size, memory.id,
            eager_remaining_capacity);
        }
        instance.destroy();
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ void MemoryManager::handle_free_eager_instance(const void *args)
    //--------------------------------------------------------------------------
    {
      const FreeEagerInstanceArgs *fargs = (const FreeEagerInstanceArgs*)args;
      fargs->manager->free_eager_instance(fargs->inst, RtEvent::NO_RT_EVENT);
    }

    //--------------------------------------------------------------------------
    void MemoryManager::free_external_allocation(uintptr_t ptr, size_t size)
    //--------------------------------------------------------------------------
    {
      switch (memory.kind())
      {
        case Memory::SYSTEM_MEM:
        case Memory::SOCKET_MEM:
          {
            free((void*)ptr);
            break;
          }
        case Memory::REGDMA_MEM:
          {
            munlock((void*)ptr, size);
            free((void*)ptr);
            break;
          }
#ifdef LEGION_USE_CUDA
#define CHECK_CUDA(cmd) do { \
  CUresult ret = (cmd); \
  if (ret != CUDA_SUCCESS) { \
    const char *name, *str; \
    cuGetErrorName(ret, &name); \
    cuGetErrorString(ret, &str); \
    fprintf(stderr, "CU: %s = %d (%s): %s\n", #cmd, ret, name, str); \
    abort(); \
  } \
} while (false)
        case Memory::GPU_FB_MEM:
          {
            CHECK_CUDA( cuMemFree((CUdeviceptr)ptr) );
            break;
          }
        case Memory::Z_COPY_MEM:
          {
            CHECK_CUDA( cuMemFreeHost((void*)ptr) );
            break;
          }
#undef CHECK_CUDA
#endif
#ifdef LEGION_USE_HIP
#define CHECK_HIP(cmd) do { \
  hipError_t ret = (cmd); \
  if (ret != hipSuccess) { \
    const char *name, *str; \
    name = hipGetErrorName(ret); \
    str = hipGetErrorString(ret); \
    fprintf(stderr, "HIP: %s = %d (%s): %s\n", #cmd, ret, name, str); \
    abort(); \
  } \
} while (false)
        case Memory::GPU_FB_MEM:
          {
            CHECK_HIP( hipFree((void*)ptr) );
            break;
          }
        case Memory::Z_COPY_MEM:
          {
            CHECK_HIP( hipHostFree((void*)ptr) );
            break;
          }
#undef CHECK_HIP
#endif
        default:
          REPORT_LEGION_FATAL(LEGION_FATAL_UNIMPLEMENTED_FEATURE,
              "Unsupported memory kind %d", memory.kind())
      }
    }

#ifdef LEGION_MALLOC_INSTANCES
    //--------------------------------------------------------------------------
    RtEvent MemoryManager::allocate_legion_instance(
                                Realm::InstanceLayoutGeneric *layout,
                                const Realm::ProfilingRequestSet &requests,
                                PhysicalInstance &instance,
                                LgEvent unique_event, bool needs_deferral)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner);
#endif
      RtEvent result;
      const size_t footprint = layout->bytes_used;
      switch (memory.kind())
      {
        case Memory::SYSTEM_MEM:
        case Memory::SOCKET_MEM:
          {
            void *ptr = NULL;
            if (footprint > 0)
            {
              if (posix_memalign(&ptr, 32/*alignment*/, footprint))
                return result; // failed
            }
            const Realm::ExternalMemoryResource resource(
                (uintptr_t)ptr, footprint, false/*read only*/);
            result = 
              RtEvent(PhysicalInstance::create_external_instance(instance,
                  resource.suggested_memory(), layout, resource, requests));
            break;
          }
        case Memory::REGDMA_MEM:
          {
            void *ptr = NULL;
            if (footprint > 0)
            {
              if (posix_memalign(&ptr, 32/*alignment*/, footprint))
                return result; // failed
              mlock(ptr, footprint);
            }
            const Realm::ExternalMemoryResource resource(
                (uintptr_t)ptr, footprint, false/*read only*/);
            result = 
              RtEvent(PhysicalInstance::create_external_instance(instance,
                  resource.suggested_memory(), layout, resource, requests));
            break;
          }
#ifdef LEGION_USE_CUDA
        case Memory::Z_COPY_MEM:
        case Memory::GPU_FB_MEM:
          {
            if (needs_deferral)
            {
              MallocInstanceArgs args(this, layout, &requests, 
                  &instance, unique_event);
              const RtEvent wait_on = 
                runtime->issue_application_processor_task(args,
                  LG_LATENCY_WORK_PRIORITY, local_gpu);
              if (wait_on.exists() && !wait_on.has_triggered())
                wait_on.wait();
              return result;
            }
            else
            {
              // Use the driver API here to avoid the CUDA hijack
              if (memory.kind() == Memory::GPU_FB_MEM)
              {
                CUdeviceptr ptr;
                if ((footprint > 0) && 
                    (cuMemAlloc(&ptr, footprint) != CUDA_SUCCESS))
                  return result;
                CUdevice device;
                if (cuCtxGetDevice(&device) != CUDA_SUCCESS)
                  return result;
                const Realm::ExternalCudaMemoryResource resource(
                    device, (uintptr_t)ptr, footprint, false/*read only*/);
                result = 
                  RtEvent(PhysicalInstance::create_external_instance(instance,
                    resource.suggested_memory(), layout, resource, requests));
              }
              else
              {
                void *ptr = NULL;
                if ((footprint > 0) && 
                    (cuMemHostAlloc(&ptr, footprint, CU_MEMHOSTALLOC_PORTABLE |
                      CU_MEMHOSTALLOC_DEVICEMAP) != CUDA_SUCCESS))
                  return result;
                // Check that the device pointer is the same as the host
                CUdeviceptr gpuptr;
                if (cuMemHostGetDevicePointer(&gpuptr,ptr,0) != CUDA_SUCCESS)
                  return result;
                if (ptr != (void*)gpuptr)
                  return result;
                const Realm::ExternalCudaPinnedHostResource resource(
                    (uintptr_t)ptr, footprint, false/*read only*/);
                result =
                  RtEvent(PhysicalInstance::create_external_instance(instance,
                    resource.suggested_memory(), layout, resource, requests));
              }
            }
            break;
          }
#endif
#ifdef LEGION_USE_HIP
        case Memory::Z_COPY_MEM:
        case Memory::GPU_FB_MEM:
          {
            if (needs_deferral)
            {
              MallocInstanceArgs args(this, layout, &requests,
                  &instance, unique_event);
              const RtEvent wait_on =
                runtime->issue_application_processor_task(args,
                  LG_LATENCY_WORK_PRIORITY, local_gpu);
              if (wait_on.exists() && !wait_on.has_triggered())
                wait_on.wait();
              return result;
            }
            else
            {
              // Use the driver API here to avoid the CUDA hijack
              if (memory.kind() == Memory::GPU_FB_MEM)
              {
                hipDeviceptr_t ptr;
                if ((footprint > 0) && 
                    (hipMalloc((void **)&ptr, footprint) != hipSuccess))
                  return result;
                int device;
                if (hipGetDevice(&device) != hipSuccess)
                  return result;
                const Realm::ExternalHipMemoryResource resource(
                    device, (uintptr_t)ptr, footprint, false/*read only*/);
                result =
                  RtEvent(PhysicalInstance::create_external_instance(instance,
                    resource.suggested_memory(), layout, resource, requests));
              }
              else
              {
                void *ptr = NULL;
                if ((footprint > 0) && 
                    (hipHostMalloc(&ptr, footprint, hipHostMallocPortable |
                      hipHostMallocMapped) != hipSuccess))
                  return result;
                hipDeviceptr_t gpuptr;
                if (hipHostGetDevicePointer((void **)&gpuptr,ptr,0) 
                      != hipSuccess)
                  return result;
                if (ptr != (void*)gpuptr)
                  return result;
                const Realm::ExternalHipPinnedHostResource resource(
                    (uintptr_t)ptr, footprint, false/*read only*/);
                result =
                  RtEvent(PhysicalInstance::create_external_instance(instance,
                    resource.suggested_memory(), layout, resource, requests));
              }
            }
            break;
          }
#endif
        default:
          REPORT_LEGION_FATAL(LEGION_FATAL_UNIMPLEMENTED_FEATURE,
              "Unsupported memory kind for LEGION_MALLOC_INSTANCES %d",
              memory.kind())
      }
      if (instance.exists())
      {
        AutoLock m_lock(manager_lock);
#ifdef DEBUG_LEGION
        assert(allocations.find(instance) == allocations.end());
#endif
        allocations[instance] = footprint;
      }
      if (result.exists() && (implicit_profiler != NULL))
        implicit_profiler->record_instance_ready(result, unique_event);
      return result;
    }

    //--------------------------------------------------------------------------
    void MemoryManager::record_legion_instance(InstanceManager *man, 
                                               PhysicalInstance instance)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner);
#endif
      AutoLock m_lock(manager_lock);
#ifdef DEBUG_LEGION
      assert(legion_instances.find(man) == legion_instances.end());
#endif
      legion_instances[man] = instance;
    }

    //--------------------------------------------------------------------------
    void MemoryManager::free_legion_instance(InstanceManager *man,RtEvent defer)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner);
#endif
      PhysicalInstance instance;
      {
        AutoLock m_lock(manager_lock);
        std::map<InstanceManager*,PhysicalInstance>::iterator finder = 
          legion_instances.find(man);
#ifdef DEBUG_LEGION
        assert(finder != legion_instances.end());
#endif
        instance = finder->second;
        legion_instances.erase(finder);
      }
      free_legion_instance(defer, instance);
    }

    //--------------------------------------------------------------------------
    void MemoryManager::free_legion_instance(RtEvent defer, 
                                    PhysicalInstance instance, bool needs_defer)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(is_owner);
      assert(instance.exists());
#endif
      size_t size;
      {
        AutoLock m_lock(manager_lock);
        if (defer.exists() && !defer.has_triggered())
        {
          std::map<RtEvent,PhysicalInstance>::iterator finder = 
            pending_collectables.find(defer);
          if (finder == pending_collectables.end())
          {
            FreeInstanceArgs args(this, instance);
#if defined(LEGION_USE_CUDA) || defined(LEGION_USE_HIP)
            if (local_gpu.exists())
              runtime->issue_application_processor_task(args, LG_LOW_PRIORITY, 
                                                        local_gpu, defer);
            else
              runtime->issue_runtime_meta_task(args, LG_LOW_PRIORITY, defer);
#else
            runtime->issue_runtime_meta_task(args, LG_LOW_PRIORITY, defer);
#endif
          }
          else
            finder->second = instance;
          return;
        }
        std::map<PhysicalInstance,size_t>::iterator finder = 
          allocations.find(instance);
#ifdef DEBUG_LEGION
        assert(finder != allocations.end());
#endif
        size = finder->second;
        allocations.erase(finder);
      }
#if defined(LEGION_USE_CUDA) || defined(LEGION_USE_HIP)
      if (needs_defer && (size > 0) &&
          ((memory.kind() == Memory::Z_COPY_MEM) || 
           (memory.kind() == Memory::GPU_FB_MEM)))
      {
        // Put the allocation back in for when we go to look
        // for it on the second pass
        {
          AutoLock m_lock(manager_lock);
#ifdef DEBUG_LEGION
          assert(allocations.find(instance) == allocations.end());
#endif
          allocations[instance] = size;
        }
        FreeInstanceArgs args(this, instance);
        runtime->issue_application_processor_task(args, LG_LOW_PRIORITY, 
                                                  local_gpu, defer);
        return;
      }
#endif
      if (size > 0)
        free_external_allocation((uintptr_t)instance.pointer_untyped(0,0),size);
      instance.destroy(defer);
    }

    //--------------------------------------------------------------------------
    /*static*/ void MemoryManager::handle_malloc_instance(const void *args)
    //--------------------------------------------------------------------------
    {
      const MallocInstanceArgs *margs = (const MallocInstanceArgs*)args;
      const RtEvent ready = margs->manager->allocate_legion_instance(
          margs->layout, *(margs->requests), *(margs->instance), 
          margs->unique_event, false/*needs defer*/);
      if (ready.exists() && !ready.has_triggered())
        ready.wait();
    }

    //--------------------------------------------------------------------------
    /*static*/ void MemoryManager::handle_free_instance(const void *args)
    //--------------------------------------------------------------------------
    {
      const FreeInstanceArgs *fargs = (const FreeInstanceArgs*)args;
      fargs->manager->free_legion_instance(RtEvent::NO_RT_EVENT, 
                                         fargs->instance, false/*needs defer*/);
    }
#endif

    /////////////////////////////////////////////////////////////
    // Virtual Channel 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    VirtualChannel::VirtualChannel(VirtualChannelKind kind, 
        AddressSpaceID local_address_space, size_t max_message_size, 
        bool profile_outgoing)
      : sending_buffer((uint8_t*)malloc(max_message_size)), 
        sending_buffer_size(max_message_size), 
        ordered_channel((kind != DEFAULT_VIRTUAL_CHANNEL) &&
                        (kind != THROUGHPUT_VIRTUAL_CHANNEL)), 
        profile_outgoing_messages(profile_outgoing),
        request_priority((kind == THROUGHPUT_VIRTUAL_CHANNEL) ?
            LG_THROUGHPUT_MESSAGE_PRIORITY : (kind == UPDATE_VIRTUAL_CHANNEL) ?
            LG_LATENCY_DEFERRED_PRIORITY : LG_LATENCY_MESSAGE_PRIORITY),
        response_priority((kind == THROUGHPUT_VIRTUAL_CHANNEL) ?
            LG_THROUGHPUT_RESPONSE_PRIORITY : (kind == UPDATE_VIRTUAL_CHANNEL) ?
            LG_LATENCY_MESSAGE_PRIORITY : LG_LATENCY_RESPONSE_PRIORITY),
        partial_messages(0), observed_recent(true)
    //--------------------------------------------------------------------------
    //
    {
      receiving_buffer_size = max_message_size;
      receiving_buffer = (uint8_t*)legion_malloc(MESSAGE_BUFFER_ALLOC,
                                              receiving_buffer_size);
#ifdef DEBUG_LEGION
      assert(sending_buffer != NULL);
      assert(receiving_buffer != NULL);
#endif
      // Use a dummy implicit provenance at the front for the message
      // to comply with the requirements of the meta-task handler which
      // expects this before the task ID. We'll actually have individual
      // implicit provenances that will override this when handling the
      // messages so we can just set this to zero.
      memset(sending_buffer, 0, sizeof(UniqueID));
      sending_index = sizeof(UniqueID);
#ifdef DEBUG_LEGION_CALLERS
      const LgTaskID scheduler = LG_SCHEDULER_ID;
      memcpy(sending_buffer+sending_index, &sched, sizeof(scheduler));
      sending_index += sizeof(scheduler);
#endif
      // Set up the buffer for sending the first batch of messages
      // Only need to write the processor once
      const LgTaskID message = LG_MESSAGE_ID;
      memcpy(sending_buffer+sending_index, &message, sizeof(message));
      sending_index += sizeof(message);
      memcpy(sending_buffer+sending_index, &local_address_space,
          sizeof(local_address_space));
      sending_index += sizeof(local_address_space);
      memcpy(sending_buffer+sending_index, &kind, sizeof(kind));
      sending_index += sizeof(kind);
      header = FULL_MESSAGE;
      sending_index += sizeof(header);
      packaged_messages = 0;
      sending_index += sizeof(packaged_messages);
      last_message_event = RtEvent::NO_RT_EVENT;
      partial_message_id = 0;
      partial_assembly = NULL;
      partial = false;
      // Set up the receiving buffer
      received_messages = 0;
      receiving_index = 0;
    }

    //--------------------------------------------------------------------------
    VirtualChannel::VirtualChannel(const VirtualChannel &rhs)
      : sending_buffer(NULL), sending_buffer_size(0), 
        ordered_channel(false), profile_outgoing_messages(false),
        request_priority(rhs.request_priority),
        response_priority(rhs.response_priority)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    VirtualChannel::~VirtualChannel(void)
    //--------------------------------------------------------------------------
    {
      free(sending_buffer);
      free(receiving_buffer);
      receiving_buffer = NULL;
      receiving_buffer_size = 0;
      if (partial_assembly != NULL)
        delete partial_assembly;
    }

    //--------------------------------------------------------------------------
    void VirtualChannel::package_message(Serializer &rez, MessageKind k,
                         bool flush, RtEvent flush_precondition,
                         Runtime *runtime, Processor target, 
                         bool response)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!flush_precondition.exists() || flush);
#endif
      // First check to see if the message fits in the current buffer    
      // including the overhead for the message: kind and size
      size_t buffer_size = rez.get_used_bytes();
      const uint8_t *buffer = (const uint8_t*)rez.get_buffer();
      const size_t header_size = 
#ifdef DEBUG_LEGION_CALLERS
        sizeof(LgTaskID) +
#endif
        sizeof(k) + sizeof(implicit_provenance) + sizeof(buffer_size);
      // Need to hold the lock when manipulating the buffer
      AutoLock c_lock(channel_lock);
      if ((sending_index+header_size+buffer_size) > sending_buffer_size)
      {
        // Make sure we can at least get the meta-data into the buffer
        // Since there is no partial data we can fake the flush
        if ((sending_buffer_size - sending_index) <= header_size)
          send_message(true/*complete*/, runtime, target, k,
                       response, flush_precondition);
        // Now can package up the meta data
        packaged_messages++;
        memcpy(sending_buffer+sending_index, &k, sizeof(k));
        sending_index += sizeof(k);
        memcpy(sending_buffer+sending_index, &implicit_provenance,
            sizeof(implicit_provenance));
        sending_index += sizeof(implicit_provenance);
#ifdef DEBUG_LEGION_CALLERS
        memcpy(sending_buffer+sending_index, &implicit_task_kind,
            sizeof(implicit_task_kind));
        sending_index += sizeof(implicit_task_kind);
#endif
        memcpy(sending_buffer+sending_index, &buffer_size, sizeof(buffer_size));
        sending_index += sizeof(buffer_size);
        while (buffer_size > 0)
        {
          unsigned remaining = sending_buffer_size - sending_index;
          if (remaining == 0)
            send_message(false/*complete*/, runtime, target, k,
                         response, flush_precondition);
          remaining = sending_buffer_size - sending_index;
#ifdef DEBUG_LEGION
          assert(remaining > 0); // should be space after the send
#endif
          // Figure out how much to copy into the buffer
          unsigned to_copy = (remaining < buffer_size) ? 
                                            remaining : buffer_size;
          memcpy(sending_buffer+sending_index,buffer,to_copy);
          buffer_size -= to_copy;
          buffer += to_copy;
          sending_index += to_copy;
        } 
      }
      else
      {
        packaged_messages++;
        // Package up the kind and the size first
        memcpy(sending_buffer+sending_index, &k, sizeof(k));
        sending_index += sizeof(k);
        memcpy(sending_buffer+sending_index, &implicit_provenance, 
            sizeof(implicit_provenance));
        sending_index += sizeof(implicit_provenance);
#ifdef DEBUG_LEGION_CALLERS
        memcpy(sending_buffer+sending_index, &implicit_task_kind,
            sizeof(implicit_task_kind));
        sending_index += sizeof(implicit_task_kind);
#endif
        memcpy(sending_buffer+sending_index, &buffer_size, sizeof(buffer_size));
        sending_index += sizeof(buffer_size);
        // Then copy over the buffer
        memcpy(sending_buffer+sending_index,buffer,buffer_size); 
        sending_index += buffer_size;
      }
      if (flush)
        send_message(true/*complete*/, runtime, target, k, 
                     response, flush_precondition);
    }

    //--------------------------------------------------------------------------
    void VirtualChannel::send_message(bool complete, Runtime *runtime,
                                      Processor target, MessageKind kind,
                                      bool response, RtEvent send_precondition)
    //--------------------------------------------------------------------------
    {
      // See if we need to switch the header file
      // and update the state of partial
      bool first_partial = false;
      if (!complete)
      {
        header = PARTIAL_MESSAGE;
        // If this is an unordered virtual channel, then embed our partial
        // message id in the high-order bits
        if (!ordered_channel)
          header = (MessageHeader)
            (((unsigned)header) | (partial_message_id << 2));
        if (!partial)
        {
          partial = true;
          first_partial = true;
        }
      }
      else if (partial)
      {
        header = FINAL_MESSAGE;
        // If this is an unordered virtual channel, then embed our partial
        // message id in the high-order bits
        if (!ordered_channel)
          // Also increment the partial message id for the next message
          // This can overflow safely since it's an unsigned integer
          header = (MessageHeader)
            (((unsigned)header) | (partial_message_id++ << 2));
        partial = false;
      }
      // Save the header and the number of messages into the buffer
      const size_t base_size = sizeof(UniqueID) + sizeof(LgTaskID) +
#ifdef DEBUG_LEGION_CALLERS
        sizeof(LgTaskID) +
#endif
        sizeof(AddressSpaceID) + sizeof(VirtualChannelKind);
      memcpy(sending_buffer + base_size, &header, sizeof(header));
      memcpy(sending_buffer + base_size + sizeof(header), &packaged_messages,
            sizeof(packaged_messages));
      // Send the message directly there, don't go through the
      // runtime interface to avoid being counted, still include
      // a profiling request though if necessary in order to 
      // see waits on message handlers
      if (profile_outgoing_messages)
      {
        Realm::ProfilingRequestSet requests;
        const RtEvent precondition = (ordered_channel || 
               ((header != FULL_MESSAGE) && !first_partial)) ?
                (send_precondition.exists() ? 
                  Runtime::merge_events(send_precondition, last_message_event) :
                  last_message_event) : send_precondition;
        LegionProfiler::add_message_request(
            requests, kind, target, precondition);
        last_message_event = RtEvent(target.spawn(
#ifdef LEGION_SEPARATE_META_TASKS
              LG_TASK_ID + LG_MESSAGE_ID + kind,
#else
              LG_TASK_ID, 
#endif
              sending_buffer, sending_index, requests, precondition,
              response ? response_priority : request_priority));
        if (!ordered_channel && (header != PARTIAL_MESSAGE))
        {
          unordered_events.insert(last_message_event);
          if (unordered_events.size() >= MAX_UNORDERED_EVENTS)
            filter_unordered_events();
        }
      }
      else
      {
        last_message_event = RtEvent(target.spawn(
#ifdef LEGION_SEPARATE_META_TASKS
                LG_TASK_ID + LG_MESSAGE_ID + kind,
#else
                LG_TASK_ID, 
#endif
                sending_buffer, sending_index, 
                (ordered_channel || 
                 ((header != FULL_MESSAGE) && !first_partial)) ?
                  (send_precondition.exists() ? 
                   Runtime::merge_events(send_precondition,last_message_event) :
                   last_message_event) : send_precondition, 
                response ? response_priority : request_priority));
        if (!ordered_channel && (header != PARTIAL_MESSAGE))
        {
          unordered_events.insert(last_message_event);
          if (unordered_events.size() >= MAX_UNORDERED_EVENTS)
            filter_unordered_events();
        }
      }
      // Reset the state of the buffer
      sending_index = base_size + sizeof(header) + sizeof(unsigned);
      if (partial)
        header = PARTIAL_MESSAGE;
      else
        header = FULL_MESSAGE;
      packaged_messages = 0;
    }

    //--------------------------------------------------------------------------
    void VirtualChannel::filter_unordered_events(void)
    //--------------------------------------------------------------------------
    {
      // Lock held from caller
#ifdef DEBUG_LEGION
      assert(!ordered_channel);
      assert(unordered_events.size() >= MAX_UNORDERED_EVENTS);
#endif
      // Prune out any triggered events
      for (std::set<RtEvent>::iterator it = unordered_events.begin();
            it != unordered_events.end(); /*nothing*/)
      {
        if (it->has_triggered())
        {
          std::set<RtEvent>::iterator to_delete = it++;
          unordered_events.erase(to_delete);
        }
        else
          it++;
      }
      // If we still have too many events, collapse them down
      if (unordered_events.size() >= MAX_UNORDERED_EVENTS)
      {
        const RtEvent summary = Runtime::merge_events(unordered_events);
        unordered_events.clear();
        unordered_events.insert(summary);
      }
    }

    //--------------------------------------------------------------------------
    void VirtualChannel::confirm_shutdown(ShutdownManager *shutdown_manager,
               bool phase_one, Processor target, bool profiling_virtual_channel)
    //--------------------------------------------------------------------------
    {
      AutoLock c_lock(channel_lock);
      if (phase_one)
      {
        if (packaged_messages > 0)
        {
          shutdown_manager->record_recent_message();
          // If this is the profiling channel then flush the messages
          if (profiling_virtual_channel)
            send_message(true/*complete*/, implicit_runtime, target,
                SEND_PROFILER_EVENT_TRIGGER, false/*response*/,
                RtEvent::NO_RT_EVENT);
        }
        if (ordered_channel)
        {
          if (!last_message_event.has_triggered())
          {
            // Subscribe to make sure we see this trigger
            last_message_event.subscribe();
            // A little hack here for slow gasnet conduits
            // If the event didn't trigger yet, make sure its just
            // because we haven't gotten the return message yet
            usleep(1000);
            if (!last_message_event.has_triggered())
              shutdown_manager->record_pending_message(last_message_event);
            else
              observed_recent = false;
          }
          else
            observed_recent = false;
        }
        else
        {
          observed_recent = false;
          for (std::set<RtEvent>::const_iterator it = 
                unordered_events.begin(); it != unordered_events.end(); it++)
          {
            if (!it->has_triggered())
            {
              // Subscribe to make sure we see this trigger
              it->subscribe();
              // A little hack here for slow gasnet conduits
              // If the event didn't trigger yet, make sure its just
              // because we haven't gotten the return message yet
              usleep(1000);
              if (!it->has_triggered())
              {
                shutdown_manager->record_pending_message(*it); 
                observed_recent = true;
                break;
              }
            }
          }
        }
      }
      else
      {
        if (observed_recent || (packaged_messages > 0)) 
        {
          shutdown_manager->record_recent_message(); 
          // If this is the profiling channel then flush the messages
          if (profiling_virtual_channel && (packaged_messages > 0))
            send_message(true/*complete*/, implicit_runtime, target,
                SEND_PROFILER_EVENT_TRIGGER, false/*response*/,
                RtEvent::NO_RT_EVENT);
        }
        else
        {
          if (ordered_channel)
          {
            if (!last_message_event.has_triggered())
            {
              // Subscribe to make sure we see this trigger
              last_message_event.subscribe();
              // A little hack here for slow gasnet conduits
              // If the event didn't trigger yet, make sure its just
              // because we haven't gotten the return message yet
              usleep(1000);
              if (!last_message_event.has_triggered())
                shutdown_manager->record_recent_message();
            }
          }
          else
          {
            for (std::set<RtEvent>::const_iterator it = 
                  unordered_events.begin(); it != unordered_events.end(); it++)
            {
              if (!it->has_triggered())
              {
                // Subscribe to make sure we see this trigger
                it->subscribe();
                // A little hack here for slow gasnet conduits
                // If the event didn't trigger yet, make sure its just
                // because we haven't gotten the return message yet
                usleep(1000);
                if (!it->has_triggered())
                {
                  shutdown_manager->record_recent_message();
                  break;
                }
              }
            }
          }
        }
      }
    }

    //--------------------------------------------------------------------------
    void VirtualChannel::process_message(const void *args, size_t arglen,
                         Runtime *runtime, AddressSpaceID remote_address_space)
    //--------------------------------------------------------------------------
    {
      // Strip off our header and the number of messages, the 
      // processor part was already stipped off by the Legion runtime
      const uint8_t *buffer = (const uint8_t*)args;
      MessageHeader head; 
      memcpy(&head, buffer, sizeof(head));
      buffer += sizeof(head);
      arglen -= sizeof(head);
      unsigned num_messages;
      memcpy(&num_messages, buffer, sizeof(num_messages));
      buffer += sizeof(num_messages);
      arglen -= sizeof(num_messages);
      unsigned incoming_message_id = 0;
      if (!ordered_channel)
      {
        incoming_message_id = ((unsigned)head) >> 2; 
        head = (MessageHeader)(((unsigned)head) & 0x3);
      }
      switch (head)
      {
        case FULL_MESSAGE:
          {
            // Can handle these messages directly
            handle_messages(num_messages, runtime, 
                            remote_address_space, buffer, arglen);
            break;
          }
        case PARTIAL_MESSAGE:
          {
            // Save these messages onto the receiving buffer
            // but do not handle them
            if (!ordered_channel)
            {
              AutoLock c_lock(channel_lock);
              if (partial_assembly == NULL)
                partial_assembly = new std::map<unsigned,PartialMessage>();
              PartialMessage &message = 
                (*partial_assembly)[incoming_message_id];
              // Allocate the buffer on the first pass
              if (message.buffer == NULL)
              {
                // Same as max message size
                message.size = sending_buffer_size;
                message.buffer = 
                  (uint8_t*)legion_malloc(MESSAGE_BUFFER_ALLOC, message.size);
              }
              buffer_messages(num_messages, buffer, arglen,
                              message.buffer, message.size,
                              message.index, message.messages, message.total);
            }
            else
              // Ordered channels don't need the lock
              buffer_messages(num_messages, buffer, arglen, receiving_buffer, 
                              receiving_buffer_size, receiving_index, 
                              received_messages, partial_messages);
            break;
          }
        case FINAL_MESSAGE:
          {
            // Save the remaining messages onto the receiving
            // buffer, then handle them and reset the state.
            uint8_t *final_buffer = NULL;
            size_t final_index = 0;
            unsigned final_messages = 0;
            bool free_buffer = false;
            if (!ordered_channel)
            {
              AutoLock c_lock(channel_lock);
#ifdef DEBUG_LEGION
              assert(partial_assembly != NULL);
#endif
              std::map<unsigned,PartialMessage>::iterator finder = 
                partial_assembly->find(incoming_message_id);
#ifdef DEBUG_LEGION
              assert(finder != partial_assembly->end());
              assert(finder->second.buffer != NULL);
#endif
              buffer_messages(num_messages, buffer, arglen,
                              finder->second.buffer, finder->second.size,
                              finder->second.index, finder->second.messages,
                              finder->second.total);
              final_index = finder->second.index;
              final_buffer = finder->second.buffer;
              final_messages = finder->second.messages;
              free_buffer = true;
              partial_assembly->erase(finder);
            }
            else
            {
              buffer_messages(num_messages, buffer, arglen, receiving_buffer,
                              receiving_buffer_size, receiving_index, 
                              received_messages, partial_messages);
              final_index = receiving_index;
              final_buffer = receiving_buffer;
              final_messages = received_messages;
              receiving_index = 0;
              received_messages = 0;
              partial_messages = 0;
            }
            handle_messages(final_messages, runtime, remote_address_space,
                                final_buffer, final_index);
            if (free_buffer)
              free(final_buffer);
            break;
          }
        default:
          assert(false); // should never get here
      }
    }

    //--------------------------------------------------------------------------
    void VirtualChannel::handle_messages(unsigned num_messages,
                                         Runtime *runtime,
                                         AddressSpaceID remote_address_space,
                                         const uint8_t *args,
                                         size_t arglen) const
    //--------------------------------------------------------------------------
    {
      for (unsigned idx = 0; idx < num_messages; idx++)
      {
        // Pull off the message kind and the size of the message
#ifdef DEBUG_LEGION
        assert(arglen >= (sizeof(MessageKind)+sizeof(size_t)));
#endif
        MessageKind kind;
        memcpy(&kind, args, sizeof(kind));
        // Any message that is not a shutdown message needs to be recorded
        if (!observed_recent && (kind != SEND_SHUTDOWN_NOTIFICATION) &&
            (kind != SEND_SHUTDOWN_RESPONSE))
          observed_recent = true;
        args += sizeof(kind);
        arglen -= sizeof(kind);
        memcpy(&implicit_provenance, args, sizeof(implicit_provenance));
        args += sizeof(implicit_provenance);
        arglen -= sizeof(implicit_provenance);
#ifdef DEBUG_LEGION_CALLERS
        implicit_task_kind = (LgTaskID)(LG_MESSAGE_ID + kind);
        memcpy(&implicit_task_caller, args, sizeof(implicit_task_caller));
        args += sizeof(implicit_task_caller);
        arglen -= sizeof(implicit_task_caller);
#endif
        size_t message_size;
        memcpy(&message_size, args, sizeof(message_size));
        args += sizeof(message_size);
        arglen -= sizeof(message_size);
#ifdef DEBUG_LEGION
        if (idx == (num_messages-1))
          assert(message_size == arglen);
#endif
        // Build the deserializer
        Deserializer derez(args,message_size);
        switch (kind)
        {
          case SEND_STARTUP_BARRIER:
            {
              runtime->handle_startup_barrier(derez);
              break;
            }
          case TASK_MESSAGE:
            {
              runtime->handle_task(derez);
              break;
            }
          case STEAL_MESSAGE:
            {
              runtime->handle_steal(derez);
              break;
            }
          case ADVERTISEMENT_MESSAGE:
            {
              runtime->handle_advertisement(derez);
              break;
            }
#ifdef LEGION_USE_LIBDL
          case SEND_REGISTRATION_CALLBACK:
            {
              runtime->handle_registration_callback(derez);
              break;
            }
#endif
          case SEND_REMOTE_TASK_REPLAY:
            {
              runtime->handle_remote_task_replay(derez);
              break;
            }
          case SEND_REMOTE_TASK_PROFILING_RESPONSE:
            {
              runtime->handle_remote_task_profiling_response(derez);
              break;
            }
          case SEND_SHARED_OWNERSHIP:
            {
              runtime->handle_shared_ownership(derez);
              break;
            }
          case SEND_INDEX_SPACE_REQUEST:
            {
              runtime->handle_index_space_request(derez);
              break;
            }
          case SEND_INDEX_SPACE_RESPONSE:
            {
              runtime->handle_index_space_response(derez, remote_address_space);
              break;
            }
          case SEND_INDEX_SPACE_RETURN:
            {
              runtime->handle_index_space_return(derez);
              break;
            }
          case SEND_INDEX_SPACE_SET:
            {
              runtime->handle_index_space_set(derez, remote_address_space);
              break;
            }
          case SEND_INDEX_SPACE_CHILD_REQUEST:
            {
              runtime->handle_index_space_child_request(derez, 
                                                        remote_address_space);
              break;
            }
          case SEND_INDEX_SPACE_CHILD_RESPONSE:
            {
              runtime->handle_index_space_child_response(derez);
              break;
            }
          case SEND_INDEX_SPACE_COLORS_REQUEST:
            {
              runtime->handle_index_space_colors_request(derez,
                                                         remote_address_space);
              break;
            }
          case SEND_INDEX_SPACE_COLORS_RESPONSE:
            {
              runtime->handle_index_space_colors_response(derez);
              break;
            }
          case SEND_INDEX_SPACE_REMOTE_EXPRESSION_REQUEST:
            {
              runtime->handle_index_space_remote_expression_request(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_INDEX_SPACE_REMOTE_EXPRESSION_RESPONSE:
            {
              runtime->handle_index_space_remote_expression_response(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_INDEX_SPACE_GENERATE_COLOR_REQUEST:
            {
              runtime->handle_index_space_generate_color_request(derez,
                                                  remote_address_space);
              break;
            }
          case SEND_INDEX_SPACE_GENERATE_COLOR_RESPONSE:
            {
              runtime->handle_index_space_generate_color_response(derez);
              break;
            }
          case SEND_INDEX_SPACE_RELEASE_COLOR:
            {
              runtime->handle_index_space_release_color(derez);
              break;
            }
          case SEND_INDEX_PARTITION_NOTIFICATION:
            {
              runtime->handle_index_partition_notification(derez);
              break;
            }
          case SEND_INDEX_PARTITION_REQUEST:
            {
              runtime->handle_index_partition_request(derez); 
              break;
            }
          case SEND_INDEX_PARTITION_RESPONSE:
            {
              runtime->handle_index_partition_response(derez, 
                                                       remote_address_space);
              break;
            }
          case SEND_INDEX_PARTITION_RETURN:
            {
              runtime->handle_index_partition_return(derez);
              break;
            }
          case SEND_INDEX_PARTITION_CHILD_REQUEST:
            {
              runtime->handle_index_partition_child_request(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_INDEX_PARTITION_CHILD_RESPONSE:
            {
              runtime->handle_index_partition_child_response(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_INDEX_PARTITION_CHILD_REPLICATION:
            {
              runtime->handle_index_partition_child_replication(derez);
              break;
            }
          case SEND_INDEX_PARTITION_DISJOINT_UPDATE:
            {
              runtime->handle_index_partition_disjoint_update(derez);
              break;
            }
          case SEND_INDEX_PARTITION_SHARD_RECTS_REQUEST:
            {
              runtime->handle_index_partition_shard_rects_request(derez);
              break;
            }
          case SEND_INDEX_PARTITION_SHARD_RECTS_RESPONSE:
            {
              runtime->handle_index_partition_shard_rects_response(derez,
                                                    remote_address_space);
              break;
            }
          case SEND_INDEX_PARTITION_REMOTE_INTERFERENCE_REQUEST:
            {
              runtime->handle_index_partition_remote_interference_request(
                                              derez, remote_address_space);
              break;
            }
          case SEND_INDEX_PARTITION_REMOTE_INTERFERENCE_RESPONSE:
            {
              runtime->handle_index_partition_remote_interference_response(
                                                                    derez);
              break;
            }
          case SEND_FIELD_SPACE_NODE:
            {
              runtime->handle_field_space_node(derez, remote_address_space);
              break;
            }
          case SEND_FIELD_SPACE_REQUEST:
            {
              runtime->handle_field_space_request(derez);
              break;
            }
          case SEND_FIELD_SPACE_RETURN:
            {
              runtime->handle_field_space_return(derez);
              break;
            }
          case SEND_FIELD_SPACE_ALLOCATOR_REQUEST:
            {
              runtime->handle_field_space_allocator_request(derez,
                                            remote_address_space);
              break;
            }
          case SEND_FIELD_SPACE_ALLOCATOR_RESPONSE:
            {
              runtime->handle_field_space_allocator_response(derez);
              break;
            }
          case SEND_FIELD_SPACE_ALLOCATOR_INVALIDATION:
            {
              runtime->handle_field_space_allocator_invalidation(derez);
              break;
            }
          case SEND_FIELD_SPACE_ALLOCATOR_FLUSH:
            {
              runtime->handle_field_space_allocator_flush(derez);
              break;
            }
          case SEND_FIELD_SPACE_ALLOCATOR_FREE:
            {
              runtime->handle_field_space_allocator_free(derez, 
                                          remote_address_space);
              break;
            }
          case SEND_FIELD_SPACE_INFOS_REQUEST:
            {
              runtime->handle_field_space_infos_request(derez);
              break;
            }
          case SEND_FIELD_SPACE_INFOS_RESPONSE:
            {
              runtime->handle_field_space_infos_response(derez);
              break;
            }
          case SEND_FIELD_ALLOC_REQUEST:
            {
              runtime->handle_field_alloc_request(derez);
              break;
            }
          case SEND_FIELD_SIZE_UPDATE:
            {
              runtime->handle_field_size_update(derez, remote_address_space);
              break;
            }
          case SEND_FIELD_FREE:
            {
              runtime->handle_field_free(derez, remote_address_space);
              break;
            }
          case SEND_FIELD_FREE_INDEXES:
            {
              runtime->handle_field_free_indexes(derez);
              break;
            }
          case SEND_FIELD_SPACE_LAYOUT_INVALIDATION:
            {
              runtime->handle_field_space_layout_invalidation(derez,
                                              remote_address_space);
              break;
            }
          case SEND_LOCAL_FIELD_ALLOC_REQUEST:
            {
              runtime->handle_local_field_alloc_request(derez, 
                                                        remote_address_space);
              break;
            }
          case SEND_LOCAL_FIELD_ALLOC_RESPONSE:
            {
              runtime->handle_local_field_alloc_response(derez);
              break;
            }
          case SEND_LOCAL_FIELD_FREE:
            {
              runtime->handle_local_field_free(derez);
              break;
            }
          case SEND_LOCAL_FIELD_UPDATE:
            {
              runtime->handle_local_field_update(derez);
              break;
            }
          case SEND_TOP_LEVEL_REGION_REQUEST:
            {
              runtime->handle_top_level_region_request(derez); 
              break;
            }
          case SEND_TOP_LEVEL_REGION_RETURN:
            {
              runtime->handle_top_level_region_return(derez,
                                                      remote_address_space);
              break;
            }
          case INDEX_SPACE_DESTRUCTION_MESSAGE:
            {
              runtime->handle_index_space_destruction(derez,
                                                      remote_address_space);
              break;
            }
          case INDEX_PARTITION_DESTRUCTION_MESSAGE:
            {
              runtime->handle_index_partition_destruction(derez); 
              break;
            }
          case FIELD_SPACE_DESTRUCTION_MESSAGE:
            {
              runtime->handle_field_space_destruction(derez); 
              break;
            }
          case LOGICAL_REGION_DESTRUCTION_MESSAGE:
            {
              runtime->handle_logical_region_destruction(derez); 
              break;
            }
          case INDIVIDUAL_REMOTE_FUTURE_SIZE:
            {
              runtime->handle_individual_remote_future_size(derez);
              break;
            }
          case INDIVIDUAL_REMOTE_OUTPUT_REGISTRATION:
            {
              runtime->handle_individual_remote_output_registration(derez);
              break;
            }
          case INDIVIDUAL_REMOTE_MAPPED:
            {
              runtime->handle_individual_remote_mapped(derez);
              break;
            }
          case INDIVIDUAL_REMOTE_COMPLETE:
            {
              runtime->handle_individual_remote_complete(derez);
              break;
            }
          case INDIVIDUAL_REMOTE_COMMIT:
            {
              runtime->handle_individual_remote_commit(derez);
              break;
            }
          case SLICE_REMOTE_MAPPED:
            {
              runtime->handle_slice_remote_mapped(derez, remote_address_space);
              break;
            }
          case SLICE_REMOTE_COMPLETE:
            {
              runtime->handle_slice_remote_complete(derez);
              break;
            }
          case SLICE_REMOTE_COMMIT:
            {
              runtime->handle_slice_remote_commit(derez);
              break;
            }
          case SLICE_RENDEZVOUS_CONCURRENT_MAPPED:
            {
              runtime->handle_slice_rendezvous_concurrent_mapped(derez);
              break;
            }
          case SLICE_CONCURRENT_ALLREDUCE_REQUEST:
            {
              runtime->handle_slice_concurrent_allreduce_request(derez,
                                                  remote_address_space);
              break;
            }
          case SLICE_CONCURRENT_ALLREDUCE_RESPONSE:
            {
              runtime->handle_slice_concurrent_allreduce_response(derez);
              break;
            }
          case SLICE_FIND_INTRA_DEP:
            {
              runtime->handle_slice_find_intra_dependence(derez);
              break;
            }
          case SLICE_RECORD_INTRA_DEP:
            {
              runtime->handle_slice_record_intra_dependence(derez);
              break;
            }
          case SLICE_REMOTE_COLLECTIVE_RENDEZVOUS:
            {
              runtime->handle_slice_remote_collective_rendezvous(derez,
                                                  remote_address_space);
              break;
            }
          case SLICE_REMOTE_VERSIONING_COLLECTIVE_RENDEZVOUS:
            {
              runtime->handle_slice_remote_collective_versioning_rendezvous(
                                                                      derez);
              break;
            }
          case SLICE_REMOTE_OUTPUT_EXTENTS:
            {
              runtime->handle_slice_remote_output_extents(derez);
              break;
            }
          case SLICE_REMOTE_OUTPUT_REGISTRATION:
            {
              runtime->handle_slice_remote_output_registration(derez);
              break;
            }
          case DISTRIBUTED_REMOTE_REGISTRATION:
            {
              runtime->handle_did_remote_registration(derez, 
                                                      remote_address_space);
              break;
            }
          case DISTRIBUTED_DOWNGRADE_REQUEST:
            {
              runtime->handle_did_downgrade_request(derez,remote_address_space);
              break;
            }
          case DISTRIBUTED_DOWNGRADE_RESPONSE:
            {
              runtime->handle_did_downgrade_response(derez);
              break;
            }
          case DISTRIBUTED_DOWNGRADE_SUCCESS:
            {
              runtime->handle_did_downgrade_success(derez);
              break;
            }
          case DISTRIBUTED_DOWNGRADE_UPDATE:
            {
              runtime->handle_did_downgrade_update(derez);
              break;
            }
          case DISTRIBUTED_DOWNGRADE_RESTART:
            {
              runtime->handle_did_downgrade_restart(derez,remote_address_space);
              break;
            }
          case DISTRIBUTED_GLOBAL_ACQUIRE_REQUEST:
            {
              runtime->handle_did_global_acquire_request(derez); 
              break;
            }
          case DISTRIBUTED_GLOBAL_ACQUIRE_RESPONSE:
            {
              runtime->handle_did_global_acquire_response(derez);
              break;
            }
          case DISTRIBUTED_VALID_ACQUIRE_REQUEST:
            {
              runtime->handle_did_valid_acquire_request(derez);
              break;
            }
          case DISTRIBUTED_VALID_ACQUIRE_RESPONSE:
            {
              runtime->handle_did_valid_acquire_response(derez);
              break;
            }
          case SEND_ATOMIC_RESERVATION_REQUEST:
            {
              runtime->handle_send_atomic_reservation_request(derez);
              break;
            }
          case SEND_ATOMIC_RESERVATION_RESPONSE:
            {
              runtime->handle_send_atomic_reservation_response(derez);
              break;
            }
          case SEND_PADDED_RESERVATION_REQUEST:
            {
              runtime->handle_send_padded_reservation_request(derez,
                                                      remote_address_space);
              break;
            }
          case SEND_PADDED_RESERVATION_RESPONSE:
            {
              runtime->handle_send_padded_reservation_response(derez);
              break;
            }
          case SEND_CREATED_REGION_CONTEXTS:
            {
              runtime->handle_created_region_contexts(derez);
              break;
            }
          case SEND_MATERIALIZED_VIEW:
            {
              runtime->handle_send_materialized_view(derez); 
              break;
            }
          case SEND_FILL_VIEW:
            {
              runtime->handle_send_fill_view(derez);
              break;
            }
          case SEND_FILL_VIEW_VALUE:
            {
              runtime->handle_send_fill_view_value(derez);
              break;
            }
          case SEND_PHI_VIEW:
            {
              runtime->handle_send_phi_view(derez);
              break;
            }
          case SEND_REDUCTION_VIEW:
            {
              runtime->handle_send_reduction_view(derez);
              break;
            }
          case SEND_REPLICATED_VIEW:
            {
              runtime->handle_send_replicated_view(derez);
              break;
            }
          case SEND_ALLREDUCE_VIEW:
            {
              runtime->handle_send_allreduce_view(derez);
              break;
            }
          case SEND_INSTANCE_MANAGER:
            {
              runtime->handle_send_instance_manager(derez, 
                                                    remote_address_space);
              break;
            }
          case SEND_MANAGER_UPDATE:
            {
              runtime->handle_send_manager_update(derez,
                                                  remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_DISTRIBUTE_FILL:
            {
              runtime->handle_collective_distribute_fill(derez,
                                                         remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_DISTRIBUTE_POINT:
            {
              runtime->handle_collective_distribute_point(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_DISTRIBUTE_POINTWISE:
            {
              runtime->handle_collective_distribute_pointwise(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_DISTRIBUTE_REDUCTION:
            {
              runtime->handle_collective_distribute_reduction(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_DISTRIBUTE_BROADCAST:
            {
              runtime->handle_collective_distribute_broadcast(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_DISTRIBUTE_REDUCECAST:
            {
              runtime->handle_collective_distribute_reducecast(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_DISTRIBUTE_HOURGLASS:
            {
              runtime->handle_collective_distribute_hourglass(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_DISTRIBUTE_ALLREDUCE:
            {
              runtime->handle_collective_distribute_allreduce(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_HAMMER_REDUCTION:
            {
              runtime->handle_collective_hammer_reduction(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_FUSE_GATHER:
            {
              runtime->handle_collective_fuse_gather(derez,
                                                     remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_USER_REQUEST:
            {
              runtime->handle_collective_user_request(derez);
              break;
            }
          case SEND_COLLECTIVE_USER_RESPONSE:
            {
              runtime->handle_collective_user_response(derez);
              break;
            }
          case SEND_COLLECTIVE_REGISTER_USER:
            {
              runtime->handle_collective_user_registration(derez);
              break;
            }
          case SEND_COLLECTIVE_REMOTE_INSTANCES_REQUEST:
            {
              runtime->handle_collective_remote_instances_request(derez,
                                                  remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_REMOTE_INSTANCES_RESPONSE:
            {
              runtime->handle_collective_remote_instances_response(derez,
                                                    remote_address_space);
              break;
            }
          case SEND_COLLECTIVE_NEAREST_INSTANCES_REQUEST:
            {
              runtime->handle_collective_nearest_instances_request(derez);
              break;
            }
          case SEND_COLLECTIVE_NEAREST_INSTANCES_RESPONSE:
            {
              runtime->handle_collective_nearest_instances_response(derez);
              break;
            }
          case SEND_COLLECTIVE_REMOTE_REGISTRATION:
            {
              runtime->handle_collective_remote_registration(derez);
              break;
            }
          case SEND_COLLECTIVE_FINALIZE_MAPPING:
            {
              runtime->handle_collective_finalize_mapping(derez);
              break;
            }
          case SEND_COLLECTIVE_VIEW_CREATION:
            {
              runtime->handle_collective_view_creation(derez);
              break;
            }
          case SEND_COLLECTIVE_VIEW_DELETION:
            {
              runtime->handle_collective_view_deletion(derez);
              break;
            }
          case SEND_COLLECTIVE_VIEW_RELEASE:
            {
              runtime->handle_collective_view_release(derez);
              break;
            }
          case SEND_COLLECTIVE_VIEW_NOTIFICATION:
            {
              runtime->handle_collective_view_notification(derez);
              break;
            }
          case SEND_COLLECTIVE_VIEW_MAKE_VALID:
            {
              runtime->handle_collective_view_make_valid(derez);
              break;
            }
          case SEND_COLLECTIVE_VIEW_MAKE_INVALID:
            {
              runtime->handle_collective_view_make_invalid(derez);
              break;
            }
          case SEND_COLLECTIVE_VIEW_INVALIDATE_REQUEST:
            {
              runtime->handle_collective_view_invalidate_request(derez);
              break;
            }
          case SEND_COLLECTIVE_VIEW_INVALIDATE_RESPONSE:
            {
              runtime->handle_collective_view_invalidate_response(derez);
              break;
            }
          case SEND_COLLECTIVE_VIEW_ADD_REMOTE_REFERENCE:
            {
              runtime->handle_collective_view_add_remote_reference(derez);
              break;
            }
          case SEND_COLLECTIVE_VIEW_REMOVE_REMOTE_REFERENCE:
            {
              runtime->handle_collective_view_remove_remote_reference(derez);
              break;
            }
          case SEND_CREATE_TOP_VIEW_REQUEST:
            {
              runtime->handle_create_top_view_request(derez,
                                                      remote_address_space);
              break;
            }
          case SEND_CREATE_TOP_VIEW_RESPONSE:
            {
              runtime->handle_create_top_view_response(derez);
              break;
            }
          case SEND_VIEW_REQUEST:
            {
              runtime->handle_view_request(derez);
              break;
            }
          case SEND_VIEW_REGISTER_USER:
            {
              runtime->handle_view_register_user(derez, remote_address_space);
              break;
            }
          case SEND_VIEW_FIND_COPY_PRE_REQUEST:
            {
              runtime->handle_view_copy_pre_request(derez,remote_address_space);
              break;
            }
          case SEND_VIEW_ADD_COPY_USER:
            {
              runtime->handle_view_add_copy_user(derez, remote_address_space);
              break;
            }
          case SEND_VIEW_FIND_LAST_USERS_REQUEST:
            {
              runtime->handle_view_find_last_users_request(derez,
                                            remote_address_space);
              break;
            }
          case SEND_VIEW_FIND_LAST_USERS_RESPONSE:
            {
              runtime->handle_view_find_last_users_response(derez);
              break;
            }
#ifdef ENABLE_VIEW_REPLICATION
          case SEND_VIEW_REPLICATION_REQUEST:
            {
              runtime->handle_view_replication_request(derez, 
                                                       remote_address_space);
              break;
            }
          case SEND_VIEW_REPLICATION_RESPONSE:
            {
              runtime->handle_view_replication_response(derez);
              break;
            }
          case SEND_VIEW_REPLICATION_REMOVAL:
            {
              runtime->handle_view_replication_removal(derez, 
                                                       remote_address_space);
              break;
            }
#endif
          case SEND_MANAGER_REQUEST:
            {
              runtime->handle_manager_request(derez);
              break;
            } 
          case SEND_FUTURE_RESULT:
            {
              runtime->handle_future_result(derez);
              break;
            }
          case SEND_FUTURE_RESULT_SIZE:
            {
              runtime->handle_future_result_size(derez, remote_address_space);
              break;
            }
          case SEND_FUTURE_SUBSCRIPTION:
            {
              runtime->handle_future_subscription(derez, remote_address_space);
              break;
            }
          case SEND_FUTURE_CREATE_INSTANCE_REQUEST:
            {
              runtime->handle_future_create_instance_request(derez);
              break;
            }
          case SEND_FUTURE_CREATE_INSTANCE_RESPONSE:
            {
              runtime->handle_future_create_instance_response(derez);
              break;
            }
          case SEND_FUTURE_MAP_REQUEST:
            {
              runtime->handle_future_map_future_request(derez, 
                                        remote_address_space);
              break;
            }
          case SEND_FUTURE_MAP_RESPONSE:
            {
              runtime->handle_future_map_future_response(derez);
              break;
            }
          case SEND_REPL_COMPUTE_EQUIVALENCE_SETS:
            {
              runtime->handle_control_replicate_compute_equivalence_sets(
                                                                    derez);
              break;
            }
          case SEND_REPL_OUTPUT_EQUIVALENCE_SET:
            {
              runtime->handle_control_replicate_output_equivalence_set(derez);
              break;
            }
          case SEND_REPL_REFINE_EQUIVALENCE_SETS:
            {
              runtime->handle_control_replicate_refine_equivalence_sets(
                                                                   derez);
              break;
            }
          case SEND_REPL_EQUIVALENCE_SET_NOTIFICATION:
            {
              runtime->handle_control_replicate_equivalence_set_notification(
                                                                      derez);
              break;
            }
          case SEND_REPL_INTRA_SPACE_DEP:
            {
              runtime->handle_control_replicate_intra_space_dependence(derez);
              break;
            }
          case SEND_REPL_BROADCAST_UPDATE:
            {
              runtime->handle_control_replicate_broadcast_update(derez);
              break;
            }
          case SEND_REPL_CREATED_REGIONS:
            {
              runtime->handle_control_replicate_created_regions(derez);
              break;
            }
          case SEND_REPL_TRACE_EVENT_REQUEST:
            {
              runtime->handle_control_replicate_trace_event_request(derez,
                                                    remote_address_space);
              break;
            }
          case SEND_REPL_TRACE_EVENT_RESPONSE:
            {
              runtime->handle_control_replicate_trace_event_response(derez);
              break;
            }
          case SEND_REPL_TRACE_EVENT_TRIGGER:
            {
              runtime->handle_control_replicate_trace_event_trigger(derez);
              break;
            }
          case SEND_REPL_TRACE_FRONTIER_REQUEST:
            {
              runtime->handle_control_replicate_trace_frontier_request(derez,
                                                       remote_address_space);
              break;
            }
          case SEND_REPL_TRACE_FRONTIER_RESPONSE:
            {
              runtime->handle_control_replicate_trace_frontier_response(derez);
              break;
            }
          case SEND_REPL_TRACE_UPDATE:
            {
              runtime->handle_control_replicate_trace_update(derez,
                                                    remote_address_space);
              break;
            }
          case SEND_REPL_FIND_TRACE_SETS:
            {
              runtime->handle_control_replicate_find_trace_local_sets(derez,
                                                  remote_address_space);
              break;
            }
          case SEND_REPL_IMPLICIT_RENDEZVOUS:
            {
              runtime->handle_control_replicate_implicit_rendezvous(derez);
              break;
            }
          case SEND_REPL_FIND_COLLECTIVE_VIEW:
            {
              runtime->handle_control_replicate_find_collective_view(derez);
              break;
            }
          case SEND_MAPPER_MESSAGE:
            {
              runtime->handle_mapper_message(derez);
              break;
            }
          case SEND_MAPPER_BROADCAST:
            {
              runtime->handle_mapper_broadcast(derez);
              break;
            }
          case SEND_TASK_IMPL_SEMANTIC_REQ:
            {
              runtime->handle_task_impl_semantic_request(derez, 
                                                        remote_address_space);
              break;
            }
          case SEND_INDEX_SPACE_SEMANTIC_REQ:
            {
              runtime->handle_index_space_semantic_request(derez,
                                                        remote_address_space);
              break;
            }
          case SEND_INDEX_PARTITION_SEMANTIC_REQ:
            {
              runtime->handle_index_partition_semantic_request(derez,
                                                        remote_address_space);
              break;
            }
          case SEND_FIELD_SPACE_SEMANTIC_REQ:
            {
              runtime->handle_field_space_semantic_request(derez,
                                                        remote_address_space);
              break;
            }
          case SEND_FIELD_SEMANTIC_REQ:
            {
              runtime->handle_field_semantic_request(derez, 
                                                     remote_address_space);
              break;
            }
          case SEND_LOGICAL_REGION_SEMANTIC_REQ:
            {
              runtime->handle_logical_region_semantic_request(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_LOGICAL_PARTITION_SEMANTIC_REQ:
            {
              runtime->handle_logical_partition_semantic_request(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_TASK_IMPL_SEMANTIC_INFO:
            {
              runtime->handle_task_impl_semantic_info(derez,
                                                      remote_address_space);
              break;
            }
          case SEND_INDEX_SPACE_SEMANTIC_INFO:
            {
              runtime->handle_index_space_semantic_info(derez,
                                                        remote_address_space);
              break;
            }
          case SEND_INDEX_PARTITION_SEMANTIC_INFO:
            {
              runtime->handle_index_partition_semantic_info(derez,
                                                        remote_address_space);
              break;
            }
          case SEND_FIELD_SPACE_SEMANTIC_INFO:
            {
              runtime->handle_field_space_semantic_info(derez,
                                                        remote_address_space);
              break;
            }
          case SEND_FIELD_SEMANTIC_INFO:
            {
              runtime->handle_field_semantic_info(derez, remote_address_space);
              break;
            }
          case SEND_LOGICAL_REGION_SEMANTIC_INFO:
            {
              runtime->handle_logical_region_semantic_info(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_LOGICAL_PARTITION_SEMANTIC_INFO:
            {
              runtime->handle_logical_partition_semantic_info(derez,
                                                          remote_address_space);
              break;
            }
          case SEND_REMOTE_CONTEXT_REQUEST:
            {
              runtime->handle_remote_context_request(derez); 
              break;
            }
          case SEND_REMOTE_CONTEXT_RESPONSE:
            {
              runtime->handle_remote_context_response(derez);
              break;
            }
          case SEND_REMOTE_CONTEXT_PHYSICAL_REQUEST:
            {
              runtime->handle_remote_context_physical_request(derez,
                                              remote_address_space);
              break;
            }
          case SEND_REMOTE_CONTEXT_PHYSICAL_RESPONSE:
            {
              runtime->handle_remote_context_physical_response(derez);
              break;
            }
          case SEND_REMOTE_CONTEXT_FIND_COLLECTIVE_VIEW_REQUEST:
            {
              runtime->handle_remote_context_find_collective_view_request(
                                              derez, remote_address_space);
              break;
            }
          case SEND_REMOTE_CONTEXT_FIND_COLLECTIVE_VIEW_RESPONSE:
            {
              runtime->handle_remote_context_find_collective_view_response(
                                                                    derez);
              break;
            }
          case SEND_REMOTE_CONTEXT_REFINE_EQUIVALENCE_SETS:
            {
              runtime->handle_remote_context_refine_equivalence_sets(derez);
              break;
            }
          case SEND_REMOTE_CONTEXT_FIND_TRACE_LOCAL_SETS_REQUEST:
            {
              runtime->handle_remote_context_find_trace_local_sets_request(
                  derez, remote_address_space);
              break;
            }
          case SEND_REMOTE_CONTEXT_FIND_TRACE_LOCAL_SETS_RESPONSE:
            {
              runtime->handle_remote_context_find_trace_local_sets_response(
                  derez);
              break;
            }
          case SEND_COMPUTE_EQUIVALENCE_SETS_REQUEST: 
            {
              runtime->handle_compute_equivalence_sets_request(derez,
                                               remote_address_space);
              break;
            }
          case SEND_COMPUTE_EQUIVALENCE_SETS_RESPONSE:
            {
              runtime->handle_compute_equivalence_sets_response(derez);
              break;
            }
          case SEND_COMPUTE_EQUIVALENCE_SETS_PENDING:
            {
              runtime->handle_compute_equivalence_sets_pending(derez);
              break;
            }
          case SEND_OUTPUT_EQUIVALENCE_SET_REQUEST:
            {
              runtime->handle_output_equivalence_set_request(derez);
              break;
            }
          case SEND_OUTPUT_EQUIVALENCE_SET_RESPONSE:
            {
              runtime->handle_output_equivalence_set_response(derez,
                                                remote_address_space);
              break;
            }
          case SEND_CANCEL_EQUIVALENCE_SETS_SUBSCRIPTION:
            {
              runtime->handle_cancel_equivalence_sets_subscription(derez,
                                                   remote_address_space);
              break;
            }
          case SEND_INVALIDATE_EQUIVALENCE_SETS_SUBSCRIPTION:
            {
              runtime->handle_invalidate_equivalence_sets_subscription(derez,
                                                       remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_CREATION:
            {
              runtime->handle_equivalence_set_creation(derez);
              break;
            }
          case SEND_EQUIVALENCE_SET_REUSE:
            {
              runtime->handle_equivalence_set_reuse(derez);
              break;
            }
          case SEND_EQUIVALENCE_SET_REQUEST:
            {
              runtime->handle_equivalence_set_request(derez); 
              break;
            }
          case SEND_EQUIVALENCE_SET_RESPONSE:
            {
              runtime->handle_equivalence_set_response(derez);
              break;
            }
          case SEND_EQUIVALENCE_SET_REPLICATION_REQUEST:
            {
              runtime->handle_equivalence_set_replication_request(derez);
              break;
            }
          case SEND_EQUIVALENCE_SET_REPLICATION_RESPONSE:
            {
              runtime->handle_equivalence_set_replication_response(derez);
              break;
            }
          case SEND_EQUIVALENCE_SET_MIGRATION:
            {
              runtime->handle_equivalence_set_migration(derez,
                                                        remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_OWNER_UPDATE:
            {
              runtime->handle_equivalence_set_owner_update(derez);
              break;
            }
          case SEND_EQUIVALENCE_SET_CLONE_REQUEST:
            {
              runtime->handle_equivalence_set_clone_request(derez,
                                            remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_CLONE_RESPONSE:
            {
              runtime->handle_equivalence_set_clone_response(derez);
              break;
            }
          case SEND_EQUIVALENCE_SET_CAPTURE_REQUEST:
            {
              runtime->handle_equivalence_set_capture_request(derez,
                                              remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_CAPTURE_RESPONSE:
            {
              runtime->handle_equivalence_set_capture_response(derez,
                                                remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_REMOTE_REQUEST_INSTANCES:
            {
              runtime->handle_equivalence_set_remote_request_instances(derez,
                                                        remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_REMOTE_REQUEST_INVALID:
            {
              runtime->handle_equivalence_set_remote_request_invalid(derez,
                                                        remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_REMOTE_REQUEST_ANTIVALID:
            {
              runtime->handle_equivalence_set_remote_request_antivalid(derez,
                                                        remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_REMOTE_UPDATES:
            {
              runtime->handle_equivalence_set_remote_updates(derez,
                                              remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_REMOTE_ACQUIRES:
            {
              runtime->handle_equivalence_set_remote_acquires(derez,
                                              remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_REMOTE_RELEASES:
            {
              runtime->handle_equivalence_set_remote_releases(derez,
                                              remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_REMOTE_COPIES_ACROSS:
            {
              runtime->handle_equivalence_set_remote_copies_across(derez,
                                                    remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_REMOTE_OVERWRITES:
            {
              runtime->handle_equivalence_set_remote_overwrites(derez,
                                                remote_address_space);
            break;
            }
          case SEND_EQUIVALENCE_SET_REMOTE_FILTERS:
            {
              runtime->handle_equivalence_set_remote_filters(derez,
                                              remote_address_space);
              break;
            }
          case SEND_EQUIVALENCE_SET_REMOTE_INSTANCES:
            {
              runtime->handle_equivalence_set_remote_instances(derez);
              break;
            }
          case SEND_EQUIVALENCE_SET_FILTER_INVALIDATIONS:
            {
              runtime->handle_equivalence_set_filter_invalidations(derez);
              break;
            }
          case SEND_INSTANCE_REQUEST:
            {
              runtime->handle_instance_request(derez, remote_address_space);
              break;
            }
          case SEND_INSTANCE_RESPONSE:
            {
              runtime->handle_instance_response(derez, remote_address_space);
              break;
            }
          case SEND_EXTERNAL_CREATE_REQUEST:
            {
              runtime->handle_external_create_request(derez, 
                                                      remote_address_space);
              break;
            }
          case SEND_EXTERNAL_CREATE_RESPONSE:
            {
              runtime->handle_external_create_response(derez);
              break;
            }
          case SEND_EXTERNAL_ATTACH:
            {
              runtime->handle_external_attach(derez);
              break;
            }
          case SEND_EXTERNAL_DETACH:
            {
              runtime->handle_external_detach(derez);
              break;
            }
          case SEND_GC_PRIORITY_UPDATE:
            {
              runtime->handle_gc_priority_update(derez, remote_address_space);
              break;
            }
          case SEND_GC_REQUEST:
            {
              runtime->handle_gc_request(derez, remote_address_space);
              break;
            }
          case SEND_GC_RESPONSE:
            {
              runtime->handle_gc_response(derez);
              break;
            }
          case SEND_GC_ACQUIRE:
            {
              runtime->handle_gc_acquire(derez);
              break;
            }
          case SEND_GC_FAILED:
            {
              runtime->handle_gc_failed(derez);
              break;
            }
          case SEND_GC_MISMATCH:
            {
              runtime->handle_gc_mismatch(derez);
              break;
            }
          case SEND_GC_NOTIFY:
            {
              runtime->handle_gc_notify(derez);
              break;
            }
          case SEND_GC_DEBUG_REQUEST:
            {
              runtime->handle_gc_debug_request(derez, remote_address_space);
              break;
            }
          case SEND_GC_DEBUG_RESPONSE:
            {
              runtime->handle_gc_debug_response(derez);
              break;
            }
          case SEND_GC_RECORD_EVENT:
            {
              runtime->handle_gc_record_event(derez);
              break;
            }
          case SEND_ACQUIRE_REQUEST:
            {
              runtime->handle_acquire_request(derez, remote_address_space);
              break;
            }
          case SEND_ACQUIRE_RESPONSE:
            {
              runtime->handle_acquire_response(derez, remote_address_space);
              break;
            }
          case SEND_VARIANT_BROADCAST:
            {
              runtime->handle_variant_broadcast(derez);
              break;
            }
          case SEND_CONSTRAINT_REQUEST:
            {
              runtime->handle_constraint_request(derez, remote_address_space);
              break;
            }
          case SEND_CONSTRAINT_RESPONSE:
            {
              runtime->handle_constraint_response(derez, remote_address_space);
              break;
            }
          case SEND_CONSTRAINT_RELEASE:
            {
              runtime->handle_constraint_release(derez);
              break;
            }
          case SEND_TOP_LEVEL_TASK_COMPLETE:
            {
              runtime->handle_top_level_task_complete(derez);
              break;
            }
          case SEND_MPI_RANK_EXCHANGE:
            {
              runtime->handle_mpi_rank_exchange(derez);
              break;
            }
          case SEND_REPLICATE_DISTRIBUTION:
            {
              runtime->handle_replicate_distribution(derez);
              break;
            }
          case SEND_REPLICATE_COLLECTIVE_VERSIONING:
            {
              runtime->handle_replicate_collective_versioning(derez);
              break;
            }
          case SEND_REPLICATE_COLLECTIVE_MAPPING:
            {
              runtime->handle_replicate_collective_mapping(derez);
              break;
            }
          case SEND_REPLICATE_VIRTUAL_RENDEZVOUS:
            {
              runtime->handle_replicate_virtual_rendezvous(derez);
              break;
            }
          case SEND_REPLICATE_STARTUP_COMPLETE:
            {
              runtime->handle_replicate_startup_complete(derez);
              break;
            }
          case SEND_REPLICATE_POST_MAPPED:
            {
              runtime->handle_replicate_post_mapped(derez);
              break;
            }
          case SEND_REPLICATE_TRIGGER_COMPLETE:
            {
              runtime->handle_replicate_trigger_complete(derez);
              break;
            }
          case SEND_REPLICATE_TRIGGER_COMMIT:
            {
              runtime->handle_replicate_trigger_commit(derez);
              break;
            }
          case SEND_CONTROL_REPLICATE_RENDEZVOUS_MESSAGE:
            {
              runtime->handle_control_replicate_rendezvous_message(derez);
              break;
            }
          case SEND_LIBRARY_MAPPER_REQUEST:
            {
              runtime->handle_library_mapper_request(derez, 
                                      remote_address_space);
              break;
            }
          case SEND_LIBRARY_MAPPER_RESPONSE:
            {
              runtime->handle_library_mapper_response(derez);
              break;
            }
          case SEND_LIBRARY_TRACE_REQUEST:
            {
              runtime->handle_library_trace_request(derez,remote_address_space);
              break;
            }
          case SEND_LIBRARY_TRACE_RESPONSE:
            {
              runtime->handle_library_trace_response(derez);
              break;
            }
          case SEND_LIBRARY_PROJECTION_REQUEST:
            {
              runtime->handle_library_projection_request(derez,
                                          remote_address_space);
              break;
            }
          case SEND_LIBRARY_PROJECTION_RESPONSE:
            {
              runtime->handle_library_projection_response(derez);
              break;
            }
          case SEND_LIBRARY_SHARDING_REQUEST:
            {
              runtime->handle_library_sharding_request(derez, 
                                                       remote_address_space);
              break;
            }
          case SEND_LIBRARY_SHARDING_RESPONSE:
            {
              runtime->handle_library_sharding_response(derez);
              break;
            }
          case SEND_LIBRARY_TASK_REQUEST:
            {
              runtime->handle_library_task_request(derez, remote_address_space);
              break;
            }
          case SEND_LIBRARY_TASK_RESPONSE:
            {
              runtime->handle_library_task_response(derez);
              break;
            }
          case SEND_LIBRARY_REDOP_REQUEST:
            {
              runtime->handle_library_redop_request(derez,remote_address_space);
              break;
            }
          case SEND_LIBRARY_REDOP_RESPONSE:
            {
              runtime->handle_library_redop_response(derez);
              break;
            }
          case SEND_LIBRARY_SERDEZ_REQUEST:
            {
              runtime->handle_library_serdez_request(derez,
                                      remote_address_space);
              break;
            }
          case SEND_LIBRARY_SERDEZ_RESPONSE:
            {
              runtime->handle_library_serdez_response(derez);
              break;
            }
          case SEND_REMOTE_OP_REPORT_UNINIT:
            {
              runtime->handle_remote_op_report_uninitialized(derez);
              break;
            }
          case SEND_REMOTE_OP_PROFILING_COUNT_UPDATE:
            {
              runtime->handle_remote_op_profiling_count_update(derez);
              break;
            }
          case SEND_REMOTE_OP_COMPLETION_EFFECT:
            {
              runtime->handle_remote_op_completion_effect(derez);
              break;
            }
          case SEND_REMOTE_TRACE_UPDATE:
            {
              runtime->handle_remote_tracing_update(derez,remote_address_space);
              break;
            }
          case SEND_REMOTE_TRACE_RESPONSE:
            {
              runtime->handle_remote_tracing_response(derez);
              break;
            }
          case SEND_FREE_EXTERNAL_ALLOCATION:
            {
              runtime->handle_free_external_allocation(derez);
              break;
            }
          case SEND_NOTIFY_COLLECTED_INSTANCES:
            {
              runtime->handle_notify_collected_instances(derez);
              break;
            }
          case SEND_CREATE_FUTURE_INSTANCE_REQUEST:
            {
              runtime->handle_create_future_instance_request(derez,
                                              remote_address_space);
              break;
            }
          case SEND_CREATE_FUTURE_INSTANCE_RESPONSE:
            {
              runtime->handle_create_future_instance_response(derez);
              break;
            }
          case SEND_FREE_FUTURE_INSTANCE:
            {
              runtime->handle_free_future_instance(derez);
              break;
            }
          case SEND_REMOTE_DISTRIBUTED_ID_REQUEST:
            {
              runtime->handle_remote_distributed_id_request(derez,
                                            remote_address_space);
              break;
            }
          case SEND_REMOTE_DISTRIBUTED_ID_RESPONSE:
            {
              runtime->handle_remote_distributed_id_response(derez);
              break;
            }
          case SEND_CONTROL_REPLICATION_FUTURE_ALLREDUCE:
          case SEND_CONTROL_REPLICATION_FUTURE_BROADCAST:
          case SEND_CONTROL_REPLICATION_FUTURE_REDUCTION:
          case SEND_CONTROL_REPLICATION_VALUE_ALLREDUCE:
          case SEND_CONTROL_REPLICATION_VALUE_BROADCAST:
          case SEND_CONTROL_REPLICATION_VALUE_EXCHANGE:
          case SEND_CONTROL_REPLICATION_BUFFER_BROADCAST:
          case SEND_CONTROL_REPLICATION_SHARD_SYNC_TREE:
          case SEND_CONTROL_REPLICATION_SHARD_EVENT_TREE:
          case SEND_CONTROL_REPLICATION_SINGLE_TASK_TREE:
          case SEND_CONTROL_REPLICATION_CROSS_PRODUCT_PARTITION:
          case SEND_CONTROL_REPLICATION_SHARDING_GATHER_COLLECTIVE:
          case SEND_CONTROL_REPLICATION_INDIRECT_COPY_EXCHANGE:
          case SEND_CONTROL_REPLICATION_FIELD_DESCRIPTOR_EXCHANGE:
          case SEND_CONTROL_REPLICATION_FIELD_DESCRIPTOR_GATHER:
          case SEND_CONTROL_REPLICATION_DEPPART_RESULT_SCATTER:
          case SEND_CONTROL_REPLICATION_BUFFER_EXCHANGE:
          case SEND_CONTROL_REPLICATION_FUTURE_NAME_EXCHANGE:
          case SEND_CONTROL_REPLICATION_MUST_EPOCH_MAPPING_BROADCAST:
          case SEND_CONTROL_REPLICATION_MUST_EPOCH_MAPPING_EXCHANGE:
          case SEND_CONTROL_REPLICATION_MUST_EPOCH_DEPENDENCE_EXCHANGE:
          case SEND_CONTROL_REPLICATION_MUST_EPOCH_COMPLETION_EXCHANGE:
          case SEND_CONTROL_REPLICATION_CHECK_COLLECTIVE_MAPPING:
          case SEND_CONTROL_REPLICATION_CHECK_COLLECTIVE_SOURCES:
          case SEND_CONTROL_REPLICATION_TEMPLATE_INDEX_EXCHANGE:
          case SEND_CONTROL_REPLICATION_UNORDERED_EXCHANGE:
          case SEND_CONTROL_REPLICATION_CONSENSUS_MATCH:
          case SEND_CONTROL_REPLICATION_VERIFY_CONTROL_REPLICATION_EXCHANGE:
          case SEND_CONTROL_REPLICATION_OUTPUT_SIZE_EXCHANGE:
          case SEND_CONTROL_REPLICATION_INDEX_ATTACH_LAUNCH_SPACE:
          case SEND_CONTROL_REPLICATION_INDEX_ATTACH_UPPER_BOUND:
          case SEND_CONTROL_REPLICATION_INDEX_ATTACH_EXCHANGE:
          case SEND_CONTROL_REPLICATION_SHARD_PARTICIPANTS_EXCHANGE:
          case SEND_CONTROL_REPLICATION_IMPLICIT_SHARDING_FUNCTOR:
          case SEND_CONTROL_REPLICATION_CREATE_FILL_VIEW:
          case SEND_CONTROL_REPLICATION_VERSIONING_RENDEZVOUS:
          case SEND_CONTROL_REPLICATION_VIEW_RENDEZVOUS:
          case SEND_CONTROL_REPLICATION_CONCURRENT_MAPPING_RENDEZVOUS:
          case SEND_CONTROL_REPLICATION_CONCURRENT_ALLREDUCE:
          case SEND_CONTROL_REPLICATION_PROJECTION_TREE_EXCHANGE:
          case SEND_CONTROL_REPLICATION_TIMEOUT_MATCH_EXCHANGE:
          case SEND_CONTROL_REPLICATION_MASK_EXCHANGE:
          case SEND_CONTROL_REPLICATION_PREDICATE_EXCHANGE:
          case SEND_CONTROL_REPLICATION_CROSS_PRODUCT_EXCHANGE:
          case SEND_CONTROL_REPLICATION_TRACING_SET_DEDUPLICATION:
          case SEND_CONTROL_REPLICATION_SLOW_BARRIER:
            {
              ShardManager::handle_collective_message(derez, runtime);
              break;
            }
          case SEND_PROFILER_EVENT_TRIGGER:
            {
              implicit_profiler->process_event_trigger(derez);
              break;
            }
          case SEND_PROFILER_EVENT_POISON:
            {
              implicit_profiler->process_event_poison(derez);
              break;
            }
          case SEND_SHUTDOWN_NOTIFICATION:
            {
              runtime->handle_shutdown_notification(derez,remote_address_space);
              break;
            }
          case SEND_SHUTDOWN_RESPONSE:
            {
              runtime->handle_shutdown_response(derez);
              break;
            }
          default:
            assert(false); // should never get here
        }
        // Update the args and arglen
        args += message_size;
        arglen -= message_size;
      }
#ifdef DEBUG_LEGION
      assert(arglen == 0); // make sure we processed everything
#endif
    }

    //--------------------------------------------------------------------------
    /*static*/ void VirtualChannel::buffer_messages(unsigned num_messages,
                                         const void *args, size_t arglen,
                                         uint8_t *&receiving_buffer,
                                         size_t &receiving_buffer_size,
                                         size_t &receiving_index,
                                         unsigned &received_messages,
                                         unsigned &partial_messages)
    //--------------------------------------------------------------------------
    {
      received_messages += num_messages;
      partial_messages += 1; // up the number of partial messages received
      // Check to see if it fits
      if (receiving_buffer_size < (receiving_index+arglen))
      {
        // Figure out what the new size should be
        // Keep doubling until it's larger
        size_t new_buffer_size = receiving_buffer_size;
        while (new_buffer_size < (receiving_index+arglen))
          new_buffer_size *= 2;
#ifdef DEBUG_LEGION
        assert(new_buffer_size != 0); // would cause deallocation
#endif
        // Now realloc the memory
        void *new_ptr = legion_realloc(MESSAGE_BUFFER_ALLOC, receiving_buffer,
                                       receiving_buffer_size, new_buffer_size);
        receiving_buffer_size = new_buffer_size;
#ifdef DEBUG_LEGION
        assert(new_ptr != NULL);
#endif
        receiving_buffer = (uint8_t*)new_ptr;
      }
      // Copy the data in
      memcpy(receiving_buffer+receiving_index,args,arglen);
      receiving_index += arglen;
    }

    /////////////////////////////////////////////////////////////
    // Message Manager 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    MessageManager::MessageManager(AddressSpaceID remote,
                                   Runtime *rt, size_t max_message_size,
                                   const Processor remote_util_group)
      : channels((VirtualChannel*)
                  malloc(MAX_NUM_VIRTUAL_CHANNELS*sizeof(VirtualChannel))), 
        runtime(rt), remote_address_space(remote), target(remote_util_group)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(remote != runtime->address_space);
#endif
      const bool has_profiler = (runtime->profiler != NULL);
      // Initialize our virtual channels 
      for (unsigned idx = 0; idx < MAX_NUM_VIRTUAL_CHANNELS; idx++)
      {
        VirtualChannelKind vc = (VirtualChannelKind)idx;
        new (channels+idx) VirtualChannel(vc, rt->address_space,
            max_message_size, has_profiler);
      }
    }

    //--------------------------------------------------------------------------
    MessageManager::~MessageManager(void)
    //--------------------------------------------------------------------------
    {
      for (unsigned idx = 0; idx < MAX_NUM_VIRTUAL_CHANNELS; idx++)
        channels[idx].~VirtualChannel();
      free(channels);
    }

    //--------------------------------------------------------------------------
    void MessageManager::send_message(MessageKind message, Serializer &rez,
        bool flush, bool response, RtEvent flush_precondition)
    //--------------------------------------------------------------------------
    {
      const VirtualChannelKind channel = find_message_vc(message);
      // Always flush for the profiler if we're doing that
      if (!flush && (runtime->profiler != NULL) && 
          (channel != PROFILING_VIRTUAL_CHANNEL))
        flush = true;
      channels[channel].package_message(rez, message, flush, flush_precondition,
                                        runtime, target, response);
    }

    //--------------------------------------------------------------------------
    void MessageManager::receive_message(const void *args, size_t arglen)
    //--------------------------------------------------------------------------
    {
      // Pull the channel off to do the receiving
      const char *buffer = (const char*)args;
      VirtualChannelKind channel = *((const VirtualChannelKind*)buffer);
      buffer += sizeof(channel);
      arglen -= sizeof(channel);
      channels[channel].process_message(buffer, arglen, runtime, 
                                        remote_address_space);
    }

    //--------------------------------------------------------------------------
    void MessageManager::confirm_shutdown(ShutdownManager *shutdown_manager, 
                                          bool phase_one)
    //--------------------------------------------------------------------------
    {
      for (unsigned idx = 0; idx < MAX_NUM_VIRTUAL_CHANNELS; idx++)
        channels[idx].confirm_shutdown(shutdown_manager, phase_one,
            target, (idx == PROFILING_VIRTUAL_CHANNEL));
    }

    /////////////////////////////////////////////////////////////
    // Shutdown Manager 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    ShutdownManager::ShutdownManager(ShutdownPhase p, Runtime *rt, 
                                     AddressSpaceID s, unsigned r, 
                                     ShutdownManager *own)
      : phase(p), runtime(rt), source(s), radix(r), owner(own),
        needed_responses(0), return_code(rt->return_code), result(true)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    ShutdownManager::ShutdownManager(const ShutdownManager &rhs)
      : phase(rhs.phase), runtime(NULL), source(0), radix(0), owner(NULL)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    ShutdownManager::~ShutdownManager(void)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    ShutdownManager& ShutdownManager::operator=(const ShutdownManager &rhs)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
      return *this;
    }

    //--------------------------------------------------------------------------
    bool ShutdownManager::attempt_shutdown(void)
    //--------------------------------------------------------------------------
    {
      // Do the broadcast tree to the other nodes
      // Figure out who we have to send messages to
      std::vector<AddressSpaceID> targets;
      const AddressSpaceID local_space = runtime->address_space;
      const AddressSpaceID start = local_space * radix + 1;
      for (unsigned idx = 0; idx < radix; idx++)
      {
        AddressSpaceID next = start+idx;
        if (next < runtime->total_address_spaces)
          targets.push_back(next);
        else
          break;
      }
      
      if (!targets.empty())
      {
        // Set the number of needed_responses
        needed_responses = targets.size();
        Serializer rez;
        rez.serialize(this);
        rez.serialize(phase);
        for (std::vector<AddressSpaceID>::const_iterator it = 
              targets.begin(); it != targets.end(); it++)
          runtime->send_shutdown_notification(*it, rez); 
        return false;
      }
      else // no messages means we can finalize right now
      {
        finalize();
        return true;
      }
    }

    //--------------------------------------------------------------------------
    bool ShutdownManager::handle_response(int code, bool success,
                                          const std::set<RtEvent> &to_add)
    //--------------------------------------------------------------------------
    {
      bool done = false;
      {
        AutoLock s_lock(shutdown_lock);
        if ((return_code == 0) && (code != 0))
          return_code = code;
        if (result && !success)
          result = false;
        wait_for.insert(to_add.begin(), to_add.end()); 
#ifdef DEBUG_LEGION
        assert(needed_responses > 0);
#endif
        needed_responses--;
        done = (needed_responses == 0);
      }
      if (done)
      {
        finalize();
        return true;
      }
      return false;
    }

    //--------------------------------------------------------------------------
    void ShutdownManager::finalize(void)
    //--------------------------------------------------------------------------
    {
      // Do our local check
      runtime->confirm_runtime_shutdown(this, 
          (phase == CHECK_TERMINATION) || (phase == CHECK_SHUTDOWN));
#ifdef DEBUG_SHUTDOWN_HANG
      if (!result)
      {
        LG_TASK_DESCRIPTIONS(task_descs);
        // Only need to see tasks less than this 
        for (unsigned idx = 0; idx < LG_BEGIN_SHUTDOWN_TASK_IDS; idx++)
        {
          if (runtime->outstanding_counts[idx].load() == 0)
            continue;
          log_shutdown.info("Meta-Task %s: %d outstanding",
                task_descs[idx], runtime->outstanding_counts[idx].load());
        }
      }
#endif
      if (result && (runtime->address_space == source))
      {
        log_shutdown.info("SHUTDOWN PHASE %d SUCCESS!", phase);
        if (phase != CONFIRM_SHUTDOWN)
        {
          if (phase == CONFIRM_TERMINATION)
            runtime->prepare_runtime_shutdown();
          // Do the next phase
          runtime->initiate_runtime_shutdown(source, (ShutdownPhase)(phase+1));
        }
        else
        {
          log_shutdown.info("SHUTDOWN SUCCEEDED!");
          std::vector<RtEvent> shutdown_events;
          Realm::ProfilingRequestSet empty_requests;
          if (runtime->separate_runtime_instances)
          {
            Machine::ProcessorQuery all_procs(Machine::get_machine());
            for (Machine::ProcessorQuery::iterator it = all_procs.begin();
                  it != all_procs.end(); it++)
              shutdown_events.push_back(RtEvent(
                    it->spawn(LG_SHUTDOWN_TASK_ID, NULL, 0, empty_requests)));
          }
          else
          {
            const Processor utility_group = runtime->find_utility_group();
            shutdown_events.push_back(RtEvent(utility_group.spawn(
                    LG_SHUTDOWN_TASK_ID, NULL, 0, empty_requests)));
          }
          // One last really crazy precondition on shutdown, we actually need to
          // make sure that this task itself is done executing before trying to
          // shutdown so add our own completion event as a precondition
          shutdown_events.push_back(
              RtEvent(Processor::get_current_finish_event()));
          // Then tell Realm to shutdown when they are all done
          RealmRuntime realm = RealmRuntime::get_runtime();
          realm.shutdown(Runtime::merge_events(shutdown_events), return_code);
        }
      }
      else if (runtime->address_space != source)
      {
#ifdef DEBUG_LEGION
        assert(owner != NULL);
#endif
        // Send the message back
        Serializer rez;
        rez.serialize(owner);
        rez.serialize(return_code);
        rez.serialize<bool>(result);
        rez.serialize<size_t>(wait_for.size());
        for (std::set<RtEvent>::const_iterator it = 
              wait_for.begin(); it != wait_for.end(); it++)
          rez.serialize(*it);
        runtime->send_shutdown_response(source, rez);
      }
      else
      {
#ifdef DEBUG_LEGION
        assert(!result);
#endif
        log_shutdown.info("FAILED SHUTDOWN PHASE %d! Trying again...", phase);
        RtEvent precondition;
        if (!wait_for.empty())
          precondition = Runtime::merge_events(wait_for);
        // If we failed an even phase we go back to the one before it
        RetryShutdownArgs args(((phase % 2) == 0) ?
            (ShutdownPhase)(phase-1) : phase);
        runtime->issue_runtime_meta_task(args, LG_LOW_PRIORITY,
                                         precondition);
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_tracing_update(Deserializer &derez,
                                               AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      RemoteTraceRecorder::handle_remote_update(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_tracing_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteTraceRecorder::handle_remote_response(derez);
    }
  
    //--------------------------------------------------------------------------
    void Runtime::handle_free_external_allocation(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FutureInstance::handle_free_external(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_notify_collected_instances(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      MemoryManager::handle_notify_collected_instances(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_create_future_instance_request(Deserializer &derez,
                                                        AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Memory memory;
      derez.deserialize(memory);
      std::atomic<FutureInstance*> *target;
      derez.deserialize(target);
      RtUserEvent done;
      derez.deserialize(done);
      UniqueID uid;
      derez.deserialize(uid);
      size_t size;
      derez.deserialize(size);
      bool eager;
      derez.deserialize<bool>(eager);

      MemoryManager *manager = find_memory_manager(memory);
      FutureInstance *result =
        manager->create_future_instance(NULL, uid, size, eager);
      if (result != NULL)
      {
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(target);
          result->pack_instance(rez, ApEvent::NO_AP_EVENT,
              true/*pack ownership*/, false/*allow by value*/);
          rez.serialize(done);
        }
        send_create_future_instance_response(source, rez);
        delete result;
      }
      else
        Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_create_future_instance_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      std::atomic<FutureInstance*> *target;
      derez.deserialize(target);
      target->store(FutureInstance::unpack_instance(derez));
      RtUserEvent done;
      derez.deserialize(done);
      Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_free_future_instance(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Memory memory;
      derez.deserialize(memory);
      PhysicalInstance instance;
      derez.deserialize(instance);
      size_t size;
      derez.deserialize(size);
      RtEvent free_event;
      derez.deserialize(free_event);
      bool eager;
      derez.deserialize<bool>(eager);
      MemoryManager *manager = find_memory_manager(memory);
      manager->free_future_instance(instance, size, free_event, eager);
    }

    //--------------------------------------------------------------------------
    /*static*/ void ShutdownManager::handle_shutdown_notification(
                   Deserializer &derez, Runtime *runtime, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      ShutdownManager *owner;
      derez.deserialize(owner);
      ShutdownPhase phase;
      derez.deserialize(phase);
      runtime->initiate_runtime_shutdown(source, phase, owner);
    }

    //--------------------------------------------------------------------------
    /*static*/ void ShutdownManager::handle_shutdown_response(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShutdownManager *shutdown_manager;
      derez.deserialize(shutdown_manager);
      int return_code;
      derez.deserialize(return_code);
      bool success;
      derez.deserialize(success);
      size_t num_events;
      derez.deserialize(num_events);
      std::set<RtEvent> wait_for;
      for (unsigned idx = 0; idx < num_events; idx++)
      {
        RtEvent event;
        derez.deserialize(event);
        wait_for.insert(event);
      }
      if (shutdown_manager->handle_response(return_code, success, wait_for))
        delete shutdown_manager;
    }

    //--------------------------------------------------------------------------
    void ShutdownManager::record_outstanding_tasks(void)
    //--------------------------------------------------------------------------
    {
      // Instant death
      result = false;
      log_shutdown.info("Outstanding tasks on node %d", runtime->address_space);
    }

    //--------------------------------------------------------------------------
    void ShutdownManager::record_recent_message(void)
    //--------------------------------------------------------------------------
    {
      // Instant death
      result = false;
      log_shutdown.info("Outstanding message on node %d", 
                        runtime->address_space);
    }

    //--------------------------------------------------------------------------
    void ShutdownManager::record_pending_message(RtEvent pending_event)
    //--------------------------------------------------------------------------
    {
      // Instant death
      result = false;
      wait_for.insert(pending_event);
      log_shutdown.info("Pending message on node %d", runtime->address_space);
    }

    /////////////////////////////////////////////////////////////
    // Pending Registrations 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    PendingVariantRegistration::PendingVariantRegistration(VariantID v,
                                  size_t return_size, bool has_return_size, 
                                  const TaskVariantRegistrar &reg,
                                  const void *udata, size_t udata_size,
                                  const CodeDescriptor &realm, 
                                  const char *task_name)
      : vid(v), return_type_size(return_size),
        has_return_type_size(has_return_size), registrar(reg), 
        realm_desc(realm), logical_task_name(NULL)
    //--------------------------------------------------------------------------
    {
      // If we're doing a pending registration, this is a static
      // registration so we don't have to register it globally
      registrar.global_registration = false;
      // Make sure we own the task variant name
      if (reg.task_variant_name != NULL)
        registrar.task_variant_name = strdup(reg.task_variant_name);
      // We need to own the user data too
      if (udata != NULL)
      {
        user_data_size = udata_size;
        user_data = malloc(user_data_size);
        memcpy(user_data,udata,user_data_size);
      }
      else
      {
        user_data_size = 0;
        user_data = NULL;
      }
      if (task_name != NULL)
        logical_task_name = strdup(task_name);
    }

    //--------------------------------------------------------------------------
    PendingVariantRegistration::PendingVariantRegistration(
                                          const PendingVariantRegistration &rhs)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    PendingVariantRegistration::~PendingVariantRegistration(void)
    //--------------------------------------------------------------------------
    {
      if (registrar.task_variant_name != NULL)
        free(const_cast<char*>(registrar.task_variant_name));
      if (user_data != NULL)
        free(user_data);
      if (logical_task_name != NULL)
        free(logical_task_name);
    }

    //--------------------------------------------------------------------------
    PendingVariantRegistration& PendingVariantRegistration::operator=(
                                          const PendingVariantRegistration &rhs)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
      return *this;
    }

    //--------------------------------------------------------------------------
    void PendingVariantRegistration::perform_registration(Runtime *runtime)
    //--------------------------------------------------------------------------
    {
      // If we have a logical task name, attach the name info
      // Do this first before any logging for the variant
      if (logical_task_name != NULL)
        runtime->attach_semantic_information(registrar.task_id, 
                          LEGION_NAME_SEMANTIC_TAG, logical_task_name, 
                          strlen(logical_task_name)+1, 
                          false/*mutable*/, false/*send to owner*/);
      runtime->register_variant(registrar, user_data, user_data_size,
            realm_desc, return_type_size, has_return_type_size, vid, 
            false/*check task*/, true/*check context*/, true/*preregistered*/);
    }

    /////////////////////////////////////////////////////////////
    // Task Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    TaskImpl::TaskImpl(TaskID tid, Runtime *rt, const char *name/*=NULL*/)
      : task_id(tid), runtime(rt), initial_name(static_cast<char*>(
          malloc(((name == NULL) ? 64 : strlen(name) + 1) * sizeof(char)))),
        all_idempotent(false)
    //--------------------------------------------------------------------------
    {
      // Always fill in semantic info 0 with a name for the task
      if (name != NULL)
      {
        const size_t name_size = strlen(name) + 1; // for \0
        char *name_copy = (char*)legion_malloc(SEMANTIC_INFO_ALLOC, name_size);
        memcpy(name_copy, name, name_size);
        semantic_infos[LEGION_NAME_SEMANTIC_TAG] = 
          SemanticInfo(name_copy, name_size, false/*mutable*/);
        if (runtime->legion_spy_enabled)
          LegionSpy::log_task_name(task_id, name);
        // Also set the initial name to be safe
        memcpy(initial_name, name, name_size);
        // Register this task with the profiler if necessary
        if (runtime->profiler != NULL)
          runtime->profiler->register_task_kind(task_id, name, false);
      }
      else // Just set the initial name
      {
        snprintf(initial_name,64,"unnamed_task_%d", task_id);
        // Register this task with the profiler if necessary
        if (runtime->profiler != NULL)
          runtime->profiler->register_task_kind(task_id, initial_name, false);
      }
    }

    //--------------------------------------------------------------------------
    TaskImpl::TaskImpl(const TaskImpl &rhs)
      : task_id(rhs.task_id), runtime(rhs.runtime), initial_name(NULL)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    TaskImpl::~TaskImpl(void)
    //-------------------------------------------------------------------------
    {
      for (std::map<SemanticTag,SemanticInfo>::const_iterator it = 
            semantic_infos.begin(); it != semantic_infos.end(); it++)
      {
        legion_free(SEMANTIC_INFO_ALLOC, it->second.buffer,
                    it->second.size);
      }
      semantic_infos.clear();
      free(initial_name);
    }

    //--------------------------------------------------------------------------
    TaskImpl& TaskImpl::operator=(const TaskImpl &rhs)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
      return *this;
    }

    //--------------------------------------------------------------------------
    VariantID TaskImpl::get_unique_variant_id(void)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(task_lock);
      // VariantIDs have to uniquely identify our node so start at our
      // current runtime name and stride by the number of nodes
      VariantID result = runtime->address_space;
      if (result == 0) // Never use VariantID 0
        result = runtime->runtime_stride;
      for ( ; result <= (UINT_MAX - runtime->runtime_stride); 
            result += runtime->runtime_stride)
      {
        if (variants.find(result) != variants.end())
          continue;
        if (pending_variants.find(result) != pending_variants.end())
          continue;
        pending_variants.insert(result);
        return result;
      }
      assert(false);
      return result;
    }

    //--------------------------------------------------------------------------
    void TaskImpl::add_variant(VariantImpl *impl)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(impl->owner == this);
#endif
      AutoLock t_lock(task_lock);
      if (!variants.empty())
      {
        if (all_idempotent != impl->is_idempotent())
          REPORT_LEGION_ERROR(ERROR_IDEMPOTENT_MISMATCH, 
                        "Variants of task %s (ID %d) have different idempotent "
                        "options.  All variants of the same task must "
                        "all be either idempotent or non-idempotent.",
                        get_name(false/*need lock*/), task_id)
      }
      else
        all_idempotent  = impl->is_idempotent();
      // Check to see if this variant has already been registered
      if (variants.find(impl->vid) != variants.end())
        REPORT_LEGION_ERROR(ERROR_DUPLICATE_VARIANT_REGISTRATION,
                      "Duplicate variant ID %d registered for task %s (ID %d)",
                      impl->vid, get_name(false/*need lock*/), task_id)
      variants[impl->vid] = impl;
      // Erase the pending VariantID if there is one
      pending_variants.erase(impl->vid);
    }

    //--------------------------------------------------------------------------
    VariantImpl* TaskImpl::find_variant_impl(VariantID variant_id,bool can_fail)
    //--------------------------------------------------------------------------
    {
      // See if we already have the variant
      {
        AutoLock t_lock(task_lock,1,false/*exclusive*/);
        std::map<VariantID,VariantImpl*>::const_iterator finder = 
          variants.find(variant_id);
        if (finder != variants.end())
          return finder->second;
      }
      if (!can_fail)
        REPORT_LEGION_ERROR(ERROR_UNREGISTERED_VARIANT, 
                            "Unable to find variant %d of task %s!",
                            variant_id, get_name())
      return NULL;
    }

    //--------------------------------------------------------------------------
    void TaskImpl::find_valid_variants(std::vector<VariantID> &valid_variants,
                                       Processor::Kind kind) const
    //--------------------------------------------------------------------------
    {
      if (kind == Processor::NO_KIND)
      {
        AutoLock t_lock(task_lock,1,false/*exclusive*/);
        valid_variants.resize(variants.size());
        unsigned idx = 0;
        for (std::map<VariantID,VariantImpl*>::const_iterator it = 
              variants.begin(); it != variants.end(); it++, idx++)
        {
          valid_variants[idx] = it->first; 
        }
      }
      else
      {
        AutoLock t_lock(task_lock,1,false/*exclusive*/);
        for (std::map<VariantID,VariantImpl*>::const_iterator it = 
              variants.begin(); it != variants.end(); it++)
        {
          if (it->second->can_use(kind, true/*warn*/))
            valid_variants.push_back(it->first);
        }
      }
    }

    //--------------------------------------------------------------------------
    const char* TaskImpl::get_name(bool needs_lock /*= true*/)
    //--------------------------------------------------------------------------
    {
      if (needs_lock)
      {
        // Do the request through the semantic information
        const void *ptr = NULL; size_t dummy_size;
        if (retrieve_semantic_information(LEGION_NAME_SEMANTIC_TAG, ptr,
              dummy_size, true/*can fail*/, false/*wait until*/))
        {
          const char *result = NULL;
          static_assert(sizeof(result) == sizeof(ptr));
          memcpy(&result, &ptr, sizeof(result));
          return result;
        }
      }
      else
      {
        // If we're already holding the lock then we can just do
        // the local look-up regardless of if we're the owner or not
        std::map<SemanticTag,SemanticInfo>::const_iterator finder = 
          semantic_infos.find(LEGION_NAME_SEMANTIC_TAG);
        if (finder != semantic_infos.end())
        {
          const char *result = NULL;
          static_assert(sizeof(result) == sizeof(finder->second.buffer));
          memcpy(&result, &finder->second.buffer, sizeof(result)); 
          return result;
        }
      }
      // Couldn't find it so use the initial name
      return initial_name;
    }

    //--------------------------------------------------------------------------
    void TaskImpl::attach_semantic_information(SemanticTag tag,
                                               AddressSpaceID source,
                                               const void *buffer, size_t size,
                                            bool is_mutable, bool send_to_owner)
    //--------------------------------------------------------------------------
    {
      if ((tag == LEGION_NAME_SEMANTIC_TAG) && (runtime->profiler != NULL))
        runtime->profiler->register_task_kind(task_id,(const char*)buffer,true);

      void *local = legion_malloc(SEMANTIC_INFO_ALLOC, size);
      memcpy(local, buffer, size);
      bool added = true;
      RtUserEvent to_trigger;
      {
        AutoLock t_lock(task_lock);
        std::map<SemanticTag,SemanticInfo>::iterator finder = 
          semantic_infos.find(tag);
        if (finder != semantic_infos.end())
        {
          // Check to see if it is valid
          if (finder->second.is_valid())
          {
            // See if it is mutable or not
            if (!finder->second.is_mutable)
            {
              // Note mutable so check to make sure that the bits are the same
              if (size != finder->second.size)
                REPORT_LEGION_ERROR(ERROR_INCONSISTENT_SEMANTIC_TAG,
                              "Inconsistent Semantic Tag value "
                              "for tag %ld with different sizes of %zd"
                              " and %zd for task impl", 
                              tag, size, finder->second.size)
              // Otherwise do a bitwise comparison
              {
                const char *orig = (const char*)finder->second.buffer;
                const char *next = (const char*)buffer;
                for (unsigned idx = 0; idx < size; idx++)
                {
                  char diff = orig[idx] ^ next[idx];
                  if (diff)
                    REPORT_LEGION_ERROR(ERROR_INCONSISTENT_SEMANTIC_TAG,
                         "Inconsistent Semantic Tag value "
                                     "for tag %ld with different values at"
                                     "byte %d for task impl, %x != %x",
                                     tag, idx, orig[idx], next[idx])
                }
              }
              added = false;
            }
            else
            {
              // It is mutable so just overwrite it
              legion_free(SEMANTIC_INFO_ALLOC, 
                          finder->second.buffer, finder->second.size);
              finder->second.buffer = local;
              finder->second.size = size;
              finder->second.ready_event = RtUserEvent::NO_RT_USER_EVENT;
              finder->second.is_mutable = is_mutable;
            }
          }
          else
          {
            finder->second.buffer = local;
            finder->second.size = size;
            to_trigger = finder->second.ready_event;
            finder->second.ready_event = RtUserEvent::NO_RT_USER_EVENT;
            finder->second.is_mutable = is_mutable;
          }
        }
        else
          semantic_infos[tag] = SemanticInfo(local, size, is_mutable);
      }
      if (to_trigger.exists())
        Runtime::trigger_event(to_trigger);
      if (added)
      {
        if (send_to_owner)
        {
          AddressSpaceID owner_space = get_owner_space();
          // if we are not the owner and the message didn't come
          // from the owner, then send it
          if ((owner_space != runtime->address_space) && 
              (source != owner_space))
          {
            if (tag == LEGION_NAME_SEMANTIC_TAG)
            {
              // Special case here for task names, the user can reasonably
              // expect all tasks to have an initial name so we have to 
              // guarantee that this update is propagated before continuing
              // because otherwise we can't distinguish the case where a 
              // name hasn't propagated from one where it was never set
              RtUserEvent wait_on = Runtime::create_rt_user_event();
              send_semantic_info(owner_space, tag, buffer, size, 
                                 is_mutable, wait_on);
              wait_on.wait();
            }
            else
              send_semantic_info(owner_space, tag, buffer, size, is_mutable);
          }
        }
      }
      else
        legion_free(SEMANTIC_INFO_ALLOC, local, size);
    }

    //--------------------------------------------------------------------------
    bool TaskImpl::retrieve_semantic_information(SemanticTag tag,
              const void *&result, size_t &size, bool can_fail, bool wait_until)
    //--------------------------------------------------------------------------
    {
      RtEvent wait_on;
      RtUserEvent request;
      const AddressSpaceID owner_space = get_owner_space();
      const bool is_remote = (owner_space != runtime->address_space);
      {
        AutoLock t_lock(task_lock);
        std::map<SemanticTag,SemanticInfo>::const_iterator finder = 
          semantic_infos.find(tag);
        if (finder != semantic_infos.end())
        {
          // Already have the data so we are done
          if (finder->second.is_valid())
          {
            result = finder->second.buffer;
            size = finder->second.size;
            return true;
          }
          else if (is_remote)
          {
            if (can_fail)
            {
              // Have to make our own event
              request = Runtime::create_rt_user_event();
              wait_on = request;
            }
            else // can use the canonical event
              wait_on = finder->second.ready_event; 
          }
          else if (wait_until) // local so use the canonical event
            wait_on = finder->second.ready_event;
        }
        else
        {
          // Otherwise we make an event to wait on
          if (!can_fail && wait_until)
          {
            // Make a canonical ready event
            request = Runtime::create_rt_user_event();
            semantic_infos[tag] = SemanticInfo(request);
            wait_on = request;
          }
          else if (is_remote)
          {
            // Make an event just for us to use
            request = Runtime::create_rt_user_event();
            wait_on = request;
          }
        }
      }
      // We didn't find it yet, see if we have something to wait on
      if (!wait_on.exists())
      {
        // Nothing to wait on so we have to do something
        if (can_fail)
          return false;
        REPORT_LEGION_ERROR(ERROR_INVALID_SEMANTIC_TAG, 
                      "Invalid semantic tag %ld for task implementation", tag)
      }
      else
      {
        // Send a request if necessary
        if (is_remote && request.exists())
          send_semantic_request(owner_space, tag, can_fail, wait_until,request);
        wait_on.wait();
      }
      // When we wake up, we should be able to find everything
      AutoLock t_lock(task_lock,1,false/*exclusive*/);
      std::map<SemanticTag,SemanticInfo>::const_iterator finder = 
        semantic_infos.find(tag);
      if (finder == semantic_infos.end())
      {
        if (can_fail)
          return false;
        REPORT_LEGION_ERROR(ERROR_INVALID_SEMANTIC_TAG, 
            "invalid semantic tag %ld for task implementation", tag)
      }
      result = finder->second.buffer;
      size = finder->second.size;
      return true;
    }

    //--------------------------------------------------------------------------
    void TaskImpl::send_semantic_info(AddressSpaceID target, SemanticTag tag,
                                      const void *buffer, size_t size, 
                                      bool is_mutable, RtUserEvent to_trigger)
    //--------------------------------------------------------------------------
    {
      Serializer rez;
      {
        RezCheck z(rez);
        rez.serialize(task_id);
        rez.serialize(tag);
        rez.serialize(size);
        rez.serialize(buffer, size);
        rez.serialize(is_mutable);
        rez.serialize(to_trigger);
      }
      runtime->send_task_impl_semantic_info(target, rez);
    }

    //--------------------------------------------------------------------------
    void TaskImpl::send_semantic_request(AddressSpaceID target, 
             SemanticTag tag, bool can_fail, bool wait_until, RtUserEvent ready)
    //--------------------------------------------------------------------------
    {
      Serializer rez;
      {
        RezCheck z(rez);
        rez.serialize(task_id);
        rez.serialize(tag);
        rez.serialize(can_fail);
        rez.serialize(wait_until);
        rez.serialize(ready);
      }
      runtime->send_task_impl_semantic_request(target, rez);
    }

    //--------------------------------------------------------------------------
    void TaskImpl::process_semantic_request(SemanticTag tag, 
       AddressSpaceID target, bool can_fail, bool wait_until, RtUserEvent ready)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(get_owner_space() == runtime->address_space);
#endif
      RtEvent precondition;
      void *result = NULL;
      size_t size = 0;
      bool is_mutable = false;
      {
        AutoLock t_lock(task_lock);
        // See if we already have the data
        std::map<SemanticTag,SemanticInfo>::iterator finder = 
          semantic_infos.find(tag);
        if (finder != semantic_infos.end())
        {
          if (finder->second.is_valid())
          {
            result = finder->second.buffer;
            size = finder->second.size;
            is_mutable = finder->second.is_mutable;
          }
          else if (!can_fail && wait_until)
            precondition = finder->second.ready_event;
        }
        else if (!can_fail && wait_until)
        {
          // Don't have it yet, make a condition and hope that one comes
          RtUserEvent ready_event = Runtime::create_rt_user_event();
          precondition = ready_event;
          semantic_infos[tag] = SemanticInfo(ready_event);
        }
      }
      if (result == NULL)
      {
        // this will cause a failure on the original node
        if (can_fail || !wait_until)
          Runtime::trigger_event(ready);  
        else
        {
          // Defer this until the semantic condition is ready
          SemanticRequestArgs args(this, tag, target);
          runtime->issue_runtime_meta_task(args, LG_LATENCY_WORK_PRIORITY, 
                                           precondition);
        }
      }
      else
        send_semantic_info(target, tag, result, size, is_mutable, ready);
    }

    //--------------------------------------------------------------------------
    /*static*/ void TaskImpl::handle_semantic_request(Runtime *runtime,
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      TaskID task_id;
      derez.deserialize(task_id);
      SemanticTag tag;
      derez.deserialize(tag);
      bool can_fail;
      derez.deserialize(can_fail);
      bool wait_until;
      derez.deserialize(wait_until);
      RtUserEvent ready;
      derez.deserialize(ready);
      TaskImpl *impl = runtime->find_or_create_task_impl(task_id);
      impl->process_semantic_request(tag, source, can_fail, wait_until, ready);
    }

    //--------------------------------------------------------------------------
    /*static*/ void TaskImpl::handle_semantic_info(Runtime *runtime,
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      TaskID task_id;
      derez.deserialize(task_id);
      SemanticTag tag;
      derez.deserialize(tag);
      size_t size;
      derez.deserialize(size);
      const void *buffer = derez.get_current_pointer();
      derez.advance_pointer(size);
      bool is_mutable;
      derez.deserialize(is_mutable);
      RtUserEvent to_trigger;
      derez.deserialize(to_trigger);
      TaskImpl *impl = runtime->find_or_create_task_impl(task_id);
      impl->attach_semantic_information(tag, source, buffer, size, 
                                        is_mutable, false/*send to owner*/);
      if (to_trigger.exists())
        Runtime::trigger_event(to_trigger);
    }

    //--------------------------------------------------------------------------
    /*static*/ AddressSpaceID TaskImpl::get_owner_space(TaskID task_id,
                                                        Runtime *runtime)
    //--------------------------------------------------------------------------
    {
      return (task_id % runtime->total_address_spaces);
    }

    /////////////////////////////////////////////////////////////
    // Variant Impl 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    VariantImpl::VariantImpl(Runtime *rt, VariantID v, TaskImpl *own, 
                             const TaskVariantRegistrar &registrar,
                             size_t return_size, bool has_return_size,
                             const CodeDescriptor &realm,
                             const void *udata/*=NULL*/,size_t udata_size/*=0*/)
      : vid(v), owner(own), runtime(rt), global(registrar.global_registration),
        needs_padding(check_padding(rt, registrar.layout_constraints)),
        has_return_type_size(has_return_size), return_type_size(return_size),
        descriptor_id(runtime->get_unique_code_descriptor_id()),
        realm_descriptor(realm),
        execution_constraints(registrar.execution_constraints),
        layout_constraints(registrar.layout_constraints),
        user_data_size(udata_size), leaf_variant(registrar.leaf_variant), 
        inner_variant(registrar.inner_variant),
        idempotent_variant(registrar.idempotent_variant),
        replicable_variant(registrar.replicable_variant),
        concurrent_variant(registrar.concurrent_variant),
        concurrent_barrier(registrar.concurrent_barrier)
    //--------------------------------------------------------------------------
    { 
      if (udata != NULL)
      {
        user_data = malloc(user_data_size);
        memcpy(user_data, udata, user_data_size);
      }
      else
        user_data = NULL;
      // If we have a variant name, then record it
      if (registrar.task_variant_name == NULL)
      {
        variant_name = (char*)malloc(64*sizeof(char));
        snprintf(variant_name,64,"unnamed_variant_%d", vid);
      }
      else
        variant_name = strdup(registrar.task_variant_name);
      // If a global registration was requested, but the code descriptor
      // provided does not have portable implementations, try to make one
      // (if it fails, we'll complain below)
      if (global && !realm_descriptor.has_portable_implementations())
	realm_descriptor.create_portable_implementation();
      // Perform the registration, the normal case is not to have separate
      // runtime instances, but if we do have them, we only register on
      // the local processor
      if (!runtime->separate_runtime_instances)
      {
        Realm::ProfilingRequestSet profiling_requests;
        const ProcessorConstraint &proc_constraint = 
          execution_constraints.processor_constraint;
        if (proc_constraint.valid_kinds.empty())
        {
          REPORT_LEGION_WARNING(LEGION_WARNING_MISSING_PROC_CONSTRAINT, 
                     "NO PROCESSOR CONSTRAINT SPECIFIED FOR VARIANT"
                     " %s (ID %d) OF TASK %s (ID %d)! ASSUMING LOC_PROC!",
                     variant_name, vid, owner->get_name(false), owner->task_id)
          ready_event = ApEvent(Processor::register_task_by_kind(
                Processor::LOC_PROC, false/*global*/, descriptor_id, 
                realm_descriptor, profiling_requests, user_data, user_data_size));
        }
        else if (proc_constraint.valid_kinds.size() > 1)
        {
          std::set<ApEvent> ready_events;
          for (std::vector<Processor::Kind>::const_iterator it = 
                proc_constraint.valid_kinds.begin(); it !=
                proc_constraint.valid_kinds.end(); it++)
            ready_events.insert(ApEvent(Processor::register_task_by_kind(*it,
                false/*global*/, descriptor_id, realm_descriptor, 
                profiling_requests, user_data, user_data_size)));
          ready_event = Runtime::merge_events(NULL, ready_events);
        }
        else
          ready_event = ApEvent(Processor::register_task_by_kind(
              proc_constraint.valid_kinds[0], false/*global*/, descriptor_id, 
              realm_descriptor, profiling_requests, user_data, user_data_size));
      }
      else
      {
        // This is a debug case for when we have one runtime instance
        // for each processor
        std::set<Processor::Kind> handled_kinds;
        Machine::ProcessorQuery local_procs(runtime->machine);
        local_procs.local_address_space();
        std::set<ApEvent> ready_events;
        for (Machine::ProcessorQuery::iterator it = 
              local_procs.begin(); it != local_procs.end(); it++)
        {
          const Processor::Kind kind = it->kind();
          if (handled_kinds.find(kind) != handled_kinds.end())
            continue;
          Realm::ProfilingRequestSet profiling_requests;
          ready_events.insert(ApEvent(Processor::register_task_by_kind(kind,
                          false/*global*/, descriptor_id, realm_descriptor, 
                          profiling_requests, user_data, user_data_size)));
          handled_kinds.insert(kind);
        }
        if (!ready_events.empty())
          ready_event = Runtime::merge_events(NULL, ready_events);
      }
      // register this with the runtime profiler if we have to
      if (runtime->profiler != NULL)
        runtime->profiler->register_task_variant(own->task_id, vid,
            variant_name);
      // Check that global registration has portable implementations
      if (global && (!realm_descriptor.has_portable_implementations()))
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_GLOBAL_VARIANT_REGISTRATION, 
             "Variant %s requested global registration without "
                         "a portable implementation.", variant_name)
      if (leaf_variant && inner_variant)
        REPORT_LEGION_ERROR(ERROR_INVALID_TASK_VARIANT_PROPERTIES,
                      "Task variant %s (ID %d) of task %s (ID %d) is not "
                      "permitted to be both inner and leaf tasks "
                      "simultaneously.", variant_name, vid,
                      owner->get_name(), owner->task_id)
      if (runtime->record_registration)
        log_run.print("Task variant %s of task %s (ID %d) has Realm ID %ld",
              variant_name, owner->get_name(), owner->task_id, descriptor_id);
    }

    //--------------------------------------------------------------------------
    VariantImpl::~VariantImpl(void)
    //--------------------------------------------------------------------------
    {
      if (user_data != NULL)
        free(user_data);
      if (variant_name != NULL)
        free(variant_name);
    }

    //--------------------------------------------------------------------------
    bool VariantImpl::is_no_access_region(unsigned idx) const
    //--------------------------------------------------------------------------
    {
      bool result = false;
      for (std::multimap<unsigned,LayoutConstraintID>::const_iterator it = 
            layout_constraints.layouts.lower_bound(idx); it !=
            layout_constraints.layouts.upper_bound(idx); it++)
      {
        result = true;
        LayoutConstraints *constraints = 
          runtime->find_layout_constraints(it->second);
        if (!constraints->specialized_constraint.is_no_access())
        {
          result = false;
          break;
        }
      }
      return result;
    }

    //--------------------------------------------------------------------------
    ApEvent VariantImpl::dispatch_task(Processor target, SingleTask *task,
                                       TaskContext *ctx, ApEvent precondition,
                                       int priority, 
                                       Realm::ProfilingRequestSet &requests)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      // Either it is local or it is a group that we made
      assert(runtime->is_local(target) || runtime->separate_runtime_instances ||
              (target.kind() == Processor::PROC_GROUP));
#endif
      // Add any profiling requests
      if (runtime->profiler != NULL)
        runtime->profiler->add_task_request(requests, owner->task_id, vid,
            task->get_unique_op_id(), target, precondition);
      // Increment the number of outstanding tasks
#ifdef DEBUG_LEGION
      runtime->increment_total_outstanding_tasks(task->task_id, false/*meta*/);
#else
      runtime->increment_total_outstanding_tasks();
#endif
      DETAILED_PROFILER(runtime, REALM_SPAWN_TASK_CALL);
      if (ready_event.exists())
        return ApEvent(target.spawn(descriptor_id, &ctx, sizeof(ctx),requests,
           Runtime::merge_events(NULL, precondition, ready_event), priority));
      return ApEvent(target.spawn(descriptor_id, &ctx, sizeof(ctx), requests,
                                  precondition, priority));
    }

    //--------------------------------------------------------------------------
    bool VariantImpl::can_use(Processor::Kind kind, bool warn) const
    //--------------------------------------------------------------------------
    {
      const ProcessorConstraint &constraint = 
                                  execution_constraints.processor_constraint;
      if (constraint.is_valid())
        return constraint.can_use(kind);
      if (warn)
        REPORT_LEGION_WARNING(LEGION_WARNING_MISSING_PROC_CONSTRAINT, 
           "NO PROCESSOR CONSTRAINT SPECIFIED FOR VARIANT"
                        " %s (ID %d) OF TASK %s (ID %d)! ASSUMING LOC_PROC!",
                      variant_name, vid, owner->get_name(false),owner->task_id)
      return (Processor::LOC_PROC == kind);
    }

    //--------------------------------------------------------------------------
    void VariantImpl::broadcast_variant(RtUserEvent done, AddressSpaceID origin,
                                        AddressSpaceID local)
    //--------------------------------------------------------------------------
    {
      std::vector<AddressSpaceID> targets;
      std::vector<AddressSpaceID> locals;
      const AddressSpaceID start = local * runtime->legion_collective_radix + 1;
      for (int idx = 0; idx < runtime->legion_collective_radix; idx++)
      {
        AddressSpaceID next = start+idx;
        if (next >= runtime->total_address_spaces)
          break;
        locals.push_back(next);
        // Convert from relative to actual address space
        AddressSpaceID actual = (origin + next) % runtime->total_address_spaces;
        targets.push_back(actual);
      }
      if (!targets.empty())
      {
        std::set<RtEvent> local_done;
        for (unsigned idx = 0; idx < targets.size(); idx++)
        {
          RtUserEvent next_done = Runtime::create_rt_user_event();
          Serializer rez;
          {
            RezCheck z(rez);
            // pack the code descriptors 
            Realm::Serialization::ByteCountSerializer counter;
            realm_descriptor.serialize(counter, true/*portable*/);
            const size_t impl_size = counter.bytes_used();
            rez.serialize(impl_size);
            {
              Realm::Serialization::FixedBufferSerializer 
                serializer(rez.reserve_bytes(impl_size), impl_size);
              realm_descriptor.serialize(serializer, true/*portable*/);
            }
            rez.serialize(owner->task_id);
            rez.serialize(vid);
            // Extra padding to fix a realm bug for now
            rez.serialize(vid);
            rez.serialize(next_done);
            rez.serialize(return_type_size);
            rez.serialize(has_return_type_size);
            rez.serialize(user_data_size);
            if (user_data_size > 0)
              rez.serialize(user_data, user_data_size);
            rez.serialize(leaf_variant);
            rez.serialize(inner_variant);
            rez.serialize(idempotent_variant);
            rez.serialize(replicable_variant);
            size_t name_size = strlen(variant_name)+1;
            rez.serialize(variant_name, name_size);
            // Pack the constraints
            execution_constraints.serialize(rez);
            layout_constraints.serialize(rez);
            rez.serialize(origin);
            rez.serialize(locals[idx]);
          }
          runtime->send_variant_broadcast(targets[idx], rez);
          local_done.insert(next_done);
        }
        Runtime::trigger_event(done, Runtime::merge_events(local_done));
      }
      else
        Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void VariantImpl::find_padded_locks(SingleTask *task,
                        const std::vector<RegionRequirement> &regions,
                        const std::deque<InstanceSet> &physical_instances) const
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(needs_padding);
#endif
      for (std::multimap<unsigned,LayoutConstraintID>::const_iterator it = 
            layout_constraints.layouts.begin(); it != 
            layout_constraints.layouts.end(); it++)
      {
        const LayoutConstraints *layout =
          runtime->find_layout_constraints(it->second);
        if (layout->padding_constraint.delta.get_dim() == 0)
          continue;
#ifdef DEBUG_LEGION
        assert(it->first < regions.size());
        assert(it->first < physical_instances.size());
#endif
        const RegionRequirement &req = regions[it->first];
        const InstanceSet &instances = physical_instances[it->first];
        // Check to see if we have any explicit fields
        std::set<FieldID> padded_fields;
        if (!layout->field_constraint.field_set.empty())
        {
          for (std::vector<FieldID>::const_iterator fit =
                layout->field_constraint.field_set.begin(); fit !=
                layout->field_constraint.field_set.end(); fit++)
          {
#ifdef DEBUG_LEGION
            assert(req.privilege_fields.find(*fit) != 
                    req.privilege_fields.end());
#endif
            padded_fields.insert(*fit);
          }
        }
        else // Add all the fields for this region requirement
          padded_fields.insert(req.privilege_fields.begin(),
                               req.privilege_fields.end());
        FieldSpaceNode *fs = 
          runtime->forest->get_node(req.region.get_field_space());
        FieldMask padded_mask = fs->get_field_mask(padded_fields);
        for (unsigned idx = 0; idx < instances.size(); idx++)
        {
          const InstanceRef &ref = instances[idx];
          const FieldMask &overlap = padded_mask & ref.get_valid_fields();
          if (!overlap)
            continue;
          PhysicalManager *manager = ref.get_physical_manager();
          manager->find_padded_reservations(overlap, task, it->first);
          padded_mask -= overlap;
          if (!padded_mask)
            break;
        }
#ifdef DEBUG_LEGION
        assert(!padded_mask);
#endif
      }
    }

    //--------------------------------------------------------------------------
    void VariantImpl::record_padded_fields(
                      const std::vector<RegionRequirement> &regions,
                      const std::vector<PhysicalRegion> &physical_regions) const
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(needs_padding);
#endif
      for (std::multimap<unsigned,LayoutConstraintID>::const_iterator it = 
            layout_constraints.layouts.begin(); it != 
            layout_constraints.layouts.end(); it++)
      {
        const LayoutConstraints *layout =
          runtime->find_layout_constraints(it->second);
        if (layout->padding_constraint.delta.get_dim() == 0)
          continue;
#ifdef DEBUG_LEGION
        assert(it->first < regions.size());
        assert(it->first < physical_regions.size());
#endif
        const RegionRequirement &req = regions[it->first];
        const PhysicalRegion &region = physical_regions[it->first];
        // Check to see if we have any explicit fields
        if (layout->field_constraint.field_set.empty())
        {
          // Add all the fields for this region requirement
          for (std::set<FieldID>::const_iterator fit =
                req.privilege_fields.begin(); fit !=
                req.privilege_fields.end(); fit++)
            region.impl->add_padded_field(*fit);
        }
        else
        {
          // Only add the fields specified by the constraint
          for (std::vector<FieldID>::const_iterator fit =
                layout->field_constraint.field_set.begin(); fit !=
                layout->field_constraint.field_set.end(); fit++)
          {
#ifdef DEBUG_LEGION
            assert(req.privilege_fields.find(*fit) != 
                    req.privilege_fields.end());
#endif
            region.impl->add_padded_field(*fit);
          }
        }
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ bool VariantImpl::check_padding(Runtime *runtime,
                                     const TaskLayoutConstraintSet &constraints)
    //--------------------------------------------------------------------------
    {
      for (std::multimap<unsigned,LayoutConstraintID>::const_iterator it = 
            constraints.layouts.begin(); it != constraints.layouts.end(); it++)
      {
        const LayoutConstraints *layout =
          runtime->find_layout_constraints(it->second);
        if (layout->padding_constraint.delta.get_dim() > 0)
          return true;
      }
      return false;
    }

    //--------------------------------------------------------------------------
    /*static*/ void VariantImpl::handle_variant_broadcast(Runtime *runtime,
                                                          Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t impl_size;
      derez.deserialize(impl_size);
      CodeDescriptor realm_desc;
      {
        // Realm's serializers assume properly aligned buffers, so
        // malloc a temporary buffer here and copy the data to ensure
        // alignment.
        void *impl_buffer = malloc(impl_size);
#ifdef DEBUG_LEGION
        assert(impl_buffer);
#endif
        memcpy(impl_buffer, derez.get_current_pointer(), impl_size);
        derez.advance_pointer(impl_size);
        Realm::Serialization::FixedBufferDeserializer
          deserializer(impl_buffer, impl_size);
#ifdef DEBUG_LEGION
#ifndef NDEBUG
        bool ok =
#endif
                  realm_desc.deserialize(deserializer);
        assert(ok);
#else
        realm_desc.deserialize(deserializer);
#endif
        free(impl_buffer);
      }
      TaskID task_id;
      derez.deserialize(task_id);
      TaskVariantRegistrar registrar(task_id, false/*global*/);
      VariantID variant_id;
      derez.deserialize(variant_id);
      // Extra padding to fix a realm bug for now
      derez.deserialize(variant_id); 
      RtUserEvent done;
      derez.deserialize(done);
      size_t return_type_size;
      derez.deserialize(return_type_size);
      bool has_return_type_size;
      derez.deserialize(has_return_type_size);
      size_t user_data_size;
      derez.deserialize(user_data_size);
      const void *user_data = derez.get_current_pointer();
      derez.advance_pointer(user_data_size);
      derez.deserialize(registrar.leaf_variant);
      derez.deserialize(registrar.inner_variant);
      derez.deserialize(registrar.idempotent_variant);
      derez.deserialize(registrar.replicable_variant);
      // The last thing will be the name
      registrar.task_variant_name = (const char*)derez.get_current_pointer();
      size_t name_size = strlen(registrar.task_variant_name)+1;
      derez.advance_pointer(name_size);
      // Unpack the constraints
      registrar.execution_constraints.deserialize(derez);
      registrar.layout_constraints.deserialize(derez);
      // Ask the runtime to perform the registration 
      // Can lie about preregistration since the user would already have
      // gotten there error message on the owner node
      runtime->register_variant(registrar, user_data, user_data_size,
            realm_desc, return_type_size, has_return_type_size, variant_id,
            false/*check task*/, false/*check context*/, true/*preregistered*/);
      AddressSpaceID origin;
      derez.deserialize(origin);
      AddressSpaceID local;
      derez.deserialize(local);
      VariantImpl *impl = runtime->find_variant_impl(task_id, variant_id);
      impl->broadcast_variant(done, origin, local);
    }

    /////////////////////////////////////////////////////////////
    // Layout Constraints 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    LayoutConstraints::LayoutConstraints(LayoutConstraintID lay_id,FieldSpace h,
                                     Runtime *rt, bool inter, DistributedID did)
      : LayoutConstraintSet(), DistributedCollectable(rt,
          LEGION_DISTRIBUTED_HELP_ENCODE((did > 0) ? did : 
            rt->get_available_distributed_id(), CONSTRAINT_SET_DC),
          false/*register*/),
        layout_id(lay_id), handle(h), internal(inter), constraints_name(NULL)
    //--------------------------------------------------------------------------
    {
#ifdef LEGION_GC
      log_garbage.info("GC Constraints %lld %d", 
          LEGION_DISTRIBUTED_ID_FILTER(this->did), local_space);
#endif
    }

    //--------------------------------------------------------------------------
    LayoutConstraints::LayoutConstraints(LayoutConstraintID lay_id, Runtime *rt,
                                     const LayoutConstraintRegistrar &registrar,
                                     bool inter, DistributedID did,
                                     CollectiveMapping *collective_mapping)
      : LayoutConstraintSet(registrar.layout_constraints), 
        DistributedCollectable(rt, LEGION_DISTRIBUTED_HELP_ENCODE((did > 0) 
              ? did : rt->get_available_distributed_id(), CONSTRAINT_SET_DC),
            false/*register with runtime*/, collective_mapping),
        layout_id(lay_id), handle(registrar.handle), internal(inter)
    //--------------------------------------------------------------------------
    {
      if (registrar.layout_name == NULL)
      {
        constraints_name = (char*)malloc(64*sizeof(char));
        snprintf(constraints_name,64,"layout constraints %ld", layout_id);
      }
      else
        constraints_name = strdup(registrar.layout_name);
#ifdef LEGION_GC
      log_garbage.info("GC Constraints %lld %d", 
          LEGION_DISTRIBUTED_ID_FILTER(this->did), local_space);
#endif
    }

    //--------------------------------------------------------------------------
    LayoutConstraints::LayoutConstraints(LayoutConstraintID lay_id, Runtime *rt,
                                         const LayoutConstraintSet &cons,
                                         FieldSpace h, bool inter)
      : LayoutConstraintSet(cons), DistributedCollectable(rt,
          LEGION_DISTRIBUTED_HELP_ENCODE(rt->get_available_distributed_id(), 
            CONSTRAINT_SET_DC), false/*register with runtime*/),
        layout_id(lay_id), handle(h), internal(inter)
    //--------------------------------------------------------------------------
    {
      constraints_name = (char*)malloc(64*sizeof(char));
      snprintf(constraints_name,64,"layout constraints %ld", layout_id);
#ifdef LEGION_GC
      log_garbage.info("GC Constraints %lld %d", 
          LEGION_DISTRIBUTED_ID_FILTER(this->did), local_space);
#endif
    }

    //--------------------------------------------------------------------------
    LayoutConstraints::LayoutConstraints(const LayoutConstraints &rhs)
      : LayoutConstraintSet(rhs), DistributedCollectable(NULL, 0), 
        layout_id(rhs.layout_id), handle(rhs.handle), internal(false)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    LayoutConstraints::~LayoutConstraints(void)
    //--------------------------------------------------------------------------
    {
      if (constraints_name != NULL)
        free(constraints_name);
    }

    //--------------------------------------------------------------------------
    LayoutConstraints& LayoutConstraints::operator=(const LayoutConstraints &rh)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
      return *this;
    }

    //--------------------------------------------------------------------------
    bool LayoutConstraints::operator==(const LayoutConstraints &rhs) const
    //--------------------------------------------------------------------------
    {
      // We check equalities only on the members of LayoutConstraintSet
      return equals(rhs);
    }

    //--------------------------------------------------------------------------
    bool LayoutConstraints::operator==(const LayoutConstraintSet &rhs) const
    //--------------------------------------------------------------------------
    {
      // We check equalities only on the members of LayoutConstraintSet
      return equals(rhs);
    }

    //--------------------------------------------------------------------------
    void LayoutConstraints::notify_local(void)
    //--------------------------------------------------------------------------
    {
      runtime->unregister_layout(layout_id);
    }

    //--------------------------------------------------------------------------
    void LayoutConstraints::send_constraint_response(AddressSpaceID target,
                                                     RtUserEvent done_event)
    //--------------------------------------------------------------------------
    {
      Serializer rez;
      {
        RezCheck z(rez);
        rez.serialize(layout_id);
        rez.serialize(did);
        rez.serialize(handle);
        rez.serialize<bool>(internal);
        size_t name_len = strlen(constraints_name)+1;
        rez.serialize(name_len);
        rez.serialize(constraints_name, name_len);
        // pack the constraints
        serialize(rez);   
        // pack the done events
        rez.serialize(done_event);
      }
      runtime->send_constraint_response(target, rez);
      update_remote_instances(target);
    }

    //--------------------------------------------------------------------------
    void LayoutConstraints::update_constraints(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(constraints_name == NULL);
#endif
      size_t name_len;
      derez.deserialize(name_len);
      constraints_name = (char*)malloc(name_len);
      derez.deserialize(constraints_name, name_len);
      // unpack the constraints
      deserialize(derez); 
    }

    //--------------------------------------------------------------------------
    bool LayoutConstraints::entails(LayoutConstraints *constraints,
                unsigned total_dims, const LayoutConstraint **failed_constraint,
                bool test_pointer)
    //--------------------------------------------------------------------------
    {
      const std::pair<LayoutConstraintID,unsigned> 
        key(constraints->layout_id, total_dims);
      // Check to see if the result is in the cache
      if (test_pointer)
      {
        AutoLock lay(layout_lock,1,false/*exclusive*/);
        std::map<std::pair<LayoutConstraintID,unsigned>,
                  const LayoutConstraint*>::const_iterator finder = 
            entailment_cache.find(key);
        if (finder != entailment_cache.end())
        {
          if (finder->second != NULL)
          {
            if (failed_constraint != NULL)
              *failed_constraint = finder->second;
            return false;
          }
          else
            return true;
        }
      }
      else
      {
        AutoLock lay(layout_lock,1,false/*exclusive*/);
        std::map<std::pair<LayoutConstraintID,unsigned>,
                  const LayoutConstraint*>::const_iterator finder = 
            no_pointer_entailment_cache.find(key);
        if (finder != no_pointer_entailment_cache.end())
        {
          if (finder->second != NULL)
          {
            if (failed_constraint != NULL)
              *failed_constraint = finder->second;
            return false;
          }
          else
            return true;
        }
      }
      // Didn't find it, so do the test for real
      const LayoutConstraint *result = NULL;
      const bool entailment =
        entails(*constraints, total_dims, &result, test_pointer);
#ifdef DEBUG_LEGION
      assert(entailment ^ (result != NULL)); // only one should be true
#endif
      if (!entailment && (failed_constraint != NULL))
        *failed_constraint = result;
      // Save the result in the cache
      AutoLock lay(layout_lock);
      if (test_pointer)
        entailment_cache[key] = result;
      else
        no_pointer_entailment_cache[key] = result;
      return entailment;
    }

    //--------------------------------------------------------------------------
    bool LayoutConstraints::entails(const LayoutConstraintSet &other,
          unsigned total_dims, const LayoutConstraint **failed_constraint,
          bool test_pointer) const
    //--------------------------------------------------------------------------
    {
      return LayoutConstraintSet::entails(other, total_dims,
                                          failed_constraint, test_pointer);
    }

    //--------------------------------------------------------------------------
    bool LayoutConstraints::conflicts(LayoutConstraints *constraints,
              unsigned total_dims, const LayoutConstraint **conflict_constraint)
    //--------------------------------------------------------------------------
    {
      const std::pair<LayoutConstraintID,unsigned> 
        key(constraints->layout_id, total_dims);
      // Check to see if the result is in the cache
      {
        AutoLock lay(layout_lock,1,false/*exclusive*/);
        std::map<std::pair<LayoutConstraintID,unsigned>,
                  const LayoutConstraint*>::const_iterator finder = 
          conflict_cache.find(key);
        if (finder != conflict_cache.end())
        {
          if (finder->second != NULL)
          {
            if (conflict_constraint != NULL)
              *conflict_constraint = finder->second;
            return true;
          }
          else
            return false;
        }
      }
      // Didn't find it, so do the test for real
      const LayoutConstraint *result = NULL;
      const bool conflicted = conflicts(*constraints, total_dims, &result);
#ifdef DEBUG_LEGION
      assert(conflicted ^ (result == NULL)); // only one should be true
#endif
      // Save the result in the cache
      AutoLock lay(layout_lock);
      conflict_cache[key] = result;
      if (conflicted && (conflict_constraint != NULL))
        *conflict_constraint = result;
      return conflicted;
    }

    //--------------------------------------------------------------------------
    bool LayoutConstraints::conflicts(const LayoutConstraintSet &other,
        unsigned total_dims, const LayoutConstraint **conflict_constraint) const
    //--------------------------------------------------------------------------
    {
      return LayoutConstraintSet::conflicts(other, total_dims, 
                                            conflict_constraint);
    }

    //--------------------------------------------------------------------------
    /*static*/ AddressSpaceID LayoutConstraints::get_owner_space(
                            LayoutConstraintID layout_id, Runtime *runtime)
    //--------------------------------------------------------------------------
    {
      return (layout_id % runtime->total_address_spaces);
    }

    //--------------------------------------------------------------------------
    /*static*/ void LayoutConstraints::process_request(Runtime *runtime,
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      LayoutConstraintID lay_id;
      derez.deserialize(lay_id);
      RtUserEvent done_event;
      derez.deserialize(done_event);
      bool can_fail;
      derez.deserialize(can_fail);
      LayoutConstraints *constraints = 
        runtime->find_layout_constraints(lay_id, can_fail);
      if (can_fail && (constraints == NULL))
        Runtime::trigger_event(done_event);
      else
        constraints->send_constraint_response(source, done_event);
    }

    //--------------------------------------------------------------------------
    /*static*/ void LayoutConstraints::process_response(
                   Runtime *runtime, Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      LayoutConstraintID lay_id;
      derez.deserialize(lay_id);
      DistributedID did;
      derez.deserialize(did);
      FieldSpace handle;
      derez.deserialize(handle);
      bool internal;
      derez.deserialize(internal);
      // Make it an unpack it, then try to register it 
      LayoutConstraints *new_constraints = 
        new LayoutConstraints(lay_id, handle, runtime, internal, did);
      new_constraints->update_constraints(derez);
      // Now try to register this with the runtime
      if (!runtime->register_layout(new_constraints))
        delete new_constraints;
      // Trigger our done event and then return it
      RtUserEvent done_event;
      derez.deserialize(done_event);
      Runtime::trigger_event(done_event);
    }

    /////////////////////////////////////////////////////////////
    // Identity Projection Functor
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    IdentityProjectionFunctor::IdentityProjectionFunctor(Legion::Runtime *rt)
      : ProjectionFunctor(rt)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    IdentityProjectionFunctor::~IdentityProjectionFunctor(void)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    LogicalRegion IdentityProjectionFunctor::project(const Mappable *mappable,
            unsigned index, LogicalRegion upper_bound, const DomainPoint &point)
    //--------------------------------------------------------------------------
    {
      // We know we don't use the domain so we can fake it
      Domain launch_domain;
      return project(upper_bound, point, launch_domain);
    }
    
    //--------------------------------------------------------------------------
    LogicalRegion IdentityProjectionFunctor::project(const Mappable *mappable,
         unsigned index, LogicalPartition upper_bound, const DomainPoint &point)
    //--------------------------------------------------------------------------
    {
      // We know we don't use the domain so we can fake it
      Domain launch_domain;
      return project(upper_bound, point, launch_domain);
    }

    //--------------------------------------------------------------------------
    LogicalRegion IdentityProjectionFunctor::project(LogicalRegion upper_bound,
                          const DomainPoint &point, const Domain &launch_domain)
    //--------------------------------------------------------------------------
    {
      return upper_bound;
    }

    //--------------------------------------------------------------------------
    LogicalRegion IdentityProjectionFunctor::project(LogicalPartition up_bound, 
                          const DomainPoint &point, const Domain &launch_domain)
    //--------------------------------------------------------------------------
    {
      return runtime->get_logical_subregion_by_color(up_bound, point);
    }

    //--------------------------------------------------------------------------
    void IdentityProjectionFunctor::invert(LogicalRegion region,
                         LogicalRegion upper_bound, const Domain &launch_domain,
                         std::vector<DomainPoint> &ordered_points)
    //--------------------------------------------------------------------------
    {
      // This is a special case for the ordered mapping of point tasks in 
      // the case where we used to try to premap regions for an index task
      // launch where all the points mapped the same region with read-write
      // Just enumerate the points in order for the domain
      ordered_points.reserve(launch_domain.get_volume());
      for (Domain::DomainPointIterator itr(launch_domain); itr; itr++)
        ordered_points.push_back(itr.p);
    }

    //--------------------------------------------------------------------------
    void IdentityProjectionFunctor::invert(LogicalRegion region,
                      LogicalPartition upper_bound, const Domain &launch_domain,
                      std::vector<DomainPoint> &ordered_points)
    //--------------------------------------------------------------------------
    {
      // This should never get called
      assert(false);
    }

    //--------------------------------------------------------------------------
    bool IdentityProjectionFunctor::is_complete(LogicalRegion upper_bound,
                                                const Domain &launch_domain)
    //--------------------------------------------------------------------------
    {
      return true;
    }

    //--------------------------------------------------------------------------
    bool IdentityProjectionFunctor::is_complete(LogicalPartition upper_bound,
                                                const Domain &launch_domain)
    //--------------------------------------------------------------------------
    {
      const Domain color_space_domain =
        runtime->get_index_partition_color_space(
            upper_bound.get_index_partition());
      return ((color_space_domain == launch_domain) ||
              (color_space_domain.get_volume() == launch_domain.get_volume()));
    }

    //--------------------------------------------------------------------------
    bool IdentityProjectionFunctor::is_functional(void) const
    //--------------------------------------------------------------------------
    {
      return true;
    }

    //--------------------------------------------------------------------------
    bool IdentityProjectionFunctor::is_exclusive(void) const
    //--------------------------------------------------------------------------
    {
      return false;
    }

    //--------------------------------------------------------------------------
    unsigned IdentityProjectionFunctor::get_depth(void) const
    //--------------------------------------------------------------------------
    {
      return 0;
    }

    /////////////////////////////////////////////////////////////
    // Projection Function 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    ProjectionFunction::ProjectionFunction(ProjectionID pid, 
                                           ProjectionFunctor *func)
      : depth(func->get_depth()), is_exclusive(func->is_exclusive()),
        is_functional(func->is_functional()), 
        is_invertible(func->is_invertible()), projection_id(pid), functor(func)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    ProjectionFunction::ProjectionFunction(const ProjectionFunction &rhs)
      : depth(rhs.depth), is_exclusive(rhs.is_exclusive), 
        is_functional(rhs.is_functional), is_invertible(rhs.is_invertible), 
        projection_id(rhs.projection_id), functor(rhs.functor)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    ProjectionFunction::~ProjectionFunction(void)
    //--------------------------------------------------------------------------
    {
      // These can be shared in the case of multiple runtime instances
      if (!implicit_runtime->separate_runtime_instances)
        delete functor;
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::prepare_for_shutdown(void)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    LogicalRegion ProjectionFunction::project_point(Task *task, unsigned idx, 
        Runtime *runtime, const Domain &launch_domain, const DomainPoint &point)
    //--------------------------------------------------------------------------
    {
      const RegionRequirement &req = task->regions[idx];
#ifdef DEBUG_LEGION
      assert(req.handle_type != LEGION_SINGULAR_PROJECTION);
#endif
      size_t arglen = 0;
      const void *args = req.get_projection_args(&arglen);
      if (!is_exclusive)
      {
        AutoLock p_lock(projection_reservation);
        if (req.handle_type == LEGION_PARTITION_PROJECTION)
        {
          LogicalRegion result = !is_functional ?
            functor->project(task, idx, req.partition, point) : (args == NULL) ?
            functor->project(req.partition, point, launch_domain) :
            functor->project(req.partition, point, launch_domain, args, arglen);
          check_projection_partition_result(req.partition, task, idx,
                                            result, runtime);
          return result;
        }
        else
        {
          LogicalRegion result = !is_functional ?
            functor->project(task, idx, req.region, point) : (args == NULL) ?
            functor->project(req.region, point, launch_domain) :
            functor->project(req.region, point, launch_domain, args, arglen);
          check_projection_region_result(req.region, task, idx, result,runtime);
          return result;
        }
      }
      else
      {
        if (req.handle_type == LEGION_PARTITION_PROJECTION)
        {
          LogicalRegion result = !is_functional ?
            functor->project(task, idx, req.partition, point) : (args == NULL) ?
            functor->project(req.partition, point, launch_domain) :
            functor->project(req.partition, point, launch_domain, args, arglen);
          check_projection_partition_result(req.partition, task, idx,
                                            result, runtime);
          return result;
        }
        else
        {
          LogicalRegion result = !is_functional ?
            functor->project(task, idx, req.region, point) : (args == NULL) ?
            functor->project(req.region, point, launch_domain) :
            functor->project(req.region, point, launch_domain, args, arglen);
          check_projection_region_result(req.region, task, idx, result,runtime);
          return result;
        }
      }
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::project_points(const RegionRequirement &req, 
                  unsigned idx, Runtime *runtime, const Domain &launch_domain,
                  const std::vector<PointTask*> &point_tasks)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(req.handle_type != LEGION_SINGULAR_PROJECTION);
#endif
      size_t arglen = 0;
      const void *args = req.get_projection_args(&arglen);
      std::map<LogicalRegion,std::vector<DomainPoint> > dependences;
      // We used to support the case of the identity projection function
      // on logical regions special with the premap case, but it is really
      // just another case of having dependences between points on a region
      // requirement so we'll detect that case that specially and handle
      // it here inside the runtime since we control the implementation of
      // the identity projection function
      const bool find_dependences = IS_WRITE(req) && !IS_COLLECTIVE(req) &&
        (is_invertible || ((projection_id == 0) && 
                           (req.handle_type == LEGION_REGION_PROJECTION)));
      if (!is_exclusive)
      {
        AutoLock p_lock(projection_reservation);
        if (req.handle_type == LEGION_PARTITION_PROJECTION)
        {
          for (std::vector<PointTask*>::const_iterator it = 
                point_tasks.begin(); it != point_tasks.end(); it++)
          {
            LogicalRegion result = !is_functional ?
              functor->project(*it, idx, req.partition, 
                               (*it)->get_domain_point()) : (args == NULL) ?
              functor->project(req.partition,
                  (*it)->get_domain_point(), launch_domain) :
              functor->project(req.partition,
                  (*it)->get_domain_point(), launch_domain, args, arglen);
            check_projection_partition_result(req.partition,
                static_cast<Task*>(*it), idx, result, runtime);
            (*it)->set_projection_result(idx, result);
            if (find_dependences)
            {
              std::vector<DomainPoint> &region_deps = dependences[result];
              if (region_deps.empty())
              {
                functor->invert(result,req.partition,launch_domain,region_deps);
                check_inversion((*it), idx, region_deps);
              }
              else
                check_containment((*it), idx, region_deps);
              (*it)->record_intra_space_dependences(idx, region_deps);
            }
          }
        }
        else
        {
          for (std::vector<PointTask*>::const_iterator it = 
                point_tasks.begin(); it != point_tasks.end(); it++)
          {
            LogicalRegion result = !is_functional ?
              functor->project(*it, idx, req.region,(*it)->get_domain_point()) :
              (args == NULL) ? functor->project(req.region, 
                  (*it)->get_domain_point(), launch_domain) :
              functor->project(req.region, (*it)->get_domain_point(),
                  launch_domain, args, arglen);
            check_projection_region_result(req.region, static_cast<Task*>(*it),
                                           idx, result, runtime);
            (*it)->set_projection_result(idx, result);
            if (find_dependences)
            {
              std::vector<DomainPoint> &region_deps = dependences[result];
              if (region_deps.empty())
              {
                functor->invert(result, req.region, launch_domain, region_deps);
                check_inversion((*it), idx, region_deps);
              }
              else
                check_containment((*it), idx, region_deps);
              (*it)->record_intra_space_dependences(idx, region_deps);
            }
          }
        }
      }
      else
      {
        if (req.handle_type == LEGION_PARTITION_PROJECTION)
        {
          for (std::vector<PointTask*>::const_iterator it = 
                point_tasks.begin(); it != point_tasks.end(); it++)
          {
            LogicalRegion result = !is_functional ?
              functor->project(*it, idx, req.partition, 
                              (*it)->get_domain_point()) : (args == NULL) ?
              functor->project(req.partition, 
                  (*it)->get_domain_point(), launch_domain) :
              functor->project(req.partition,
                  (*it)->get_domain_point(), launch_domain, args, arglen);
            check_projection_partition_result(req.partition,
                static_cast<Task*>(*it), idx, result, runtime);
            (*it)->set_projection_result(idx, result);
            if (find_dependences)
            {
              std::vector<DomainPoint> &region_deps = dependences[result];
              if (region_deps.empty())
              {
                functor->invert(result,req.partition,launch_domain,region_deps);
                check_inversion((*it), idx, region_deps);
              }
              else
                check_containment((*it), idx, region_deps);
              (*it)->record_intra_space_dependences(idx, region_deps);
            }
          }
        }
        else
        {
          for (std::vector<PointTask*>::const_iterator it = 
                point_tasks.begin(); it != point_tasks.end(); it++)
          {
            LogicalRegion result = !is_functional ? 
              functor->project(*it, idx, req.region,(*it)->get_domain_point()) :
              (args == NULL) ? functor->project(req.region, 
                  (*it)->get_domain_point(), launch_domain) :
              functor->project(req.region, (*it)->get_domain_point(),
                  launch_domain, args, arglen);
            check_projection_region_result(req.region, static_cast<Task*>(*it),
                                           idx, result, runtime);
            (*it)->set_projection_result(idx, result);
            if (find_dependences)
            {
              std::vector<DomainPoint> &region_deps = dependences[result];
              if (region_deps.empty())
              {
                functor->invert(result, req.region, launch_domain, region_deps);
                check_inversion((*it), idx, region_deps);
              }
              else
                check_containment((*it), idx, region_deps);
              (*it)->record_intra_space_dependences(idx, region_deps);
            }
          }
        }
      }
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::project_points(Operation *op, unsigned idx,
                         const RegionRequirement &req, 
                         Runtime *runtime, const Domain &launch_domain, 
                         const std::vector<ProjectionPoint*> &points)
    //--------------------------------------------------------------------------
    {
      Mappable *mappable = op->get_mappable();
#ifdef DEBUG_LEGION
      assert(req.handle_type != LEGION_SINGULAR_PROJECTION);
      assert(mappable != NULL);
#endif
      size_t arglen = 0;
      const void *args = req.get_projection_args(&arglen);
      const bool find_dependences = is_invertible && IS_WRITE(req);
      std::map<LogicalRegion,std::vector<DomainPoint> > dependences;
      if (!is_exclusive)
      {
        AutoLock p_lock(projection_reservation);
        if (req.handle_type == LEGION_PARTITION_PROJECTION)
        {
          for (std::vector<ProjectionPoint*>::const_iterator it = 
                points.begin(); it != points.end(); it++)
          {
            LogicalRegion result = !is_functional ?
              functor->project(mappable, idx, req.partition, 
                                (*it)->get_domain_point()) : (args == NULL) ?
              functor->project(req.partition, 
                  (*it)->get_domain_point(), launch_domain) :
              functor->project(req.partition,
                  (*it)->get_domain_point(), launch_domain, args, arglen);
            check_projection_partition_result(req.partition, op, idx,
                                              result, runtime);
            (*it)->set_projection_result(idx, result);
            if (find_dependences)
            {
              std::vector<DomainPoint> &region_deps = dependences[result];
              if (region_deps.empty())
              {
                functor->invert(result,req.partition,launch_domain,region_deps);
                check_inversion((*it)->as_mappable(), idx, region_deps);
              }
              else
                check_containment((*it)->as_mappable(), idx, region_deps);
              (*it)->record_intra_space_dependences(idx, region_deps);
            }
          }
        }
        else
        {
          for (std::vector<ProjectionPoint*>::const_iterator it = 
                points.begin(); it != points.end(); it++)
          {
            LogicalRegion result = !is_functional ?
              functor->project(mappable, idx, req.region,
                               (*it)->get_domain_point()) : (args == NULL) ?
              functor->project(req.region, 
                  (*it)->get_domain_point(), launch_domain) :
              functor->project(req.region,
                  (*it)->get_domain_point(), launch_domain, args, arglen);
            check_projection_region_result(req.region, op, idx, result,runtime);
            (*it)->set_projection_result(idx, result);
            if (find_dependences)
            {
              std::vector<DomainPoint> &region_deps = dependences[result];
              if (region_deps.empty())
              {
                functor->invert(result, req.region, launch_domain, region_deps);
                check_inversion((*it)->as_mappable(), idx, region_deps);
              }
              else
                check_containment((*it)->as_mappable(), idx, region_deps);
              (*it)->record_intra_space_dependences(idx, region_deps);
            }
          }
        }
      }
      else
      {
        if (req.handle_type == LEGION_PARTITION_PROJECTION)
        {
          for (std::vector<ProjectionPoint*>::const_iterator it = 
                points.begin(); it != points.end(); it++)
          {
            LogicalRegion result = !is_functional ?
              functor->project(mappable, idx, req.partition, 
                               (*it)->get_domain_point()) : (args == NULL) ?
              functor->project(req.partition, 
                  (*it)->get_domain_point(), launch_domain) :
              functor->project(req.partition,
                  (*it)->get_domain_point(), launch_domain, args, arglen);
            check_projection_partition_result(req.partition, op, idx,
                                              result, runtime);
            (*it)->set_projection_result(idx, result);
            if (find_dependences)
            {
              std::vector<DomainPoint> &region_deps = dependences[result];
              if (region_deps.empty())
              {
                functor->invert(result,req.partition,launch_domain,region_deps);
                check_inversion((*it)->as_mappable(), idx, region_deps);
              }
              else
                check_containment((*it)->as_mappable(), idx, region_deps);
              (*it)->record_intra_space_dependences(idx, region_deps);
            }
          }
        }
        else
        {
          for (std::vector<ProjectionPoint*>::const_iterator it = 
                points.begin(); it != points.end(); it++)
          {
            LogicalRegion result = !is_functional ?
              functor->project(mappable, idx, req.region,
                               (*it)->get_domain_point()) : (args == NULL) ?
              functor->project(req.region, 
                  (*it)->get_domain_point(), launch_domain) :
              functor->project(req.region,
                  (*it)->get_domain_point(), launch_domain, args, arglen);
            check_projection_region_result(req.region, op, idx, result,runtime);
            (*it)->set_projection_result(idx, result);
            if (find_dependences)
            {
              std::vector<DomainPoint> &region_deps = dependences[result];
              if (region_deps.empty())
              {
                functor->invert(result, req.region, launch_domain, region_deps);
                check_inversion((*it)->as_mappable(), idx, region_deps);
              }
              else
                check_containment((*it)->as_mappable(), idx, region_deps);
              (*it)->record_intra_space_dependences(idx, region_deps);
            }
          }
        }
      }
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::check_projection_region_result(
        LogicalRegion upper_bound, const Task *task, unsigned idx,
        LogicalRegion result, Runtime *runtime) const
    //--------------------------------------------------------------------------
    {
      // NO_REGION is always an acceptable answer
      if (result == LogicalRegion::NO_REGION)
        return;
      if (result.get_tree_id() != upper_bound.get_tree_id())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion of tree ID %d for region requirement %d "
            "of task %s (UID %lld) which is different from the upper "
            "bound node of tree ID %d", projection_id, 
            result.get_tree_id(), idx, task->get_task_name(), 
            task->get_unique_id(), upper_bound.get_tree_id())
#ifdef DEBUG_LEGION
      if (!runtime->forest->is_subregion(result, upper_bound))
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion which is not a subregion of the "
            "upper bound region for region requirement %d of "
            "task %s (UID %lld)", projection_id, idx,
            task->get_task_name(), task->get_unique_id())
      const unsigned projection_depth = 
        runtime->forest->get_projection_depth(result, upper_bound);
      if (projection_depth > functor->get_depth())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion which has projection depth %d which "
            "is different from stated projection depth of the functor "
            "which is %d for region requirement %d of task %s (ID %lld)",
            projection_id, projection_depth, functor->get_depth(),
            idx, task->get_task_name(), task->get_unique_id())
#endif
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::check_projection_partition_result(
        LogicalPartition upper_bound, const Task *task, unsigned idx,
        LogicalRegion result, Runtime *runtime) const
    //--------------------------------------------------------------------------
    {
      // NO_REGION is always an acceptable answer
      if (result == LogicalRegion::NO_REGION)
        return;
      if (result.get_tree_id() != upper_bound.get_tree_id())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion of tree ID %d for region requirement %d "
            "of task %s (UID %lld) which is different from the upper "
            "bound node of tree ID %d", projection_id, 
            result.get_tree_id(), idx, task->get_task_name(), 
            task->get_unique_id(), upper_bound.get_tree_id())
#ifdef DEBUG_LEGION
      if (!runtime->forest->is_subregion(result, upper_bound))
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion which is not a subregion of the "
            "upper bound region for region requirement %d of "
            "task %s (UID %lld)", projection_id, idx,
            task->get_task_name(), task->get_unique_id())
      const unsigned projection_depth = 
        runtime->forest->get_projection_depth(result, upper_bound);
      if (projection_depth > functor->get_depth())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion which has projection depth %d which "
            "is different from stated projection depth of the functor "
            "which is %d for region requirement %d of task %s (ID %lld)",
            projection_id, projection_depth, functor->get_depth(),
            idx, task->get_task_name(), task->get_unique_id())
#endif
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::check_projection_region_result(
        LogicalRegion upper_bound, Operation *op, unsigned idx,
        LogicalRegion result, Runtime *runtime) const
    //--------------------------------------------------------------------------
    {
      // NO_REGION is always an acceptable answer
      if (result == LogicalRegion::NO_REGION)
        return;
      if (result.get_tree_id() != upper_bound.get_tree_id())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion of tree ID %d for region requirement %d "
            "of operation %s (UID %lld) which is different from the upper "
            "bound node of tree ID %d", projection_id, 
            result.get_tree_id(), idx, op->get_logging_name(), 
            op->get_unique_op_id(), upper_bound.get_tree_id())
#ifdef DEBUG_LEGION
      if (!runtime->forest->is_subregion(result, upper_bound))
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion which is not a subregion of the "
            "upper bound region for region requirement %d of "
            "operation %s (UID %lld)", projection_id, idx,
            op->get_logging_name(), op->get_unique_op_id())
      const unsigned projection_depth = 
        runtime->forest->get_projection_depth(result, upper_bound);
      if (projection_depth > functor->get_depth())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion which has projection depth %d which "
            "is different from stated projection depth of the functor "
            "which is %d for region requirement %d of operation %s (ID %lld)",
            projection_id, projection_depth, functor->get_depth(),
            idx, op->get_logging_name(), op->get_unique_op_id())
#endif
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::check_projection_partition_result(
        LogicalPartition upper_bound, Operation *op, unsigned idx,
        LogicalRegion result, Runtime *runtime) const
    //--------------------------------------------------------------------------
    {
      // NO_REGION is always an acceptable answer
      if (result == LogicalRegion::NO_REGION)
        return;
      if (result.get_tree_id() != upper_bound.get_tree_id())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion of tree ID %d for region requirement %d "
            "of operation %s (UID %lld) which is different from the upper "
            "bound node of tree ID %d", projection_id, 
            result.get_tree_id(), idx, op->get_logging_name(), 
            op->get_unique_op_id(), upper_bound.get_tree_id())
#ifdef DEBUG_LEGION
      if (!runtime->forest->is_subregion(result, upper_bound))
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion which is not a subregion of the "
            "upper bound region for region requirement %d of "
            "operation %s (UID %lld)", projection_id, idx,
            op->get_logging_name(), op->get_unique_op_id())
      const unsigned projection_depth = 
        runtime->forest->get_projection_depth(result, upper_bound);
      if (projection_depth > functor->get_depth())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT, 
            "Projection functor %d produced an invalid "
            "logical subregion which has projection depth %d which "
            "is different from stated projection depth of the functor "
            "which is %d for region requirement %d of operation %s (ID %lld)",
            projection_id, projection_depth, functor->get_depth(),
            idx, op->get_logging_name(), op->get_unique_op_id())
#endif
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::check_inversion(const Task *task, unsigned index,
                                         const std::vector<DomainPoint> &points)
    //--------------------------------------------------------------------------
    {
      if (points.empty())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
            "Projection functor %d produced an empty inversion result "
            "while inverting region requirement %d of task %s (UID %lld). "
            "Empty inversions are never legal because the point task that "
            "produced the region must always be included.",
            projection_id, index, task->get_task_name(), task->get_unique_id())
#ifdef DEBUG_LEGION
      std::set<DomainPoint> unique_points(points.begin(), points.end());
      if (unique_points.size() != points.size())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
            "Projection functor %d produced an invalid inversion result "
            "containing duplicate points for region requirement %d of "
            "task %s (UID %lld). Each point is only permitted to "
            "appear once in an inversion.", projection_id, index,
            task->get_task_name(), task->get_unique_id())
      if (unique_points.find(task->index_point) == unique_points.end())
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
            "Projection functor %d produced an invalid inversion result "
            "that does not contain the original point for region requirement "
            "%d of task %s (UID %lld).", projection_id, index,
            task->get_task_name(), task->get_unique_id())
#endif
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::check_inversion(const Mappable *mappable, 
                         unsigned index, const std::vector<DomainPoint> &points)
    //--------------------------------------------------------------------------
    {
      switch (mappable->get_mappable_type())
      {
        case LEGION_COPY_MAPPABLE:
          {
            const Copy *copy = mappable->as_copy();
            if (points.empty())
              REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
                  "Projection functor %d produced an empty inversion result "
                  "while inverting region requirement %d of copy (UID %lld)."
                  "Empty inversions are never legal because the point copy "
                  "that produced the region must always be included.",
                  projection_id, index, copy->get_unique_id())
#ifdef DEBUG_LEGION
            std::set<DomainPoint> unique_points(points.begin(), points.end());
            if (unique_points.size() != points.size())
              REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
                  "Projection functor %d produced an invalid inversion result "
                  "containing duplicate points for region requirement %d of "
                  "copy (UID %lld). Each point is only permitted to "
                  "appear once in an inversion.", projection_id, index,
                  copy->get_unique_id())
            if (unique_points.find(copy->index_point) == unique_points.end())
              REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
                  "Projection functor %d produced an invalid inversion result "
                  "that does not contain the original point for region "
                  "requirement %d of copy (UID %lld).", projection_id, index,
                  copy->get_unique_id())
#endif
            break;
          }
        case LEGION_FILL_MAPPABLE:
          {
            const Fill *fill = mappable->as_fill();
            if (points.empty())
              REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
                  "Projection functor %d produced an empty inversion result "
                  "while inverting region requirement %d of fill (UID %lld)."
                  "Empty inversions are never legal because the point fill "
                  "that produced the region must always be included.",
                  projection_id, index, fill->get_unique_id())
#ifdef DEBUG_LEGION
            std::set<DomainPoint> unique_points(points.begin(), points.end());
            if (unique_points.size() != points.size())
              REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
                  "Projection functor %d produced an invalid inversion result "
                  "containing duplicate points for region requirement %d of "
                  "fill (UID %lld). Each point is only permitted to "
                  "appear once in an inversion.", projection_id, index,
                  fill->get_unique_id())
            if (unique_points.find(fill->index_point) == unique_points.end())
              REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
                  "Projection functor %d produced an invalid inversion result "
                  "that does not contain the original point for region "
                  "requirement %d of fill (UID %lld).", projection_id, index,
                  fill->get_unique_id())
#endif
            break;
          }
        default:
          assert(false);
      }
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::check_containment(const Task *task, unsigned index,
                                         const std::vector<DomainPoint> &points)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      for (std::vector<DomainPoint>::const_iterator it = 
            points.begin(); it != points.end(); it++)
      {
        if ((*it) == task->index_point)
          return;
      }
      REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
          "Projection functor %d produced an invalid inversion result "
          "that does not contain the original point for region requirement "
          "%d of task %s (UID %lld).", projection_id, index,
          task->get_task_name(), task->get_unique_id())
#endif
    }

    //--------------------------------------------------------------------------
    bool ProjectionFunction::is_complete(RegionTreeNode *node, Operation *op,
                         unsigned index, IndexSpaceNode *projection_space) const
    //--------------------------------------------------------------------------
    {
      Domain launch_domain;
      projection_space->get_domain(launch_domain);
      if (node->is_region())
      {
        RegionNode *region = node->as_region_node();
        if (is_functional)
        {
          if (is_exclusive)
          {
            AutoLock p_lock(projection_reservation);
            return functor->is_complete(region->handle, launch_domain);
          }
          else
            return functor->is_complete(region->handle, launch_domain);
        }
        else
        {
          Mappable *mappable = op->get_mappable();
          if (is_exclusive)
          {
            AutoLock p_lock(projection_reservation);
            return functor->is_complete(mappable, index,
                                        region->handle, launch_domain);
          }
          else
            return functor->is_complete(mappable, index, 
                                        region->handle, launch_domain);
        }
      }
      else
      {
        PartitionNode *partition = node->as_partition_node();
        if (is_functional)
        {
          if (is_exclusive)
          {
            AutoLock p_lock(projection_reservation);
            return functor->is_complete(partition->handle, launch_domain);
          }
          else
            return functor->is_complete(partition->handle, launch_domain);
        }
        else
        {
          Mappable *mappable = op->get_mappable();
          if (is_exclusive)
          {
            AutoLock p_lock(projection_reservation);
            return functor->is_complete(mappable, index,
                                        partition->handle, launch_domain);
          }
          else
            return functor->is_complete(mappable, index,
                                        partition->handle, launch_domain);
        }
      }
    }

    //--------------------------------------------------------------------------
    void ProjectionFunction::check_containment(const Mappable *mappable, 
                         unsigned index, const std::vector<DomainPoint> &points)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      
      switch (mappable->get_mappable_type())
      {
        case LEGION_COPY_MAPPABLE:
          {
            const Copy *copy = mappable->as_copy();
            for (std::vector<DomainPoint>::const_iterator it = 
                  points.begin(); it != points.end(); it++)
            {
              if ((*it) == copy->index_point)
                return;
            }
            REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
              "Projection functor %d produced an invalid inversion result "
              "that does not contain the original point for region requirement "
              "%d of copy (UID %lld).", projection_id, index,
              copy->get_unique_id())
            break;
          }
        case LEGION_FILL_MAPPABLE:
          {
            const Fill *fill = mappable->as_fill();
            for (std::vector<DomainPoint>::const_iterator it = 
                  points.begin(); it != points.end(); it++)
            {
              if ((*it) == fill->index_point)
                return;
            }
            REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_RESULT,
              "Projection functor %d produced an invalid inversion result "
              "that does not contain the original point for region requirement "
              "%d of fill (UID %lld).", projection_id, index,
              fill->get_unique_id())
            break;
          }
        default:
          assert(false);
      
      }
#endif
    } 

    //--------------------------------------------------------------------------
    ProjectionNode* ProjectionFunction::construct_projection_tree(
          Operation *op, unsigned index, const RegionRequirement &req,
          ShardID local_shard, RegionTreeNode *root, const ProjectionInfo &info)
    //--------------------------------------------------------------------------
    {
      RegionTreeForest *forest = root->context;
      ProjectionNode *result = NULL;
      if (root->is_region())
        result = new ProjectionRegion(root->as_region_node());
      else
        result = new ProjectionPartition(root->as_partition_node());
      IndexSpaceNode *launch_space = info.projection_space;
      IndexSpace local_space = (info.sharding_function == NULL) ? 
        IndexSpace::NO_SPACE : info.sharding_function->find_shard_space(
                  local_shard, launch_space, info.sharding_space->handle,
                  op->get_provenance());
      if (!local_space.exists())
        return result;
      Domain local_domain, launch_domain;
      forest->find_domain(local_space, local_domain);
      launch_space->get_domain(launch_domain);
      std::map<RegionTreeNode*,ProjectionNode*> node_map;
      node_map[root] = result;
      Mappable *mappable = is_functional ? NULL : op->get_mappable();
      size_t arglen = 0;
      const void *args = req.get_projection_args(&arglen);
      if (root->is_region())
      {
        RegionNode *region = root->as_region_node();
        for (Domain::DomainPointIterator itr(local_domain); itr; itr++)
        {
          LogicalRegion result;
          if (!is_exclusive)
          {
            AutoLock p_lock(projection_reservation);
            result = !is_functional ?
              functor->project(mappable, index, region->handle, itr.p) : 
              (args == NULL) ?
                functor->project(region->handle, itr.p, launch_domain) :
                functor->project(region->handle, itr.p, launch_domain, 
                                 args, arglen);
          }
          else
            result = !is_functional ?
              functor->project(mappable, index, region->handle, itr.p) :
              (args == NULL) ?
                functor->project(region->handle, itr.p, launch_domain) :
                functor->project(region->handle, itr.p, launch_domain,
                                 args, arglen);
          check_projection_region_result(region->handle, op, index,
                                         result, op->runtime);
          if (!result.exists())
            continue;
          add_to_projection_tree(result, root, forest, node_map, local_shard);
        }
      }
      else
      {
        PartitionNode *partition = root->as_partition_node();
        for (Domain::DomainPointIterator itr(local_domain); itr; itr++)
        {
          LogicalRegion result;
          if (!is_exclusive)
          {
            AutoLock p_lock(projection_reservation);
            result = !is_functional ?
              functor->project(mappable, index, partition->handle, itr.p) :
              (args == NULL) ?
                functor->project(partition->handle, itr.p, launch_domain) :
                functor->project(partition->handle, itr.p, launch_domain,
                                 args, arglen);
          }
          else
            result = !is_functional ?
              functor->project(mappable, index, partition->handle, itr.p) :
              (args == NULL) ?
                functor->project(partition->handle, itr.p, launch_domain) :
                functor->project(partition->handle, itr.p, launch_domain,
                                 args, arglen);
          check_projection_partition_result(partition->handle, op, index,
                                            result, op->runtime);
          if (!result.exists())
            continue;
          add_to_projection_tree(result, root, forest, node_map, local_shard);
        }
      }
      return result;
    }

    //--------------------------------------------------------------------------
    /*static*/ void ProjectionFunction::add_to_projection_tree(LogicalRegion r,
                            RegionTreeNode *root, RegionTreeForest *context,
                            std::map<RegionTreeNode*,ProjectionNode*> &node_map,
                            ShardID owner_shard)
    //--------------------------------------------------------------------------
    {
      RegionNode *child = context->get_node(r);
      std::map<RegionTreeNode*,ProjectionNode*>::const_iterator finder = 
        node_map.find(child);
      ProjectionRegion *current = NULL;
      if (finder == node_map.end())
      {
        current = new ProjectionRegion(child);
        node_map[child] = current;
      }
      else
        current = static_cast<ProjectionRegion*>(finder->second);
      current->add_user(owner_shard);
      while (child != root)
      {
        // Do the next partition
        finder = node_map.find(child->parent);
        ProjectionPartition *parent = NULL;
        if (finder == node_map.end())
        {
          parent = new ProjectionPartition(child->parent);
          node_map[child->parent] = parent;
        }
        else
          parent = static_cast<ProjectionPartition*>(finder->second);
        parent->add_child(current);
        if (child->parent == root)
          break;
        // Do the next region
        finder = node_map.find(child->parent->parent);
        ProjectionRegion *next = NULL;
        if (finder == node_map.end())
        {
          next = new ProjectionRegion(child->parent->parent);
          node_map[child->parent->parent] = next;
        }
        else
          next = static_cast<ProjectionRegion*>(finder->second);
        next->add_child(parent); 
        // Now we can walk up the tree
        child = child->parent->parent;
        current = next;
      }
    }

    /////////////////////////////////////////////////////////////
    // Cyclic Sharding Functor
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    CyclicShardingFunctor::CyclicShardingFunctor(void)
      : ShardingFunctor()
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    CyclicShardingFunctor::~CyclicShardingFunctor(void)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    template<int DIM>
    size_t CyclicShardingFunctor::linearize_point(
                                   const Realm::IndexSpace<DIM,coord_t> &is,
                                   const Realm::Point<DIM,coord_t> &point) const
    //--------------------------------------------------------------------------
    {
      if (is.dense())
      {
        Realm::AffineLinearizedIndexSpace<DIM,coord_t> linearizer(is);
        return linearizer.linearize(point);
      }
      else
      {
        size_t offset = 0;
        for (Realm::IndexSpaceIterator<DIM,coord_t> it(is); it.valid; it.step())
        {
          if (it.rect.contains(point))
          {
            Realm::AffineLinearizedIndexSpace<DIM,coord_t> 
              linearizer(Realm::IndexSpace<DIM,coord_t>(it.rect));
            return offset + linearizer.linearize(point);
          }
          else
            offset += it.rect.volume();
        }
        return offset;
      }
    }

    //--------------------------------------------------------------------------
    ShardID CyclicShardingFunctor::shard(const DomainPoint &point,
                                         const Domain &full_space,
                                         const size_t total_shards)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(point.get_dim() == full_space.get_dim());
#endif
      switch (point.get_dim())
      {
#define DIMFUNC(DIM) \
        case DIM: \
          { \
            const DomainT<DIM,coord_t> is = full_space; \
            const Point<DIM,coord_t> p1 = point; \
            return (linearize_point<DIM>(is, p1) % total_shards); \
          }
        LEGION_FOREACH_N(DIMFUNC)
#undef DIMFUNC
        default:
          assert(false);
      }
      return 0;
    }

    /////////////////////////////////////////////////////////////
    // Sharding Function 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    ShardingFunction::ShardingFunction(ShardingFunctor *func, 
       RegionTreeForest *f, ShardManager *m, ShardingID id, bool skip, bool own)
      : functor(func), forest(f), manager(m), sharding_id(id),
        use_points(func->use_points()), skip_checks(skip), own_functor(own)
    //--------------------------------------------------------------------------
    {
    }

    //--------------------------------------------------------------------------
    ShardingFunction::~ShardingFunction(void)
    //--------------------------------------------------------------------------
    {
      if (own_functor)
        delete functor;
    }

    //--------------------------------------------------------------------------
    ShardID ShardingFunction::find_owner(const DomainPoint &point,
                                         const Domain &sharding_space)
    //--------------------------------------------------------------------------
    {
      if (use_points)
      {
        const DomainPoint result = functor->shard_points(point, sharding_space,
                                  manager->shard_points, manager->shard_domain);
        if (manager->isomorphic_points)
        {
          if (result.get_dim() != 1)
            REPORT_LEGION_ERROR(ERROR_ILLEGAL_SHARDING_FUNCTOR_OUTPUT,
                                "Illegal output from sharding functor %d. "
                                "Shards must be contained in the set of "
                                "'shard_points' for control replicated task.",
                                sharding_id)
          const coord_t shard = result[0];
          if (!skip_checks && 
              ((shard < 0) || (manager->total_shards <= size_t(shard))))
            REPORT_LEGION_ERROR(ERROR_ILLEGAL_SHARDING_FUNCTOR_OUTPUT,
                                "Illegal output shard %lld from sharding "
                                "functor %d. Shards for this index space "
                                "launch must be between 0 and %zd (exclusive).",
                                shard, sharding_id, manager->total_shards)
          return result[0];
        }
        else
        {
          std::vector<DomainPoint>::const_iterator finder = 
            std::lower_bound(manager->sorted_points.begin(),
                             manager->sorted_points.end(), result);
          if (finder == manager->sorted_points.end())
            REPORT_LEGION_ERROR(ERROR_ILLEGAL_SHARDING_FUNCTOR_OUTPUT,
                                "Illegal output from sharding functor %d. "
                                "Shards must be contained in the set of "
                                "'shard_points' for control replicated task.",
                                sharding_id)
          const unsigned offset =
            std::distance(manager->sorted_points.begin(), finder);
#ifdef DEBUG_LEGION
          assert(offset < manager->shard_lookup.size());
#endif
          return manager->shard_lookup[offset];
        }
      }
      else
      {
        const ShardID shard =
          functor->shard(point, sharding_space, manager->total_shards);
        if (!skip_checks && (manager->total_shards <= shard))
          REPORT_LEGION_ERROR(ERROR_ILLEGAL_SHARDING_FUNCTOR_OUTPUT,
                              "Illegal output shard %d from sharding "
                              "functor %d. Shards for this index space "
                              "launch must be between 0 and %zd (exclusive).",
                              shard, sharding_id, manager->total_shards)
        return shard;
      }
    }

    //--------------------------------------------------------------------------
    IndexSpace ShardingFunction::find_shard_space(ShardID shard,
     IndexSpaceNode *full_space, IndexSpace shard_space, Provenance *provenance)
    //--------------------------------------------------------------------------
    {
      const ShardKey key(shard, full_space->handle, shard_space);
      // Check to see if we already have it
      {
        AutoLock s_lock(sharding_lock,1,false/*exclusive*/);
        std::map<ShardKey,IndexSpace>::const_iterator 
          finder = shard_index_spaces.find(key);
        if (finder != shard_index_spaces.end())
          return finder->second;
      }
      // Otherwise we need to make it
      IndexSpace result = 
        full_space->create_shard_space(this, shard, shard_space,
                  manager->shard_domain, manager->shard_points, provenance);
      AutoLock s_lock(sharding_lock);
      shard_index_spaces[key] = result;
      return result;
    } 

    //--------------------------------------------------------------------------
    bool ShardingFunction::find_shard_participants(IndexSpaceNode *full_space,
                     IndexSpace shard_space, std::vector<ShardID> &participants)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(participants.empty());
#endif
      std::pair<IndexSpace,IndexSpace> key(full_space->handle, shard_space); 
      {
        AutoLock s_lock(sharding_lock,1,false/*exclusive*/);
        std::map<std::pair<IndexSpace,IndexSpace>,std::vector<ShardID> >::
          const_iterator finder = shard_participants.find(key);
        if (finder != shard_participants.end())
        {
          // If the vector is empty that means all the shards are 
          // participants so we didn't need to record them all 
          if (!finder->second.empty())
          {
            // Record the specific participating shards
            participants = finder->second;
            return false;
          }
          else
            return true;
        }
      }
      std::set<ShardID> range_shards;
      full_space->compute_range_shards(this, shard_space,
          manager->shard_points, manager->shard_domain, range_shards);
#ifdef DEBUG_LEGION
      // Should always have at least one shard participant
      assert(!range_shards.empty());
#endif
      // Only need to record the results if they aren't all participating
      if (range_shards.size() < manager->total_shards)
        participants.insert(participants.end(), 
            range_shards.begin(), range_shards.end());
      AutoLock s_lock(sharding_lock);
      shard_participants[key] = participants;
      return participants.empty();
    }

    //--------------------------------------------------------------------------
    bool ShardingFunction::has_participants(ShardID shard, 
                                            IndexSpaceNode *full_space,
                                            IndexSpace shard_space)
    //--------------------------------------------------------------------------
    {
      const ShardKey key(shard, full_space->handle, shard_space);
      // Check to see if we already have it
      {
        AutoLock s_lock(sharding_lock,1,false/*exclusive*/);
        std::map<ShardKey,IndexSpace>::const_iterator 
          finder = shard_index_spaces.find(key);
        if (finder != shard_index_spaces.end())
          return finder->second.exists();
      }
      return full_space->has_shard_participants(this, shard, shard_space,
          manager->shard_points, manager->shard_domain);
    }

    /////////////////////////////////////////////////////////////
    // Legion Runtime 
    /////////////////////////////////////////////////////////////

    //--------------------------------------------------------------------------
    Runtime::Runtime(Machine m, const LegionConfiguration &config, 
                     bool background, InputArgs args, 
                     AddressSpaceID unique, Memory system,
                     const std::set<Processor> &locals,
                     const std::set<Processor> &local_utilities,
                     const std::set<AddressSpaceID> &address_spaces,
                     const std::map<Processor,AddressSpaceID> &processor_spaces,
                     bool default_mapper)
      : external(new Legion::Runtime(this)),
        mapper_runtime(new Legion::Mapping::MapperRuntime(this)),
        machine(m), runtime_system_memory(system), address_space(unique), 
        total_address_spaces(address_spaces.size()),
        runtime_stride(address_spaces.size()), profiler(NULL),
        forest(new RegionTreeForest(this)), virtual_manager(NULL), 
        num_utility_procs(local_utilities.empty() ? locals.size() : 
                          local_utilities.size()), input_args(args),
        initial_task_window_size(config.initial_task_window_size),
        initial_task_window_hysteresis(config.initial_task_window_hysteresis),
        initial_tasks_to_schedule(config.initial_tasks_to_schedule),
        initial_meta_task_vector_width(config.initial_meta_task_vector_width),
        eager_alloc_percentage(config.eager_alloc_percentage),
        eager_alloc_percentage_overrides(config.eager_alloc_percentage_overrides),
        max_message_size(config.max_message_size),
        gc_epoch_size(config.gc_epoch_size),
        max_control_replication_contexts(
                      config.max_control_replication_contexts),
        max_local_fields(config.max_local_fields),
        max_replay_parallelism(config.max_replay_parallelism),
        safe_control_replication(config.safe_control_replication),
        program_order_execution(config.program_order_execution),
        dump_physical_traces(config.dump_physical_traces),
        no_tracing(config.no_tracing),
        no_physical_tracing(config.no_physical_tracing || no_tracing ||
                            program_order_execution),
        no_trace_optimization(config.no_trace_optimization),
        no_fence_elision(config.no_fence_elision),
        no_transitive_reduction(config.no_transitive_reduction),
        inline_transitive_reduction(config.inline_transitive_reduction),
        replay_on_cpus(config.replay_on_cpus),
        verify_partitions(config.verify_partitions),
        runtime_warnings(config.runtime_warnings),
        warnings_backtrace(config.warnings_backtrace),
        warnings_are_errors(config.warnings_are_errors),
        report_leaks(config.report_leaks),
        separate_runtime_instances(config.separate_runtime_instances),
        record_registration(config.record_registration),
        stealing_disabled(config.stealing_disabled),
        resilient_mode(config.resilient_mode),
        unsafe_launch(config.unsafe_launch),
#ifdef DEBUG_LEGION
        unsafe_mapper(config.unsafe_mapper),
#else
        unsafe_mapper(!config.safe_mapper),
#endif
        safe_tracing(config.safe_tracing),
        disable_independence_tests(config.disable_independence_tests),
        legion_spy_enabled(config.legion_spy_enabled),
        supply_default_mapper(default_mapper),
        enable_test_mapper(config.enable_test_mapper),
        legion_ldb_enabled(!config.ldb_file.empty()),
        replay_file(legion_ldb_enabled ? config.ldb_file : config.replay_file),
#ifdef DEBUG_LEGION
        logging_region_tree_state(config.logging_region_tree_state),
        verbose_logging(config.verbose_logging),
        logical_logging_only(config.logical_logging_only),
        physical_logging_only(config.physical_logging_only),
#endif
        check_privileges(config.check_privileges),
        dump_free_ranges(config.dump_free_ranges),
        legion_collective_radix(config.legion_collective_radix),
        mpi_rank_table((mpi_rank >= 0) ? new MPIRankTable(this) : NULL),
        prepared_for_shutdown(false), total_outstanding_tasks(0), 
        outstanding_top_level_tasks(initialize_outstanding_top_level_tasks(
              address_space, total_address_spaces, legion_collective_radix)),
        local_procs(locals), local_utils(local_utilities),
        proc_spaces(processor_spaces),
        unique_index_space_id((unique == 0) ? runtime_stride : unique),
        unique_index_partition_id((unique == 0) ? runtime_stride : unique), 
        unique_field_space_id((unique == 0) ? runtime_stride : unique),
        unique_index_tree_id((unique == 0) ? runtime_stride : unique),
        unique_region_tree_id((unique == 0) ? runtime_stride : unique),
        unique_field_id(LEGION_MAX_APPLICATION_FIELD_ID + 
                        ((unique == 0) ? runtime_stride : unique)),
        unique_operation_id((unique == 0) ? runtime_stride : unique),
        unique_code_descriptor_id(LG_TASK_ID_AVAILABLE +
                        ((unique == 0) ? runtime_stride : unique)),
        unique_constraint_id(LEGION_MAX_APPLICATION_LAYOUT_ID + 
            (((LEGION_MAX_APPLICATION_LAYOUT_ID % runtime_stride) <= unique) ?
             (runtime_stride - 
              ((LEGION_MAX_APPLICATION_LAYOUT_ID % runtime_stride) - unique)) :
             (unique - (LEGION_MAX_APPLICATION_LAYOUT_ID % runtime_stride)))),
        unique_is_expr_id((unique == 0) ? runtime_stride : unique),
        unique_top_level_task_id((unique == 0) ? runtime_stride : unique),
        unique_provenance_id((unique == 0) ? runtime_stride : unique),
        unique_implicit_top_level_task_id(0),
#ifdef LEGION_SPY
        unique_indirections_id((unique == 0) ? runtime_stride : unique),
#endif
        unique_task_id(get_current_static_task_id()+unique),
        unique_mapper_id(get_current_static_mapper_id()+unique),
        unique_trace_id(get_current_static_trace_id()+unique),
        unique_projection_id(get_current_static_projection_id()+unique),
        unique_sharding_id(get_current_static_sharding_id()+unique),
        unique_redop_id(get_current_static_reduction_id()+unique),
        unique_serdez_id(get_current_static_serdez_id()+unique),
        unique_library_mapper_id(LEGION_INITIAL_LIBRARY_ID_OFFSET),
        unique_library_trace_id(LEGION_INITIAL_LIBRARY_ID_OFFSET),
        unique_library_projection_id(LEGION_INITIAL_LIBRARY_ID_OFFSET),
        unique_library_sharding_id(LEGION_INITIAL_LIBRARY_ID_OFFSET),
        unique_library_task_id(LEGION_INITIAL_LIBRARY_ID_OFFSET),
        unique_library_redop_id(LEGION_INITIAL_LIBRARY_ID_OFFSET),
        unique_library_serdez_id(LEGION_INITIAL_LIBRARY_ID_OFFSET),
        unique_distributed_id((unique == 0) ? runtime_stride : unique)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert((unique_constraint_id % runtime_stride) == unique);
#endif
      if (LEGION_MAX_NUM_NODES <= address_space)
        REPORT_LEGION_ERROR(ERROR_MAXIMUM_NODES_EXCEEDED,
            "Maximum number of nodes exceeded. Detected node %d but "
            "'LEGION_MAX_NUM_NODES' is set to %d. Change the value of "
            "'LEGION_MAX_NUM_NODES' in legion_config.h and recompile. "
            "Please note that 'LEGION_MAX_NUM_NODES' must be a power of two.",
            address_space, LEGION_MAX_NUM_NODES)
      log_run.debug("Initializing Legion runtime in address space %x",
                            address_space);
      // Construct a local utility processor group
      if (local_utils.empty())
      {
        // make the utility group the set of all the local processors
#ifdef DEBUG_LEGION
        assert(!locals.empty());
#endif
        if (locals.size() == 1)
          utility_group = *(locals.begin());
        else
        {
          std::vector<Processor> util_group(locals.begin(), locals.end());
          utility_group = ProcessorGroup::create_group(util_group);
        }
      }
      else if (local_utils.size() == 1)
        utility_group = *(local_utils.begin());
      else
      {
        std::vector<Processor> util_g(local_utils.begin(), local_utils.end());
        utility_group = ProcessorGroup::create_group(util_g);
      }
#ifdef DEBUG_LEGION
      assert(utility_group.exists());
#endif
      // For each of the processors in our local set construct a manager
      for (std::set<Processor>::const_iterator it = local_procs.begin();
            it != local_procs.end(); it++)
      {
#ifdef DEBUG_LEGION
        assert((*it).kind() != Processor::UTIL_PROC);
#endif
        ProcessorManager *manager = new ProcessorManager(*it,
				    (*it).kind(), this,
                                    LEGION_DEFAULT_MAPPER_SLOTS, 
                                    stealing_disabled,
                                    !replay_file.empty());
        proc_managers[*it] = manager;
      }
      // Initialize the message manager array so that we can construct
      // message managers lazily as they are needed
      for (unsigned idx = 0; idx < LEGION_MAX_NUM_NODES; idx++)
        message_managers[idx].store(NULL);
      
      // Make the default number of contexts
      // No need to hold the lock yet because nothing is running
      total_contexts = LEGION_DEFAULT_CONTEXTS;
      available_contexts.resize(LEGION_DEFAULT_CONTEXTS);
      // Add in reverse order so lower numbers get popped off first
      for (unsigned idx = 0; idx < LEGION_DEFAULT_CONTEXTS; idx++)
        available_contexts[idx] = LEGION_DEFAULT_CONTEXTS-(idx+1);
      // Initialize our random number generator state
      random_state[0] = address_space & 0xFFFF; // low-order bits of node ID 
      random_state[1] = (address_space >> 16) & 0xFFFF; // high-order bits
      random_state[2] = LEGION_INIT_SEED;
      // Do some mixing
      for (int i = 0; i < 256; i++)
        nrand48(random_state);
      // We've intentionally switched this to profile all the nodes if we're 
      // profiling any nodes since some information about things like copies
      // usage of instances are now split across multiple log files
      if (config.num_profiling_nodes > 0)
        initialize_legion_prof(config);

      if (config.legion_spy_enabled)
        log_local_machine();

#ifdef LEGION_TRACE_ALLOCATION
      allocation_tracing_count.store(0);
      // Instantiate all the kinds of allocations
      for (unsigned idx = ARGUMENT_MAP_ALLOC; idx < UNTRACKED_ALLOC; idx++)
        allocation_manager[((AllocationType)idx)] = AllocationTracker();
#endif
#ifdef LEGION_GC
      {
        REFERENCE_NAMES_ARRAY(reference_names);
        for (unsigned idx = 0; idx < LAST_SOURCE_REF; idx++)
        {
          log_garbage.info("GC Source Kind %d %s", idx, reference_names[idx]);
        }
      }
#endif 
#ifdef DEBUG_LEGION
      if (logging_region_tree_state)
      {
	tree_state_logger = new TreeStateLogger(address_space, 
                                                verbose_logging,
                                                logical_logging_only,
                                                physical_logging_only);
	assert(tree_state_logger != NULL);
      } else {
	tree_state_logger = NULL;
      }
#endif
#ifdef DEBUG_SHUTDOWN_HANG
      outstanding_counts = std::vector<std::atomic<int> >(LG_LAST_TASK_ID);
      for (unsigned idx = 0; idx < outstanding_counts.size(); idx++)
        outstanding_counts[idx].store(0);
#endif
    }

    //--------------------------------------------------------------------------
    Runtime::Runtime(const Runtime &rhs)
      : external(NULL), mapper_runtime(NULL), machine(rhs.machine), 
        runtime_system_memory(Memory::NO_MEMORY), address_space(0), 
        total_address_spaces(0), runtime_stride(0), profiler(NULL),forest(NULL),
        num_utility_procs(rhs.num_utility_procs), input_args(rhs.input_args),
        initial_task_window_size(rhs.initial_task_window_size),
        initial_task_window_hysteresis(rhs.initial_task_window_hysteresis),
        initial_tasks_to_schedule(rhs.initial_tasks_to_schedule),
        initial_meta_task_vector_width(rhs.initial_meta_task_vector_width),
        eager_alloc_percentage(rhs.eager_alloc_percentage),
        max_message_size(rhs.max_message_size),
        gc_epoch_size(rhs.gc_epoch_size), 
        max_control_replication_contexts(rhs.max_control_replication_contexts),
        max_local_fields(rhs.max_local_fields),
        max_replay_parallelism(rhs.max_replay_parallelism),
        safe_control_replication(rhs.safe_control_replication),
        program_order_execution(rhs.program_order_execution),
        dump_physical_traces(rhs.dump_physical_traces),
        no_tracing(rhs.no_tracing),
        no_physical_tracing(rhs.no_physical_tracing),
        no_trace_optimization(rhs.no_trace_optimization),
        no_fence_elision(rhs.no_fence_elision),
        no_transitive_reduction(rhs.no_transitive_reduction),
        inline_transitive_reduction(rhs.inline_transitive_reduction),
        replay_on_cpus(rhs.replay_on_cpus),
        verify_partitions(rhs.verify_partitions),
        runtime_warnings(rhs.runtime_warnings),
        warnings_backtrace(rhs.warnings_backtrace),
        warnings_are_errors(rhs.warnings_are_errors),
        report_leaks(rhs.report_leaks),
        separate_runtime_instances(rhs.separate_runtime_instances),
        record_registration(rhs.record_registration),
        stealing_disabled(rhs.stealing_disabled),
        resilient_mode(rhs.resilient_mode),
        unsafe_launch(rhs.unsafe_launch),
        unsafe_mapper(rhs.unsafe_mapper),
        safe_tracing(rhs.safe_tracing),
        disable_independence_tests(rhs.disable_independence_tests),
        legion_spy_enabled(rhs.legion_spy_enabled),
        supply_default_mapper(rhs.supply_default_mapper),
        enable_test_mapper(rhs.enable_test_mapper),
        legion_ldb_enabled(rhs.legion_ldb_enabled),
        replay_file(rhs.replay_file),
#ifdef DEBUG_LEGION
        logging_region_tree_state(rhs.logging_region_tree_state),
        verbose_logging(rhs.verbose_logging),
        logical_logging_only(rhs.logical_logging_only),
        physical_logging_only(rhs.physical_logging_only),
#endif
        check_privileges(rhs.check_privileges),
        dump_free_ranges(rhs.dump_free_ranges),
        legion_collective_radix(rhs.legion_collective_radix),
        mpi_rank_table(NULL), local_procs(rhs.local_procs), 
        local_utils(rhs.local_utils), proc_spaces(rhs.proc_spaces)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
    }

    //--------------------------------------------------------------------------
    Runtime::~Runtime(void)
    //--------------------------------------------------------------------------
    {
      if (profiler != NULL)
      {
        delete profiler;
        profiler = NULL;
      }
      // Make sure we don't send anymore messages
      for (unsigned idx = 0; idx < LEGION_MAX_NUM_NODES; idx++)
      {
        MessageManager *manager = message_managers[idx].load();
        if (manager != NULL)
        {
          delete manager;
          message_managers[idx].store(NULL);
        }
      } 
      // Free any input arguments
      if (input_args.argc > 0)
      {
        for (int i = 0; i < input_args.argc; i++)
          if (input_args.argv[i] != NULL)
            free(input_args.argv[i]);
        free(input_args.argv);
      }
      delete forest;
      delete external;
      delete mapper_runtime;
      // Avoid duplicate deletions on these for separate runtime
      // instances by just leaking them for now
      if (!separate_runtime_instances)
      {
        for (std::map<ProjectionID,ProjectionFunction*>::
              iterator it = projection_functions.begin(); 
              it != projection_functions.end(); it++)
        {
          delete it->second;
        } 
        projection_functions.clear();
        for (std::map<ShardingID,ShardingFunctor*>::iterator it = 
              sharding_functors.begin(); it != 
              sharding_functors.end(); it++)
        {
          delete it->second;
        }
        sharding_functors.clear();
      }
      for (std::map<Processor,ProcessorManager*>::const_iterator it = 
            proc_managers.begin(); it != proc_managers.end(); it++)
      {
        delete it->second;
      }
      proc_managers.clear(); 
      free_available(available_individual_tasks);
      free_available(available_point_tasks);
      free_available(available_index_tasks);
      free_available(available_slice_tasks);
      free_available(available_map_ops);
      free_available(available_copy_ops);
      free_available(available_fence_ops);
      free_available(available_frame_ops);
      free_available(available_creation_ops);
      free_available(available_deletion_ops);
      free_available(available_merge_close_ops);
      free_available(available_post_close_ops);
      free_available(available_refinement_ops);
      free_available(available_reset_ops);
      free_available(available_dynamic_collective_ops);
      free_available(available_future_pred_ops);
      free_available(available_not_pred_ops);
      free_available(available_and_pred_ops);
      free_available(available_or_pred_ops);
      free_available(available_acquire_ops);
      free_available(available_release_ops);
      free_available(available_begin_ops);
      free_available(available_recurrent_ops);
      free_available(available_complete_ops);
      free_available(available_epoch_ops);
      free_available(available_pending_partition_ops);
      free_available(available_dependent_partition_ops);
      free_available(available_fill_ops);
      free_available(available_discard_ops);
      free_available(available_attach_ops);
      free_available(available_index_attach_ops);
      free_available(available_point_attach_ops);
      free_available(available_detach_ops);
      free_available(available_index_detach_ops);
      free_available(available_point_detach_ops);
      free_available(available_timing_ops);
      free_available(available_tunable_ops);
      free_available(available_all_reduce_ops);
      free_available(available_repl_individual_tasks);
      free_available(available_repl_index_tasks);
      free_available(available_repl_merge_close_ops);
      free_available(available_repl_refinement_ops);
      free_available(available_repl_reset_ops);
      free_available(available_repl_fill_ops);
      free_available(available_repl_index_fill_ops);
      free_available(available_repl_discard_ops);
      free_available(available_repl_copy_ops);
      free_available(available_repl_index_copy_ops);
      free_available(available_repl_deletion_ops);
      free_available(available_repl_pending_partition_ops);
      free_available(available_repl_dependent_partition_ops);
      free_available(available_repl_must_epoch_ops);
      free_available(available_repl_timing_ops);
      free_available(available_repl_tunable_ops);
      free_available(available_repl_all_reduce_ops);
      free_available(available_repl_fence_ops);
      free_available(available_repl_map_ops);
      free_available(available_repl_attach_ops);
      free_available(available_repl_index_attach_ops);
      free_available(available_repl_detach_ops);
      free_available(available_repl_index_detach_ops);
      free_available(available_repl_acquire_ops);
      free_available(available_repl_release_ops);
      free_available(available_repl_begin_ops);
      free_available(available_repl_recurrent_ops);
      free_available(available_repl_complete_ops);
      for (std::map<TaskID,TaskImpl*>::const_iterator it = 
            task_table.begin(); it != task_table.end(); it++)
      {
        delete (it->second);
      }
      task_table.clear();
      // Skip this if we are in separate runtime mode
      if (!separate_runtime_instances)
      {
        for (std::deque<VariantImpl*>::const_iterator it = 
              variant_table.begin(); it != variant_table.end(); it++)
        {
          delete (*it);
        }
      }
      variant_table.clear();
      // Skip this if we are in separate runtime mode
      if (!separate_runtime_instances)
      {
        while (!layout_constraints_table.empty())
        {
          std::map<LayoutConstraintID,LayoutConstraints*>::iterator next_it = 
            layout_constraints_table.begin();
          LayoutConstraints *next = next_it->second;
          layout_constraints_table.erase(next_it);
          if (next->remove_base_resource_ref(RUNTIME_REF))
            delete (next);
        }
        while (!layout_constraints_table.empty())
        {
          std::map<LayoutConstraintID,LayoutConstraints*>::iterator next_it = 
            layout_constraints_table.begin();
          LayoutConstraints *next = next_it->second;
          layout_constraints_table.erase(next_it);
          if (next->remove_base_resource_ref(RUNTIME_REF))
            delete (next);
        }
        // We can also delete all of our reduction operators
        ReductionOpTable &redop_table = get_reduction_table(true/*safe*/);
        while (!redop_table.empty())
        {
          ReductionOpTable::iterator it = redop_table.begin();
          // Free ReductionOp *'s with free, not delete!
          static_assert(
            std::is_trivially_destructible<typename std::decay<decltype(*(it->second))>::type>::value,
            "ReducionOp must be trivially destructible"
          );
          free(it->second);
          redop_table.erase(it);
        }
      }
      for (LegionMap<uint64_t,LegionDeque<ProcessorGroupInfo>,
            PROCESSOR_GROUP_ALLOC>::const_iterator git = 
            processor_groups.begin(); git != processor_groups.end(); git++)
        for (LegionDeque<ProcessorGroupInfo>::const_iterator it = 
              git->second.begin(); it != git->second.end(); it++)
          it->processor_group.destroy();
      for (std::map<Memory,MemoryManager*>::const_iterator it =
            memory_managers.begin(); it != memory_managers.end(); it++)
      {
        delete it->second;
      }
      memory_managers.clear();
      for (std::map<size_t,std::vector<Provenance*> >::const_iterator pit =
            provenances.begin(); pit != provenances.end(); pit++)
        for (std::vector<Provenance*>::const_iterator it =
              pit->second.begin(); it != pit->second.end(); it++)
          if ((*it)->remove_reference())
            delete (*it);
      provenances.clear();
#ifdef DEBUG_LEGION
      if (logging_region_tree_state)
	delete tree_state_logger;
#endif
    }

    //--------------------------------------------------------------------------
    Runtime& Runtime::operator=(const Runtime &rhs)
    //--------------------------------------------------------------------------
    {
      // should never be called
      assert(false);
      return *this;
    }

    //--------------------------------------------------------------------------
    void Runtime::register_static_variants(void)
    //--------------------------------------------------------------------------
    {
      std::deque<PendingVariantRegistration*> &pending_variants = 
        get_pending_variant_table();
      if (!pending_variants.empty())
      {
        for (std::deque<PendingVariantRegistration*>::const_iterator it =
              pending_variants.begin(); it != pending_variants.end(); it++)
        {
          (*it)->perform_registration(this);
          // avoid races on separate runtime instances
          if (!separate_runtime_instances)
            delete *it;
        }
        // avoid races on separate runtime instances
        if (!separate_runtime_instances)
          pending_variants.clear();
      }
    }

    //--------------------------------------------------------------------------
    CollectiveMapping* Runtime::register_static_constraints(
        uint64_t &next_static_did, LayoutConstraintID &virtual_layout_id)
    //--------------------------------------------------------------------------
    {
      // Register any pending constraint sets
      std::map<LayoutConstraintID,LayoutConstraintRegistrar> 
        &pending_constraints = get_pending_constraint_table();
      // Create a collective mapping for all the nodes
      CollectiveMapping *mapping = NULL;
      if (total_address_spaces > 1)
      {
        std::vector<AddressSpaceID> all_spaces(total_address_spaces);
        for (unsigned idx = 0; idx < total_address_spaces; idx++)
          all_spaces[idx] = idx;
        mapping = new CollectiveMapping(all_spaces, legion_collective_radix);
      }
      unsigned already_used = 0;
      // Now do the registrations
      std::map<AddressSpaceID,unsigned> address_counts;
      for (std::map<LayoutConstraintID,LayoutConstraintRegistrar>::
            const_iterator it = pending_constraints.begin(); 
            it != pending_constraints.end(); it++)
      {
        if (LEGION_MAX_APPLICATION_LAYOUT_ID < it->first)
          already_used++;
        register_layout(it->second, it->first,
          get_next_static_distributed_id(next_static_did), mapping);
      }
      // Now register the virtual layout constraints
      LayoutConstraintRegistrar virtual_registrar;
      virtual_registrar.add_constraint(
          SpecializedConstraint(LEGION_VIRTUAL_SPECIALIZE));
      virtual_layout_id = LEGION_MAX_APPLICATION_LAYOUT_ID + ++already_used;
      register_layout(virtual_registrar, virtual_layout_id,
          get_next_static_distributed_id(next_static_did), mapping);
      // Bump up our unique constraint ID if we already used the IDs statically
      while (unique_constraint_id <=
          (LEGION_MAX_APPLICATION_LAYOUT_ID + already_used))
        unique_constraint_id += runtime_stride;
      // avoid races if we are doing separate runtime creation
      if (!separate_runtime_instances)
        pending_constraints.clear();
      return mapping;
    }

    //--------------------------------------------------------------------------
    void Runtime::register_static_projections(void)
    //--------------------------------------------------------------------------
    {
      std::map<ProjectionID,ProjectionFunctor*> &pending_projection_functors =
        get_pending_projection_table();
      for (std::map<ProjectionID,ProjectionFunctor*>::const_iterator it =
            pending_projection_functors.begin(); it !=
            pending_projection_functors.end(); it++)
      {
        it->second->set_runtime(external);
        register_projection_functor(it->first, it->second, true/*need check*/,
                          true/*was preregistered*/, NULL, true/*pregistered*/);
      }
      register_projection_functor(0, 
          new IdentityProjectionFunctor(this->external), false/*need check*/,
                        true/*was preregistered*/, NULL, true/*preregistered*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::register_static_sharding_functors(void)
    //--------------------------------------------------------------------------
    {
      std::map<ShardingID,ShardingFunctor*> &pending_sharding_functors = 
        get_pending_sharding_table();
      for (std::map<ShardingID,ShardingFunctor*>::const_iterator it = 
            pending_sharding_functors.begin(); it !=
            pending_sharding_functors.end(); it++)
        register_sharding_functor(it->first, it->second, true/*zero check*/,
                    true/*was preregistered*/, NULL, true/*preregistered*/);
      register_sharding_functor(0,
          new CyclicShardingFunctor(), false/*need check*/, 
          true/*was preregistered*/, NULL, true/*preregistered*/);
      // Register the attach-detach sharding functor
      ReplicateContext::register_attach_detach_sharding_functor(this);
      // Register the universal sharding functor
      ReplicateContext::register_universal_sharding_functor(this);
    }

    //--------------------------------------------------------------------------
    void Runtime::initialize_legion_prof(const LegionConfiguration &config)
    //--------------------------------------------------------------------------
    {
      // For the profiler we want to find as many "holes" in the execution
      // as possible in which to run profiler tasks so we can minimize the
      // overhead on the application. To do this we want profiler tasks to
      // run on any processor that has a dedicated core which is either any
      // CPU processor a utility processor. There's no need to use GPU or
      // I/O processors since they share the same cores as the utility cores. 
      // In the future we can relax this to use any processor core that doesn't
      // support multiple threads executing concurrently (e.g. I/O procs) as
      // that could lead to a lot of profiling instances being made since this
      // will clear the implicit_profiler if we're not self-profiling and then
      // we'll have to make new instances in 
      // LegionProfiler::find_or_create_profiling_instance the next time we
      // go to profile anything on that processor.
      std::vector<Processor> prof_procs(local_utils.begin(), local_utils.end());
      for (std::set<Processor>::const_iterator it = local_procs.begin();
            it != local_procs.end(); it++)
      {
        if (it->kind() == Processor::LOC_PROC)
          prof_procs.push_back(*it);
      }
#ifdef DEBUG_LEGION
      assert(!prof_procs.empty());
#endif
      const Processor target_proc_for_profiler = prof_procs.size() > 1 ?
        ProcessorGroup::create_group(prof_procs) : prof_procs.front();
      LG_TASK_DESCRIPTIONS(lg_task_descriptions);
      LG_MESSAGE_DESCRIPTIONS(lg_message_descriptions);
      static_assert((LG_MESSAGE_ID+1) == LG_LAST_TASK_ID,
          "LG_MESSAGE_ID must always be the last meta-task ID");
      profiler = new LegionProfiler(target_proc_for_profiler,
                                    machine, this, LG_MESSAGE_ID,
                                    lg_task_descriptions, LAST_SEND_KIND, 
                                    lg_message_descriptions,
                                    Operation::LAST_OP_KIND,
                                    Operation::op_names,
                                    config.serializer_type.c_str(),
                                    config.prof_logfile.c_str(),
                                    total_address_spaces,
                                    config.prof_footprint_threshold << 20,
                                    config.prof_target_latency,
                                    config.prof_call_threshold,
                                    config.slow_config_ok,
                                    config.prof_self_profile,
                                    config.prof_no_critical_paths,
                                    config.prof_all_critical_arrivals);
      MAPPER_CALL_NAMES(lg_mapper_calls);
      profiler->record_mapper_call_kinds(lg_mapper_calls, LAST_MAPPER_CALL);
      RUNTIME_CALL_DESCRIPTIONS(lg_runtime_calls);
      profiler->record_runtime_call_kinds(lg_runtime_calls, 
                                          LAST_RUNTIME_CALL_KIND);
    }

    //--------------------------------------------------------------------------
    void Runtime::log_local_machine(void) const
    //--------------------------------------------------------------------------
    {
      std::set<Processor::Kind> proc_kinds;
      Machine::ProcessorQuery local_procs(machine);
      local_procs.local_address_space();
#define COUNTER(X,Y) +1
      constexpr size_t num_procs = REALM_PROCESSOR_KINDS(COUNTER);
      static_assert(num_procs == 9, "Add new processor kinds"); 
#undef COUNTER
      // Log processors
      for (Machine::ProcessorQuery::iterator it = local_procs.begin();
            it != local_procs.end(); it++)
      {
        Processor::Kind kind = it->kind();
        if (proc_kinds.find(kind) == proc_kinds.end())
        {
          switch (kind)
          {
            case Processor::NO_KIND:
              {
                LegionSpy::log_processor_kind(kind, "NoProc");
                break;
              }
            case Processor::TOC_PROC:
              {
                LegionSpy::log_processor_kind(kind, "GPU");
                break;
              }
            case Processor::LOC_PROC:
              {
                LegionSpy::log_processor_kind(kind, "CPU");
                break;
              }
            case Processor::UTIL_PROC:
              {
                LegionSpy::log_processor_kind(kind, "Utility");
                break;
              }
            case Processor::IO_PROC:
              {
                LegionSpy::log_processor_kind(kind, "IO");
                break;
              }
            case Processor::PROC_GROUP:
              {
                LegionSpy::log_processor_kind(kind, "ProcGroup");
                break;
              }
            case Processor::PROC_SET:
              {
                LegionSpy::log_processor_kind(kind, "ProcSet");
                break;
              }
            case Processor::OMP_PROC:
              {
                LegionSpy::log_processor_kind(kind, "OpenMP");
                break;
              }
            case Processor::PY_PROC:
              {
                LegionSpy::log_processor_kind(kind, "Python");
                break;
              }
            default:
              assert(false); // unknown processor kind
          }
          proc_kinds.insert(kind);
        }
        LegionSpy::log_processor(it->id, kind);
      }
      // Log memories
      std::set<Memory::Kind> mem_kinds;
      Machine::MemoryQuery local_mems(machine);
      local_mems.local_address_space();
#define COUNTER(X,Y) +1
      constexpr size_t num_mems = REALM_MEMORY_KINDS(COUNTER);
      static_assert(num_mems == 15, "Add new memory kinds"); 
#undef COUNTER
      for (Machine::MemoryQuery::iterator it = local_mems.begin();
            it != local_mems.end(); it++)
      {
        Memory::Kind kind = it->kind();
        if (mem_kinds.find(kind) == mem_kinds.end())
        {
          switch (kind)
          {
	    case Memory::GLOBAL_MEM:
              {
                LegionSpy::log_memory_kind(kind, "GASNet");
                break;
              }
	    case Memory::SYSTEM_MEM:
              {
                LegionSpy::log_memory_kind(kind, "System");
                break;
              }
	    case Memory::REGDMA_MEM:
              {
                LegionSpy::log_memory_kind(kind, "Registered");
                break;
              }
	    case Memory::SOCKET_MEM:
              {
                LegionSpy::log_memory_kind(kind, "NUMA");
                break;
              }
	    case Memory::Z_COPY_MEM:
              {
                LegionSpy::log_memory_kind(kind, "Zero-Copy");
                break;
              }
	    case Memory::GPU_FB_MEM:
              {
                LegionSpy::log_memory_kind(kind, "Framebuffer");
                break;
              }
	    case Memory::DISK_MEM:
              {
                LegionSpy::log_memory_kind(kind, "Disk");
                break;
              }
	    case Memory::HDF_MEM:
              {
                LegionSpy::log_memory_kind(kind, "HDF");
                break;
              }
	    case Memory::FILE_MEM:
              {
                LegionSpy::log_memory_kind(kind, "File");
                break;
              }
	    case Memory::LEVEL3_CACHE:
              {
                LegionSpy::log_memory_kind(kind, "L3");
                break;
              }
	    case Memory::LEVEL2_CACHE:
              {
                LegionSpy::log_memory_kind(kind, "L2");
                break;
              }
	    case Memory::LEVEL1_CACHE:
              {
                LegionSpy::log_memory_kind(kind, "L1");
                break;
              }
            case Memory::GPU_MANAGED_MEM:
              {
                LegionSpy::log_memory_kind(kind, "UVM");
                break;
              }
            case Memory::GPU_DYNAMIC_MEM:
              {
                LegionSpy::log_memory_kind(kind, "Dynamic Framebuffer");
                break;
              }
            default:
              assert(false); // unknown memory kind
          }
        }
        LegionSpy::log_memory(it->id, it->capacity(), it->kind());
      }
      // Log Proc-Mem Affinity
      Machine::ProcessorQuery local_procs2(machine);
      local_procs2.local_address_space();
      for (Machine::ProcessorQuery::iterator pit = local_procs2.begin();
            pit != local_procs2.end(); pit++)
      {
        std::vector<ProcessorMemoryAffinity> affinities;
        machine.get_proc_mem_affinity(affinities, *pit);
        for (std::vector<ProcessorMemoryAffinity>::const_iterator it = 
              affinities.begin(); it != affinities.end(); it++)
        {
          LegionSpy::log_proc_mem_affinity(pit->id, it->m.id, 
                                           it->bandwidth, it->latency);
        }
      }
      // Log Mem-Mem Affinity
      Machine::MemoryQuery local_mems2(machine);
      local_mems2.local_address_space();
      for (Machine::MemoryQuery::iterator mit = local_mems2.begin();
            mit != local_mems2.begin(); mit++)
      {
        std::vector<MemoryMemoryAffinity> affinities;
        machine.get_mem_mem_affinity(affinities, *mit);
        for (std::vector<MemoryMemoryAffinity>::const_iterator it = 
              affinities.begin(); it != affinities.end(); it++)
        {
          LegionSpy::log_mem_mem_affinity(it->m1.id, it->m2.id, 
                                          it->bandwidth, it->latency);
        }
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::initialize_mappers(void)
    //--------------------------------------------------------------------------
    {
      if (replay_file.empty()) // This is the normal path
      {
        if (enable_test_mapper)
        {
          // Make test mappers for everyone
          for (std::map<Processor,ProcessorManager*>::const_iterator it = 
                proc_managers.begin(); it != proc_managers.end(); it++)
          {
            Mapper *mapper = 
              new Mapping::TestMapper(mapper_runtime, machine, it->first);
            MapperManager *wrapper = wrap_mapper(this, mapper, 0, it->first);
            it->second->add_mapper(0, wrapper, false/*check*/, true/*owns*/);
          }
        }
        else if (supply_default_mapper)
        {
          // Make default mappers for everyone
          for (std::map<Processor,ProcessorManager*>::const_iterator it = 
                proc_managers.begin(); it != proc_managers.end(); it++)
          {
            Mapper *mapper = 
              new Mapping::DefaultMapper(mapper_runtime, machine, it->first);
            MapperManager *wrapper = 
             wrap_mapper(this, mapper, 0, it->first, true/*is default mapper*/);
            it->second->add_mapper(0, wrapper, false/*check*/, true/*owns*/);
          } 
        }
      }
      else // This is the replay/debug path
      {
        if (legion_ldb_enabled)
        {
          // This path is not quite ready yet
          assert(false);
          for (std::map<Processor,ProcessorManager*>::const_iterator it = 
                proc_managers.begin(); it != proc_managers.end(); it++)
          {
            Mapper *mapper = new Mapping::DebugMapper(mapper_runtime, 
                                    machine, it->first, replay_file.c_str());
            MapperManager *wrapper = wrap_mapper(this, mapper, 0, it->first);
            it->second->add_mapper(0, wrapper, false/*check*/, true/*owns*/, 
                                    true/*skip replay*/);
          }
        }
        else
        {
          for (std::map<Processor,ProcessorManager*>::const_iterator it =
                proc_managers.begin(); it != proc_managers.end(); it++)
          {
            Mapper *mapper = new Mapping::ReplayMapper(mapper_runtime, 
                                    machine, it->first, replay_file.c_str());
            MapperManager *wrapper = wrap_mapper(this, mapper, 0, it->first);
            it->second->add_mapper(0, wrapper, false/*check*/, true/*owns*/,
                                    true/*skip replay*/);
          }
        }
      }
      
    }

    //--------------------------------------------------------------------------
    void Runtime::initialize_virtual_manager(uint64_t &next_static_did,
               LayoutConstraintID virtual_layout_id, CollectiveMapping *mapping)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(virtual_manager == NULL);
#endif
      // make a layout constraints
      FieldMask all_ones(LEGION_FIELD_MASK_FIELD_ALL_ONES);
      std::vector<unsigned> mask_index_map;
      std::vector<CustomSerdezID> serdez;
      std::vector<std::pair<FieldID,size_t> > field_sizes;
      LayoutConstraints *virtual_constraints =
        find_layout_constraints(virtual_layout_id);
      LayoutDescription *layout = 
        new LayoutDescription(all_ones, virtual_constraints);
      virtual_manager = new VirtualManager(this, 0/*did*/, layout, mapping);
      virtual_manager->add_base_gc_ref(NEVER_GC_REF);
    }

    //--------------------------------------------------------------------------
    TopLevelContext* Runtime::initialize_runtime(Processor first_proc)
    //--------------------------------------------------------------------------
    {  
      // If we have an MPI rank table do the exchanges before initializing
      // the mappers as they may want to look at the rank table
      if (mpi_rank_table != NULL)
        mpi_rank_table->perform_rank_exchange();
      // Starts at 1 since 0 is a reserved ID for the virtual manager
      uint64_t next_static_did = 1;
      // Pull in any static registrations that were done
      LayoutConstraintID virtual_layout_id = 0;
      CollectiveMapping *mapping =
        register_static_constraints(next_static_did, virtual_layout_id);
      register_static_variants();
      register_static_projections();
      register_static_sharding_functors();
      // Has to come after registring the static constraints
      initialize_virtual_manager(next_static_did, virtual_layout_id, mapping);
      // Initialize the mappers
      initialize_mappers(); 
      // Finally perform the registration callback methods
      std::vector<RegistrationCallback> &registration_callbacks
        = get_pending_registration_callbacks();
      if (!registration_callbacks.empty())
      {
        log_run.info("Invoking registration callback functions...");
        for (std::vector<RegistrationCallback>::const_iterator it = 
              registration_callbacks.begin(); it !=
              registration_callbacks.end(); it++)
        {
          perform_registration_callback(it->has_args ?
              (void*)it->callback.withargs : (void*)it->callback.withoutargs,
              it->buffer.get_ptr(), it->buffer.get_size(), it->has_args,
              false/*global*/, true/*preregistered*/, it->deduplicate,
              it->dedup_tag);
          if (it->buffer.get_size() > 0)
            free(it->buffer.get_ptr());
        }
        log_run.info("Finished execution of registration callbacks");
        if (!separate_runtime_instances)
          registration_callbacks.clear();
      }
      // If we have main top-level task, make a context for it
      if (legion_main_set)
      {
        TopLevelContext *top_context = new TopLevelContext(this, first_proc,
            get_unique_top_level_task_id(), 0/*implicit*/,
            get_next_static_distributed_id(next_static_did), mapping);
        top_context->register_with_runtime();
        return top_context;
      }
      else
        return NULL;
    }

#ifdef LEGION_USE_LIBDL
    //--------------------------------------------------------------------------
    void Runtime::send_registration_callback(AddressSpaceID target,
                                         Realm::DSOReferenceImplementation *dso,
                                         RtEvent global_done_event,
                                         std::set<RtEvent> &applied_events,
                                         const void *buffer, size_t buffer_size,
                                         bool withargs, bool deduplicate,
                                         size_t dedup_tag)
    //--------------------------------------------------------------------------
    {
      const RtUserEvent done_event = Runtime::create_rt_user_event();
      Serializer rez;
      {
        RezCheck z(rez);
        const size_t dso_size = dso->dso_name.size() + 1;
        const size_t sym_size = dso->symbol_name.size() + 1;
        rez.serialize(dso_size);
        rez.serialize(dso->dso_name.c_str(), dso_size);
        rez.serialize(sym_size);
        rez.serialize(dso->symbol_name.c_str(), sym_size);
        rez.serialize(buffer_size);
        if (buffer_size > 0)
          rez.serialize(buffer, buffer_size);
        rez.serialize<bool>(withargs);
        rez.serialize<bool>(deduplicate);
        rez.serialize(dedup_tag);
        rez.serialize(global_done_event);
        rez.serialize(done_event);
      }
      find_messenger(target)->send_message(SEND_REGISTRATION_CALLBACK, rez,
                                                              true/*flush*/);
      applied_events.insert(done_event);
    }
#endif // LEGION_USE_LIBDL

    //--------------------------------------------------------------------------
    RtEvent Runtime::perform_registration_callback(void *callback,
                                 const void *buffer, size_t buffer_size,
                                 bool withargs, bool global, bool preregistered,
                                 bool deduplicate, size_t dedup_tag)
    //--------------------------------------------------------------------------
    { 
      if (inside_registration_callback)
        REPORT_LEGION_ERROR(ERROR_NESTED_REGISTRATION_CALLBACKS,
            "Nested registration callbacks are not permitted in Legion")
      RegistrationKey global_key;
#ifdef LEGION_USE_LIBDL
      Realm::DSOReferenceImplementation *dso = NULL;
      if (global)
      {
        // No such thing as global registration if there's only one addres space
        if (total_address_spaces > 1)
        {
          // Convert this to it's portable representation or raise an error
          // This is a little scary, we could still be inside of dlopen when
          // we get this call as part of the constructor for a shared object
          // and yet we're about to do a call to dladdr. This seems to work
          // but there is no documentation anywhere about whether this is 
          // legal or safe to do...
          Realm::FunctionPointerImplementation impl((void (*)(void))callback);
#ifdef DEBUG_LEGION
          assert(callback_translator.can_translate(
                typeid(Realm::FunctionPointerImplementation),
                typeid(Realm::DSOReferenceImplementation)));
#endif
          dso = static_cast<Realm::DSOReferenceImplementation*>(
              callback_translator.translate(&impl, 
                typeid(Realm::DSOReferenceImplementation)));
          if (dso == NULL)
            REPORT_LEGION_FATAL(LEGION_FATAL_CALLBACK_NOT_PORTABLE,
                "Global registration callback function pointer %p is not "
                "portable. All registration callbacks requesting to be "
                "performed 'globally' must be able to be recognized by "
                "a call to 'dladdr'. This requires that they come from a "
                "shared object or the binary is linked with the '-rdynamic' "
                "flag.", callback)
          global_key = 
            RegistrationKey(dedup_tag, dso->dso_name, dso->symbol_name); 
        }
        else
          global = false;
      }
#else
      if (global)
      {
        if (total_address_spaces > 1)
          REPORT_LEGION_ERROR(ERROR_ILLEGAL_PERFORM_REGISTRATION_CALLBACK,
              "Global registration callbacks are not supported in multi-node "
              "executions without support for libdl. Please build Legion "
              "with LEGION_USE_LIBDL defined.")
        else
          global = false;
      }
#endif
      RtEvent local_done, global_done;
      RtUserEvent local_perform, global_perform;
      if (deduplicate)
      {
        AutoLock c_lock(callback_lock); 
        if (global)
        {
          // See if we're going to perform this or not
          std::map<RegistrationKey,RtEvent>::const_iterator local_finder =
            global_local_done.find(global_key);
          if (local_finder == global_local_done.end())
          {
            local_perform = Runtime::create_rt_user_event();
            global_local_done[global_key] = local_perform;
            // Check to see if we have any pending global callbacks to 
            // notify about being done locally
            std::map<RegistrationKey,std::set<RtUserEvent> >::iterator
              pending_finder = pending_remote_callbacks.find(global_key);
            if (pending_finder != pending_remote_callbacks.end())
            {
              for (std::set<RtUserEvent>::const_iterator it = 
                    pending_finder->second.begin(); it != 
                    pending_finder->second.end(); it++)
                Runtime::trigger_event(*it, local_perform);
              pending_remote_callbacks.erase(pending_finder);
            }
          }
          else
            local_done = local_finder->second;
          // Now see if we need to do our global registration callbacks
          std::map<RegistrationKey,RtEvent>::const_iterator global_finder = 
            global_callbacks_done.find(global_key);
          if (global_finder == global_callbacks_done.end())
          {
            global_perform = Runtime::create_rt_user_event();
            global_callbacks_done[global_key] = global_perform;
          }
          else
            global_done = global_finder->second;
        }
        else
        {
          std::map<void*,RtEvent>::const_iterator
            local_finder = local_callbacks_done.find(callback);
          if (local_finder == local_callbacks_done.end())
          {
            local_perform = Runtime::create_rt_user_event();
            local_callbacks_done[callback] = local_perform;
          }
          else
            return local_finder->second;
        }
      }
      else if (global)
        global_perform = Runtime::create_rt_user_event();
      // Do the local callback and record it now 
      if (!deduplicate || local_perform.exists())
      {
        // All the pregistered cases are effectively global too
        if (global || preregistered)
          inside_registration_callback = GLOBAL_REGISTRATION_CALLBACK;
        else
          inside_registration_callback = LOCAL_REGISTRATION_CALLBACK;
        if (withargs)
        {
          RegistrationWithArgsCallbackFnptr callbackwithargs =
            (RegistrationWithArgsCallbackFnptr)callback;
          RegistrationCallbackArgs args{ machine, external, 
            local_procs, UntypedBuffer(buffer, buffer_size) };
          (*callbackwithargs)(args);
        }
        else
        {
          RegistrationCallbackFnptr callbackwithoutargs =
            (RegistrationCallbackFnptr)callback;
          (*callbackwithoutargs)(machine, external, local_procs);
        }
        inside_registration_callback = NO_REGISTRATION_CALLBACK;
        if (local_perform.exists())
          Runtime::trigger_event(local_perform);
        if (!global)
          return local_perform;
      }
#ifdef LEGION_USE_LIBDL
#ifdef DEBUG_LEGION
      assert(global);
#endif
      if (global_done.exists())
      {
        delete dso;
        return global_done;
      }
#ifdef DEBUG_LEGION
      assert(global_perform.exists());
#endif
      // See if we're inside of a task and can use that to help do the 
      // global invocations of this registration callback
      if (!deduplicate || (implicit_context == NULL))
      {
        // This means we're in an external thread asking for us to
        // perform a global registration so just send out messages
        // to all the nodes asking them to do the registration
        std::set<RtEvent> preconditions;
        for (AddressSpaceID space = 0; space < total_address_spaces; space++)
        {
          if (space == address_space)
            continue;
          send_registration_callback(space, dso, global_perform, preconditions,
              buffer, buffer_size, withargs, deduplicate, dedup_tag);
        }
        if (!preconditions.empty())
          Runtime::trigger_event(global_perform,
              Runtime::merge_events(preconditions));
        else
          Runtime::trigger_event(global_perform);
      }
      else
      {
        std::set<RtEvent> preconditions;
        implicit_context->perform_global_registration_callbacks(
            dso, buffer, buffer_size, withargs, dedup_tag, local_done,
            global_perform, preconditions);
        if (!preconditions.empty())
          Runtime::trigger_event(global_perform,
              Runtime::merge_events(preconditions));
        else
          Runtime::trigger_event(global_perform);
      }
      delete dso;
#endif // LEGION_USE_LIBDL
      return global_perform;
    }

    //--------------------------------------------------------------------------
    void Runtime::finalize_runtime(std::vector<RtEvent> &shutdown_preconditions)
    //--------------------------------------------------------------------------
    {
      if (!separate_runtime_instances)
      {
        // If we we're doing separate runtime instances then the 
        // ShutdownManager already launched tasks on all the processors
        // Otherwise we send messages to the next address spaces up the
        // tree from us to do the shutdown
        Realm::ProfilingRequestSet empty_requests;
        AddressSpaceID start = address_space * legion_collective_radix + 1;
        for (int idx = 0; idx < legion_collective_radix; idx++)
        {
          AddressSpaceID next = start + idx;
          if (total_address_spaces <= next)
            break;
          MessageManager *messenger = find_messenger(next);
          shutdown_preconditions.push_back(RtEvent(messenger->target.spawn(
                  LG_SHUTDOWN_TASK_ID, NULL, 0, empty_requests)));
        }
      }
      // Have the memory managers for deletion of all their instances
      for (std::map<Memory,MemoryManager*>::const_iterator it =
           memory_managers.begin(); it != memory_managers.end(); it++)
        it->second->finalize();
      if (profiler != NULL)
        profiler->finalize();
    }
    
    //--------------------------------------------------------------------------
    ApEvent Runtime::launch_mapper_task(Mapper *mapper, Processor proc, 
                                        TaskID tid, const UntypedBuffer &arg,
                                        MapperID map_id)
    //--------------------------------------------------------------------------
    {
      // Get a remote task to serve as the top of the top-level task
      TopLevelContext *map_context = new TopLevelContext(this, proc, 
          get_unique_top_level_task_id(), 0/*implicit*/);
      map_context->add_base_gc_ref(RUNTIME_REF);
      TaskLauncher launcher(tid, arg, Predicate::TRUE_PRED, map_id);
      // Get an individual task to be the top-level task
      IndividualTask *mapper_task = get_available_individual_task();
      Future f = mapper_task->initialize_task(map_context, launcher, 
                          NULL/*provenance*/, true/*top level*/);
      mapper_task->set_current_proc(proc);
      mapper_task->select_task_options(false/*prioritize*/);
      // Add a reference to the future impl to prevent it being collected
      f.impl->add_base_gc_ref(META_TASK_REF);
      // Create a meta-task to return the results to the mapper
      MapperTaskArgs args(f.impl, map_id, proc, map_context);
      ApEvent post(issue_runtime_meta_task(args, LG_LATENCY_WORK_PRIORITY,
                                           mapper_task->get_commit_event()));
      // Mark that we have another outstanding top level task
      increment_outstanding_top_level_tasks();
      // Now we can put it on the queue
      add_to_ready_queue(proc, mapper_task);
      return post;
    }

    //--------------------------------------------------------------------------
    void Runtime::process_mapper_task_result(const MapperTaskArgs *args)
    //--------------------------------------------------------------------------
    {
#if 0
      MapperManager *mapper = find_mapper(args->proc, args->map_id);
      Mapper::MapperTaskResult result;
      result.mapper_event = args->event;
      result.result = args->future->get_untyped_result();
      result.result_size = args->future->get_untyped_size();
      mapper->invoke_handle_task_result(result);
#else
      assert(false); // update this
#endif
    }

    //--------------------------------------------------------------------------
    void Runtime::create_shared_ownership(IndexSpace handle,
              const bool total_sharding_collective, const bool unpack_reference)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode *node = forest->get_node(handle);
      if (!node->check_valid_and_increment(APPLICATION_REF))
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_SHARED_OWNERSHIP,
            "Illegal call to add shared ownership to index space %x "
            "which has already been deleted", handle.get_id())
      if (!node->is_owner())
      {
#ifdef DEBUG_LEGION
        assert(!unpack_reference);
#endif
        if (!total_sharding_collective)
        {
          node->pack_valid_ref();
          Serializer rez;
          {
            RezCheck z(rez);
            rez.serialize<int>(0);
            rez.serialize(handle);
          }
          send_shared_ownership(node->owner_space, rez);
        }
        node->remove_base_valid_ref(APPLICATION_REF);
      }
      else if (unpack_reference)
        node->unpack_valid_ref();
    }

    //--------------------------------------------------------------------------
    void Runtime::create_shared_ownership(IndexPartition handle,
              const bool total_sharding_collective, const bool unpack_reference)
    //--------------------------------------------------------------------------
    {
      IndexPartNode *node = forest->get_node(handle);
      if (!node->check_valid_and_increment(APPLICATION_REF))
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_SHARED_OWNERSHIP,
            "Illegal call to add shared ownership to index partition %x "
            "which has already been deleted", handle.get_id())
      if (!node->is_owner())
      {
#ifdef DEBUG_LEGION
        assert(!unpack_reference);
#endif
        if (!total_sharding_collective)
        {
          node->pack_valid_ref();
          Serializer rez;
          {
            RezCheck z(rez);
            rez.serialize<int>(1);
            rez.serialize(handle);
          }
          send_shared_ownership(node->owner_space, rez);
        }
        node->remove_base_valid_ref(APPLICATION_REF);
      }
      else if (unpack_reference)
        node->unpack_valid_ref();
    }

    //--------------------------------------------------------------------------
    void Runtime::create_shared_ownership(FieldSpace handle,
              const bool total_sharding_collective, const bool unpack_reference)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode *node = forest->get_node(handle);
      if (!node->check_global_and_increment(APPLICATION_REF))
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_SHARED_OWNERSHIP,
            "Illegal call to add shared ownership to field space %x "
            "which has already been deleted", handle.get_id())
      if (!node->is_owner())
      {
#ifdef DEBUG_LEGION
        assert(!unpack_reference);
#endif
        if (!total_sharding_collective)
        {
          node->pack_global_ref();
          Serializer rez;
          {
            RezCheck z(rez);
            rez.serialize<int>(2);
            rez.serialize(handle);
          }
          send_shared_ownership(node->owner_space, rez);
        }
        node->remove_base_gc_ref(APPLICATION_REF);
      }
      else if (unpack_reference)
        node->unpack_global_ref();
    }

    //--------------------------------------------------------------------------
    void Runtime::create_shared_ownership(LogicalRegion handle,
              const bool total_sharding_collective, const bool unpack_reference)
    //--------------------------------------------------------------------------
    {
      RegionNode *node = forest->get_node(handle);
      if (!node->check_global_and_increment(APPLICATION_REF))
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_SHARED_OWNERSHIP,
            "Illegal call to add shared ownership to logical region "
            "(%x,%x,%x) which has already been deleted", 
            handle.index_space.get_id(), handle.field_space.get_id(),
            handle.tree_id)
      if (!node->is_owner())
      {
#ifdef DEBUG_LEGION
        assert(!unpack_reference);
#endif
        if (!total_sharding_collective)
        {
          node->pack_global_ref();
          Serializer rez;
          {
            RezCheck z(rez);
            rez.serialize<int>(3);
            rez.serialize(handle);
          }
          send_shared_ownership(node->owner_space, rez);
        }
        node->remove_base_gc_ref(APPLICATION_REF);
      }
      else if (unpack_reference)
        node->unpack_global_ref();
    }

    //--------------------------------------------------------------------------
    IndexPartition Runtime::get_index_partition(Context ctx, 
                                                IndexSpace parent, Color color)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      IndexPartition result = get_index_partition(parent, color);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    IndexPartition Runtime::get_index_partition(IndexSpace parent, Color color)
    //--------------------------------------------------------------------------
    {
      IndexPartition result = forest->get_index_partition(parent, color);
#ifdef DEBUG_LEGION
      if (!result.exists())
        REPORT_LEGION_ERROR(ERROR_INVALID_INDEX_SPACE_COLOR, 
            "Invalid color %d for get index partitions", color);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_index_partition(Context ctx, IndexSpace parent, 
                                      Color color)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      bool result = has_index_partition(parent, color);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_index_partition(IndexSpace parent, Color color)
    //--------------------------------------------------------------------------
    {
      return forest->has_index_partition(parent, color);
    }

    //--------------------------------------------------------------------------
    IndexSpace Runtime::get_index_subspace(Context ctx, IndexPartition p, 
                                           const void *realm_color,
                                           TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      IndexSpace result = get_index_subspace(p, realm_color, type_tag); 
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    IndexSpace Runtime::get_index_subspace(IndexPartition p, 
                                           const void *realm_color,
                                           TypeTag type_tag) 
    //--------------------------------------------------------------------------
    {
      return forest->get_index_subspace(p, realm_color, type_tag);
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_index_subspace(Context ctx, IndexPartition p,
                                     const void *realm_color, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      bool result = has_index_subspace(p, realm_color, type_tag); 
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_index_subspace(IndexPartition p,
                                     const void *realm_color, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      return forest->has_index_subspace(p, realm_color, type_tag);
    }

    //--------------------------------------------------------------------------
    void Runtime::get_index_space_domain(Context ctx, IndexSpace handle,
                                         void *realm_is, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      get_index_space_domain(handle, realm_is, type_tag);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
    }

    //--------------------------------------------------------------------------
    void Runtime::get_index_space_domain(IndexSpace handle, 
                                         void *realm_is, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      forest->get_index_space_domain(handle, realm_is, type_tag);
    }

    //--------------------------------------------------------------------------
    Domain Runtime::get_index_partition_color_space(Context ctx,
                                                    IndexPartition p)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      Domain result = get_index_partition_color_space(p); 
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    Domain Runtime::get_index_partition_color_space(IndexPartition p)
    //--------------------------------------------------------------------------
    {
      IndexPartNode *part = forest->get_node(p);
      const IndexSpace color_space = part->color_space->handle;
      switch (NT_TemplateHelper::get_dim(color_space.get_type_tag()))
      {
#define DIMFUNC(DIM) \
        case DIM: \
          { \
            DomainT<DIM,coord_t> color_index_space; \
            forest->get_index_space_domain(color_space, &color_index_space, \
                NT_TemplateHelper::encode_tag<DIM,coord_t>()); \
            return Domain(color_index_space); \
          }
        LEGION_FOREACH_N(DIMFUNC)
#undef DIMFUNC
        default:
          assert(false);
      }
      return Domain::NO_DOMAIN;
    }

    //--------------------------------------------------------------------------
    void Runtime::get_index_partition_color_space(IndexPartition p,
                                               void *realm_is, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      IndexPartNode *part = forest->get_node(p);
      const IndexSpace color_space = part->color_space->handle;
      forest->get_index_space_domain(color_space, realm_is, type_tag);
    }

    //--------------------------------------------------------------------------
    IndexSpace Runtime::get_index_partition_color_space_name(Context ctx,
                                                             IndexPartition p)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      IndexSpace result = get_index_partition_color_space_name(p);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    IndexSpace Runtime::get_index_partition_color_space_name(IndexPartition p)
    //--------------------------------------------------------------------------
    {
      return forest->get_index_partition_color_space(p);
    }

    //--------------------------------------------------------------------------
    void Runtime::get_index_space_partition_colors(Context ctx, IndexSpace sp,
                                                   std::set<Color> &colors)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      get_index_space_partition_colors(sp, colors);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
    }

    //--------------------------------------------------------------------------
    void Runtime::get_index_space_partition_colors(IndexSpace handle,
                                                   std::set<Color> &colors)
    //--------------------------------------------------------------------------
    {
      forest->get_index_space_partition_colors(handle, colors);
    }

    //--------------------------------------------------------------------------
    bool Runtime::is_index_partition_disjoint(Context ctx, IndexPartition p)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(implicit_reference_tracker == NULL);
#endif
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      const bool result = forest->is_index_partition_disjoint(p);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      else if (implicit_reference_tracker != NULL)
      {
        delete implicit_reference_tracker;
        implicit_reference_tracker = NULL;
      }
      return result;
    }

    //--------------------------------------------------------------------------
    bool Runtime::is_index_partition_disjoint(IndexPartition p)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(implicit_reference_tracker == NULL);
#endif
      const bool result = forest->is_index_partition_disjoint(p);
      if (implicit_reference_tracker != NULL)
      {
        delete implicit_reference_tracker;
        implicit_reference_tracker = NULL;
      }
      return result;
    }

    //--------------------------------------------------------------------------
    bool Runtime::is_index_partition_complete(Context ctx, IndexPartition p)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(implicit_reference_tracker == NULL);
#endif
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      bool result = forest->is_index_partition_complete(p);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      else if (implicit_reference_tracker != NULL)
      {
        delete implicit_reference_tracker;
        implicit_reference_tracker = NULL;
      }
      return result;
    }

    //--------------------------------------------------------------------------
    bool Runtime::is_index_partition_complete(IndexPartition p)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(implicit_reference_tracker == NULL);
#endif
      const bool result = forest->is_index_partition_complete(p);
      if (implicit_reference_tracker != NULL)
      {
        delete implicit_reference_tracker;
        implicit_reference_tracker = NULL;
      }
      return result;
    }

    //--------------------------------------------------------------------------
    void Runtime::get_index_space_color_point(Context ctx, IndexSpace handle,
                                            void *realm_color, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      forest->get_index_space_color(handle, realm_color, type_tag);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
    }

    //--------------------------------------------------------------------------
    void Runtime::get_index_space_color_point(IndexSpace handle,
                                            void *realm_color, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      forest->get_index_space_color(handle, realm_color, type_tag);
    }

    //--------------------------------------------------------------------------
    DomainPoint Runtime::get_index_space_color_point(Context ctx, 
                                                     IndexSpace handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      IndexSpaceNode *node = forest->get_node(handle);
      DomainPoint result = node->get_domain_point_color();
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    DomainPoint Runtime::get_index_space_color_point(IndexSpace handle)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode *node = forest->get_node(handle);
      return node->get_domain_point_color();
    }

    //--------------------------------------------------------------------------
    Color Runtime::get_index_partition_color(Context ctx, 
                                                   IndexPartition handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      Color result = forest->get_index_partition_color(handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    Color Runtime::get_index_partition_color(IndexPartition handle)
    //--------------------------------------------------------------------------
    {
      return forest->get_index_partition_color(handle);
    }

    //--------------------------------------------------------------------------
    IndexSpace Runtime::get_parent_index_space(Context ctx,   
                                               IndexPartition handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      IndexSpace result = forest->get_parent_index_space(handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    IndexSpace Runtime::get_parent_index_space(IndexPartition handle)
    //--------------------------------------------------------------------------
    {
      return forest->get_parent_index_space(handle);
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_parent_index_partition(Context ctx, IndexSpace handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      bool result = forest->has_parent_index_partition(handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_parent_index_partition(IndexSpace handle)
    //--------------------------------------------------------------------------
    {
      return forest->has_parent_index_partition(handle);
    }

    //--------------------------------------------------------------------------
    IndexPartition Runtime::get_parent_index_partition(Context ctx,
                                                       IndexSpace handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      IndexPartition result = forest->get_parent_index_partition(handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    IndexPartition Runtime::get_parent_index_partition(IndexSpace handle)
    //--------------------------------------------------------------------------
    {
      return forest->get_parent_index_partition(handle);
    }

    //--------------------------------------------------------------------------
    unsigned Runtime::get_index_space_depth(Context ctx, IndexSpace handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      unsigned result = forest->get_index_space_depth(handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    unsigned Runtime::get_index_space_depth(IndexSpace handle)
    //--------------------------------------------------------------------------
    {
      return forest->get_index_space_depth(handle);
    }

    //--------------------------------------------------------------------------
    unsigned Runtime::get_index_partition_depth(Context ctx, 
                                                IndexPartition handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      unsigned result = forest->get_index_partition_depth(handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    unsigned Runtime::get_index_partition_depth(IndexPartition handle)
    //--------------------------------------------------------------------------
    {
      return forest->get_index_partition_depth(handle);
    }

    //--------------------------------------------------------------------------
    bool Runtime::safe_cast(Context ctx, LogicalRegion region,
                            const void *realm_point, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context safe cast!");
      return ctx->safe_cast(forest, region.get_index_space(), 
                            realm_point, type_tag);
    }

    //--------------------------------------------------------------------------
    size_t Runtime::get_field_size(Context ctx, FieldSpace handle, FieldID fid)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      size_t result = forest->get_field_size(handle, fid);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    size_t Runtime::get_field_size(FieldSpace handle, FieldID fid)
    //--------------------------------------------------------------------------
    {
      return forest->get_field_size(handle, fid);
    }

    //--------------------------------------------------------------------------
    void Runtime::get_field_space_fields(Context ctx, FieldSpace handle,
                                         std::vector<FieldID> &fields)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      forest->get_field_space_fields(handle, fields);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
    }

    //--------------------------------------------------------------------------
    void Runtime::get_field_space_fields(FieldSpace handle, 
                                         std::vector<FieldID> &fields)
    //--------------------------------------------------------------------------
    {
      forest->get_field_space_fields(handle, fields);
    }

    //--------------------------------------------------------------------------
    LogicalPartition Runtime::get_logical_partition(Context ctx, 
                                    LogicalRegion parent, IndexPartition handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      LogicalPartition result = forest->get_logical_partition(parent, handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    LogicalPartition Runtime::get_logical_partition(LogicalRegion parent,
                                                    IndexPartition handle)
    //--------------------------------------------------------------------------
    {
      return forest->get_logical_partition(parent, handle);
    }

    //--------------------------------------------------------------------------
    LogicalPartition Runtime::get_logical_partition_by_color(
                                    Context ctx, LogicalRegion parent, Color c)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      LogicalPartition result = 
        forest->get_logical_partition_by_color(parent, c);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    LogicalPartition Runtime::get_logical_partition_by_color(LogicalRegion par,
                                                             Color c)
    //--------------------------------------------------------------------------
    {
      return forest->get_logical_partition_by_color(par, c);
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_logical_partition_by_color(Context ctx, 
                                              LogicalRegion parent, Color color)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      bool result = forest->has_logical_partition_by_color(parent, color);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_logical_partition_by_color(LogicalRegion parent, 
                                                 Color color)
    //--------------------------------------------------------------------------
    {
      return forest->has_logical_partition_by_color(parent, color);
    }

    //--------------------------------------------------------------------------
    LogicalPartition Runtime::get_logical_partition_by_tree(
                                            Context ctx, IndexPartition handle, 
                                            FieldSpace fspace, RegionTreeID tid)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      LogicalPartition result = 
        forest->get_logical_partition_by_tree(handle, fspace, tid);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    LogicalPartition Runtime::get_logical_partition_by_tree(
                                                            IndexPartition part,
                                                            FieldSpace fspace,
                                                            RegionTreeID tid)
    //--------------------------------------------------------------------------
    {
      return forest->get_logical_partition_by_tree(part, fspace, tid);
    }

    //--------------------------------------------------------------------------
    LogicalRegion Runtime::get_logical_subregion(Context ctx, 
                                    LogicalPartition parent, IndexSpace handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      LogicalRegion result = forest->get_logical_subregion(parent, handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    LogicalRegion Runtime::get_logical_subregion(LogicalPartition parent,
                                                 IndexSpace handle)
    //--------------------------------------------------------------------------
    {
      return forest->get_logical_subregion(parent, handle);
    }

    //--------------------------------------------------------------------------
    LogicalRegion Runtime::get_logical_subregion_by_color(Context ctx,
             LogicalPartition parent, const void *realm_color, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      LogicalRegion result = 
        forest->get_logical_subregion_by_color(parent, realm_color, type_tag);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    LogicalRegion Runtime::get_logical_subregion_by_color(LogicalPartition par,
                                      const void *realm_color, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      return forest->get_logical_subregion_by_color(par, realm_color, type_tag);
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_logical_subregion_by_color(Context ctx,
             LogicalPartition parent, const void *realm_point, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      bool result = 
        forest->has_logical_subregion_by_color(parent, realm_point, type_tag);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_logical_subregion_by_color(LogicalPartition parent, 
                                      const void *realm_color, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      return forest->has_logical_subregion_by_color(parent, 
                                                    realm_color, type_tag);
    }

    //--------------------------------------------------------------------------
    LogicalRegion Runtime::get_logical_subregion_by_tree(Context ctx, 
                        IndexSpace handle, FieldSpace fspace, RegionTreeID tid)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      LogicalRegion result = 
        forest->get_logical_subregion_by_tree(handle, fspace, tid);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    LogicalRegion Runtime::get_logical_subregion_by_tree(IndexSpace handle,
                                                         FieldSpace fspace,
                                                         RegionTreeID tid)
    //--------------------------------------------------------------------------
    {
      return forest->get_logical_subregion_by_tree(handle, fspace, tid);
    }

    //--------------------------------------------------------------------------
    void Runtime::get_logical_region_color(Context ctx, LogicalRegion handle, 
                                           void *realm_color, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      forest->get_logical_region_color(handle, realm_color, type_tag);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
    }

    //--------------------------------------------------------------------------
    void Runtime::get_logical_region_color(LogicalRegion handle,
                                            void *realm_color, TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      forest->get_logical_region_color(handle, realm_color, type_tag);
    }

    //--------------------------------------------------------------------------
    DomainPoint Runtime::get_logical_region_color_point(Context ctx,
                                                        LogicalRegion handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      IndexSpaceNode *node = forest->get_node(handle.get_index_space());
      DomainPoint result = node->get_domain_point_color();
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    DomainPoint Runtime::get_logical_region_color_point(LogicalRegion handle)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode *node = forest->get_node(handle.get_index_space());
      return node->get_domain_point_color();
    }

    //--------------------------------------------------------------------------
    Color Runtime::get_logical_partition_color(Context ctx,
                                                     LogicalPartition handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      Color result = forest->get_logical_partition_color(handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    Color Runtime::get_logical_partition_color(LogicalPartition handle)
    //--------------------------------------------------------------------------
    {
      return forest->get_logical_partition_color(handle);
    }

    //--------------------------------------------------------------------------
    LogicalRegion Runtime::get_parent_logical_region(Context ctx, 
                                                     LogicalPartition handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      LogicalRegion result = forest->get_parent_logical_region(handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    LogicalRegion Runtime::get_parent_logical_region(LogicalPartition handle)
    //--------------------------------------------------------------------------
    {
      return forest->get_parent_logical_region(handle);
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_parent_logical_partition(Context ctx, 
                                               LogicalRegion handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      bool result = forest->has_parent_logical_partition(handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_parent_logical_partition(LogicalRegion handle)
    //--------------------------------------------------------------------------
    {
      return forest->has_parent_logical_partition(handle);
    }

    //--------------------------------------------------------------------------
    LogicalPartition Runtime::get_parent_logical_partition(Context ctx,
                                                           LogicalRegion handle)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      LogicalPartition result = forest->get_parent_logical_partition(handle);
      if (ctx != DUMMY_CONTEXT)
        ctx->end_runtime_call();
      return result;
    }

    //--------------------------------------------------------------------------
    LogicalPartition Runtime::get_parent_logical_partition(
                                                           LogicalRegion handle)
    //--------------------------------------------------------------------------
    {
      return forest->get_parent_logical_partition(handle);
    }

    //--------------------------------------------------------------------------
    ArgumentMap Runtime::create_argument_map(void)
    //--------------------------------------------------------------------------
    {
      ArgumentMapImpl *impl = new ArgumentMapImpl();
#ifdef DEBUG_LEGION
      assert(impl != NULL);
#endif
      return ArgumentMap(impl);
    }

    //--------------------------------------------------------------------------
    Future Runtime::execute_task(Context ctx, const TaskLauncher &launcher,
                                 std::vector<OutputRequirement> *outputs)
    //--------------------------------------------------------------------------
    { 
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context execute task!");
      return ctx->execute_task(launcher, outputs);
    }

    //--------------------------------------------------------------------------
    FutureMap Runtime::execute_index_space(
                                  Context ctx, const IndexTaskLauncher &launcher,
                                  std::vector<OutputRequirement> *outputs)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context execute index space!");
      return ctx->execute_index_space(launcher, outputs);
    }

    //--------------------------------------------------------------------------
    Future Runtime::execute_index_space(
                                 Context ctx, const IndexTaskLauncher &launcher,
                                 ReductionOpID redop, bool deterministic,
                                 std::vector<OutputRequirement> *outputs)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context execute index space!");
      return ctx->execute_index_space(launcher, redop, deterministic, outputs);
    }

    //--------------------------------------------------------------------------
    PhysicalRegion Runtime::map_region(Context ctx, 
                                                const InlineLauncher &launcher)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context map region!");
      return ctx->map_region(launcher); 
    }

    //--------------------------------------------------------------------------
    PhysicalRegion Runtime::map_region(Context ctx, unsigned idx, 
                          MapperID id, MappingTagID tag, Provenance *provenance)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context map region!");
      PhysicalRegion result = ctx->get_physical_region(idx);
      // Check to see if we are already mapped, if not, then remap it
      if (!result.impl->is_mapped())
        remap_region(ctx, result, provenance);
      return result;
    }

    //--------------------------------------------------------------------------
    void Runtime::remap_region(Context ctx, const PhysicalRegion &region,
                               Provenance *provenance)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context remap region!");
      ctx->remap_region(region, provenance);
    }

    //--------------------------------------------------------------------------
    void Runtime::unmap_region(Context ctx, PhysicalRegion region)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context unmap region!");
      ctx->unmap_region(region); 
    }

    //--------------------------------------------------------------------------
    void Runtime::fill_fields(Context ctx, const FillLauncher &launcher)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context fill operation!");
      ctx->fill_fields(launcher); 
    }

    //--------------------------------------------------------------------------
    void Runtime::fill_fields(Context ctx, const IndexFillLauncher &launcher)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context fill operation!");
      ctx->fill_fields(launcher);
    }

    //--------------------------------------------------------------------------
    void Runtime::issue_copy_operation(Context ctx,const CopyLauncher &launcher)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context issue copy operation!");
      ctx->issue_copy(launcher); 
    }

    //--------------------------------------------------------------------------
    void Runtime::issue_copy_operation(Context ctx,
                                       const IndexCopyLauncher &launcher)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context issue copy operation!");
      ctx->issue_copy(launcher);
    }

    //--------------------------------------------------------------------------
    void Runtime::issue_acquire(Context ctx, const AcquireLauncher &launcher)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context issue acquire!");
      ctx->issue_acquire(launcher); 
    }

    //--------------------------------------------------------------------------
    void Runtime::issue_release(Context ctx, const ReleaseLauncher &launcher)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context issue release!");
      ctx->issue_release(launcher); 
    }

    //--------------------------------------------------------------------------
    TraceID Runtime::generate_dynamic_trace_id(bool check_context/*= true*/)
    //--------------------------------------------------------------------------
    {
      if (check_context && (implicit_context != NULL))
        return implicit_context->generate_dynamic_trace_id();
      TraceID result = unique_trace_id.fetch_add(runtime_stride);
      // Check for hitting the library limit
      if (result >= LEGION_INITIAL_LIBRARY_ID_OFFSET)
        REPORT_LEGION_FATAL(LEGION_FATAL_EXCEEDED_LIBRARY_ID_OFFSET,
            "Dynamic Trace IDs exceeded library ID offset %d",
            LEGION_INITIAL_LIBRARY_ID_OFFSET)
      return result;
    }
    
    //--------------------------------------------------------------------------
    TraceID Runtime::generate_library_trace_ids(const char *name, size_t count)
    //--------------------------------------------------------------------------
    {
      // Easy case if the user asks for no IDs
      if (count == 0)
        return LEGION_AUTO_GENERATE_ID;
      const std::string library_name(name); 
      // Take the lock in read only mode and see if we can find the result
      RtEvent wait_on;
      {
        AutoLock l_lock(library_lock,1,false/*exclusive*/);
        std::map<std::string,LibraryTraceIDs>::const_iterator finder = 
          library_trace_ids.find(library_name);
        if (finder != library_trace_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != count)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "TraceID generation counts %zd and %zd differ for library %s",
                finder->second.count, count, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
      }
      RtUserEvent request_event;
      if (!wait_on.exists())
      {
        AutoLock l_lock(library_lock);
        // Check to make sure we didn't lose the race
        std::map<std::string,LibraryTraceIDs>::const_iterator finder = 
          library_trace_ids.find(library_name);
        if (finder != library_trace_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != count)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "TraceID generation counts %zd and %zd differ for library %s",
                finder->second.count, count, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
        if (!wait_on.exists())
        {
          LibraryTraceIDs &record = library_trace_ids[library_name];
          record.count = count;
          if (address_space == 0)
          {
            // We're going to make the result
            record.result = unique_library_trace_id;
            unique_library_trace_id += count;
#ifdef DEBUG_LEGION
            assert(unique_library_trace_id > record.result);
#endif
            record.result_set = true;
            return record.result;
          }
          else
          {
            // We're going to request the result
            request_event = Runtime::create_rt_user_event();
            record.ready = request_event;
            record.result_set = false;
            wait_on = request_event;
          }
        }
      }
      // Should only get here on nodes other than 0
#ifdef DEBUG_LEGION
      assert(address_space > 0);
      assert(wait_on.exists());
#endif
      if (request_event.exists())
      {
        // Include the null terminator in length
        const size_t string_length = strlen(name) + 1;
        // Send the request to node 0 for the result
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize<size_t>(string_length);
          rez.serialize(name, string_length);
          rez.serialize<size_t>(count);
          rez.serialize(request_event);
        }
        send_library_trace_request(0/*target*/, rez);
      }
      wait_on.wait();
      // When we wake up we should be able to find the result
      AutoLock l_lock(library_lock,1,false/*exclusive*/);
      std::map<std::string,LibraryTraceIDs>::const_iterator finder = 
          library_trace_ids.find(library_name);
#ifdef DEBUG_LEGION
      assert(finder != library_trace_ids.end());
      assert(finder->second.result_set);
#endif
      return finder->second.result;
    }

    //--------------------------------------------------------------------------
    /*static*/ TraceID& Runtime::get_current_static_trace_id(void)
    //--------------------------------------------------------------------------
    {
      static TraceID next_trace_id = LEGION_MAX_APPLICATION_TRACE_ID;
      return next_trace_id;
    }

    //--------------------------------------------------------------------------
    /*static*/ TraceID Runtime::generate_static_trace_id(void)
    //--------------------------------------------------------------------------
    {
      TraceID &next_trace = get_current_static_trace_id();
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'generate_static_trace_id' after "
                      "the runtime has been started!")
      return next_trace++;
    }

    //--------------------------------------------------------------------------
    FutureMap Runtime::execute_must_epoch(Context ctx, 
                                          const MustEpochLauncher &launcher)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context issue must epoch!");
      return ctx->execute_must_epoch(launcher); 
    }

    //--------------------------------------------------------------------------
    Future Runtime::issue_timing_measurement(Context ctx,
                                             const TimingLauncher &launcher)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT(
            "Illegal dummy context in timing measurement!");
      return ctx->issue_timing_measurement(launcher); 
    }

    //--------------------------------------------------------------------------
    void* Runtime::get_local_task_variable(Context ctx, LocalVariableID id)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT(
            "Illegal dummy context get local task variable!");
      return ctx->get_local_task_variable(id);
    }

    //--------------------------------------------------------------------------
    void Runtime::set_local_task_variable(Context ctx, LocalVariableID id,
                                   const void *value, void (*destructor)(void*))
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT(
            "Illegal dummy context set local task variable!");
      ctx->set_local_task_variable(id, value, destructor);
    }

    //--------------------------------------------------------------------------
    Mapper* Runtime::get_mapper(Context ctx, MapperID id, Processor target)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      if (!target.exists())
      {
        Processor proc = ctx->get_executing_processor();
#ifdef DEBUG_LEGION
        assert(proc_managers.find(proc) != proc_managers.end());
#endif
        if (ctx != DUMMY_CONTEXT)
          ctx->end_runtime_call();
        return proc_managers[proc]->find_mapper(id)->mapper;
      }
      else
      {
        std::map<Processor,ProcessorManager*>::const_iterator finder = 
          proc_managers.find(target);
        if (finder == proc_managers.end())
          REPORT_LEGION_ERROR(ERROR_INVALID_PROCESSOR_NAME, 
           "Invalid processor " IDFMT " passed to get mapper call.", target.id);
        if (ctx != DUMMY_CONTEXT)
          ctx->end_runtime_call();
        return finder->second->find_mapper(id)->mapper;
      }
    }

    //--------------------------------------------------------------------------
    MappingCallInfo* Runtime::begin_mapper_call(Context ctx, MapperID id, 
                                                Processor target)
    //--------------------------------------------------------------------------
    {
      if (ctx != DUMMY_CONTEXT)
        ctx->begin_runtime_call();
      MapperManager *manager;
      if (!target.exists())
      {
        Processor proc = ctx->get_executing_processor();
#ifdef DEBUG_LEGION
        assert(proc_managers.find(proc) != proc_managers.end());
#endif
        manager = proc_managers[proc]->find_mapper(id);
      }
      else
      {
        std::map<Processor,ProcessorManager*>::const_iterator finder = 
          proc_managers.find(target);
        if (finder == proc_managers.end())
          REPORT_LEGION_ERROR(ERROR_INVALID_PROCESSOR_NAME, "Invalid processor "
                              IDFMT " passed to begin mapper call.", target.id)
        manager = finder->second->find_mapper(id);
      }
      return new MappingCallInfo(manager, APPLICATION_MAPPER_CALL, NULL);
    }

    //--------------------------------------------------------------------------
    void Runtime::end_mapper_call(MappingCallInfo *info)
    //--------------------------------------------------------------------------
    {
      delete info;
    }

    //--------------------------------------------------------------------------
    void Runtime::print_once(Context ctx, FILE *f, const char *message)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context print once!");
      ctx->print_once(f, message);
    }

    //--------------------------------------------------------------------------
    void Runtime::log_once(Context ctx, Realm::LoggerMessage &message)
    //--------------------------------------------------------------------------
    {
      if (ctx == DUMMY_CONTEXT)
        REPORT_DUMMY_CONTEXT("Illegal dummy context log once!");
      ctx->log_once(message);
    }

    //--------------------------------------------------------------------------
    bool Runtime::is_MPI_interop_configured(void)
    //--------------------------------------------------------------------------
    {
      return (mpi_rank_table != NULL);
    }

    //--------------------------------------------------------------------------
    const std::map<int,AddressSpace>& Runtime::find_forward_MPI_mapping(void)
    //--------------------------------------------------------------------------
    {
      if (mpi_rank_table == NULL)
        REPORT_LEGION_ERROR(ERROR_MPI_INTEROPERABILITY_NOT_CONFIGURED, 
             "Forward MPI mapping call not supported without "
                      "calling configure_MPI_interoperability during "
                      "start up")
#ifdef DEBUG_LEGION
      assert(!mpi_rank_table->forward_mapping.empty());
#endif
      return mpi_rank_table->forward_mapping;
    }

    //--------------------------------------------------------------------------
    const std::map<AddressSpace,int>& Runtime::find_reverse_MPI_mapping(void)
    //--------------------------------------------------------------------------
    {
      if (mpi_rank_table == NULL)
        REPORT_LEGION_ERROR(ERROR_MPI_INTEROPERABILITY_NOT_CONFIGURED,
             "Reverse MPI mapping call not supported without "
                      "calling configure_MPI_interoperability during "
                      "start up")
#ifdef DEBUG_LEGION
      assert(!mpi_rank_table->reverse_mapping.empty());
#endif
      return mpi_rank_table->reverse_mapping;
    }

    //--------------------------------------------------------------------------
    int Runtime::find_local_MPI_rank(void)
    //-------------------------------------------------------------------------
    {
      if (mpi_rank_table == NULL)
        REPORT_LEGION_ERROR(ERROR_MPI_INTEROPERABILITY_NOT_CONFIGURED,
             "Findling local MPI rank not supported without "
                      "calling configure_MPI_interoperability during "
                      "start up")
      return mpi_rank;
    }

    //--------------------------------------------------------------------------
    void Runtime::add_mapper(MapperID map_id, Mapper *mapper, Processor proc)
    //--------------------------------------------------------------------------
    {
      // If we have a custom mapper then silently ignore this
      if (!replay_file.empty() || enable_test_mapper)
      {
        // We take ownership of these things so delete it now
        delete mapper;
        return;
      }
      const bool all_local_procs = !proc.exists();
      if (all_local_procs)
      {
        std::vector<Processor> all_local_processors;
        all_local_processors.reserve(proc_managers.size());
        for (std::map<Processor,ProcessorManager*>::const_iterator it = 
              proc_managers.begin(); it != proc_managers.end(); it++)
          all_local_processors.push_back(it->first);
        proc = find_processor_group(all_local_processors);
      }
      // First, wrap this mapper in a mapper manager
      MapperManager *manager = wrap_mapper(this, mapper, map_id, proc);
      if (all_local_procs)
      {
        bool own = true;
        // Save it to all the managers
        for (std::map<Processor,ProcessorManager*>::const_iterator it = 
              proc_managers.begin(); it != proc_managers.end(); it++)
        {
          it->second->add_mapper(map_id, manager, true/*check*/, own);
          own = false;
        }
      }
      else if (proc.address_space() == address_space)
      {
#ifdef DEBUG_LEGION
        assert(proc_managers.find(proc) != proc_managers.end());
#endif
        proc_managers[proc]->add_mapper(map_id, manager, 
                                        true/*check*/, true/*own*/);
      }
      else
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_MAPPER_PROCESSOR,
            "Illegal attempt to register mapper %s as mapper %d "
            "for processor " IDFMT ". That processor is not local to the "
            "process where 'Runtime::add_mapper' was called.",
            manager->get_mapper_name(), map_id, proc.id);
    }

    //--------------------------------------------------------------------------
    Mapping::MapperRuntime* Runtime::get_mapper_runtime(void)
    //--------------------------------------------------------------------------
    {
      return mapper_runtime;
    }

    //--------------------------------------------------------------------------
    MapperID Runtime::generate_dynamic_mapper_id(bool check_context/*= true*/)
    //--------------------------------------------------------------------------
    {
      if (check_context && (implicit_context != NULL))
        return implicit_context->generate_dynamic_mapper_id();
      MapperID result = unique_mapper_id.fetch_add(runtime_stride);
      // Check for hitting the library limit
      if (result >= LEGION_INITIAL_LIBRARY_ID_OFFSET)
        REPORT_LEGION_FATAL(LEGION_FATAL_EXCEEDED_LIBRARY_ID_OFFSET,
            "Dynamic Mapper IDs exceeded library ID offset %d",
            LEGION_INITIAL_LIBRARY_ID_OFFSET)
      return result;
    }

    //--------------------------------------------------------------------------
    MapperID Runtime::generate_library_mapper_ids(const char *name, size_t cnt)
    //--------------------------------------------------------------------------
    {
      // Easy case if the user asks for no IDs
      if (cnt == 0)
        return LEGION_AUTO_GENERATE_ID;
      const std::string library_name(name); 
      // Take the lock in read only mode and see if we can find the result
      RtEvent wait_on;
      {
        AutoLock l_lock(library_lock,1,false/*exclusive*/);
        std::map<std::string,LibraryMapperIDs>::const_iterator finder = 
          library_mapper_ids.find(library_name);
        if (finder != library_mapper_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != cnt)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "MapperID generation counts %zd and %zd differ for library %s",
                finder->second.count, cnt, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
      }
      RtUserEvent request_event;
      if (!wait_on.exists())
      {
        AutoLock l_lock(library_lock);
        // Check to make sure we didn't lose the race
        std::map<std::string,LibraryMapperIDs>::const_iterator finder = 
          library_mapper_ids.find(library_name);
        if (finder != library_mapper_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != cnt)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "MapperID generation counts %zd and %zd differ for library %s",
                finder->second.count, cnt, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
        if (!wait_on.exists())
        {
          LibraryMapperIDs &record = library_mapper_ids[library_name];
          record.count = cnt;
          if (address_space == 0)
          {
            // We're going to make the result
            record.result = unique_library_mapper_id;
            unique_library_mapper_id += cnt;
#ifdef DEBUG_LEGION
            assert(unique_library_mapper_id > record.result);
#endif
            record.result_set = true;
            return record.result;
          }
          else
          {
            // We're going to request the result
            request_event = Runtime::create_rt_user_event();
            record.ready = request_event;
            record.result_set = false;
            wait_on = request_event;
          }
        }
      }
      // Should only get here on nodes other than 0
#ifdef DEBUG_LEGION
      assert(address_space > 0);
      assert(wait_on.exists());
#endif
      if (request_event.exists())
      {
        // Include the null terminator in length
        const size_t string_length = strlen(name) + 1;
        // Send the request to node 0 for the result
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize<size_t>(string_length);
          rez.serialize(name, string_length);
          rez.serialize<size_t>(cnt);
          rez.serialize(request_event);
        }
        send_library_mapper_request(0/*target*/, rez);
      }
      wait_on.wait();
      // When we wake up we should be able to find the result
      AutoLock l_lock(library_lock,1,false/*exclusive*/);
      std::map<std::string,LibraryMapperIDs>::const_iterator finder = 
          library_mapper_ids.find(library_name);
#ifdef DEBUG_LEGION
      assert(finder != library_mapper_ids.end());
      assert(finder->second.result_set);
#endif
      return finder->second.result;
    }

    //--------------------------------------------------------------------------
    /*static*/ MapperID& Runtime::get_current_static_mapper_id(void)
    //--------------------------------------------------------------------------
    {
      static MapperID current_mapper_id = LEGION_MAX_APPLICATION_MAPPER_ID;
      return current_mapper_id;
    }

    //--------------------------------------------------------------------------
    /*static*/ MapperID Runtime::generate_static_mapper_id(void)
    //--------------------------------------------------------------------------
    {
      MapperID &next_mapper = get_current_static_mapper_id(); 
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'generate_static_mapper_id' after "
                      "the runtime has been started!")
      return next_mapper++;
    }

    //--------------------------------------------------------------------------
    void Runtime::replace_default_mapper(Mapper *mapper, Processor proc)
    //--------------------------------------------------------------------------
    {
      // If we have a custom mapper then silently ignore this
      if (!replay_file.empty() || enable_test_mapper)
      {
        // We take ownership of mapper so delete it now
        delete mapper;
        return;
      }
      const bool all_local_procs = !proc.exists();
      if (all_local_procs)
      {
        std::vector<Processor> all_local_processors;
        all_local_processors.reserve(proc_managers.size());
        for (std::map<Processor,ProcessorManager*>::const_iterator it = 
              proc_managers.begin(); it != proc_managers.end(); it++)
          all_local_processors.push_back(it->first);
        proc = find_processor_group(all_local_processors);
      }
      // First, wrap this mapper in a mapper manager
      MapperManager *manager = wrap_mapper(this, mapper, 0, proc); 
      if (all_local_procs)
      {
        bool own = true;
        // Save it to all the managers
        for (std::map<Processor,ProcessorManager*>::const_iterator it = 
              proc_managers.begin(); it != proc_managers.end(); it++)
        {
          it->second->replace_default_mapper(manager, own);
          own = false;
        }
      }
      else if (local_procs.find(proc) != local_procs.end())
      {
#ifdef DEBUG_LEGION
        assert(proc_managers.find(proc) != proc_managers.end());
#endif
        proc_managers[proc]->replace_default_mapper(manager, true/*own*/);
      }
      else
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_MAPPER_PROCESSOR,
            "Illegal attempt to register mapper %s as the default mapper "
            "for processor " IDFMT ". That processor is not local to the "
            "process where 'Runtime::replace_default_mapper' was called.",
            manager->get_mapper_name(), proc.id);
    }

    //--------------------------------------------------------------------------
    /*static*/ MapperManager* Runtime::wrap_mapper(Runtime *rt, Mapper *mapper,
                                  MapperID map_id, Processor p, bool is_default)
    //--------------------------------------------------------------------------
    {
      MapperManager *manager = NULL;
      switch (mapper->get_mapper_sync_model())
      {
        case Mapper::CONCURRENT_MAPPER_MODEL:
          {
            manager = new ConcurrentManager(rt, mapper, map_id, p, is_default);
            break;
          }
        case Mapper::SERIALIZED_REENTRANT_MAPPER_MODEL:
          {
            manager = new SerializingManager(rt, mapper, map_id, p, 
                                             true/*reentrant*/, is_default);
            break;
          }
        case Mapper::SERIALIZED_NON_REENTRANT_MAPPER_MODEL:
          {
            manager = new SerializingManager(rt, mapper, map_id, p,
                                             false/*reentrant*/, is_default);
            break;
          }
        default:
          assert(false);
      }
      return manager;
    }

    //--------------------------------------------------------------------------
    MapperManager* Runtime::find_mapper(MapperID map_id)
    //--------------------------------------------------------------------------
    {
      for (std::map<Processor,ProcessorManager*>::const_iterator it = 
            proc_managers.begin(); it != proc_managers.end(); it++)
      {
        MapperManager *result = it->second->find_mapper(map_id);
        if (result != NULL)
          return result;
      }
      return NULL;
    }

    //--------------------------------------------------------------------------
    MapperManager* Runtime::find_mapper(Processor target, MapperID map_id)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(target.exists());
#endif
      std::map<Processor,ProcessorManager*>::const_iterator finder = 
        proc_managers.find(target);
#ifdef DEBUG_LEGION
      assert(finder != proc_managers.end());
#endif
      return finder->second->find_mapper(map_id);
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_non_default_mapper(void) const
    //--------------------------------------------------------------------------
    {
      for (std::map<Processor,ProcessorManager*>::const_iterator it = 
            proc_managers.begin(); it != proc_managers.end(); it++)
        if (it->second->has_non_default_mapper())
          return true;
      return false;
    }

    //--------------------------------------------------------------------------
    ProjectionID Runtime::generate_dynamic_projection_id(
                                                   bool check_context/*= true*/)
    //--------------------------------------------------------------------------
    {
      if (check_context && (implicit_context != NULL))
        return implicit_context->generate_dynamic_projection_id();
      ProjectionID result = unique_projection_id.fetch_add(runtime_stride);
      // Check for hitting the library limit
      if (result >= LEGION_INITIAL_LIBRARY_ID_OFFSET)
        REPORT_LEGION_FATAL(LEGION_FATAL_EXCEEDED_LIBRARY_ID_OFFSET,
            "Dynamic Projection IDs exceeded library ID offset %d",
            LEGION_INITIAL_LIBRARY_ID_OFFSET)
      return result;
    }

    //--------------------------------------------------------------------------
    ProjectionID Runtime::generate_library_projection_ids(const char *name, 
                                                          size_t cnt)
    //--------------------------------------------------------------------------
    {
      // Easy case if the user asks for no IDs
      if (cnt == 0)
        return LEGION_AUTO_GENERATE_ID;
      const std::string library_name(name); 
      // Take the lock in read only mode and see if we can find the result
      RtEvent wait_on;
      {
        AutoLock l_lock(library_lock,1,false/*exclusive*/);
        std::map<std::string,LibraryProjectionIDs>::const_iterator finder = 
          library_projection_ids.find(library_name);
        if (finder != library_projection_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != cnt)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "ProjectionID generation counts %zd and %zd differ for "
                "library %s", finder->second.count, cnt, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
      }
      RtUserEvent request_event;
      if (!wait_on.exists())
      {
        AutoLock l_lock(library_lock);
        // Check to make sure we didn't lose the race
        std::map<std::string,LibraryProjectionIDs>::const_iterator finder = 
          library_projection_ids.find(library_name);
        if (finder != library_projection_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != cnt)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "ProjectionID generation counts %zd and %zd differ for "
                "library %s", finder->second.count, cnt, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
        if (!wait_on.exists())
        {
          LibraryProjectionIDs &record = library_projection_ids[library_name];
          record.count = cnt;
          if (address_space == 0)
          {
            // We're going to make the result
            record.result = unique_library_projection_id;
            unique_library_projection_id += cnt;
#ifdef DEBUG_LEGION
            assert(unique_library_projection_id > record.result);
#endif
            record.result_set = true;
            return record.result;
          }
          else
          {
            // We're going to request the result
            request_event = Runtime::create_rt_user_event();
            record.ready = request_event;
            record.result_set = false;
            wait_on = request_event;
          }
        }
      }
      // Should only get here on nodes other than 0
#ifdef DEBUG_LEGION
      assert(address_space > 0);
      assert(wait_on.exists());
#endif
      if (request_event.exists())
      {
        // Include the null terminator in length
        const size_t string_length = strlen(name) + 1;
        // Send the request to node 0 for the result
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize<size_t>(string_length);
          rez.serialize(name, string_length);
          rez.serialize<size_t>(cnt);
          rez.serialize(request_event);
        }
        send_library_projection_request(0/*target*/, rez);
      }
      wait_on.wait();
      // When we wake up we should be able to find the result
      AutoLock l_lock(library_lock,1,false/*exclusive*/);
      std::map<std::string,LibraryProjectionIDs>::const_iterator finder = 
          library_projection_ids.find(library_name);
#ifdef DEBUG_LEGION
      assert(finder != library_projection_ids.end());
      assert(finder->second.result_set);
#endif
      return finder->second.result;
    }
    
    //--------------------------------------------------------------------------
    /*static*/ ProjectionID& Runtime::get_current_static_projection_id(void)
    //--------------------------------------------------------------------------
    {
      static ProjectionID current_projection_id = 
        LEGION_MAX_APPLICATION_PROJECTION_ID;
      return current_projection_id;
    }

    //--------------------------------------------------------------------------
    /*static*/ ProjectionID Runtime::generate_static_projection_id(void)
    //--------------------------------------------------------------------------
    {
      ProjectionID &next_projection = get_current_static_projection_id();
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'generate_static_projection_id' after "
                      "the runtime has been started!");
      return next_projection++;
    }

    //--------------------------------------------------------------------------
    void Runtime::register_projection_functor(ProjectionID pid,
                                              ProjectionFunctor *functor,
                                              bool need_zero_check,
                                              bool silence_warnings,
                                              const char *warning_string,
                                              bool preregistered)
    //--------------------------------------------------------------------------
    {
      if (need_zero_check && (pid == 0))
        REPORT_LEGION_ERROR(ERROR_RESERVED_PROJECTION_ID, 
                            "ProjectionID zero is reserved.\n");
      if (!preregistered && !inside_registration_callback && !silence_warnings)
        REPORT_LEGION_WARNING(LEGION_WARNING_NON_CALLBACK_REGISTRATION,
            "Projection functor %d was dynamically registered outside of a "
            "registration callback invocation. In the near future this will "
            "become an error in order to support task subprocesses. Please "
            "use 'perform_registration_callback' to generate a callback where "
            "it will be safe to perform dynamic registrations.", pid)
      if (!silence_warnings && (total_address_spaces > 1) &&
          (inside_registration_callback != GLOBAL_REGISTRATION_CALLBACK))
        REPORT_LEGION_WARNING(LEGION_WARNING_DYNAMIC_PROJECTION_REG,
                        "Projection functor %d is being dynamically "
                        "registered for a multi-node run with %d nodes. It is "
                        "currently the responsibility of the application to "
                        "ensure that this projection functor is registered on "
                        "all nodes where it will be required. "
                        "Warning string: %s", pid, total_address_spaces,
                        (warning_string == NULL) ? "" : warning_string)
      ProjectionFunction *function = new ProjectionFunction(pid, functor);
      AutoLock p_lock(projection_lock);
      std::map<ProjectionID,ProjectionFunction*>::
        const_iterator finder = projection_functions.find(pid);
      if (finder != projection_functions.end())
        REPORT_LEGION_ERROR(ERROR_DUPLICATE_PROJECTION_ID, 
                      "ProjectionID %d has already been used in "
                      "the region projection table\n", pid)
      projection_functions[pid] = function;
      if (legion_spy_enabled)
        LegionSpy::log_projection_function(pid, function->depth, 
                                           function->is_invertible);
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::preregister_projection_functor(ProjectionID pid,
                                                     ProjectionFunctor *functor)
    //--------------------------------------------------------------------------
    {
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'preregister_projection_functor' after "
                      "the runtime has started!")
      if (pid == 0)
        REPORT_LEGION_ERROR(ERROR_RESERVED_PROJECTION_ID, 
                            "ProjectionID zero is reserved.\n");
      std::map<ProjectionID,ProjectionFunctor*> &pending_projection_functors =
        get_pending_projection_table();
      std::map<ProjectionID,ProjectionFunctor*>::const_iterator finder = 
        pending_projection_functors.find(pid);
      if (finder != pending_projection_functors.end())
        REPORT_LEGION_ERROR(ERROR_DUPLICATE_PROJECTION_ID, 
                      "ProjectionID %d has already been used in "
                      "the region projection table\n", pid)
      pending_projection_functors[pid] = functor;
    }

    //--------------------------------------------------------------------------
    ProjectionFunction* Runtime::find_projection_function(ProjectionID pid,
                                                          bool can_fail)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(projection_lock,1,false/*exclusive*/);
      std::map<ProjectionID,ProjectionFunction*>::
        const_iterator finder = projection_functions.find(pid);
      if (finder == projection_functions.end())
      {
        if (can_fail)
          return NULL;
        REPORT_LEGION_ERROR(ERROR_INVALID_PROJECTION_ID, 
                        "Unable to find registered region projection ID %d. "
                        "Please upgrade to using projection functors!", pid);
      }
      return finder->second;
    }

    //--------------------------------------------------------------------------
    /*static*/ ProjectionFunctor* Runtime::get_projection_functor(
                                                               ProjectionID pid) 
    //--------------------------------------------------------------------------
    {
      if (runtime_started)
      {
        ProjectionFunction *func = 
          the_runtime->find_projection_function(pid, true/*can fail*/);
        if (func != NULL)
          return func->functor;
      }
      else
      {
        std::map<ProjectionID,ProjectionFunctor*> &pending_projection_functors =
          get_pending_projection_table();
        std::map<ProjectionID,ProjectionFunctor*>::const_iterator finder = 
          pending_projection_functors.find(pid);
        if (finder != pending_projection_functors.end())
          return finder->second;
      }
      return NULL;
    }

    //--------------------------------------------------------------------------
    ShardingID Runtime::generate_dynamic_sharding_id(bool check_context/*true*/)
    //--------------------------------------------------------------------------
    {
      if (check_context && (implicit_context != NULL))
        return implicit_context->generate_dynamic_sharding_id();
      ShardingID result = unique_sharding_id.fetch_add(runtime_stride); 
      // Check for hitting the library limit
      if (result >= LEGION_INITIAL_LIBRARY_ID_OFFSET)
        REPORT_LEGION_FATAL(LEGION_FATAL_EXCEEDED_LIBRARY_ID_OFFSET,
            "Dynamic Shardinging IDs exceeded library ID offset %d",
            LEGION_INITIAL_LIBRARY_ID_OFFSET)
      return result;
    }

    //--------------------------------------------------------------------------
    ShardingID Runtime::generate_library_sharding_ids(const char *name,
                                                      size_t cnt)
    //--------------------------------------------------------------------------
    {
      // Easy case if the user asks for no IDs
      if (cnt == 0)
        return LEGION_AUTO_GENERATE_ID;
      const std::string library_name(name); 
      // Take the lock in read only mode and see if we can find the result
      RtEvent wait_on;
      {
        AutoLock l_lock(library_lock,1,false/*exclusive*/);
        std::map<std::string,LibraryShardingIDs>::const_iterator finder = 
          library_sharding_ids.find(library_name);
        if (finder != library_sharding_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != cnt)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
               "ShardingID generation counts %zd and %zd differ for library %s",
               finder->second.count, cnt, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
      }
      RtUserEvent request_event;
      if (!wait_on.exists())
      {
        AutoLock l_lock(library_lock);
        // Check to make sure we didn't lose the race
        std::map<std::string,LibraryShardingIDs>::const_iterator finder = 
          library_sharding_ids.find(library_name);
        if (finder != library_sharding_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != cnt)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
               "ShardingID generation counts %zd and %zd differ for library %s",
               finder->second.count, cnt, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
        if (!wait_on.exists())
        {
          LibraryShardingIDs &record = library_sharding_ids[library_name];
          record.count = cnt;
          if (address_space == 0)
          {
            // We're going to make the result
            record.result = unique_library_sharding_id;
            unique_library_sharding_id += cnt;
#ifdef DEBUG_LEGION
            assert(unique_library_sharding_id > record.result);
#endif
            record.result_set = true;
            return record.result;
          }
          else
          {
            // We're going to request the result
            request_event = Runtime::create_rt_user_event();
            record.ready = request_event;
            record.result_set = false;
            wait_on = request_event;
          }
        }
      }
      // Should only get here on nodes other than 0
#ifdef DEBUG_LEGION
      assert(address_space > 0);
      assert(wait_on.exists());
#endif
      if (request_event.exists())
      {
        // Include the null terminator in length
        const size_t string_length = strlen(name) + 1;
        // Send the request to node 0 for the result
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize<size_t>(string_length);
          rez.serialize(name, string_length);
          rez.serialize<size_t>(cnt);
          rez.serialize(request_event);
        }
        send_library_sharding_request(0/*target*/, rez);
      }
      wait_on.wait();
      // When we wake up we should be able to find the result
      AutoLock l_lock(library_lock,1,false/*exclusive*/);
      std::map<std::string,LibraryShardingIDs>::const_iterator finder = 
          library_sharding_ids.find(library_name);
#ifdef DEBUG_LEGION
      assert(finder != library_sharding_ids.end());
      assert(finder->second.result_set);
#endif
      return finder->second.result;
    }

    //--------------------------------------------------------------------------
    /*static*/ ShardingID& Runtime::get_current_static_sharding_id(void)
    //--------------------------------------------------------------------------
    {
      // + 2 since we use that for first one for the attach-detach functor
      // and the second one for the universal functor
      static ShardingID current_sharding_id =
        LEGION_MAX_APPLICATION_SHARDING_ID + 2;
      return current_sharding_id;
    }

    //--------------------------------------------------------------------------
    /*static*/ ShardingID Runtime::generate_static_sharding_id(void)
    //--------------------------------------------------------------------------
    {
      ShardingID &next_sharding = get_current_static_sharding_id();
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START,
                      "Illegal call to 'generate_static_sharding_id' after "
                      "the runtime has been started!")
      return next_sharding++;
    }

    //--------------------------------------------------------------------------
    void Runtime::register_sharding_functor(ShardingID sid,
                                            ShardingFunctor *functor,
                                            bool need_zero_check,
                                            bool silence_warnings,
                                            const char *warning_string,
                                            bool preregistered)
    //--------------------------------------------------------------------------
    {
      if (sid == UINT_MAX)
        REPORT_LEGION_ERROR(ERROR_RESERVED_SHARDING_ID,
            "ERROR: %d (UINT_MAX) is a reserved sharding ID.", UINT_MAX)
      else if (need_zero_check && (sid == 0))
        REPORT_LEGION_ERROR(ERROR_RESERVED_SHARDING_ID,
                            "ERROR: ShardingID zero is reserved.")
      if (!preregistered && !inside_registration_callback && !silence_warnings)
        REPORT_LEGION_WARNING(LEGION_WARNING_NON_CALLBACK_REGISTRATION,
            "Sharding functor %d was dynamically registered outside of a "
            "registration callback invocation. In the near future this will "
            "become an error in order to support task subprocesses. Please "
            "use 'perform_registration_callback' to generate a callback where "
            "it will be safe to perform dynamic registrations.", sid)
      if (!silence_warnings && (total_address_spaces > 1) &&
          (inside_registration_callback != GLOBAL_REGISTRATION_CALLBACK))
        REPORT_LEGION_WARNING(LEGION_WARNING_DYNAMIC_SHARDING_REG,
                        "WARNING: Sharding functor %d is being dynamically "
                        "registered for a multi-node run with %d nodes. It is "
                        "currently the responsibility of the application to "
                        "ensure that this sharding functor is registered on "
                        "all nodes where it will be required. "
                        "Warning string: %s", sid, total_address_spaces,
                        (warning_string == NULL) ? "" : warning_string)
      AutoLock s_lock(sharding_lock);
      std::map<ShardingID,ShardingFunctor*>::const_iterator finder = 
        sharding_functors.find(sid);
      if (finder != sharding_functors.end())
        REPORT_LEGION_ERROR(ERROR_DUPLICATE_SHARDING_ID,
                      "ERROR: ShardingID %d has already been used by another "
                      "sharding functor.", sid)
      sharding_functors[sid] = functor;
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::preregister_sharding_functor(ShardingID sid,
                                                       ShardingFunctor *functor)
    //--------------------------------------------------------------------------
    {
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START,
                      "Illegal call to 'preregister_sharding_functor' after "
                      "the runtime has started!");
      if (sid == UINT_MAX)
        REPORT_LEGION_ERROR(ERROR_RESERVED_SHARDING_ID,
            "ERROR: %d (UINT_MAX) is a reserved sharding ID.", UINT_MAX)
      else if (sid == 0)
        REPORT_LEGION_ERROR(ERROR_RESERVED_SHARDING_ID,
                            "ERROR: ShardingID zero is reserved.")
      std::map<ShardingID,ShardingFunctor*> &pending_sharding_functors = 
        get_pending_sharding_table();
      std::map<ShardID,ShardingFunctor*>::const_iterator finder = 
        pending_sharding_functors.find(sid);
      if (finder != pending_sharding_functors.end())
        REPORT_LEGION_ERROR(ERROR_DUPLICATE_SHARDING_ID,
                      "ERROR: ShardingID %d has already been used by another "
                      "sharding functor.", sid)
      pending_sharding_functors[sid] = functor;
    }

    //--------------------------------------------------------------------------
    ShardingFunctor* Runtime::find_sharding_functor(ShardingID sid, 
                                                    bool can_fail)
    //--------------------------------------------------------------------------
    {
      AutoLock s_lock(sharding_lock,1,false/*exclusive*/);
      std::map<ShardingID,ShardingFunctor*>::const_iterator finder = 
        sharding_functors.find(sid);
      if (finder == sharding_functors.end())
      {
        if (can_fail)
          return NULL;
        REPORT_LEGION_ERROR(ERROR_INVALID_SHARDING_ID,
                    "Unable to find registered sharding functor ID %d.", sid)
      }
      return finder->second;
    }

    //--------------------------------------------------------------------------
    /*static*/ ShardingFunctor* Runtime::get_sharding_functor(ShardingID sid)
    //--------------------------------------------------------------------------
    {
      if (!runtime_started)
      {
        std::map<ShardingID,ShardingFunctor*> &pending_sharding_functors = 
          get_pending_sharding_table();
        std::map<ShardID,ShardingFunctor*>::const_iterator finder = 
          pending_sharding_functors.find(sid);
        if (finder == pending_sharding_functors.end())
          return NULL;
        else
          return finder->second;
      }
      else
        return the_runtime->find_sharding_functor(sid, true/*can fail*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::unregister_projection_functor(ProjectionID pid)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(runtime_started);
#endif
      AutoLock p_lock(projection_lock);
      std::map<ProjectionID,ProjectionFunction*>::iterator finder =
        projection_functions.find(pid);
      if (finder != projection_functions.end())
      {
        delete finder->second;
        projection_functions.erase(finder);
        return;
      }
#ifdef DEBUG_LEGION
      assert(separate_runtime_instances);
#endif
    }

    //--------------------------------------------------------------------------
    void Runtime::attach_semantic_information(TaskID task_id, SemanticTag tag,
           const void *buffer, size_t size, bool is_mutable, bool send_to_owner)
    //--------------------------------------------------------------------------
    {
      if ((implicit_context != NULL) && 
          !implicit_context->perform_semantic_attach(__func__, 
            ReplicateContext::REPLICATE_ATTACH_TASK_INFO, &task_id,
            sizeof(task_id), tag, buffer, size, is_mutable, send_to_owner))
        return;
      if ((tag == LEGION_NAME_SEMANTIC_TAG) && legion_spy_enabled)
        LegionSpy::log_task_name(task_id, static_cast<const char*>(buffer));
      TaskImpl *impl = find_or_create_task_impl(task_id);
      impl->attach_semantic_information(tag, address_space, buffer, size, 
                                        is_mutable, send_to_owner);
      if (implicit_context != NULL)
        implicit_context->post_semantic_attach();
    }

    //--------------------------------------------------------------------------
    void Runtime::attach_semantic_information(IndexSpace handle, 
                                              SemanticTag tag,
                                              const void *buffer, size_t size,
                                              bool is_mutable)
    //--------------------------------------------------------------------------
    {
      bool global = true;
      if ((implicit_context != NULL) && 
          !implicit_context->perform_semantic_attach(__func__,
            ReplicateContext::REPLICATE_ATTACH_INDEX_SPACE_INFO, &handle,
            sizeof(handle), tag, buffer, size, is_mutable, global))
        return;
      forest->attach_semantic_information(handle, tag, address_space, 
                                          buffer, size, is_mutable, !global);
      if (implicit_context != NULL)
        implicit_context->post_semantic_attach();
    }

    //--------------------------------------------------------------------------
    void Runtime::attach_semantic_information(IndexPartition handle, 
                                              SemanticTag tag,
                                              const void *buffer, size_t size,
                                              bool is_mutable)
    //--------------------------------------------------------------------------
    {
      bool global = true;
      if ((implicit_context != NULL) && 
          !implicit_context->perform_semantic_attach(__func__,
            ReplicateContext::REPLICATE_ATTACH_INDEX_PARTITION_INFO, &handle,
            sizeof(handle), tag, buffer, size, is_mutable, global))
        return;
      forest->attach_semantic_information(handle, tag, address_space, 
                                          buffer, size, is_mutable, !global);
      if (implicit_context != NULL)
        implicit_context->post_semantic_attach();
    }

    //--------------------------------------------------------------------------
    void Runtime::attach_semantic_information(FieldSpace handle, 
                                              SemanticTag tag,
                                              const void *buffer, size_t size,
                                              bool is_mutable)
    //--------------------------------------------------------------------------
    {
      bool global = true;
      if ((implicit_context != NULL) && 
          !implicit_context->perform_semantic_attach(__func__,
            ReplicateContext::REPLICATE_ATTACH_FIELD_SPACE_INFO, &handle,
            sizeof(handle), tag, buffer, size, is_mutable, global))
        return;
      forest->attach_semantic_information(handle, tag, address_space, 
                                          buffer, size, is_mutable, !global);
      if (implicit_context != NULL)
        implicit_context->post_semantic_attach();
    }

    //--------------------------------------------------------------------------
    void Runtime::attach_semantic_information(FieldSpace handle, FieldID fid,
                                              SemanticTag tag,
                                              const void *buffer, size_t size,
                                              bool is_mutable)
    //--------------------------------------------------------------------------
    {
      bool global = true;
      if ((implicit_context != NULL) && 
          !implicit_context->perform_semantic_attach(__func__,
            ReplicateContext::REPLICATE_ATTACH_FIELD_INFO, &handle,
            sizeof(handle), tag, buffer, size, is_mutable, global, 
            &fid, sizeof(fid)))
        return;
      forest->attach_semantic_information(handle, fid, tag, address_space, 
                                          buffer, size, is_mutable, !global);
      if (implicit_context != NULL)
        implicit_context->post_semantic_attach();
    }

    //--------------------------------------------------------------------------
    void Runtime::attach_semantic_information(LogicalRegion handle, 
                                              SemanticTag tag,
                                              const void *buffer, size_t size,
                                              bool is_mutable)
    //--------------------------------------------------------------------------
    {
      bool global = true;
      if ((implicit_context != NULL) && 
          !implicit_context->perform_semantic_attach(__func__,
            ReplicateContext::REPLICATE_ATTACH_LOGICAL_REGION_INFO, &handle,
            sizeof(handle), tag, buffer, size, is_mutable, global))
        return;
      forest->attach_semantic_information(handle, tag, address_space, 
                                          buffer, size, is_mutable, !global);
      if (implicit_context != NULL)
        implicit_context->post_semantic_attach();
    }

    //--------------------------------------------------------------------------
    void Runtime::attach_semantic_information(LogicalPartition handle, 
                                              SemanticTag tag,
                                              const void *buffer, size_t size,
                                              bool is_mutable)
    //--------------------------------------------------------------------------
    {
      bool global = true;
      if ((implicit_context != NULL) && 
          !implicit_context->perform_semantic_attach(__func__,
            ReplicateContext::REPLICATE_ATTACH_LOGICAL_PARTITION_INFO, &handle,
            sizeof(handle), tag, buffer, size, is_mutable, global))
        return;
      forest->attach_semantic_information(handle, tag, address_space, 
                                          buffer, size, is_mutable, !global);
      if (implicit_context != NULL)
        implicit_context->post_semantic_attach();
    }

    //--------------------------------------------------------------------------
    bool Runtime::retrieve_semantic_information(TaskID task_id,SemanticTag tag,
              const void *&result, size_t &size, bool can_fail, bool wait_until)
    //--------------------------------------------------------------------------
    {
      TaskImpl *impl = find_or_create_task_impl(task_id);
      return impl->retrieve_semantic_information(tag, result, size, 
                                                 can_fail, wait_until);
    }

    //--------------------------------------------------------------------------
    bool Runtime::retrieve_semantic_information(IndexSpace handle,
                                                SemanticTag tag,
                                                const void *&result, 
                                                size_t &size, bool can_fail,
                                                bool wait_until)
    //--------------------------------------------------------------------------
    {
      return forest->retrieve_semantic_information(handle, tag, result, size,
                                                   can_fail, wait_until);
    }

    //--------------------------------------------------------------------------
    bool Runtime::retrieve_semantic_information(IndexPartition handle,
                                                SemanticTag tag,
                                                const void *&result, 
                                                size_t &size, bool can_fail,
                                                bool wait_until)
    //--------------------------------------------------------------------------
    {
      return forest->retrieve_semantic_information(handle, tag, result, size, 
                                                   can_fail, wait_until);
    }

    //--------------------------------------------------------------------------
    bool Runtime::retrieve_semantic_information(FieldSpace handle,
                                                SemanticTag tag,
                                                const void *&result, 
                                                size_t &size, bool can_fail,
                                                bool wait_until)
    //--------------------------------------------------------------------------
    {
      return forest->retrieve_semantic_information(handle, tag, result, size,
                                                   can_fail, wait_until);
    }

    //--------------------------------------------------------------------------
    bool Runtime::retrieve_semantic_information(FieldSpace handle, FieldID fid,
                                                SemanticTag tag,
                                                const void *&result, 
                                                size_t &size, bool can_fail,
                                                bool wait_until)
    //--------------------------------------------------------------------------
    {
      return forest->retrieve_semantic_information(handle, fid, tag, result, 
                                                   size, can_fail, wait_until);
    }

    //--------------------------------------------------------------------------
    bool Runtime::retrieve_semantic_information(LogicalRegion handle,
                                                SemanticTag tag,
                                                const void *&result, 
                                                size_t &size, bool can_fail,
                                                bool wait_until)
    //--------------------------------------------------------------------------
    {
      return forest->retrieve_semantic_information(handle, tag, result, size,
                                                   can_fail, wait_until);
    }

    //--------------------------------------------------------------------------
    bool Runtime::retrieve_semantic_information(LogicalPartition handle,
                                                SemanticTag tag,
                                                const void *&result, 
                                                size_t &size, bool can_fail,
                                                bool wait_until)
    //--------------------------------------------------------------------------
    {
      return forest->retrieve_semantic_information(handle, tag, result, size,
                                                   can_fail, wait_until);
    }

    //--------------------------------------------------------------------------
    TaskID Runtime::generate_dynamic_task_id(bool check_context/*= true*/)
    //--------------------------------------------------------------------------
    {
      if (check_context && (implicit_context != NULL))
        return implicit_context->generate_dynamic_task_id();
      TaskID result = unique_task_id.fetch_add(runtime_stride);
      // Check for hitting the library limit
      if (result >= LEGION_INITIAL_LIBRARY_ID_OFFSET)
        REPORT_LEGION_FATAL(LEGION_FATAL_EXCEEDED_LIBRARY_ID_OFFSET,
            "Dynamic Task IDs exceeded library ID offset %d",
            LEGION_INITIAL_LIBRARY_ID_OFFSET)
      return result;
    }

    //--------------------------------------------------------------------------
    TaskID Runtime::generate_library_task_ids(const char *name, size_t cnt)
    //--------------------------------------------------------------------------
    {
      // Easy case if the user asks for no IDs
      if (cnt == 0)
        return LEGION_AUTO_GENERATE_ID;
      const std::string library_name(name); 
      // Take the lock in read only mode and see if we can find the result
      RtEvent wait_on;
      {
        AutoLock l_lock(library_lock,1,false/*exclusive*/);
        std::map<std::string,LibraryTaskIDs>::const_iterator finder = 
          library_task_ids.find(library_name);
        if (finder != library_task_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != cnt)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "TaskID generation counts %zd and %zd differ for library %s",
                finder->second.count, cnt, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
      }
      RtUserEvent request_event;
      if (!wait_on.exists())
      {
        AutoLock l_lock(library_lock);
        // Check to make sure we didn't lose the race
        std::map<std::string,LibraryTaskIDs>::const_iterator finder = 
          library_task_ids.find(library_name);
        if (finder != library_task_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != cnt)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "TaskID generation counts %zd and %zd differ for library %s",
                finder->second.count, cnt, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
        if (!wait_on.exists())
        {
          LibraryTaskIDs &record = library_task_ids[library_name];
          record.count = cnt;
          if (address_space == 0)
          {
            // We're going to make the result
            record.result = unique_library_task_id;
            unique_library_task_id += cnt;
#ifdef DEBUG_LEGION
            assert(unique_library_task_id > record.result);
#endif
            record.result_set = true;
            return record.result;
          }
          else
          {
            // We're going to request the result
            request_event = Runtime::create_rt_user_event();
            record.ready = request_event;
            record.result_set = false;
            wait_on = request_event;
          }
        }
      }
      // Should only get here on nodes other than 0
#ifdef DEBUG_LEGION
      assert(address_space > 0);
      assert(wait_on.exists());
#endif
      if (request_event.exists())
      {
        // Include the null terminator in length
        const size_t string_length = strlen(name) + 1;
        // Send the request to node 0 for the result
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize<size_t>(string_length);
          rez.serialize(name, string_length);
          rez.serialize<size_t>(cnt);
          rez.serialize(request_event);
        }
        send_library_task_request(0/*target*/, rez);
      }
      wait_on.wait();
      // When we wake up we should be able to find the result
      AutoLock l_lock(library_lock,1,false/*exclusive*/);
      std::map<std::string,LibraryTaskIDs>::const_iterator finder = 
          library_task_ids.find(library_name);
#ifdef DEBUG_LEGION
      assert(finder != library_task_ids.end());
      assert(finder->second.result_set);
#endif
      return finder->second.result;
    }

    //--------------------------------------------------------------------------
    VariantID Runtime::register_variant(const TaskVariantRegistrar &registrar,
                                  const void *user_data, size_t user_data_size,
                                  const CodeDescriptor &realm_code_desc,
                                  size_t return_type_size, bool has_return_size,
                                  VariantID vid /*= AUTO_GENERATE_ID*/,
                                  bool check_task_id /*= true*/,
                                  bool check_context /*= true*/,
                                  bool preregistered /*= false*/)
    //--------------------------------------------------------------------------
    {
      if (check_context && (implicit_context != NULL))
        return implicit_context->register_variant(registrar, user_data,
         user_data_size, realm_code_desc, return_type_size, has_return_size,
         vid, check_task_id);
      // TODO: figure out a way to make this check safe with dynamic generation
#if 0
      if (check_task_id && 
          (registrar.task_id >= LEGION_MAX_APPLICATION_TASK_ID))
        REPORT_LEGION_ERROR(ERROR_MAX_APPLICATION_TASK_ID_EXCEEDED, 
                      "Error registering task with ID %d. Exceeds the "
                      "statically set bounds on application task IDs of %d. "
                      "See %s in legion_config.h.", 
                      registrar.task_id, LEGION_MAX_APPLICATION_TASK_ID, 
                      LEGION_MACRO_TO_STRING(LEGION_MAX_APPLICATION_TASK_ID))
#endif  
      // First find the task implementation
      TaskImpl *task_impl = find_or_create_task_impl(registrar.task_id);
      // See if we need to make a new variant ID
      if (vid == LEGION_AUTO_GENERATE_ID) // Make a variant ID to use
        vid = task_impl->get_unique_variant_id();
      else if (vid == 0)
        REPORT_LEGION_ERROR(ERROR_RESERVED_VARIANT_ID,
                      "Error registering variant for task ID %d with "
                      "variant ID 0. Variant ID 0 is reserved for task "
                      "generators.", registrar.task_id)
      // Make our variant and add it to the set of variants
      VariantImpl *impl = new VariantImpl(this, vid, task_impl, registrar,
                                          return_type_size, has_return_size,
                                          realm_code_desc, user_data, 
                                          user_data_size);
      // Add this variant to the owner
      task_impl->add_variant(impl);
      {
        AutoLock tv_lock(task_variant_lock);
        variant_table.push_back(impl);
      }
      // If this is a global registration we need to broadcast the variant
      if (registrar.global_registration && (total_address_spaces > 1))
      {
        RtUserEvent done_event = Runtime::create_rt_user_event();
        impl->broadcast_variant(done_event, address_space, 0);
        done_event.wait();
      }
      if (legion_spy_enabled)
        LegionSpy::log_task_variant(registrar.task_id, vid, 
                                    impl->is_inner(), impl->is_leaf(),
                                    impl->is_idempotent(), impl->get_name());
      return vid;
    }

    //--------------------------------------------------------------------------
    TaskImpl* Runtime::find_or_create_task_impl(TaskID task_id)
    //--------------------------------------------------------------------------
    {
      {
        AutoLock tv_lock(task_variant_lock,1,false/*exclusive*/);
        std::map<TaskID,TaskImpl*>::const_iterator finder = 
          task_table.find(task_id);
        if (finder != task_table.end())
          return finder->second;
      }
      AutoLock tv_lock(task_variant_lock);
      std::map<TaskID,TaskImpl*>::const_iterator finder = 
        task_table.find(task_id);
      // Check to see if we lost the race
      if (finder == task_table.end())
      {
        TaskImpl *result = new TaskImpl(task_id, this);
        task_table[task_id] = result;
        return result;
      }
      else // Lost the race as it already exists
        return finder->second;
    }

    //--------------------------------------------------------------------------
    TaskImpl* Runtime::find_task_impl(TaskID task_id)
    //--------------------------------------------------------------------------
    {
      AutoLock tv_lock(task_variant_lock,1,false/*exclusive*/);
      std::map<TaskID,TaskImpl*>::const_iterator finder = 
        task_table.find(task_id);
#ifdef DEBUG_LEGION
      assert(finder != task_table.end());
#endif
      return finder->second;
    }

    //--------------------------------------------------------------------------
    VariantImpl* Runtime::find_variant_impl(TaskID task_id, 
                                             VariantID variant_id,bool can_fail)
    //--------------------------------------------------------------------------
    {
      TaskImpl *owner = find_or_create_task_impl(task_id);
      return owner->find_variant_impl(variant_id, can_fail);
    }

    //--------------------------------------------------------------------------
    ReductionOpID Runtime::generate_dynamic_reduction_id(
                                                   bool check_context/*= true*/)
    //--------------------------------------------------------------------------
    {
      if (check_context && (implicit_context != NULL))
        return implicit_context->generate_dynamic_reduction_id();
      ReductionOpID result = unique_redop_id.fetch_add(runtime_stride);
      // Check for hitting the library limit
      if (result >= LEGION_INITIAL_LIBRARY_ID_OFFSET)
        REPORT_LEGION_FATAL(LEGION_FATAL_EXCEEDED_LIBRARY_ID_OFFSET,
            "Dynamic Reduction IDs exceeded library ID offset %d",
            LEGION_INITIAL_LIBRARY_ID_OFFSET)
      return result;
    }

    //--------------------------------------------------------------------------
    ReductionOpID Runtime::generate_library_reduction_ids(const char *name,
                                                          size_t count)
    //--------------------------------------------------------------------------
    {
      // Easy case if the user asks for no IDs
      if (count == 0)
        return (ReductionOpID)LEGION_AUTO_GENERATE_ID;
      const std::string library_name(name); 
      // Take the lock in read only mode and see if we can find the result
      RtEvent wait_on;
      {
        AutoLock l_lock(library_lock,1,false/*exclusive*/);
        std::map<std::string,LibraryRedopIDs>::const_iterator finder = 
          library_redop_ids.find(library_name);
        if (finder != library_redop_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != count)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "ReductionOpID generation counts %zd and %zd differ for "
                "library %s", finder->second.count, count, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
      }
      RtUserEvent request_event;
      if (!wait_on.exists())
      {
        AutoLock l_lock(library_lock);
        // Check to make sure we didn't lose the race
        std::map<std::string,LibraryRedopIDs>::const_iterator finder = 
          library_redop_ids.find(library_name);
        if (finder != library_redop_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != count)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "ReductionOpID generation counts %zd and %zd differ for "
                "library %s", finder->second.count, count, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
        if (!wait_on.exists())
        {
          LibraryRedopIDs &record = library_redop_ids[library_name];
          record.count = count;
          if (address_space == 0)
          {
            // We're going to make the result
            record.result = unique_library_redop_id;
            unique_library_redop_id += count;
#ifdef DEBUG_LEGION
            assert(unique_library_redop_id > unsigned(record.result));
#endif
            record.result_set = true;
            return record.result;
          }
          else
          {
            // We're going to request the result
            request_event = Runtime::create_rt_user_event();
            record.ready = request_event;
            record.result_set = false;
            wait_on = request_event;
          }
        }
      }
      // Should only get here on nodes other than 0
#ifdef DEBUG_LEGION
      assert(address_space > 0);
      assert(wait_on.exists());
#endif
      if (request_event.exists())
      {
        // Include the null terminator in length
        const size_t string_length = strlen(name) + 1;
        // Send the request to node 0 for the result
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize<size_t>(string_length);
          rez.serialize(name, string_length);
          rez.serialize<size_t>(count);
          rez.serialize(request_event);
        }
        send_library_redop_request(0/*target*/, rez);
      }
      wait_on.wait();
      // When we wake up we should be able to find the result
      AutoLock l_lock(library_lock,1,false/*exclusive*/);
      std::map<std::string,LibraryRedopIDs>::const_iterator finder = 
          library_redop_ids.find(library_name);
#ifdef DEBUG_LEGION
      assert(finder != library_redop_ids.end());
      assert(finder->second.result_set);
#endif
      return finder->second.result;
    }

    //--------------------------------------------------------------------------
    CustomSerdezID Runtime::generate_dynamic_serdez_id(
                                                   bool check_context/*= true*/)
    //--------------------------------------------------------------------------
    {
      if (check_context && (implicit_context != NULL))
        return implicit_context->generate_dynamic_serdez_id();
      CustomSerdezID result = unique_serdez_id.fetch_add(runtime_stride);
      // Check for hitting the library limit
      if (result >= LEGION_INITIAL_LIBRARY_ID_OFFSET)
        REPORT_LEGION_FATAL(LEGION_FATAL_EXCEEDED_LIBRARY_ID_OFFSET,
            "Dynamic Custom Serdez IDs exceeded library ID offset %d",
            LEGION_INITIAL_LIBRARY_ID_OFFSET)
      return result;
    }

    //--------------------------------------------------------------------------
    CustomSerdezID Runtime::generate_library_serdez_ids(const char *name,
                                                        size_t count)
    //--------------------------------------------------------------------------
    {
      // Easy case if the user asks for no IDs
      if (count == 0)
        return (CustomSerdezID)LEGION_AUTO_GENERATE_ID;
      const std::string library_name(name); 
      // Take the lock in read only mode and see if we can find the result
      RtEvent wait_on;
      {
        AutoLock l_lock(library_lock,1,false/*exclusive*/);
        std::map<std::string,LibrarySerdezIDs>::const_iterator finder = 
          library_serdez_ids.find(library_name);
        if (finder != library_serdez_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != count)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "CustomSerdezID generation counts %zd and %zd differ for "
                "library %s", finder->second.count, count, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
      }
      RtUserEvent request_event;
      if (!wait_on.exists())
      {
        AutoLock l_lock(library_lock);
        // Check to make sure we didn't lose the race
        std::map<std::string,LibrarySerdezIDs>::const_iterator finder = 
          library_serdez_ids.find(library_name);
        if (finder != library_serdez_ids.end())
        {
          // First do a check to see if the counts match
          if (finder->second.count != count)
            REPORT_LEGION_ERROR(ERROR_LIBRARY_COUNT_MISMATCH,
                "CustomSerdezID generation counts %zd and %zd differ for "
                "library %s", finder->second.count, count, name)
          if (finder->second.result_set)
            return finder->second.result;
          // This should never happen unless we are on a node other than 0
#ifdef DEBUG_LEGION
          assert(address_space > 0);
#endif
          wait_on = finder->second.ready;
        }
        if (!wait_on.exists())
        {
          LibrarySerdezIDs &record = library_serdez_ids[library_name];
          record.count = count;
          if (address_space == 0)
          {
            // We're going to make the result
            record.result = unique_library_serdez_id;
            unique_library_serdez_id += count;
#ifdef DEBUG_LEGION
            assert(unique_library_serdez_id > unsigned(record.result));
#endif
            record.result_set = true;
            return record.result;
          }
          else
          {
            // We're going to request the result
            request_event = Runtime::create_rt_user_event();
            record.ready = request_event;
            record.result_set = false;
            wait_on = request_event;
          }
        }
      }
      // Should only get here on nodes other than 0
#ifdef DEBUG_LEGION
      assert(address_space > 0);
      assert(wait_on.exists());
#endif
      if (request_event.exists())
      {
        // Include the null terminator in length
        const size_t string_length = strlen(name) + 1;
        // Send the request to node 0 for the result
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize<size_t>(string_length);
          rez.serialize(name, string_length);
          rez.serialize<size_t>(count);
          rez.serialize(request_event);
        }
        send_library_serdez_request(0/*target*/, rez);
      }
      wait_on.wait();
      // When we wake up we should be able to find the result
      AutoLock l_lock(library_lock,1,false/*exclusive*/);
      std::map<std::string,LibrarySerdezIDs>::const_iterator finder = 
          library_serdez_ids.find(library_name);
#ifdef DEBUG_LEGION
      assert(finder != library_serdez_ids.end());
      assert(finder->second.result_set);
#endif
      return finder->second.result;
    }

    //--------------------------------------------------------------------------
    MemoryManager* Runtime::find_memory_manager(Memory mem)
    //--------------------------------------------------------------------------
    {
      {
        AutoLock m_lock(memory_manager_lock,1,false/*exclusive*/);
        std::map<Memory,MemoryManager*>::const_iterator finder = 
          memory_managers.find(mem);
        if (finder != memory_managers.end())
          return finder->second;
      }
      // Not there?  Take exclusive lock and check again, create if needed
      AutoLock m_lock(memory_manager_lock);
      std::map<Memory,MemoryManager*>::const_iterator finder =
        memory_managers.find(mem);
      if (finder != memory_managers.end())
        return finder->second;
      // Really do need to create it (and put it in the map)
      MemoryManager *result = new MemoryManager(mem, this);
      memory_managers[mem] = result;
      return result;
    }

    //--------------------------------------------------------------------------
    AddressSpaceID Runtime::find_address_space(Memory handle) const
    //--------------------------------------------------------------------------
    {
      // Just use the standard translation for now
      AddressSpaceID result = handle.address_space();
      return result;
    } 

    //--------------------------------------------------------------------------
    MessageManager* Runtime::find_messenger(AddressSpaceID sid)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(sid < LEGION_MAX_NUM_NODES);
      assert(sid != address_space); // shouldn't be sending messages to ourself
#endif
      MessageManager *result = message_managers[sid].load();
      if (result != NULL)
        return result;
      // If we made it here, then we don't have a message manager yet
      // re-take the lock and re-check to see if we don't have a manager
      // If we still don't then we need to make one
      RtEvent wait_on;
      bool send_request = false;
      {
        AutoLock m_lock(message_manager_lock);
        // Re-check to see if we lost the race, force the compiler
        // to re-load the value here
        result = message_managers[sid].load();
        if (result != NULL)
          return result;
        // Figure out if there is an event to wait on yet
        std::map<AddressSpace,RtUserEvent>::const_iterator finder = 
          pending_endpoint_requests.find(sid);
        if (finder == pending_endpoint_requests.end())
        {
          RtUserEvent done = Runtime::create_rt_user_event();
          pending_endpoint_requests[sid] = done;
          wait_on = done;
          send_request = true;
        }
        else
          wait_on = finder->second;
      }
      if (send_request)
      {
#ifdef DEBUG_LEGION
        bool found = false;
#endif
        // Find a processor on which to send the task
        for (std::map<Processor,AddressSpaceID>::const_iterator it = 
              proc_spaces.begin(); it != proc_spaces.end(); it++)
        {
          if (it->second != sid)
            continue;
#ifdef DEBUG_LEGION
          found = true;
#endif
          Serializer rez;
          {
            RezCheck z(rez);
            rez.serialize<bool>(true); // request
            rez.serialize(utility_group);
          }
          const Realm::ProfilingRequestSet empty_requests;
          it->first.spawn(LG_ENDPOINT_TASK_ID, rez.get_buffer(),
              rez.get_used_bytes(), empty_requests);
          break;
        }
#ifdef DEBUG_LEGION
        assert(found);
#endif
      }
#ifdef DEBUG_LEGION
      assert(wait_on.exists());
#endif
      if (!wait_on.has_triggered())
        wait_on.wait();
      // When we wake up there should be a result
      result = message_managers[sid].load();
#ifdef DEBUG_LEGION
      assert(result != NULL);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    MessageManager* Runtime::find_messenger(Processor target)
    //--------------------------------------------------------------------------
    {
      return find_messenger(find_address_space(target));
    }

    //--------------------------------------------------------------------------
    AddressSpaceID Runtime::find_address_space(Processor target) const
    //--------------------------------------------------------------------------
    {
      std::map<Processor,AddressSpaceID>::const_iterator finder = 
        proc_spaces.find(target);
      if (finder != proc_spaces.end())
        return finder->second;
#ifdef DEBUG_LEGION
      // If we get here then this better be a processor group
      assert(target.kind() == Processor::PROC_GROUP);
#endif
      AutoLock m_lock(message_manager_lock,1,false/*exclusive*/);
      finder = endpoint_spaces.find(target);
#ifdef DEBUG_LEGION
      assert(finder != endpoint_spaces.end());
#endif
      return finder->second;
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_endpoint_creation(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      bool request;
      derez.deserialize(request);
      Processor remote_utility_group;
      derez.deserialize(remote_utility_group);
      if (request)
      {
        Serializer rez;
        {
          RezCheck z2(rez);
          rez.serialize<bool>(false/*request*/);
          rez.serialize(utility_group);
          rez.serialize(address_space);
        }
        const Realm::ProfilingRequestSet empty_requests;
        remote_utility_group.spawn(LG_ENDPOINT_TASK_ID, rez.get_buffer(),
            rez.get_used_bytes(), empty_requests); 
      }
      else
      {
        AddressSpaceID remote_space;
        derez.deserialize(remote_space);
        AutoLock m_lock(message_manager_lock);
        message_managers[remote_space].store(new MessageManager(remote_space,
                              this, max_message_size, remote_utility_group));
        // Also update the endpoint spaces
        endpoint_spaces[remote_utility_group] = remote_space;
        std::map<AddressSpaceID,RtUserEvent>::iterator finder = 
          pending_endpoint_requests.find(remote_space);
#ifdef DEBUG_LEGION
        assert(finder != pending_endpoint_requests.end());
#endif
        Runtime::trigger_event(finder->second);
        pending_endpoint_requests.erase(finder);
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::process_mapper_message(Processor target, MapperID map_id,
                                     Processor source, const void *message,
                                     size_t message_size, unsigned message_kind)
    //--------------------------------------------------------------------------
    {
      if (is_local(target))
      {
        Mapper::MapperMessage message_args;
        message_args.sender = source;
        message_args.kind = message_kind;
        message_args.message = message;
        message_args.size = message_size;
        message_args.broadcast = false;
        MapperManager *mapper = find_mapper(target, map_id);
        mapper->invoke_handle_message(&message_args);
      }
      else
      {
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(target);
          rez.serialize(map_id);
          rez.serialize(source);
          rez.serialize(message_kind);
          rez.serialize(message_size);
          rez.serialize(message, message_size);
        }
        send_mapper_message(find_address_space(target), rez);
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::process_mapper_broadcast(MapperID map_id, Processor source, 
                                    const void *message, size_t message_size, 
                                    unsigned message_kind, int radix, int index)
    //--------------------------------------------------------------------------
    {
      // First forward the message onto any remote nodes
      int base = index * radix;
      int init;
      if (separate_runtime_instances)
      {
        std::map<Processor,AddressSpaceID>::const_iterator finder = 
          proc_spaces.find(source); 
#ifdef DEBUG_LEGION
        // only works with a single process
        assert(finder != proc_spaces.end()); 
#endif
        init = finder->second;
      }
      else
        init = source.address_space();
      // The runtime stride is the same as the number of nodes
      const int total_nodes = total_address_spaces;
      for (int r = 1; r <= radix; r++)
      {
        int offset = base + r;
        // If we've handled all of our nodes then we are done
        if (offset >= total_nodes)
          break;
        AddressSpaceID target = (init + offset) % total_nodes;
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(map_id);
          rez.serialize(source);
          rez.serialize(message_kind);
          rez.serialize(radix);
          rez.serialize(offset);
          rez.serialize(message_size);
          rez.serialize(message, message_size);
        }
        send_mapper_broadcast(target, rez);
      }
      // Then send it to all our local mappers, set will deduplicate
      std::set<MapperManager*> managers;
      for (std::map<Processor,ProcessorManager*>::const_iterator it = 
            proc_managers.begin(); it != proc_managers.end(); it++)
      {
        managers.insert(it->second->find_mapper(map_id));
      }
      Mapper::MapperMessage message_args;
      message_args.sender = source;
      message_args.kind = message_kind;
      message_args.message = message;
      message_args.size = message_size;
      message_args.broadcast = true;
      for (std::set<MapperManager*>::const_iterator it = 
            managers.begin(); it != managers.end(); it++)
        (*it)->invoke_handle_message(&message_args);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_message(MessageKind message, AddressSpaceID target,
                               Serializer &rez, bool flush, bool response)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(message, rez, flush, response);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_startup_barrier(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_STARTUP_BARRIER, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_task(TaskOp *task)
    //--------------------------------------------------------------------------
    {
      Processor target = task->target_proc;
      if (!target.exists())
        REPORT_LEGION_ERROR(ERROR_INVALID_TARGET_PROC, 
                      "Mapper requested invalid NO_PROC as target proc!");
      // Check to see if the target processor is still local 
      std::map<Processor,ProcessorManager*>::const_iterator finder = 
        proc_managers.find(target);
      if (finder != proc_managers.end())
      {
        // Update the current processor
        task->set_current_proc(target);
        finder->second->add_to_ready_queue(task);
      }
      else
      {
        MessageManager *manager = find_messenger(target);
        Serializer rez;
        bool deactivate_task;
        const AddressSpaceID target_addr = find_address_space(target);
        {
          RezCheck z(rez);
          rez.serialize(target);
          rez.serialize(task->get_task_kind());
          deactivate_task = task->pack_task(rez, target_addr);
        }
        manager->send_message(TASK_MESSAGE, rez, true/*flush*/);
        if (deactivate_task)
          task->deactivate();
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::send_tasks(Processor target, const std::set<TaskOp*> &tasks)
    //--------------------------------------------------------------------------
    {
      if (!target.exists())
        REPORT_LEGION_ERROR(ERROR_INVALID_TARGET_PROC, 
                      "Mapper requested invalid NO_PROC as target proc!");
      // Check to see if the target processor is still local 
      std::map<Processor,ProcessorManager*>::const_iterator finder = 
        proc_managers.find(target);
      if (finder != proc_managers.end())
      {
        // Still local
        for (std::set<TaskOp*>::const_iterator it = tasks.begin();
              it != tasks.end(); it++)
        {
          // Update the current processor
          (*it)->set_current_proc(target);
          finder->second->add_to_ready_queue(*it);
        }
      }
      else
      {
        // Otherwise we need to send it remotely
        MessageManager *manager = find_messenger(target);
        unsigned idx = 1;
        const AddressSpaceID target_addr = find_address_space(target);
        for (std::set<TaskOp*>::const_iterator it = tasks.begin();
              it != tasks.end(); it++,idx++)
        {
          Serializer rez;
          bool deactivate_task;
          {
            RezCheck z(rez);
            rez.serialize(target);
            rez.serialize((*it)->get_task_kind());
            deactivate_task = (*it)->pack_task(rez, target_addr);
          }
          // Put it in the queue, flush the last task
          manager->send_message(TASK_MESSAGE, rez, (idx == tasks.size()));
          // Deactivate the task if it is remote
          if (deactivate_task)
            (*it)->deactivate();
        }
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::send_steal_request(
              const std::multimap<Processor,MapperID> &targets, Processor thief)
    //--------------------------------------------------------------------------
    {
      for (std::multimap<Processor,MapperID>::const_iterator it = 
            targets.begin(); it != targets.end(); it++)
      {
        Processor target = it->first;
        std::map<Processor,ProcessorManager*>::const_iterator finder = 
          proc_managers.find(target);
        if (finder == proc_managers.end())
        {
          // Need to send remotely
          MessageManager *manager = find_messenger(target);
          Serializer rez;
          {
            RezCheck z(rez);
            rez.serialize(target);
            rez.serialize(thief);
            int num_mappers = targets.count(target);
            rez.serialize(num_mappers);
            for ( ; it != targets.upper_bound(target); it++)
              rez.serialize(it->second);
          }
          manager->send_message(STEAL_MESSAGE, rez, true/*flush*/);
        }
        else
        {
          // Still local, so notify the processor manager
          std::vector<MapperID> thieves;
          for ( ; it != targets.upper_bound(target); it++)
            thieves.push_back(it->second);
          finder->second->process_steal_request(thief, thieves);
          
        }
        if (it == targets.end())
          break;
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::send_advertisements(const std::set<Processor> &targets,
                                            MapperID map_id, Processor source)
    //--------------------------------------------------------------------------
    {
      std::set<MessageManager*> already_sent;
      for (std::set<Processor>::const_iterator it = targets.begin();
            it != targets.end(); it++)
      {
        std::map<Processor,ProcessorManager*>::const_iterator finder = 
          proc_managers.find(*it);
        if (finder != proc_managers.end())
        {
          // still local
          finder->second->process_advertisement(source, map_id);
        }
        else
        {
          // otherwise remote, check to see if we already sent it
          MessageManager *messenger = find_messenger(*it);
          if (already_sent.find(messenger) != already_sent.end())
            continue;
          Serializer rez;
          {
            RezCheck z(rez);
            rez.serialize(source);
            rez.serialize(map_id);
          }
          messenger->send_message(ADVERTISEMENT_MESSAGE, rez, true/*flush*/);
          already_sent.insert(messenger);
        }
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_task_replay(AddressSpaceID target,Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REMOTE_TASK_REPLAY, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_task_profiling_response(Processor target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REMOTE_TASK_PROFILING_RESPONSE,
                                          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_shared_ownership(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_SHARED_OWNERSHIP, rez,
                                      true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_request(AddressSpaceID target,
                                           Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_SPACE_REQUEST, rez, 
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_response(AddressSpaceID target,
                                            Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_SPACE_RESPONSE, rez, 
                                                          false/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_return(AddressSpaceID target,
                                     Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_SPACE_RETURN, rez,
                      true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_set(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_SPACE_SET, rez,
                                      true/*flush*/, true/*return*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_child_request(AddressSpaceID target,
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_SPACE_CHILD_REQUEST, rez,
                                                                true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_child_response(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_SPACE_CHILD_RESPONSE, rez,
                                               true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_colors_request(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_SPACE_COLORS_REQUEST, rez,
                                                                 true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_colors_response(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_SPACE_COLORS_RESPONSE,
                                        rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_remote_expression_request(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_INDEX_SPACE_REMOTE_EXPRESSION_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_remote_expression_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_INDEX_SPACE_REMOTE_EXPRESSION_RESPONSE, rez,
          true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_generate_color_request(AddressSpaceID target,
                                                          Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_INDEX_SPACE_GENERATE_COLOR_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_generate_color_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_INDEX_SPACE_GENERATE_COLOR_RESPONSE, rez,
            true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_release_color(AddressSpaceID target,
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // This has to go on the reference virtual channel so that it is 
      // handled before the owner node is deleted
      find_messenger(target)->send_message(SEND_INDEX_SPACE_RELEASE_COLOR, rez,
                                                                true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_notification(AddressSpaceID target,
                                                    Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_PARTITION_NOTIFICATION,
                                                          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_request(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_PARTITION_REQUEST, rez,
                                                              true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_response(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_PARTITION_RESPONSE, rez,
                                                              false/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_return(AddressSpaceID target,
                                     Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_PARTITION_RETURN, rez,
                        true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_child_request(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_PARTITION_CHILD_REQUEST,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_child_response(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_PARTITION_CHILD_RESPONSE,
                                          rez, true/*flush*/, true/*response*/); 
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_child_replication(AddressSpaceID target,
                                                         Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_INDEX_PARTITION_CHILD_REPLICATION, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_disjoint_update(AddressSpaceID target,
                                          Serializer &rez, RtEvent precondition)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_INDEX_PARTITION_DISJOINT_UPDATE, rez, true/*flush*/, 
            true/*response*/, precondition);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_shard_rects_request(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_INDEX_PARTITION_SHARD_RECTS_REQUEST,
                              rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_shard_rects_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_INDEX_PARTITION_SHARD_RECTS_RESPONSE,
              rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_remote_interference_request(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_INDEX_PARTITION_REMOTE_INTERFERENCE_REQUEST,
                                          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_remote_interference_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_INDEX_PARTITION_REMOTE_INTERFERENCE_RESPONSE,
                        rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_node(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // Will be flushed by return
      find_messenger(target)->send_message(SEND_FIELD_SPACE_NODE, rez,
                                                      false/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_request(AddressSpaceID target,
                                           Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SPACE_REQUEST, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_return(AddressSpaceID target,
                                          Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SPACE_RETURN, rez,
                                        true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_allocator_request(AddressSpaceID target,
                                                     Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SPACE_ALLOCATOR_REQUEST,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_allocator_response(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SPACE_ALLOCATOR_RESPONSE,
                                          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_allocator_invalidation(AddressSpaceID target,
                                                          Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_FIELD_SPACE_ALLOCATOR_INVALIDATION, rez,
          true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_allocator_flush(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SPACE_ALLOCATOR_FLUSH,
                                        rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_allocator_free(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SPACE_ALLOCATOR_FREE,
                                                        rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_infos_request(AddressSpaceID target, 
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SPACE_INFOS_REQUEST, rez,
                                                                true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_infos_response(AddressSpaceID target, 
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SPACE_INFOS_RESPONSE, rez,
                                               true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_alloc_request(AddressSpaceID target,
                                           Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_ALLOC_REQUEST, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_size_update(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // put this on the reference virtual channel since it has no effects
      // tracking and we need to make sure it is handled before references
      // are removed from the remote copies
      find_messenger(target)->send_message(SEND_FIELD_SIZE_UPDATE, rez,
                                      true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_free(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_FREE, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_free_indexes(AddressSpaceID target,Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_FREE_INDEXES,
                                                  rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_layout_invalidation(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // Send this on the reference virtual channel since it's effects
      // are not being tracked and we need to know it is handled before
      // the remote objects have their references removed
      find_messenger(target)->send_message(
        SEND_FIELD_SPACE_LAYOUT_INVALIDATION, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_local_field_alloc_request(AddressSpaceID target,
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LOCAL_FIELD_ALLOC_REQUEST, rez,
                                                                true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_local_field_alloc_response(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LOCAL_FIELD_ALLOC_RESPONSE, rez,
                                               true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_local_field_free(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LOCAL_FIELD_FREE, rez,
                                                        true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_local_field_update(AddressSpaceID target,Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LOCAL_FIELD_UPDATE, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_top_level_region_request(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_TOP_LEVEL_REGION_REQUEST, rez,
                                                                true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_top_level_region_return(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_TOP_LEVEL_REGION_RETURN, rez,
                                            true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_destruction(IndexSpace handle, 
                                               AddressSpaceID target,
                                               std::set<RtEvent> &applied)
    //--------------------------------------------------------------------------
    {
      Serializer rez;
      {
        RezCheck z(rez);
        rez.serialize(handle);
        const RtUserEvent done = create_rt_user_event();
        rez.serialize(done);
        applied.insert(done);
      }
      // Put this message on the same virtual channel as the unregister
      // messages for distributed collectables to make sure that they 
      // are properly ordered
      find_messenger(target)->send_message(INDEX_SPACE_DESTRUCTION_MESSAGE,
                                                        rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_destruction(IndexPartition handle, 
                                                   AddressSpaceID target,
                                                   std::set<RtEvent> &applied)
    //--------------------------------------------------------------------------
    {
      Serializer rez;
      {
        RezCheck z(rez);
        rez.serialize(handle);
        const RtUserEvent done = create_rt_user_event();
        rez.serialize(done);
        applied.insert(done);
      }
      // Put this message on the same virtual channel as the unregister
      // messages for distributed collectables to make sure that they 
      // are properly ordered
      find_messenger(target)->send_message(
        INDEX_PARTITION_DESTRUCTION_MESSAGE, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_destruction(FieldSpace handle, 
                                               AddressSpaceID target,
                                               std::set<RtEvent> &applied)
    //--------------------------------------------------------------------------
    {
      Serializer rez;
      {
        RezCheck z(rez);
        rez.serialize(handle);
        const RtUserEvent done = create_rt_user_event();
        rez.serialize(done);
        applied.insert(done);
      }
      // Put this message on the same virtual channel as the unregister
      // messages for distributed collectables to make sure that they 
      // are properly ordered
      find_messenger(target)->send_message(FIELD_SPACE_DESTRUCTION_MESSAGE,
                                                          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_logical_region_destruction(LogicalRegion handle, 
                                                  AddressSpaceID target,
                                                  std::set<RtEvent> &applied)
    //--------------------------------------------------------------------------
    {
      Serializer rez;
      {
        RezCheck z(rez);
        rez.serialize(handle);
        const RtUserEvent done = create_rt_user_event();
        rez.serialize(done);
        applied.insert(done);
      }
      // Put this message on the same virtual channel as the unregister
      // messages for distributed collectables to make sure that they 
      // are properly ordered
      find_messenger(target)->send_message(LOGICAL_REGION_DESTRUCTION_MESSAGE,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_individual_remote_future_size(Processor target,
                                                     Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(INDIVIDUAL_REMOTE_FUTURE_SIZE,
                                      rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_individual_remote_output_registration(Processor target,
                                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        INDIVIDUAL_REMOTE_OUTPUT_REGISTRATION,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_individual_remote_mapped(Processor target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(INDIVIDUAL_REMOTE_MAPPED, rez,
                                          true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_individual_remote_complete(Processor target,
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(INDIVIDUAL_REMOTE_COMPLETE, rez,
                                          true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_individual_remote_commit(Processor target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(INDIVIDUAL_REMOTE_COMMIT, rez,
                                        true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_remote_mapped(Processor target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SLICE_REMOTE_MAPPED, rez,
                                    true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_remote_complete(Processor target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SLICE_REMOTE_COMPLETE, rez,
                                      true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_remote_commit(Processor target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SLICE_REMOTE_COMMIT, rez,
                                    true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_rendezvous_concurrent_mapped(Processor target,
                                                          Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SLICE_RENDEZVOUS_CONCURRENT_MAPPED,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_concurrent_allreduce_request(Processor target,
                                                              Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SLICE_CONCURRENT_ALLREDUCE_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_concurrent_allreduce_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SLICE_CONCURRENT_ALLREDUCE_RESPONSE,
          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_find_intra_space_dependence(Processor target,
                                                         Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SLICE_FIND_INTRA_DEP, rez,
                                                      true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_record_intra_space_dependence(Processor target,
                                                           Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SLICE_RECORD_INTRA_DEP, rez,
                                                         true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_remote_rendezvous(Processor target,Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SLICE_REMOTE_COLLECTIVE_RENDEZVOUS,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_remote_versioning_rendezvous(Processor target,
                                                          Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SLICE_REMOTE_VERSIONING_COLLECTIVE_RENDEZVOUS, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_remote_output_extents(Processor target, 
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SLICE_REMOTE_OUTPUT_EXTENTS, rez, 
          true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_slice_remote_output_registration(Processor target, 
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SLICE_REMOTE_OUTPUT_REGISTRATION,
          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_did_remote_registration(AddressSpaceID target, 
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(DISTRIBUTED_REMOTE_REGISTRATION, rez,
                                               true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_did_downgrade_request(AddressSpaceID target,
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(DISTRIBUTED_DOWNGRADE_REQUEST, rez,
                                                        true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_did_downgrade_response(AddressSpaceID target,
                                              Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(DISTRIBUTED_DOWNGRADE_RESPONSE, rez,
                                              true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_did_downgrade_success(AddressSpaceID target,
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(DISTRIBUTED_DOWNGRADE_SUCCESS, rez,
                                                        true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_did_downgrade_update(AddressSpaceID target,
                                              Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(DISTRIBUTED_DOWNGRADE_UPDATE, rez,
                                                              true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_did_downgrade_restart(AddressSpaceID target,
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(DISTRIBUTED_DOWNGRADE_RESTART, rez,
                                            true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_did_acquire_global_request(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(DISTRIBUTED_GLOBAL_ACQUIRE_REQUEST,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_did_acquire_global_response(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(DISTRIBUTED_GLOBAL_ACQUIRE_RESPONSE,
                                          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_did_acquire_valid_request(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(DISTRIBUTED_VALID_ACQUIRE_REQUEST,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_did_acquire_valid_response(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(DISTRIBUTED_VALID_ACQUIRE_RESPONSE,
                                          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_created_region_contexts(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_CREATED_REGION_CONTEXTS,
                                    rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_atomic_reservation_request(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_ATOMIC_RESERVATION_REQUEST, rez,
                                                                 true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_atomic_reservation_response(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_ATOMIC_RESERVATION_RESPONSE,
                                        rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_padded_reservation_request(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_PADDED_RESERVATION_REQUEST, rez,
                                                                 true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_padded_reservation_response(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_PADDED_RESERVATION_RESPONSE,
                                        rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_materialized_view(AddressSpaceID target,Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_MATERIALIZED_VIEW,
                              rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_fill_view(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FILL_VIEW,
                      rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_fill_view_value(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FILL_VIEW_VALUE,
                            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_phi_view(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_PHI_VIEW,
                      rez, true/*flush*/, true/*response*/); 
    }

    //--------------------------------------------------------------------------
    void Runtime::send_reduction_view(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REDUCTION_VIEW,
                           rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_replicated_view(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPLICATED_VIEW,
                           rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_allreduce_view(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_ALLREDUCE_VIEW,
                           rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_instance_manager(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INSTANCE_MANAGER,
                              rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_manager_update(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_MANAGER_UPDATE,
                          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_distribute_fill(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_DISTRIBUTE_FILL, rez,
                                                                 true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_distribute_point(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_DISTRIBUTE_POINT,
                                                          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_distribute_pointwise(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_DISTRIBUTE_POINTWISE, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_distribute_reduction(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_DISTRIBUTE_REDUCTION, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_distribute_broadcast(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_DISTRIBUTE_BROADCAST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_distribute_reducecast(AddressSpaceID target,
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_DISTRIBUTE_REDUCECAST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_distribute_hourglass(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_DISTRIBUTE_HOURGLASS, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_distribute_allreduce(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_DISTRIBUTE_ALLREDUCE, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_hammer_reduction(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_HAMMER_REDUCTION,
                                                          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_fuse_gather(AddressSpaceID target,
                                              Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_FUSE_GATHER,
                                                      rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_register_user_request(AddressSpaceID target,
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_USER_REQUEST,
                                                      rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_register_user_response(AddressSpaceID target,
                                                         Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_USER_RESPONSE,
                                    rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_individual_register_user(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_REGISTER_USER,
                                                        rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_remote_instances_request(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_REMOTE_INSTANCES_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_remote_instances_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_REMOTE_INSTANCES_RESPONSE,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_nearest_instances_request(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_NEAREST_INSTANCES_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_nearest_instances_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_NEAREST_INSTANCES_RESPONSE,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_remote_registration(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_REMOTE_REGISTRATION,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_finalize_mapping(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_FINALIZE_MAPPING,
                                          rez, true/*flush*/, true/*return*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_view_creation(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_VIEW_CREATION,
                                                        rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_view_deletion(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_VIEW_DELETION,
                                                        rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_view_release(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_VIEW_RELEASE,
                                                        rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_view_notification(AddressSpaceID target,
                                                    Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_VIEW_NOTIFICATION,
                                                        rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_view_make_valid(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_VIEW_MAKE_VALID,
                                                        rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_view_make_invalid(AddressSpaceID target,
                                                    Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_COLLECTIVE_VIEW_MAKE_INVALID,
                                                          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_view_invalidate_request(AddressSpaceID target,
                                                          Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_VIEW_INVALIDATE_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_view_invalidate_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_VIEW_INVALIDATE_RESPONSE,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_view_add_remote_reference(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_VIEW_ADD_REMOTE_REFERENCE, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_collective_view_remove_remote_reference(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COLLECTIVE_VIEW_REMOVE_REMOTE_REFERENCE, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_create_top_view_request(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_CREATE_TOP_VIEW_REQUEST, rez,
                                                              true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_create_top_view_response(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_CREATE_TOP_VIEW_RESPONSE, rez,
                                              true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_view_request(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_VIEW_REQUEST, rez, 
                                                    true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_view_register_user(AddressSpaceID target,Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_VIEW_REGISTER_USER, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_view_find_copy_preconditions_request(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_VIEW_FIND_COPY_PRE_REQUEST, rez,
                                                                 true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_view_add_copy_user(AddressSpaceID target,Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_VIEW_ADD_COPY_USER, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_view_find_last_users_request(AddressSpaceID target,
                                                    Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_VIEW_FIND_LAST_USERS_REQUEST,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_view_find_last_users_response(AddressSpaceID target,
                                                     Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_VIEW_FIND_LAST_USERS_RESPONSE,
                                          rez, true/*flush*/, true/*response*/);
    }

#ifdef ENABLE_VIEW_REPLICATION
    //--------------------------------------------------------------------------
    void Runtime::send_view_replication_request(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_VIEW_REPLICATION_REQUEST, rez,
                                                                true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_view_replication_response(AddressSpaceID target,
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_VIEW_REPLICATION_RESPONSE, rez,
                                              true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_view_replication_removal(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_VIEW_REPLICATION_REMOVAL, rez,
                                                                true/*flush*/);
    }
#endif

    //--------------------------------------------------------------------------
    void Runtime::send_future_result(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FUTURE_RESULT, rez,
                                  true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_future_result_size(AddressSpaceID target,Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // This message is asynchronous with other processes for futures so we
      // put it on the reference virtual channel to ensure that the future
      // is not collected before it arrives
      find_messenger(target)->send_message(SEND_FUTURE_RESULT_SIZE,
                                rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_future_subscription(AddressSpaceID target,
                                           Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // Since this message is fused with doing the remote registration for
      // the future it also needs to go on the same virtual channel as 
      // send_did_remote_registration which is the REFERENCE_VIRTUAL_CHANNEL 
      find_messenger(target)->send_message(SEND_FUTURE_SUBSCRIPTION, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_future_create_instance_request(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FUTURE_CREATE_INSTANCE_REQUEST,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_future_create_instance_response(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_FUTURE_CREATE_INSTANCE_RESPONSE,
          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_future_map_request_future(AddressSpaceID target,
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FUTURE_MAP_REQUEST, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_future_map_response_future(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FUTURE_MAP_RESPONSE, rez,
                                        true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_compute_equivalence_sets(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_REPL_COMPUTE_EQUIVALENCE_SETS, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_output_equivalence_set(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_REPL_OUTPUT_EQUIVALENCE_SET, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_refine_equivalence_sets(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_REPL_REFINE_EQUIVALENCE_SETS, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_equivalence_set_notification(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_REPL_EQUIVALENCE_SET_NOTIFICATION, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_intra_space_dependence(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_INTRA_SPACE_DEP,
                                                    rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_broadcast_update(AddressSpaceID target,
                                                          Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_BROADCAST_UPDATE,
                                                    rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_created_regions(AddressSpaceID target,
                                                         Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_CREATED_REGIONS,
                                                    rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_trace_event_request(
                                         AddressSpaceID target, Serializer &rez) 
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_TRACE_EVENT_REQUEST,
                                                      rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_trace_event_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_TRACE_EVENT_RESPONSE,
                                      rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_trace_event_trigger(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_TRACE_EVENT_TRIGGER,
                                      rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_trace_frontier_request(
                                         AddressSpaceID target, Serializer &rez) 
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_TRACE_FRONTIER_REQUEST,
                                                      rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_trace_frontier_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_TRACE_FRONTIER_RESPONSE,
                                        rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_trace_update(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_TRACE_UPDATE,
                                                rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_find_trace_local_sets(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_FIND_TRACE_SETS,
                                                rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_implicit_rendezvous(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_IMPLICIT_RENDEZVOUS,
                                                    rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_find_collective_view(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPL_FIND_COLLECTIVE_VIEW,
                                                          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_mapper_message(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_MAPPER_MESSAGE, rez,
                                                      true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_mapper_broadcast(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_MAPPER_BROADCAST, rez,
                                                        true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_task_impl_semantic_request(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_TASK_IMPL_SEMANTIC_REQ, rez,
                                                              true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_semantic_request(AddressSpaceID target,
                                                    Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_SPACE_SEMANTIC_REQ, rez,
                                                                true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_semantic_request(AddressSpaceID target,
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_PARTITION_SEMANTIC_REQ,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_semantic_request(AddressSpaceID target,
                                                    Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SPACE_SEMANTIC_REQ, rez,
                                                                true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_semantic_request(AddressSpaceID target,
                                              Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SEMANTIC_REQ, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_logical_region_semantic_request(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LOGICAL_REGION_SEMANTIC_REQ,
                                                          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_logical_partition_semantic_request(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LOGICAL_PARTITION_SEMANTIC_REQ,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_task_impl_semantic_info(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_TASK_IMPL_SEMANTIC_INFO, rez,
                                            true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_space_semantic_info(AddressSpaceID target,
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_SPACE_SEMANTIC_INFO, rez,
                                              true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_index_partition_semantic_info(AddressSpaceID target,
                                                     Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INDEX_PARTITION_SEMANTIC_INFO,
                                          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_space_semantic_info(AddressSpaceID target,
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SPACE_SEMANTIC_INFO, rez,
                                              true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_field_semantic_info(AddressSpaceID target,
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FIELD_SEMANTIC_INFO, rez,
                                        true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_logical_region_semantic_info(AddressSpaceID target,
                                                    Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LOGICAL_REGION_SEMANTIC_INFO,
                                        rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_logical_partition_semantic_info(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_LOGICAL_PARTITION_SEMANTIC_INFO,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_context_response(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REMOTE_CONTEXT_RESPONSE, rez,
                                            true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_context_physical_request(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_REMOTE_CONTEXT_PHYSICAL_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_context_physical_response(AddressSpaceID target,
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_REMOTE_CONTEXT_PHYSICAL_RESPONSE, rez,
              true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_context_find_collective_view_request(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_REMOTE_CONTEXT_FIND_COLLECTIVE_VIEW_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_context_find_collective_view_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_REMOTE_CONTEXT_FIND_COLLECTIVE_VIEW_RESPONSE, rez, 
              true/*flush*/, true/*response*/);
    } 

    //--------------------------------------------------------------------------
    void Runtime::send_remote_context_refine_equivalence_sets(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_REMOTE_CONTEXT_REFINE_EQUIVALENCE_SETS, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_context_find_trace_local_sets_request(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_REMOTE_CONTEXT_FIND_TRACE_LOCAL_SETS_REQUEST,
          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_context_find_trace_local_sets_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_REMOTE_CONTEXT_FIND_TRACE_LOCAL_SETS_RESPONSE,
          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_compute_equivalence_sets_request(AddressSpaceID target,
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COMPUTE_EQUIVALENCE_SETS_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_compute_equivalence_sets_response(AddressSpaceID target,
                                                         Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COMPUTE_EQUIVALENCE_SETS_RESPONSE,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_compute_equivalence_sets_pending(AddressSpaceID target,
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_COMPUTE_EQUIVALENCE_SETS_PENDING,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_output_equivalence_set_request(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_OUTPUT_EQUIVALENCE_SET_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_output_equivalence_set_response(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_OUTPUT_EQUIVALENCE_SET_RESPONSE,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_cancel_equivalence_sets_subscription(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_CANCEL_EQUIVALENCE_SETS_SUBSCRIPTION, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_invalidate_equivalence_sets_subscription(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_INVALIDATE_EQUIVALENCE_SETS_SUBSCRIPTION,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_creation(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EQUIVALENCE_SET_CREATION,
          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_reuse(AddressSpaceID target,
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EQUIVALENCE_SET_REUSE, rez,
                                              true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_response(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EQUIVALENCE_SET_RESPONSE, rez,
                                              true/*flush*/, true/*response*/);
    } 

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_replication_request(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_REPLICATION_REQUEST,
                                  rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_replication_response(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_REPLICATION_RESPONSE,
                rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_migration(AddressSpaceID target,
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EQUIVALENCE_SET_MIGRATION, rez,
                                              true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_owner_update(AddressSpaceID target,
                                                    Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_OWNER_UPDATE,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_clone_request(AddressSpaceID target,
                                                     Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EQUIVALENCE_SET_CLONE_REQUEST,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_clone_response(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EQUIVALENCE_SET_CLONE_RESPONSE,
                                          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_capture_request(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_CAPTURE_REQUEST,
                              rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_capture_response(AddressSpaceID target,
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_CAPTURE_RESPONSE,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_remote_request_instances(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_REMOTE_REQUEST_INSTANCES, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_remote_request_invalid(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_REMOTE_REQUEST_INVALID, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_remote_request_antivalid(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_EQUIVALENCE_SET_REMOTE_REQUEST_ANTIVALID,
                                    rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_remote_updates(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_REMOTE_UPDATES, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_remote_acquires(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_REMOTE_ACQUIRES, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_remote_releases(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_REMOTE_RELEASES, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_remote_copies_across(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_REMOTE_COPIES_ACROSS, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_remote_overwrites(AddressSpaceID target,
                                                         Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_REMOTE_OVERWRITES, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_remote_filters(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EQUIVALENCE_SET_REMOTE_FILTERS,
                                                            rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_remote_instances(AddressSpaceID target,
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_REMOTE_INSTANCES, rez,
              true/*flush*/, true/*return*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_equivalence_set_filter_invalidations(
        AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_EQUIVALENCE_SET_FILTER_INVALIDATIONS, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_instance_request(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INSTANCE_REQUEST, rez,
                                                        true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_instance_response(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_INSTANCE_RESPONSE, rez,
                                      true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_external_create_request(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EXTERNAL_CREATE_REQUEST, rez,
                                                              true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_external_create_response(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EXTERNAL_CREATE_RESPONSE, rez,
                                              true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_external_attach(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EXTERNAL_ATTACH, rez,
                                                      true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_external_detach(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_EXTERNAL_DETACH, rez,
                                                      true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_gc_priority_update(AddressSpaceID target,Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_GC_PRIORITY_UPDATE, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_gc_request(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_GC_REQUEST, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_gc_response(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_GC_RESPONSE, rez, 
                                true/*flush*/, true/*response*/);
    } 

    //--------------------------------------------------------------------------
    void Runtime::send_gc_acquire(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_GC_ACQUIRE, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_gc_failed(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_GC_FAILED, rez,
                                true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_gc_mismatch(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_GC_MISMATCH, rez,
                                true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_gc_notify(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_GC_NOTIFY, rez,
                                                true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_gc_debug_request(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_GC_DEBUG_REQUEST, rez,
                                                        true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_gc_debug_response(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_GC_DEBUG_RESPONSE, rez,
                                       true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_gc_record_event(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_GC_RECORD_EVENT, rez,
                                                        true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_acquire_request(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_ACQUIRE_REQUEST, rez,
                                                      true/*flush*/);
    }
    
    //--------------------------------------------------------------------------
    void Runtime::send_acquire_response(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_ACQUIRE_RESPONSE, rez,
                                      true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_variant_broadcast(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_VARIANT_BROADCAST, rez,
                                                        true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_constraint_request(AddressSpaceID target, 
                                           Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // This is paging in constraints so it needs its own virtual channel
      find_messenger(target)->send_message(SEND_CONSTRAINT_REQUEST,
                                                  rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_constraint_response(AddressSpaceID target, 
                                            Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // This is paging in constraints so it needs its own virtual channel
      find_messenger(target)->send_message(SEND_CONSTRAINT_RESPONSE, rez,
                                        true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_constraint_release(AddressSpaceID target,
                                           Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_CONSTRAINT_RELEASE,
                                                  rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_mpi_rank_exchange(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_MPI_RANK_EXCHANGE, rez,
                                                        true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_replicate_distribution(AddressSpaceID target,
                                              Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPLICATE_DISTRIBUTION,
                                           rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_replicate_collective_versioning(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPLICATE_COLLECTIVE_VERSIONING,
                                           rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_replicate_collective_mapping(AddressSpaceID target,
                                                    Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPLICATE_COLLECTIVE_MAPPING,
                                           rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_replicate_rendezvous_virtual_mappings(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPLICATE_VIRTUAL_RENDEZVOUS,
                                           rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_replicate_startup_complete(AddressSpaceID target, 
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPLICATE_STARTUP_COMPLETE,
                                                    rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_replicate_post_mapped(AddressSpaceID target, 
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPLICATE_POST_MAPPED,
                                                    rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_replicate_trigger_complete(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPLICATE_TRIGGER_COMPLETE,
                                                          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_replicate_trigger_commit(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REPLICATE_TRIGGER_COMMIT,
                                                        rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_control_replicate_rendezvous_message(
                                         AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_CONTROL_REPLICATE_RENDEZVOUS_MESSAGE,
                                rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_mapper_request(AddressSpaceID target, 
                                              Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_MAPPER_REQUEST, rez,
                                                              true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_mapper_response(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_MAPPER_RESPONSE, rez,
                                            true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_trace_request(AddressSpaceID target, 
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_TRACE_REQUEST, rez,
                                                            true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_trace_response(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_TRACE_RESPONSE, rez,
                                            true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_projection_request(AddressSpaceID target, 
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_PROJECTION_REQUEST, rez,
                                                                 true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_projection_response(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_PROJECTION_RESPONSE,
                                        rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_sharding_request(AddressSpaceID target, 
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_SHARDING_REQUEST,
                                                       rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_sharding_response(AddressSpaceID target,
                                                 Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_SHARDING_RESPONSE,
                                     rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_task_request(AddressSpaceID target, 
                                            Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_TASK_REQUEST, rez,
                                                            true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_task_response(AddressSpaceID target,
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_TASK_RESPONSE, rez,
                                          true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_redop_request(AddressSpaceID target, 
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_REDOP_REQUEST, rez,
                                                            true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_redop_response(AddressSpaceID target,
                                              Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_REDOP_RESPONSE, rez,
                                            true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_serdez_request(AddressSpaceID target, 
                                              Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_SERDEZ_REQUEST, rez,
                                                              true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_library_serdez_response(AddressSpaceID target,
                                               Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_LIBRARY_SERDEZ_RESPONSE, rez,
                                            true/*flush*/, true/*response*/);
    } 

    //--------------------------------------------------------------------------
    void Runtime::send_remote_op_report_uninitialized(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_REMOTE_OP_REPORT_UNINIT, rez,
                                                              true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_op_profiling_count_update(AddressSpaceID target,
                                                        Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_REMOTE_OP_PROFILING_COUNT_UPDATE, rez, 
          true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_op_completion_effect(AddressSpaceID target,
                                                   Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_REMOTE_OP_COMPLETION_EFFECT, rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_trace_update(AddressSpaceID target, 
                                           Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // All these messages must be on the same ordered virtual channel
      // so that they are ordered in their program order and handled on
      // the target node in this order as they would have been if they
      // were being handled directly on the owner node
      find_messenger(target)->send_message(SEND_REMOTE_TRACE_UPDATE, rez,
                                                          true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_remote_trace_response(AddressSpaceID target, 
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // No need for responses to be ordered so they can be handled on
      // the default virtual channel in whatever order
      find_messenger(target)->send_message(SEND_REMOTE_TRACE_RESPONSE, rez,
                                          true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_free_external_allocation(AddressSpaceID target,
                                                Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FREE_EXTERNAL_ALLOCATION,
                                      rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_notify_collected_instances(AddressSpaceID target,
                                                  Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_NOTIFY_COLLECTED_INSTANCES,
                                           rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_create_future_instance_request(AddressSpaceID target,
                                                      Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
        SEND_CREATE_FUTURE_INSTANCE_REQUEST,
                          rez, true/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_create_future_instance_response(AddressSpaceID target,
                                                       Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(
          SEND_CREATE_FUTURE_INSTANCE_RESPONSE,
            rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_free_future_instance(AddressSpaceID target,
                                            Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_FREE_FUTURE_INSTANCE,
                                rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_profiler_event_trigger(AddressSpaceID target,
                                              Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // Never flush these
      find_messenger(target)->send_message(SEND_PROFILER_EVENT_TRIGGER,
          rez, false/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_profiler_event_poison(AddressSpaceID target,
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      // Never flush these
      find_messenger(target)->send_message(SEND_PROFILER_EVENT_POISON,
          rez, false/*flush*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_shutdown_notification(AddressSpaceID target, 
                                             Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_SHUTDOWN_NOTIFICATION, rez,
                        true/*flush*/, false/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::send_shutdown_response(AddressSpaceID target, Serializer &rez)
    //--------------------------------------------------------------------------
    {
      find_messenger(target)->send_message(SEND_SHUTDOWN_RESPONSE, rez,
                        true/*flush*/, false/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_startup_barrier(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RtBarrier startup_barrier;
      derez.deserialize(startup_barrier);
      broadcast_startup_barrier(startup_barrier);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_task(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      TaskOp::process_unpack_task(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_steal(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Processor target;
      derez.deserialize(target);
      Processor thief;
      derez.deserialize(thief);
      int num_mappers;
      derez.deserialize(num_mappers);
      std::vector<MapperID> thieves(num_mappers);
      for (int idx = 0; idx < num_mappers; idx++)
        derez.deserialize(thieves[idx]);
#ifdef DEBUG_LEGION
      assert(proc_managers.find(target) != proc_managers.end());
#endif
      proc_managers[target]->process_steal_request(thief, thieves);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_advertisement(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Processor source;
      derez.deserialize(source);
      MapperID map_id;
      derez.deserialize(map_id);
      // Just advertise it to all the managers
      for (std::map<Processor,ProcessorManager*>::const_iterator it = 
            proc_managers.begin(); it != proc_managers.end(); it++)
      {
        it->second->process_advertisement(source, map_id);
      }
    }

#ifdef LEGION_USE_LIBDL
    //--------------------------------------------------------------------------
    void Runtime::handle_registration_callback(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(implicit_context == NULL);
      assert(implicit_runtime != NULL);
#endif
      DerezCheck z(derez);
      size_t dso_size;
      derez.deserialize(dso_size);
      const std::string dso_name((const char*)derez.get_current_pointer());
      derez.advance_pointer(dso_size);
      size_t sym_size;
      derez.deserialize(sym_size);
      const std::string sym_name((const char*)derez.get_current_pointer());
      derez.advance_pointer(sym_size);
      size_t buffer_size;
      derez.deserialize(buffer_size);
      const void *buffer = derez.get_current_pointer();
      if (buffer_size > 0)
        derez.advance_pointer(buffer_size);
      bool withargs;
      derez.deserialize<bool>(withargs);
      bool deduplicate;
      derez.deserialize(deduplicate);
      size_t dedup_tag;
      derez.deserialize(dedup_tag);
      RtEvent global_done_event;
      derez.deserialize(global_done_event);
      RtUserEvent done_event;
      derez.deserialize(done_event);

      // Converting the DSO reference could call dlopen and might block
      // us if the constructor for that shared object requests its own
      // global registration callback, so register our guards first
      const RegistrationKey key(dedup_tag, dso_name, sym_name);
      if (deduplicate)
      {
        AutoLock c_lock(callback_lock);
        // First see if the local case has already been done in which case
        // we know that we are done also when it is done
        std::map<RegistrationKey,RtEvent>::const_iterator finder =
          global_local_done.find(key);
        if (finder != global_local_done.end())
        {
          Runtime::trigger_event(done_event, finder->second);
          return;
        }
        // No one has attempted a global registration callback here yet
        // Record that we are pending and put in a guard for all the
        // of the global registrations being done
        if (global_callbacks_done.find(key) == global_callbacks_done.end())
          global_callbacks_done[key] = global_done_event;
        pending_remote_callbacks[key].insert(done_event);
      }

      // Now we can do the translation of ourselves to get the function pointer
      Realm::DSOReferenceImplementation dso(dso_name, sym_name);
#ifdef DEBUG_LEGION
      assert(callback_translator.can_translate(
            typeid(Realm::DSOReferenceImplementation),
            typeid(Realm::FunctionPointerImplementation)));
#endif
      Realm::FunctionPointerImplementation *impl = 
        static_cast<Realm::FunctionPointerImplementation*>(
            callback_translator.translate(&dso, 
              typeid(Realm::FunctionPointerImplementation)));
#ifdef DEBUG_LEGION
      assert(impl != NULL);
#endif
      void* callback = impl->get_impl<void*>();
      RtEvent precondition;
      // Now take the lock and see if we need to perform anything
      if (deduplicate)
      {
        AutoLock c_lock(callback_lock);
        std::map<RegistrationKey,std::set<RtUserEvent> >::iterator finder =
            pending_remote_callbacks.find(key);
        // If someone already handled everything then we are done
        if (finder != pending_remote_callbacks.end())
        {
          // We should still be in there
#ifdef DEBUG_LEGION
          assert(finder->second.find(done_event) != finder->second.end());
#endif
          finder->second.erase(done_event);
          if (finder->second.empty())
            pending_remote_callbacks.erase(finder);
          // Now see if anyone else has done the local registration
          std::map<void*,RtEvent>::const_iterator
            finder = local_callbacks_done.find(callback);
          if (finder != local_callbacks_done.end())
          {
#ifdef DEBUG_LEGION
            assert(finder->second.exists());
#endif
            precondition = finder->second;
          }
          else
          {
            local_callbacks_done[callback] = done_event;
            global_local_done[key] = done_event; 
          }
        }
        else // We were already handled so nothing to do
          done_event = RtUserEvent::NO_RT_USER_EVENT;
      }
      if (!deduplicate || done_event.exists())
      {
        // This is the signal that we need to do the callback
        if (!precondition.exists())
        {
          inside_registration_callback = GLOBAL_REGISTRATION_CALLBACK;
          if (withargs)
          {
            RegistrationWithArgsCallbackFnptr callbackwithargs =
              (RegistrationWithArgsCallbackFnptr)callback;
            RegistrationCallbackArgs args{ machine, external, 
              local_procs, UntypedBuffer(buffer, buffer_size) };
            (*callbackwithargs)(args);
          }
          else
          {
            RegistrationCallbackFnptr callbackwithoutargs =
              (RegistrationCallbackFnptr)callback;
            (*callbackwithoutargs)(machine, external, local_procs);
          }
          inside_registration_callback = NO_REGISTRATION_CALLBACK;
        }
        if (done_event.exists())
          Runtime::trigger_event(done_event, precondition);
      }
      // Delete our resources that we allocated
      delete impl;
    }
#endif // LEGION_USE_LIBDL

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_task_replay(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      TaskOp::process_remote_replay(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_task_profiling_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      SingleTask::process_remote_profiling_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_shared_ownership(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      int kind;
      derez.deserialize(kind);
      switch (kind)
      {
        case 0:
          {
            IndexSpace handle;
            derez.deserialize(handle);
            create_shared_ownership(handle, false, true);
            break;
          }
        case 1:
          {
            IndexPartition handle;
            derez.deserialize(handle);
            create_shared_ownership(handle, false, true);
            break;
          }
        case 2:
          {
            FieldSpace handle;
            derez.deserialize(handle);
            create_shared_ownership(handle, false, true);
            break;
          }
        case 3:
          {
            LogicalRegion handle;
            derez.deserialize(handle);
            create_shared_ownership(handle, false, true);
            break;
          }
        default:
          assert(false);
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_node_request(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_response(Deserializer &derez,
                                              AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_node_creation(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_return(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_node_return(forest, derez); 
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_set(Deserializer &derez,
                                         AddressSpaceID source) 
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_index_space_set(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_child_request(Deserializer &derez,
                                                   AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_node_child_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_child_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_node_child_response(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_colors_request(Deserializer &derez,
                                                    AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_colors_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_colors_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_colors_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_remote_expression_request(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      forest->handle_remote_expression_request(derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_remote_expression_response(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      forest->handle_remote_expression_response(derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_generate_color_request(Deserializer &derez,
                                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_generate_color_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_generate_color_response(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_generate_color_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_release_color(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_release_color(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_notification(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_notification(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_node_request(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_response(Deserializer &derez,
                                                  AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_node_creation(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_return(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_node_return(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_child_request(Deserializer &derez,
                                                       AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_node_child_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_child_response(Deserializer &derez,
                                                        AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_node_child_response(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_child_replication(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_child_replication(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_disjoint_update(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_node_disjoint_update(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_shard_rects_request(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_shard_rects_request(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_shard_rects_response(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_shard_rects_response(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_remote_interference_request(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_remote_interference_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_remote_interference_response(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_remote_interference_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_node(Deserializer &derez, 
                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_node_creation(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_node_request(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_return(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_node_return(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_allocator_request(Deserializer &derez,
                                                       AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_allocator_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_allocator_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_allocator_response(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_allocator_invalidation(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_allocator_invalidation(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_allocator_flush(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_allocator_flush(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_allocator_free(Deserializer &derez,
                                                    AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_allocator_free(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_infos_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_infos_request(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_infos_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_infos_response(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_alloc_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_alloc_request(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_size_update(Deserializer &derez,
                                           AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_field_size_update(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_free(Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_field_free(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_free_indexes(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_field_free_indexes(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_layout_invalidation(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_layout_invalidation(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_local_field_alloc_request(Deserializer &derez,
                                                   AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_local_alloc_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_local_field_alloc_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_local_alloc_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_local_field_free(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_local_free(forest, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_local_field_update(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_local_field_update(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_top_level_region_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RegionNode::handle_top_level_request(forest, derez); 
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_top_level_region_return(Deserializer &derez,
                                                 AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      RegionNode::handle_top_level_return(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_destruction(Deserializer &derez,
                                                 AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      IndexSpace handle;
      derez.deserialize(handle);
      RtUserEvent done;
      derez.deserialize(done);
#ifdef DEBUG_LEGION
      assert(done.exists());
#endif
      std::set<RtEvent> applied;
      forest->destroy_index_space(handle, source, applied);
      if (!applied.empty())
        Runtime::trigger_event(done, Runtime::merge_events(applied));
      else
        Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_destruction(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      IndexPartition handle;
      derez.deserialize(handle);
      RtUserEvent done;
      derez.deserialize(done);
#ifdef DEBUG_LEGION
      assert(done.exists());
#endif
      std::set<RtEvent> applied;
      forest->destroy_index_partition(handle, applied);
      if (!applied.empty())
        Runtime::trigger_event(done, Runtime::merge_events(applied));
      else
        Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_destruction(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      FieldSpace handle;
      derez.deserialize(handle);
      RtUserEvent done;
      derez.deserialize(done);
#ifdef DEBUG_LEGION
      assert(done.exists());
#endif
      std::set<RtEvent> applied;
      forest->destroy_field_space(handle, applied);
      if (!applied.empty())
        Runtime::trigger_event(done, Runtime::merge_events(applied));
      else
        Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_logical_region_destruction(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      LogicalRegion handle;
      derez.deserialize(handle);
      RtUserEvent done;
      derez.deserialize(done);
      std::set<RtEvent> applied;
      forest->destroy_logical_region(handle, applied);
      if (done.exists())
      {
        if (!applied.empty())
          Runtime::trigger_event(done, Runtime::merge_events(applied));
        else
          Runtime::trigger_event(done);
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_individual_remote_future_size(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndividualTask::process_unpack_remote_future_size(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_individual_remote_output_registration(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndividualTask::handle_remote_output_registration(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_individual_remote_mapped(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndividualTask::process_unpack_remote_mapped(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_individual_remote_complete(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndividualTask::process_unpack_remote_complete(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_individual_remote_commit(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndividualTask::process_unpack_remote_commit(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_remote_mapped(Deserializer &derez,
                                             AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexTask::process_slice_mapped(derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_remote_complete(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexTask::process_slice_complete(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_remote_commit(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexTask::process_slice_commit(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_rendezvous_concurrent_mapped(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      SliceTask::handle_rendezvous_concurrent_mapped(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_concurrent_allreduce_request(Deserializer &derez,
                                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      SliceTask::handle_concurrent_allreduce_request(derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_concurrent_allreduce_response(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      SliceTask::handle_concurrent_allreduce_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_find_intra_dependence(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexTask::process_slice_find_intra_dependence(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_record_intra_dependence(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndexTask::process_slice_record_intra_dependence(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_remote_collective_rendezvous(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      SliceTask::handle_collective_rendezvous(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_remote_collective_versioning_rendezvous(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      SliceTask::handle_collective_versioning_rendezvous(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_remote_output_extents(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      SliceTask::handle_remote_output_extents(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_slice_remote_output_registration(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      SliceTask::handle_remote_output_registration(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_did_remote_registration(Deserializer &derez,
                                                 AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DistributedCollectable::handle_did_remote_registration(this,derez,source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_created_region_contexts(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_created_region_contexts(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_atomic_reservation_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndividualView::handle_atomic_reservation_request(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_atomic_reservation_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndividualView::handle_atomic_reservation_response(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_padded_reservation_request(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_padded_reservation_request(this, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_padded_reservation_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_padded_reservation_response(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_materialized_view(Deserializer &derez) 
    //--------------------------------------------------------------------------
    {
      MaterializedView::handle_send_materialized_view(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_fill_view(Deserializer &derez) 
    //--------------------------------------------------------------------------
    {
      FillView::handle_send_fill_view(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_fill_view_value(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FillView::handle_send_fill_view_value(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_phi_view(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhiView::handle_send_phi_view(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_reduction_view(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ReductionView::handle_send_reduction_view(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_replicated_view(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ReplicatedView::handle_send_replicated_view(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_allreduce_view(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      AllreduceView::handle_send_allreduce_view(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_instance_manager(Deserializer &derez,
                                               AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_send_manager(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_send_manager_update(Deserializer &derez,
                                             AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_send_manager_update(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_distribute_fill(Deserializer &derez,
                                                    AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_distribute_fill(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_distribute_point(Deserializer &derez,
                                                     AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_distribute_point(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_distribute_pointwise(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_distribute_pointwise(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_distribute_reduction(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      AllreduceView::handle_distribute_reduction(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_distribute_broadcast(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_distribute_broadcast(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_distribute_reducecast(Deserializer &derez,
                                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_distribute_reducecast(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_distribute_hourglass(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_distribute_hourglass(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_distribute_allreduce(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      AllreduceView::handle_distribute_allreduce(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_hammer_reduction(Deserializer &derez,
                                                     AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      AllreduceView::handle_hammer_reduction(this, source, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_fuse_gather(Deserializer &derez,
                                                AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_fuse_gather(this, source, derez); 
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_user_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_register_user_request(this, derez);
    } 

    //--------------------------------------------------------------------------
    void Runtime::handle_did_downgrade_request(Deserializer &derez,
                                               AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DistributedCollectable::handle_downgrade_request(this, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_did_downgrade_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DistributedCollectable::handle_downgrade_response(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_did_downgrade_success(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DistributedCollectable::handle_downgrade_success(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_did_downgrade_update(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DistributedCollectable::handle_downgrade_update(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_did_downgrade_restart(Deserializer &derez,
                                               AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DistributedCollectable::handle_downgrade_restart(this, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_did_global_acquire_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DistributedCollectable::handle_global_acquire_request(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_did_global_acquire_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DistributedCollectable::handle_global_acquire_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_did_valid_acquire_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ValidDistributedCollectable::handle_valid_acquire_request(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_did_valid_acquire_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ValidDistributedCollectable::handle_valid_acquire_response(derez);
    }
    
    //--------------------------------------------------------------------------
    void Runtime::handle_collective_user_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_register_user_response(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_user_registration(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndividualView::handle_collective_user_registration(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_remote_instances_request(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_remote_instances_request(this, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_remote_instances_response(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_remote_instances_response(this, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_nearest_instances_request(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_nearest_instances_request(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_nearest_instances_response(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_nearest_instances_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_remote_registration(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_remote_analysis_registration(derez, this);
    }
    
    //--------------------------------------------------------------------------
    void Runtime::handle_collective_finalize_mapping(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveViewCreatorBase::handle_finalize_collective_mapping(derez,this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_view_creation(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      InnerContext::handle_create_collective_view(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_view_deletion(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      InnerContext::handle_delete_collective_view(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_view_release(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      InnerContext::handle_release_collective_view(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_view_notification(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_collective_view_deletion(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_view_make_valid(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_make_valid(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_view_make_invalid(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_make_invalid(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_view_invalidate_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_invalidate_request(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_view_invalidate_response(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_invalidate_response(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_view_add_remote_reference(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_add_remote_reference(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_collective_view_remove_remote_reference(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      CollectiveView::handle_remove_remote_reference(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_create_top_view_request(Deserializer &derez,
                                                 AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_top_view_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_create_top_view_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_top_view_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_view_request(Deserializer &derez) 
    //--------------------------------------------------------------------------
    {
      LogicalView::handle_view_request(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_manager_request(Deserializer &derez) 
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_manager_request(derez, this);
    }

#ifdef ENABLE_VIEW_REPLICATION
    //--------------------------------------------------------------------------
    void Runtime::handle_view_replication_request(Deserializer &derez,
                                                  AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      InstanceView::handle_view_replication_request(derez, this, source);
    }
    
    //--------------------------------------------------------------------------
    void Runtime::handle_view_replication_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      InstanceView::handle_view_replication_response(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_view_replication_removal(Deserializer &derez,
                                                  AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      InstanceView::handle_view_replication_removal(derez, this, source);
    }
#endif // ENABLE_VIEW_REPLICATION

    //--------------------------------------------------------------------------
    void Runtime::handle_future_result(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FutureImpl::handle_future_result(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_future_result_size(Deserializer &derez,
                                            AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FutureImpl::handle_future_result_size(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_future_subscription(Deserializer &derez,
                                             AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FutureImpl::handle_future_subscription(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_future_map_future_request(Deserializer &derez,
                                                   AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FutureMapImpl::handle_future_map_future_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_future_map_future_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FutureMapImpl::handle_future_map_future_response(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_future_create_instance_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FutureImpl::handle_future_create_instance_request(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_future_create_instance_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FutureImpl::handle_future_create_instance_response(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_compute_equivalence_sets(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_compute_equivalence_sets(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_output_equivalence_set(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_output_equivalence_set(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_refine_equivalence_sets(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_refine_equivalence_sets(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_equivalence_set_notification(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_equivalence_set_notification(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_intra_space_dependence(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_intra_space_dependence(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_broadcast_update(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_broadcast_update(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_created_regions(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_created_regions(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_trace_event_request(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_trace_event_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_trace_event_response(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_trace_event_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_trace_event_trigger(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_trace_event_trigger(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_trace_frontier_request(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_trace_frontier_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_trace_frontier_response(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_trace_frontier_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_trace_update(Deserializer &derez,
                                                        AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_trace_update(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_find_trace_local_sets(
        Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_find_trace_local_sets(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_implicit_rendezvous(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ImplicitShardManager::handle_remote_rendezvous(derez, this);  
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_find_collective_view(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_find_collective_view(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_view_register_user(Deserializer &derez,
                                            AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      InstanceView::handle_view_register_user(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_view_copy_pre_request(Deserializer &derez,
                                               AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndividualView::handle_view_find_copy_pre_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_view_add_copy_user(Deserializer &derez,
                                            AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndividualView::handle_view_add_copy_user(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_view_find_last_users_request(Deserializer &derez,
                                                      AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndividualView::handle_view_find_last_users_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_view_find_last_users_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      IndividualView::handle_view_find_last_users_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_mapper_message(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Processor target;
      derez.deserialize(target);
      MapperID map_id;
      derez.deserialize(map_id);
      Processor source;
      derez.deserialize(source);
      unsigned message_kind;
      derez.deserialize(message_kind);
      size_t message_size;
      derez.deserialize(message_size);
      const void *message = derez.get_current_pointer();
      derez.advance_pointer(message_size);
      process_mapper_message(target, map_id, source, message, 
                             message_size, message_kind);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_mapper_broadcast(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      MapperID map_id;
      derez.deserialize(map_id);
      Processor source;
      derez.deserialize(source);
      unsigned message_kind;
      derez.deserialize(message_kind);
      int radix;
      derez.deserialize(radix);
      int index;
      derez.deserialize(index);
      size_t message_size;
      derez.deserialize(message_size);
      const void *message = derez.get_current_pointer();
      derez.advance_pointer(message_size);
      process_mapper_broadcast(map_id, source, message, 
                               message_size, message_kind, radix, index);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_task_impl_semantic_request(Deserializer &derez,
                                                     AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      TaskImpl::handle_semantic_request(this, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_semantic_request(Deserializer &derez,
                                                      AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_semantic_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_semantic_request(Deserializer &derez, 
                                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_semantic_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_semantic_request(Deserializer &derez,
                                                      AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_semantic_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_semantic_request(Deserializer &derez,
                                                AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_field_semantic_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_logical_region_semantic_request(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      RegionNode::handle_semantic_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_logical_partition_semantic_request(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PartitionNode::handle_semantic_request(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_task_impl_semantic_info(Deserializer &derez,
                                                  AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      TaskImpl::handle_semantic_info(this, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_space_semantic_info(Deserializer &derez,
                                                   AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexSpaceNode::handle_semantic_info(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_index_partition_semantic_info(Deserializer &derez, 
                                                       AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      IndexPartNode::handle_semantic_info(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_space_semantic_info(Deserializer &derez,
                                                   AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_semantic_info(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_field_semantic_info(Deserializer &derez,
                                             AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_field_semantic_info(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_logical_region_semantic_info(Deserializer &derez,
                                                      AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      RegionNode::handle_semantic_info(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_logical_partition_semantic_info(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PartitionNode::handle_semantic_info(forest, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_context_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_context_request(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_context_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_context_response(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_context_physical_request(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_physical_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_context_physical_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_physical_response(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_context_find_collective_view_request(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_find_collective_view_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_context_find_collective_view_response(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_find_collective_view_response(derez, this);
    } 

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_context_refine_equivalence_sets(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_refine_equivalence_sets(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_context_find_trace_local_sets_request(
        Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_find_trace_local_sets_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_context_find_trace_local_sets_response(
        Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteContext::handle_find_trace_local_sets_response(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_compute_equivalence_sets_request(Deserializer &derez,
                                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      InnerContext::handle_compute_equivalence_sets_request(derez, this,source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_compute_equivalence_sets_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      InnerContext::handle_compute_equivalence_sets_response(derez, this); 
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_compute_equivalence_sets_pending(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      EqSetTracker::handle_pending_equivalence_set(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_output_equivalence_set_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      InnerContext::handle_output_equivalence_set_request(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_output_equivalence_set_response(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      InnerContext::handle_output_equivalence_set_response(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_cancel_equivalence_sets_subscription(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      EqSetTracker::handle_cancel_subscription(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_invalidate_equivalence_sets_subscription(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      EqSetTracker::handle_invalidate_subscription(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_creation(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      EqSetTracker::handle_equivalence_set_creation(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_reuse(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      EqSetTracker::handle_equivalence_set_reuse(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_request(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_equivalence_set_request(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_equivalence_set_response(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_replication_request(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_replication_request(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_replication_response(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_replication_response(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_migration(Deserializer &derez,
                                                   AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_migration(derez, this, source); 
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_owner_update(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_owner_update(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_clone_request(Deserializer &derez,
                                                       AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_clone_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_clone_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_clone_response(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_capture_request(Deserializer &derez,
                                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_capture_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_capture_response(Deserializer &derez,
                                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_capture_response(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_remote_request_instances(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      ValidInstAnalysis::handle_remote_request_instances(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_remote_request_invalid(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      InvalidInstAnalysis::handle_remote_request_invalid(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_remote_request_antivalid(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      AntivalidInstAnalysis::handle_remote_request_antivalid(derez,this,source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_remote_updates(Deserializer &derez,
                                                        AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      UpdateAnalysis::handle_remote_updates(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_remote_acquires(Deserializer &derez,
                                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      AcquireAnalysis::handle_remote_acquires(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_remote_releases(Deserializer &derez,
                                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      ReleaseAnalysis::handle_remote_releases(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_remote_copies_across(
                                     Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      CopyAcrossAnalysis::handle_remote_copies_across(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_remote_overwrites(Deserializer &derez,
                                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      OverwriteAnalysis::handle_remote_overwrites(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_remote_filters(Deserializer &derez,
                                                        AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FilterAnalysis::handle_remote_filters(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_remote_instances(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhysicalAnalysis::handle_remote_instances(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_equivalence_set_filter_invalidations(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      EquivalenceSet::handle_filter_invalidations(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_instance_request(Deserializer &derez, 
                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Memory target_memory;
      derez.deserialize(target_memory);
      MemoryManager *manager = find_memory_manager(target_memory);
      manager->process_instance_request(derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_instance_response(Deserializer &derez,
                                           AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Memory target_memory;
      derez.deserialize(target_memory);
      MemoryManager *manager = find_memory_manager(target_memory);
      manager->process_instance_response(derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_external_create_request(Deserializer &derez,
                                                 AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_external_create_request(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_external_create_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      FieldSpaceNode::handle_external_create_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_external_attach(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Memory target_memory;
      derez.deserialize(target_memory);
      DistributedID did;
      derez.deserialize(did);
      RtEvent manager_ready;
      PhysicalManager *manager = 
        find_or_request_instance_manager(did, manager_ready);
      RtUserEvent done_event;
      derez.deserialize(done_event);
      MemoryManager *memory_manager = find_memory_manager(target_memory);
      if (manager_ready.exists() && !manager_ready.has_triggered())
        manager_ready.wait();
      RtEvent local_done = memory_manager->attach_external_instance(manager);
      Runtime::trigger_event(done_event, local_done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_external_detach(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      Memory target_memory;
      derez.deserialize(target_memory);
      DistributedID did;
      derez.deserialize(did);
      RtEvent manager_ready;
      PhysicalManager *manager = 
        find_or_request_instance_manager(did, manager_ready);
      MemoryManager *memory_manager = find_memory_manager(target_memory);
      if (manager_ready.exists() && !manager_ready.has_triggered())
        manager_ready.wait();
      memory_manager->detach_external_instance(manager);
      manager->unpack_valid_ref();
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_gc_priority_update(Deserializer &derez,
                                            AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_garbage_collection_priority_update(this, derez,
                                                                 source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_gc_request(Deserializer &derez, AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_garbage_collection_request(this, derez, source); 
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_gc_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_garbage_collection_response(derez); 
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_gc_acquire(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_garbage_collection_acquire(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_gc_failed(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_garbage_collection_failed(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_gc_mismatch(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_garbage_collection_mismatch(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_gc_notify(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_garbage_collection_notify(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_gc_debug_request(Deserializer &derez,
                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_garbage_collection_debug_request(this, derez,
                                                               source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_gc_debug_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_garbage_collection_debug_response(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_gc_record_event(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_record_event(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_acquire_request(Deserializer &derez, 
                                         AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_acquire_request(this, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_acquire_response(Deserializer &derez, 
                                          AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      PhysicalManager::handle_acquire_response(derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_variant_broadcast(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      VariantImpl::handle_variant_broadcast(this, derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_constraint_request(Deserializer &derez,
                                             AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      LayoutConstraints::process_request(this, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_constraint_response(Deserializer &derez,
                                             AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      LayoutConstraints::process_response(this, derez, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_constraint_release(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      LayoutConstraintID layout_id;
      derez.deserialize(layout_id);
      release_layout(layout_id);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_top_level_task_complete(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      decrement_outstanding_top_level_tasks();
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_mpi_rank_exchange(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(Runtime::mpi_rank_table != NULL);
#endif
      Runtime::mpi_rank_table->handle_mpi_rank_exchange(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_replicate_distribution(Deserializer &derez) 
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_distribution(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_replicate_collective_versioning(Deserializer &derez) 
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_collective_versioning(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_replicate_collective_mapping(Deserializer &derez) 
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_collective_mapping(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_replicate_virtual_rendezvous(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_virtual_rendezvous(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_replicate_startup_complete(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_startup_complete(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_replicate_post_mapped(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_post_mapped(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_replicate_trigger_complete(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_trigger_complete(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_replicate_trigger_commit(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_trigger_commit(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_control_replicate_rendezvous_message(
                                                            Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      ShardManager::handle_rendezvous_message(derez, this);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_mapper_request(Deserializer &derez,
                                                AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      size_t count;
      derez.deserialize(count);
      RtUserEvent done;
      derez.deserialize(done);
      
      MapperID result = generate_library_mapper_ids(name, count);
      Serializer rez;
      {
        RezCheck z2(rez);
        rez.serialize(string_length);
        rez.serialize(name, string_length);
        rez.serialize(result);
        rez.serialize(done);
      }
      send_library_mapper_response(source, rez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_mapper_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      MapperID result;
      derez.deserialize(result);
      RtUserEvent done;
      derez.deserialize(done);

      const std::string library_name(name);
      {
        AutoLock l_lock(library_lock); 
        std::map<std::string,LibraryMapperIDs>::iterator finder = 
          library_mapper_ids.find(library_name);
#ifdef DEBUG_LEGION
        assert(finder != library_mapper_ids.end());
        assert(!finder->second.result_set);
        assert(finder->second.ready == done);
#endif
        finder->second.result = result;
        finder->second.result_set = true;
      }
      Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_trace_request(Deserializer &derez,
                                               AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      size_t count;
      derez.deserialize(count);
      RtUserEvent done;
      derez.deserialize(done);
      
      TraceID result = generate_library_trace_ids(name, count);
      Serializer rez;
      {
        RezCheck z2(rez);
        rez.serialize(string_length);
        rez.serialize(name, string_length);
        rez.serialize(result);
        rez.serialize(done);
      }
      send_library_trace_response(source, rez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_trace_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      TraceID result;
      derez.deserialize(result);
      RtUserEvent done;
      derez.deserialize(done);

      const std::string library_name(name);
      {
        AutoLock l_lock(library_lock); 
        std::map<std::string,LibraryTraceIDs>::iterator finder = 
          library_trace_ids.find(library_name);
#ifdef DEBUG_LEGION
        assert(finder != library_trace_ids.end());
        assert(!finder->second.result_set);
        assert(finder->second.ready == done);
#endif
        finder->second.result = result;
        finder->second.result_set = true;
      }
      Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_projection_request(Deserializer &derez,
                                                    AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      size_t count;
      derez.deserialize(count);
      RtUserEvent done;
      derez.deserialize(done);
      
      ProjectionID result = generate_library_projection_ids(name, count);
      Serializer rez;
      {
        RezCheck z2(rez);
        rez.serialize(string_length);
        rez.serialize(name, string_length);
        rez.serialize(result);
        rez.serialize(done);
      }
      send_library_projection_response(source, rez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_projection_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      ProjectionID result;
      derez.deserialize(result);
      RtUserEvent done;
      derez.deserialize(done);

      const std::string library_name(name);
      {
        AutoLock l_lock(library_lock); 
        std::map<std::string,LibraryProjectionIDs>::iterator finder = 
          library_projection_ids.find(library_name);
#ifdef DEBUG_LEGION
        assert(finder != library_projection_ids.end());
        assert(!finder->second.result_set);
        assert(finder->second.ready == done);
#endif
        finder->second.result = result;
        finder->second.result_set = true;
      }
      Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_sharding_request(Deserializer &derez,
                                                  AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      size_t count;
      derez.deserialize(count);
      RtUserEvent done;
      derez.deserialize(done);
      
      ShardingID result = generate_library_sharding_ids(name, count);
      Serializer rez;
      {
        RezCheck z2(rez);
        rez.serialize(string_length);
        rez.serialize(name, string_length);
        rez.serialize(result);
        rez.serialize(done);
      }
      send_library_sharding_response(source, rez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_sharding_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      ShardingID result;
      derez.deserialize(result);
      RtUserEvent done;
      derez.deserialize(done);

      const std::string library_name(name);
      {
        AutoLock l_lock(library_lock); 
        std::map<std::string,LibraryShardingIDs>::iterator finder = 
          library_sharding_ids.find(library_name);
#ifdef DEBUG_LEGION
        assert(finder != library_sharding_ids.end());
        assert(!finder->second.result_set);
        assert(finder->second.ready == done);
#endif
        finder->second.result = result;
        finder->second.result_set = true;
      }
      Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_task_request(Deserializer &derez,
                                              AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      size_t count;
      derez.deserialize(count);
      RtUserEvent done;
      derez.deserialize(done);
      
      TaskID result = generate_library_task_ids(name, count);
      Serializer rez;
      {
        RezCheck z2(rez);
        rez.serialize(string_length);
        rez.serialize(name, string_length);
        rez.serialize(result);
        rez.serialize(done);
      }
      send_library_task_response(source, rez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_task_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      TaskID result;
      derez.deserialize(result);
      RtUserEvent done;
      derez.deserialize(done);

      const std::string library_name(name);
      {
        AutoLock l_lock(library_lock); 
        std::map<std::string,LibraryTaskIDs>::iterator finder = 
          library_task_ids.find(library_name);
#ifdef DEBUG_LEGION
        assert(finder != library_task_ids.end());
        assert(!finder->second.result_set);
        assert(finder->second.ready == done);
#endif
        finder->second.result = result;
        finder->second.result_set = true;
      }
      Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_redop_request(Deserializer &derez,
                                               AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      size_t count;
      derez.deserialize(count);
      RtUserEvent done;
      derez.deserialize(done);
      
      ReductionOpID result = generate_library_reduction_ids(name, count);
      Serializer rez;
      {
        RezCheck z2(rez);
        rez.serialize(string_length);
        rez.serialize(name, string_length);
        rez.serialize(result);
        rez.serialize(done);
      }
      send_library_redop_response(source, rez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_redop_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      ReductionOpID result;
      derez.deserialize(result);
      RtUserEvent done;
      derez.deserialize(done);

      const std::string library_name(name);
      {
        AutoLock l_lock(library_lock); 
        std::map<std::string,LibraryRedopIDs>::iterator finder = 
          library_redop_ids.find(library_name);
#ifdef DEBUG_LEGION
        assert(finder != library_redop_ids.end());
        assert(!finder->second.result_set);
        assert(finder->second.ready == done);
#endif
        finder->second.result = result;
        finder->second.result_set = true;
      }
      Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_serdez_request(Deserializer &derez,
                                                AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      size_t count;
      derez.deserialize(count);
      RtUserEvent done;
      derez.deserialize(done);
      
      CustomSerdezID result = generate_library_serdez_ids(name, count);
      Serializer rez;
      {
        RezCheck z2(rez);
        rez.serialize(string_length);
        rez.serialize(name, string_length);
        rez.serialize(result);
        rez.serialize(done);
      }
      send_library_serdez_response(source, rez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_library_serdez_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DerezCheck z(derez);
      size_t string_length;
      derez.deserialize(string_length);
      const char *name = (const char*)derez.get_current_pointer();
      derez.advance_pointer(string_length);
      CustomSerdezID result;
      derez.deserialize(result);
      RtUserEvent done;
      derez.deserialize(done);

      const std::string library_name(name);
      {
        AutoLock l_lock(library_lock); 
        std::map<std::string,LibrarySerdezIDs>::iterator finder = 
          library_serdez_ids.find(library_name);
#ifdef DEBUG_LEGION
        assert(finder != library_serdez_ids.end());
        assert(!finder->second.result_set);
        assert(finder->second.ready == done);
#endif
        finder->second.result = result;
        finder->second.result_set = true;
      }
      Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_op_report_uninitialized(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteOp::handle_report_uninitialized(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_op_profiling_count_update(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteOp::handle_report_profiling_count_update(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_op_completion_effect(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      RemoteOp::handle_completion_effect(derez);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_shutdown_notification(Deserializer &derez,
                                               AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      ShutdownManager::handle_shutdown_notification(derez, this, source);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_shutdown_response(Deserializer &derez) 
    //--------------------------------------------------------------------------
    {
      ShutdownManager::handle_shutdown_response(derez);
    }

    //--------------------------------------------------------------------------
    bool Runtime::create_physical_instance(Memory target_memory,
                                     const LayoutConstraintSet &constraints,
                                     const std::vector<LogicalRegion> &regions,
                                     MappingInstance &result,
                                     Processor processor, 
                                     bool acquire, GCPriority priority,
                                     bool tight_bounds, 
                                     const LayoutConstraint **unsat,
                                     size_t *footprint, UniqueID creator_id)
    //--------------------------------------------------------------------------
    {
      MemoryManager *manager = find_memory_manager(target_memory);
      if (unsat != NULL)
      {
        LayoutConstraintKind unsat_kind = LEGION_SPECIALIZED_CONSTRAINT;
        unsigned unsat_index = 0;
        if (!manager->create_physical_instance(constraints, regions, result,
                         processor, acquire, priority, tight_bounds,
                         &unsat_kind, &unsat_index, footprint, creator_id))
        {
          *unsat = constraints.convert_unsatisfied(unsat_kind, unsat_index);
          return false;
        }
        else
          return true;
      }
      else
        return manager->create_physical_instance(constraints, regions, result,
                         processor, acquire, priority, tight_bounds,
                         NULL, NULL, footprint, creator_id);
    }

    //--------------------------------------------------------------------------
    bool Runtime::create_physical_instance(Memory target_memory,
                                     LayoutConstraints *constraints,
                                     const std::vector<LogicalRegion> &regions,
                                     MappingInstance &result,
                                     Processor processor,
                                     bool acquire, GCPriority priority,
                                     bool tight_bounds, 
                                     const LayoutConstraint **unsat,
                                     size_t *footprint, UniqueID creator_id)
    //--------------------------------------------------------------------------
    { 
      MemoryManager *manager = find_memory_manager(target_memory);
      if (unsat != NULL)
      {
        LayoutConstraintKind unsat_kind = LEGION_SPECIALIZED_CONSTRAINT;
        unsigned unsat_index = 0;
        if (!manager->create_physical_instance(constraints, regions, result,
                         processor, acquire, priority, tight_bounds,
                         &unsat_kind, &unsat_index, footprint, creator_id))
        {
          *unsat = constraints->convert_unsatisfied(unsat_kind, unsat_index);
          return false;
        }
        else
          return true;
      }
      else
        return manager->create_physical_instance(constraints, regions, result,
                         processor, acquire, priority, tight_bounds,
                         NULL, NULL, footprint, creator_id);
    }

    //--------------------------------------------------------------------------
    bool Runtime::find_or_create_physical_instance(Memory target_memory,
                                     const LayoutConstraintSet &constraints,
                                     const std::vector<LogicalRegion> &regions,
                                     MappingInstance &result, bool &created, 
                                     Processor processor,
                                     bool acquire, GCPriority priority,
                                     bool tight_bounds, 
                                     const LayoutConstraint **unsat,
                                     size_t *footprint, UniqueID creator_id)
    //--------------------------------------------------------------------------
    {
      MemoryManager *manager = find_memory_manager(target_memory);
      if (unsat != NULL)
      {
        LayoutConstraintKind unsat_kind = LEGION_SPECIALIZED_CONSTRAINT;
        unsigned unsat_index = 0;
        if (!manager->find_or_create_physical_instance(constraints, regions, 
                         result, created, processor, acquire, 
                         priority, tight_bounds, &unsat_kind, &unsat_index,
                         footprint, creator_id))
        {
          *unsat = constraints.convert_unsatisfied(unsat_kind, unsat_index);
          return false;
        }
        else
          return true;
      }
      else
        return manager->find_or_create_physical_instance(constraints, regions, 
                         result, created, processor, acquire, 
                         priority, tight_bounds,NULL,NULL,footprint,creator_id);
    }

    //--------------------------------------------------------------------------
    bool Runtime::find_or_create_physical_instance(Memory target_memory,
                                    LayoutConstraints *constraints,
                                    const std::vector<LogicalRegion> &regions,
                                    MappingInstance &result, bool &created, 
                                    Processor processor,
                                    bool acquire, GCPriority priority,
                                    bool tight_bounds, 
                                    const LayoutConstraint **unsat,
                                    size_t *footprint, UniqueID creator_id)
    //--------------------------------------------------------------------------
    { 
      MemoryManager *manager = find_memory_manager(target_memory);
      if (unsat != NULL)
      {
        LayoutConstraintKind unsat_kind = LEGION_SPECIALIZED_CONSTRAINT;
        unsigned unsat_index = 0;
        if (!manager->find_or_create_physical_instance(constraints, regions,
                           result, created, processor, acquire, 
                           priority, tight_bounds, &unsat_kind, &unsat_index,
                           footprint, creator_id))
        {
          *unsat = constraints->convert_unsatisfied(unsat_kind, unsat_index);
          return false;
        }
        else
          return true;
      }
      else
        return manager->find_or_create_physical_instance(constraints, regions,
                     result, created, processor, acquire, 
                     priority, tight_bounds, NULL, NULL, footprint, creator_id);
    }

    //--------------------------------------------------------------------------
    bool Runtime::find_physical_instance(Memory target_memory,
                                      const LayoutConstraintSet &constraints,
                                      const std::vector<LogicalRegion> &regions,
                                      MappingInstance &result, bool acquire,
                                      bool tight_region_bounds)
    //--------------------------------------------------------------------------
    {
      MemoryManager *manager = find_memory_manager(target_memory);
      return manager->find_physical_instance(constraints, regions,
                            result, acquire, tight_region_bounds);
    }

    //--------------------------------------------------------------------------
    bool Runtime::find_physical_instance(Memory target_memory,
                                      LayoutConstraints *constraints,
                                      const std::vector<LogicalRegion> &regions,
                                      MappingInstance &result, bool acquire,
                                      bool tight_region_bounds)
    //--------------------------------------------------------------------------
    {
      MemoryManager *manager = find_memory_manager(target_memory);
      return manager->find_physical_instance(constraints, regions, 
                            result, acquire, tight_region_bounds);
    }

    //--------------------------------------------------------------------------
    void Runtime::find_physical_instances(Memory target_memory,
                                      const LayoutConstraintSet &constraints,
                                      const std::vector<LogicalRegion> &regions,
                                      std::vector<MappingInstance> &results, 
                                      bool acquire, bool tight_region_bounds)
    //--------------------------------------------------------------------------
    {
      MemoryManager *manager = find_memory_manager(target_memory);
      return manager->find_physical_instances(constraints, regions, 
                            results, acquire, tight_region_bounds);
    }

    //--------------------------------------------------------------------------
    void Runtime::find_physical_instances(Memory target_memory,
                                      LayoutConstraints *constraints,
                                      const std::vector<LogicalRegion> &regions,
                                      std::vector<MappingInstance> &results, 
                                      bool acquire, bool tight_region_bounds)
    //--------------------------------------------------------------------------
    {
      MemoryManager *manager = find_memory_manager(target_memory);
      return manager->find_physical_instances(constraints, regions, 
                            results, acquire, tight_region_bounds);
    }

    //--------------------------------------------------------------------------
    void Runtime::release_tree_instances(RegionTreeID tid)
    //--------------------------------------------------------------------------
    {
      std::map<Memory,MemoryManager*> copy_managers;
      {
        AutoLock m_lock(memory_manager_lock,1,false/*exclusive*/);
        copy_managers = memory_managers;
      }
      for (std::map<Memory,MemoryManager*>::const_iterator it = 
            copy_managers.begin(); it != copy_managers.end(); it++)
        it->second->release_tree_instances(tid);
    }

    //--------------------------------------------------------------------------
    void Runtime::process_schedule_request(Processor proc)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(local_procs.find(proc) != local_procs.end());
#endif
      log_run.debug("Running scheduler on processor " IDFMT "", proc.id);
      ProcessorManager *manager = proc_managers[proc];
      manager->perform_scheduling();
#ifdef LEGION_TRACE_ALLOCATION
      unsigned long long trace_count = allocation_tracing_count.fetch_add(1); 
      if ((trace_count % LEGION_TRACE_ALLOCATION_FREQUENCY) == 0)
        dump_allocation_info();
#endif
    }

    //--------------------------------------------------------------------------
    void Runtime::process_message_task(const void *args, size_t arglen)
    //--------------------------------------------------------------------------
    {
      const char *buffer = (const char*)args;
      AddressSpaceID sender = *((const AddressSpaceID*)buffer);
      buffer += sizeof(sender);
      arglen -= sizeof(sender);
      find_messenger(sender)->receive_message(buffer, arglen);
    }

    //--------------------------------------------------------------------------
    void Runtime::activate_context(InnerContext *context)
    //--------------------------------------------------------------------------
    {
      for (std::map<Processor,ProcessorManager*>::const_iterator it =
            proc_managers.begin(); it != proc_managers.end(); it++)
      {
        it->second->activate_context(context);
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::deactivate_context(InnerContext *context)
    //--------------------------------------------------------------------------
    {
      for (std::map<Processor,ProcessorManager*>::const_iterator it = 
            proc_managers.begin(); it != proc_managers.end(); it++)
      {
        it->second->deactivate_context(context);
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::add_to_ready_queue(Processor p, TaskOp *task)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(p.kind() != Processor::UTIL_PROC);
      assert(proc_managers.find(p) != proc_managers.end());
#endif
      proc_managers[p]->add_to_ready_queue(task);
    }

    //--------------------------------------------------------------------------
    Processor Runtime::find_processor_group(const std::vector<Processor> &procs)
    //--------------------------------------------------------------------------
    {
      // Compute a hash of all the processor ids to avoid testing all sets 
      // Only need to worry about local IDs since all processors are
      // in this address space.
      ProcessorMask local_mask = find_processor_mask(procs);
      uint64_t hash = local_mask.get_hash_key();
      AutoLock g_lock(group_lock);
      std::map<uint64_t,LegionDeque<ProcessorGroupInfo> >::iterator 
        finder = processor_groups.find(hash);
      if (finder != processor_groups.end())
      {
        for (LegionDeque<ProcessorGroupInfo>::const_iterator it = 
              finder->second.begin(); it != finder->second.end(); it++)
        {
          if (local_mask == it->processor_mask)
            return it->processor_group;
        }
      }
      // If we make it here create a new processor group and add it
      ProcessorGroup group = ProcessorGroup::create_group(procs);
      if (finder != processor_groups.end())
        finder->second.push_back(ProcessorGroupInfo(group, local_mask));
      else
        processor_groups[hash].push_back(ProcessorGroupInfo(group, local_mask));
      return group;
    }

    //--------------------------------------------------------------------------
    ProcessorMask Runtime::find_processor_mask(
                                            const std::vector<Processor> &procs)
    //--------------------------------------------------------------------------
    {
      ProcessorMask result;
      std::vector<Processor> need_allocation;
      {
        AutoLock p_lock(processor_mapping_lock,1,false/*exclusive*/);
        for (std::vector<Processor>::const_iterator it = procs.begin();
              it != procs.end(); it++)
        {
          std::map<Processor,unsigned>::const_iterator finder = 
            processor_mapping.find(*it);
          if (finder == processor_mapping.end())
          {
            need_allocation.push_back(*it);
            continue;
          }
          result.set_bit(finder->second);
        }
      }
      if (need_allocation.empty())
        return result;
      AutoLock p_lock(processor_mapping_lock);
      for (std::vector<Processor>::const_iterator it = 
            need_allocation.begin(); it != need_allocation.end(); it++)
      {
        // Check to make sure we didn't lose the race
        std::map<Processor,unsigned>::const_iterator finder = 
            processor_mapping.find(*it);
        if (finder != processor_mapping.end())
        {
          result.set_bit(finder->second);
          continue;
        }
        unsigned next_index = processor_mapping.size();
#ifdef DEBUG_LEGION
        assert(next_index < LEGION_MAX_NUM_PROCS);
#endif
        processor_mapping[*it] = next_index;
        result.set_bit(next_index);
      }
      return result;
    }

    //--------------------------------------------------------------------------
    void Runtime::order_concurrent_task_launch(Processor proc, SingleTask *task,
                    ApEvent precondition, ApUserEvent ready, VariantID vid)
    //--------------------------------------------------------------------------
    {
      std::map<Processor,ProcessorManager*>::const_iterator finder =
        proc_managers.find(proc);
#ifdef DEBUG_LEGION
      assert(finder != proc_managers.end());
#endif
      finder->second->order_concurrent_task_launch(task, precondition,
                                                   ready, vid);
    }

    //--------------------------------------------------------------------------
    void Runtime::end_concurrent_task(Processor proc)
    //--------------------------------------------------------------------------
    {
      std::map<Processor,ProcessorManager*>::const_iterator finder =
        proc_managers.find(proc);
#ifdef DEBUG_LEGION
      assert(finder != proc_managers.end());
#endif
      finder->second->end_concurrent_task();
    }

    //--------------------------------------------------------------------------
    DistributedID Runtime::get_next_static_distributed_id(uint64_t &next_did)
    //--------------------------------------------------------------------------
    {
      DistributedID result = next_did++;
      // If we're the owner we have to bump the available ones here too
      if (determine_owner(result) == address_space)
      {
#ifdef DEBUG_LEGION
#ifndef NDEBUG
        DistributedID expected =
#endif
#endif
          get_available_distributed_id();
#ifdef DEBUG_LEGION
        assert(result == expected);
#endif
      }
      return result;
    }

    //--------------------------------------------------------------------------
    DistributedID Runtime::get_available_distributed_id(void)
    //--------------------------------------------------------------------------
    {
      DistributedID result = unique_distributed_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // Check for overflow
      assert(result < LEGION_DISTRIBUTED_ID_MASK);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    DistributedID Runtime::get_remote_distributed_id(AddressSpaceID target)
    //--------------------------------------------------------------------------
    {
      std::atomic<DistributedID> result(0);
      const RtUserEvent done = Runtime::create_rt_user_event();
      Serializer rez;
      rez.serialize(&result);
      rez.serialize(done);
      find_messenger(target)->send_message(SEND_REMOTE_DISTRIBUTED_ID_REQUEST,
                                                            rez, true/*flush*/);
      if (!done.has_triggered())
        done.wait();
#ifdef DEBUG_LEGION
      assert(result.load() != 0);
#endif
      return result.load();
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_distributed_id_request(Deserializer &derez,
                                                       AddressSpaceID source)
    //--------------------------------------------------------------------------
    {
      std::atomic<DistributedID> *target;
      derez.deserialize(target);
      RtUserEvent done;
      derez.deserialize(done);

      const DistributedID did = get_available_distributed_id();
      Serializer rez;
      rez.serialize(did);
      rez.serialize(target);
      rez.serialize(done);
      find_messenger(source)->send_message(SEND_REMOTE_DISTRIBUTED_ID_RESPONSE,
                                          rez, true/*flush*/, true/*response*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::handle_remote_distributed_id_response(Deserializer &derez)
    //--------------------------------------------------------------------------
    {
      DistributedID did;
      derez.deserialize(did);
      std::atomic<DistributedID> *target;
      derez.deserialize(target);
      target->store(did);
      RtUserEvent done;
      derez.deserialize(done);
      Runtime::trigger_event(done);
    }

    //--------------------------------------------------------------------------
    AddressSpaceID Runtime::determine_owner(DistributedID did) const
    //--------------------------------------------------------------------------
    {
      return ((did & LEGION_DISTRIBUTED_ID_MASK) % total_address_spaces);
    }

    //--------------------------------------------------------------------------
    size_t Runtime::find_distance(AddressSpaceID src, AddressSpaceID dst) const
    //--------------------------------------------------------------------------
    {
      size_t abs_diff = (src < dst) ? (dst - src) : (src - dst);
      return (abs_diff < (total_address_spaces / 2)) ? abs_diff : 
        (total_address_spaces - abs_diff);
    }

    //--------------------------------------------------------------------------
    void Runtime::register_distributed_collectable(DistributedID did,
                                                   DistributedCollectable *dc)
    //--------------------------------------------------------------------------
    {
      did &= LEGION_DISTRIBUTED_ID_MASK;
      RtUserEvent to_trigger;
      {
        AutoLock dc_lock(distributed_collectable_lock);
        // If we make it here then we have the lock
#ifdef DEBUG_LEGION
        assert(dist_collectables.find(did) == dist_collectables.end());
#endif
        dist_collectables[did] = dc;
        // See if this was a pending collectable
        std::map<DistributedID,
                 std::pair<DistributedCollectable*,RtUserEvent> >::iterator 
            finder = pending_collectables.find(did);
        if (finder != pending_collectables.end())
        {
#ifdef DEBUG_LEGION
          assert((finder->second.first == dc) || 
                 (finder->second.first == NULL));
#endif
          to_trigger = finder->second.second;
          pending_collectables.erase(finder);
        }
      }
      if (to_trigger.exists())
        Runtime::trigger_event(to_trigger);
    }

    //--------------------------------------------------------------------------
    void Runtime::unregister_distributed_collectable(DistributedID did)
    //--------------------------------------------------------------------------
    {
      did &= LEGION_DISTRIBUTED_ID_MASK;
      AutoLock d_lock(distributed_collectable_lock);
      std::map<DistributedID,DistributedCollectable*>::iterator finder =
        dist_collectables.find(did);
#ifdef DEBUG_LEGION
      assert(finder != dist_collectables.end());
#endif
      dist_collectables.erase(finder);
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_distributed_collectable(DistributedID did)
    //--------------------------------------------------------------------------
    {
      did &= LEGION_DISTRIBUTED_ID_MASK;
      AutoLock d_lock(distributed_collectable_lock,1,false/*exclusive*/);
      return (dist_collectables.find(did) != dist_collectables.end());
    }

    //--------------------------------------------------------------------------
    DistributedCollectable* Runtime::find_distributed_collectable(
                                                              DistributedID did)
    //--------------------------------------------------------------------------
    {
      RtEvent ready;
      DistributedCollectable *result = NULL;
      const DistributedID to_find = LEGION_DISTRIBUTED_ID_FILTER(did);
      {
        AutoLock d_lock(distributed_collectable_lock,1,false/*exclusive*/);
        std::map<DistributedID,DistributedCollectable*>::const_iterator finder =
          dist_collectables.find(to_find);
        if (finder == dist_collectables.end())
        {
          // Check to see if it is in the pending set too
          std::map<DistributedID,
            std::pair<DistributedCollectable*,RtUserEvent> >::const_iterator
              pending_finder = pending_collectables.find(to_find);
          if (pending_finder != pending_collectables.end())
          {
            result = pending_finder->second.first;
            ready = pending_finder->second.second;
          }
        }
        else
          return finder->second;
      }
      if (!ready.exists())
      {
        AutoLock d_lock(distributed_collectable_lock);
        // Try again to see if we lost the race
        std::map<DistributedID,DistributedCollectable*>::const_iterator 
          finder = dist_collectables.find(to_find);
        if (finder == dist_collectables.end())
        {
          // Check to see if it is in the pending set too
          std::map<DistributedID,
            std::pair<DistributedCollectable*,RtUserEvent> >::iterator
              pending_finder = pending_collectables.find(to_find);
          if (pending_finder == pending_collectables.end())
            pending_finder = pending_collectables.emplace(std::make_pair(
                  to_find, std::pair<DistributedCollectable*,RtUserEvent>(
                    (DistributedCollectable*)NULL,
                    RtUserEvent::NO_RT_USER_EVENT))).first;
          result = pending_finder->second.first;
          if (!pending_finder->second.second.exists())
            pending_finder->second.second = Runtime::create_rt_user_event();
          ready = pending_finder->second.second;
        }
        else
          return finder->second;
      }
      if (!ready.has_triggered())
        ready.wait();
      if (result != NULL)
        return result;
      AutoLock d_lock(distributed_collectable_lock,1,false/*exclusive*/);
      std::map<DistributedID,DistributedCollectable*>::const_iterator finder =
        dist_collectables.find(to_find);
#ifdef DEBUG_LEGION
      assert(finder != dist_collectables.end());
#endif
      return finder->second;
    }

    //--------------------------------------------------------------------------
    DistributedCollectable* Runtime::weak_find_distributed_collectable(
                                                              DistributedID did)
    //--------------------------------------------------------------------------
    {
      const DistributedID to_find = LEGION_DISTRIBUTED_ID_FILTER(did);
      AutoLock d_lock(distributed_collectable_lock,1,false/*exclusive*/);
      std::map<DistributedID,DistributedCollectable*>::const_iterator finder =
        dist_collectables.find(to_find);
      if (finder == dist_collectables.end())
        return NULL;
      finder->second->add_base_resource_ref(RUNTIME_REF);
      return finder->second;
    }

    //--------------------------------------------------------------------------
    template<typename T>
    void* Runtime::find_or_create_pending_collectable_location(
                                                              DistributedID did)
    //--------------------------------------------------------------------------
    {
      did &= LEGION_DISTRIBUTED_ID_MASK;
      AutoLock d_lock(distributed_collectable_lock);
#ifdef DEBUG_LEGION
      assert(dist_collectables.find(did) == dist_collectables.end());
#endif
      std::map<DistributedID,std::pair<DistributedCollectable*,RtUserEvent> >::
        iterator finder = pending_collectables.find(did);
      if (finder == pending_collectables.end())
        finder = pending_collectables.emplace(std::make_pair(did,
          std::pair<DistributedCollectable*,RtUserEvent>(
           (DistributedCollectable*)NULL,RtUserEvent::NO_RT_USER_EVENT))).first;
      if (finder->second.first == NULL)
        finder->second.first =
          (T*)legion_alloc_aligned<T,false/*bytes*/>(1/*count*/);
      return finder->second.first;
    }

    // Instantiate the template for types that use it
    template void*
    Runtime::find_or_create_pending_collectable_location<RemoteContext>(
                                                            DistributedID);
    template void*
    Runtime::find_or_create_pending_collectable_location<PhysicalManager>(
                                                            DistributedID);
    template void*
    Runtime::find_or_create_pending_collectable_location<EquivalenceSet>(
                                                            DistributedID);
    template void*
    Runtime::find_or_create_pending_collectable_location<MaterializedView>(
                                                            DistributedID);
    template void*
    Runtime::find_or_create_pending_collectable_location<ReductionView>(
                                                            DistributedID);
    template void*
    Runtime::find_or_create_pending_collectable_location<FillView>(
                                                            DistributedID);
    template void*
    Runtime::find_or_create_pending_collectable_location<PhiView>(
                                                            DistributedID);
    template void*
    Runtime::find_or_create_pending_collectable_location<ReplicatedView>(
                                                            DistributedID);
    template void*
    Runtime::find_or_create_pending_collectable_location<AllreduceView>(
                                                            DistributedID);

    //--------------------------------------------------------------------------
    LogicalView* Runtime::find_or_request_logical_view(DistributedID did,
                                                       RtEvent &ready)
    //--------------------------------------------------------------------------
    {
      DistributedCollectable *dc = NULL;
      if (LogicalView::is_materialized_did(did))
        dc = find_or_request_distributed_collectable<
         MaterializedView,SEND_VIEW_REQUEST>(did,ready);
      else if (LogicalView::is_reduction_did(did))
        dc = find_or_request_distributed_collectable<
          ReductionView, SEND_VIEW_REQUEST>(did,ready);
      else if (LogicalView::is_fill_did(did))
        dc = find_or_request_distributed_collectable<
          FillView, SEND_VIEW_REQUEST>(did, ready);
      else if (LogicalView::is_replicated_did(did))
        dc = find_or_request_distributed_collectable<
          ReplicatedView, SEND_VIEW_REQUEST>(did, ready);
      else if (LogicalView::is_allreduce_did(did))
        dc = find_or_request_distributed_collectable<
          AllreduceView, SEND_VIEW_REQUEST>(did, ready);
      else if (LogicalView::is_phi_did(did))
        dc = find_or_request_distributed_collectable<
          PhiView, SEND_VIEW_REQUEST>(did, ready);
      else
        assert(false);
      // Have to static cast since the memory might not have been initialized
      return static_cast<LogicalView*>(dc);
    }

    //--------------------------------------------------------------------------
    PhysicalManager* Runtime::find_or_request_instance_manager(
                                              DistributedID did, RtEvent &ready)
    //--------------------------------------------------------------------------
    {
      DistributedCollectable *dc = NULL;
      if (InstanceManager::is_physical_did(did))
        dc = find_or_request_distributed_collectable<
          PhysicalManager, SEND_MANAGER_REQUEST>(did, ready);
      else
        assert(false);
      // Have to static cast since the memory might not have been initialized
      return static_cast<PhysicalManager*>(dc);
    }

    //--------------------------------------------------------------------------
    EquivalenceSet* Runtime::find_or_request_equivalence_set(DistributedID did,
                                                             RtEvent &ready)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(LEGION_DISTRIBUTED_HELP_DECODE(did) == EQUIVALENCE_SET_DC);
#endif
      DistributedCollectable *dc = find_or_request_distributed_collectable<
        EquivalenceSet, SEND_EQUIVALENCE_SET_REQUEST>(did, ready);
      // Have to static cast since the memory might not have been initialized
      return static_cast<EquivalenceSet*>(dc);
    }

    //--------------------------------------------------------------------------
    InnerContext* Runtime::find_or_request_inner_context(DistributedID did)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(LEGION_DISTRIBUTED_HELP_DECODE(did) == INNER_CONTEXT_DC);
#endif
      RtEvent ready;
      DistributedCollectable *dc = find_or_request_distributed_collectable<
        RemoteContext, SEND_REMOTE_CONTEXT_REQUEST>(did, ready);
      if (ready.exists() && !ready.has_triggered())
        ready.wait();
      return static_cast<InnerContext*>(dc);
    }

    //--------------------------------------------------------------------------
    ShardManager* Runtime::find_shard_manager(DistributedID did, bool can_fail)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(LEGION_DISTRIBUTED_HELP_DECODE(did) == SHARD_MANAGER_DC);
#endif
      if (can_fail)
      {
        const DistributedID to_find = LEGION_DISTRIBUTED_ID_FILTER(did);
        AutoLock d_lock(distributed_collectable_lock,1,false/*exclusive*/);
        std::map<DistributedID,DistributedCollectable*>::const_iterator 
          finder = dist_collectables.find(to_find);
        if (finder == dist_collectables.end())
          return NULL;
        else
          return static_cast<ShardManager*>(finder->second);
      }
      else
        return static_cast<ShardManager*>(find_distributed_collectable(did));
    }

    //--------------------------------------------------------------------------
    template<typename T, MessageKind MK>
    DistributedCollectable* Runtime::find_or_request_distributed_collectable(
                                          DistributedID to_find, RtEvent &ready)
    //--------------------------------------------------------------------------
    {
      const DistributedID did = LEGION_DISTRIBUTED_ID_FILTER(to_find);
      DistributedCollectable *result = NULL;
      {
        AutoLock d_lock(distributed_collectable_lock);
        std::map<DistributedID,DistributedCollectable*>::const_iterator finder =
          dist_collectables.find(did);
        // If we've already got it, then we are done
        if (finder != dist_collectables.end())
        {
          ready = RtEvent::NO_RT_EVENT;
          return finder->second;
        }
        // If it is already pending, we can just return the ready event
        std::map<DistributedID,std::pair<DistributedCollectable*,RtUserEvent> 
          >::iterator pending_finder = pending_collectables.find(did);
        if (pending_finder != pending_collectables.end())
        {
          if (pending_finder->second.first == NULL)
            pending_finder->second.first =
              (T*)legion_alloc_aligned<T,false/*bytes*/>(1/*count*/);
          if (!pending_finder->second.second.exists())
            pending_finder->second.second = Runtime::create_rt_user_event();
          ready = pending_finder->second.second;
          return pending_finder->second.first;
        }
        // This is the first request we've seen for this did, make it now
        // Allocate space for the result and type case
        result = (T*)legion_alloc_aligned<T,false/*bytes*/>(1/*count*/);  
        RtUserEvent to_trigger = Runtime::create_rt_user_event();
        pending_collectables[did] = 
          std::pair<DistributedCollectable*,RtUserEvent>(result, to_trigger);
        ready = to_trigger;
      }
      AddressSpaceID target = determine_owner(did);
#ifdef DEBUG_LEGION
      assert(target != address_space); // shouldn't be sending to ourself
#endif
      // Now send the message
      Serializer rez;
      {
        RezCheck z(rez);
        rez.serialize(to_find);
        rez.serialize(address_space);
      }
      find_messenger(target)->send_message(MK, rez, true/*flush*/);
      return result;
    }
    
    //--------------------------------------------------------------------------
    FutureImpl* Runtime::find_or_create_future(DistributedID did,
                                               DistributedID ctx_did,
                                               const ContextCoordinate &coord,
                                               Provenance *provenance,
                                               Operation *op, GenerationID gen,
                                               UniqueID op_uid, int op_depth, 
                                               CollectiveMapping *mapping)
    //--------------------------------------------------------------------------
    {
      did &= LEGION_DISTRIBUTED_ID_MASK; 
      {
        AutoLock d_lock(distributed_collectable_lock,1,false/*exclusive*/);
        std::map<DistributedID,DistributedCollectable*>::const_iterator 
          finder = dist_collectables.find(did);
        if (finder != dist_collectables.end())
        {
#ifdef DEBUG_LEGION
          FutureImpl *result = dynamic_cast<FutureImpl*>(finder->second);
          assert(result != NULL);
#else
          FutureImpl *result = static_cast<FutureImpl*>(finder->second);
#endif
          return result;
        }
      }
      InnerContext *context = find_or_request_inner_context(ctx_did);
      FutureImpl *result = new FutureImpl(context, this, false/*register*/, did,
          op, gen, coord, op_uid, op_depth, provenance, mapping);
      // Retake the lock and see if we lost the race
      RtEvent ready;
      {
        AutoLock d_lock(distributed_collectable_lock);
        std::map<DistributedID,DistributedCollectable*>::const_iterator 
          finder = dist_collectables.find(did);
        if (finder != dist_collectables.end())
        {
          // We lost the race
          delete result;
#ifdef DEBUG_LEGION
          result = dynamic_cast<FutureImpl*>(finder->second);
          assert(result != NULL);
#else
          result = static_cast<FutureImpl*>(finder->second);
#endif
          return result;
        }
        ready = result->record_future_registered();
        dist_collectables[did] = result;
      }
      if (ready.exists() && !ready.has_triggered())
        ready.wait();
      return result;
    }

    //--------------------------------------------------------------------------
    FutureMapImpl* Runtime::find_or_create_future_map(DistributedID did,
                          TaskContext *ctx, uint64_t coord, IndexSpace domain,
                          Provenance *provenance)
    //--------------------------------------------------------------------------
    {
      did &= LEGION_DISTRIBUTED_ID_MASK;
      {
        AutoLock d_lock(distributed_collectable_lock,1,false/*exclusive*/);
        std::map<DistributedID,DistributedCollectable*>::const_iterator 
          finder = dist_collectables.find(did);
        if (finder != dist_collectables.end())
        {
#ifdef DEBUG_LEGION
          FutureMapImpl *result = dynamic_cast<FutureMapImpl*>(finder->second);
          assert(result != NULL);
#else
          FutureMapImpl *result = static_cast<FutureMapImpl*>(finder->second);
#endif
          return result;
        }
      }
#ifdef DEBUG_LEGION
      assert(domain.exists());
#endif
      IndexSpaceNode *domain_node = forest->get_node(domain);
      FutureMapImpl *result = new FutureMapImpl(ctx, this, domain_node, did,
           coord, provenance, false/*register now*/);
      // Retake the lock and see if we lost the race
      RtEvent ready;
      {
        AutoLock d_lock(distributed_collectable_lock);
        std::map<DistributedID,DistributedCollectable*>::const_iterator 
          finder = dist_collectables.find(did);
        if (finder != dist_collectables.end())
        {
          // We lost the race
          delete result;
#ifdef DEBUG_LEGION
          result = dynamic_cast<FutureMapImpl*>(finder->second);
          assert(result != NULL);
#else
          result = static_cast<FutureMapImpl*>(finder->second);
#endif
          return result;
        }
        ready = result->record_future_map_registered();
        dist_collectables[did] = result;
      }
      if (ready.exists() && !ready.has_triggered())
        ready.wait();
      return result;
    }

    //--------------------------------------------------------------------------
    IndexSpace Runtime::find_or_create_index_slice_space(const Domain &domain,
                                       TypeTag type_tag, Provenance *provenance)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(type_tag != 0);
#endif
      const std::pair<Domain,TypeTag> key(domain, type_tag);
      {
        AutoLock is_lock(is_slice_lock,1,false/*exclusive*/);
        std::map<std::pair<Domain,TypeTag>,IndexSpace>::const_iterator finder =
          index_slice_spaces.find(key);
        if (finder != index_slice_spaces.end())
          return finder->second;
      }
      const IndexSpace result(get_unique_index_space_id(),
                              get_unique_index_tree_id(), type_tag);
      const DistributedID did = get_available_distributed_id();
      forest->create_index_space(result, &domain, did, provenance);
      if (legion_spy_enabled)
        LegionSpy::log_top_index_space(result.id, address_space,
            (provenance == NULL) ? NULL : provenance->human_str());
      // Overwrite and leak for now, don't care too much as this 
      // should occur infrequently
      AutoLock is_lock(is_slice_lock);
      index_slice_spaces[key] = result;
      return result;
    } 

    //--------------------------------------------------------------------------
    void Runtime::increment_outstanding_top_level_tasks(void)
    //--------------------------------------------------------------------------
    {
      unsigned previous = outstanding_top_level_tasks.fetch_add(1);
      if (previous == 0)
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_TOP_LEVEL_TASK_CREATION,
            "Illegal attempt to launch a top-level task after "
            "Runtime::wait_for_shutdown has been called. All top-level tasks "
            "must be created on a node before signaling to the runtime that "
            "the client is ready for Legion to shutdown on that node.")
    }

    //--------------------------------------------------------------------------
    void Runtime::decrement_outstanding_top_level_tasks(void)
    //--------------------------------------------------------------------------
    {
      unsigned previous = outstanding_top_level_tasks.fetch_sub(1);
#ifdef DEBUG_LEGION
      assert(previous > 0);
#endif
      if (previous == 1)
      {
        if (address_space > 0)
        {
          // Send a message to the next node down the tree to remove our
          // guard reference that we have there
          AddressSpaceID parent = (address_space - 1) / legion_collective_radix;
          Serializer rez;
          find_messenger(parent)->send_message(SEND_TOP_LEVEL_TASK_COMPLETE,
                                                          rez, true/*flush*/);
        }
        else // We're the owner node so start the quiesence algorithm
          issue_runtime_shutdown_attempt();
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::issue_runtime_shutdown_attempt(void)
    //--------------------------------------------------------------------------
    {
      ShutdownManager::RetryShutdownArgs args(
            ShutdownManager::CHECK_TERMINATION);
      // Issue this with a low priority so that other meta-tasks
      // have an opportunity to run
      issue_runtime_meta_task(args, LG_LOW_PRIORITY);
    }

    //--------------------------------------------------------------------------
    void Runtime::initiate_runtime_shutdown(AddressSpaceID source,
                                           ShutdownManager::ShutdownPhase phase,
                                           ShutdownManager *owner)
    //--------------------------------------------------------------------------
    {
      log_shutdown.info("Received notification on node %d for phase %d",
                        address_space, phase);
      // If this is the first phase, do all our normal stuff
      if (phase == ShutdownManager::CHECK_TERMINATION)
      {
        // Get the preconditions for any outstanding operations still
        // available for garabage collection and wait on them to 
        // try and get close to when there are no more outstanding tasks
        std::map<Memory,MemoryManager*> copy_managers;
        {
          AutoLock m_lock(memory_manager_lock,1,false/*exclusive*/);
          copy_managers = memory_managers;
        }
        std::set<ApEvent> wait_events;
        for (std::map<Memory,MemoryManager*>::const_iterator it = 
              copy_managers.begin(); it != copy_managers.end(); it++)
          it->second->find_shutdown_preconditions(wait_events);
        if (!wait_events.empty())
        {
          RtEvent wait_on = Runtime::protect_merge_events(wait_events);
          wait_on.wait();
        }
      }
      else if ((phase == ShutdownManager::CHECK_SHUTDOWN) && 
                !prepared_for_shutdown)
      {
        // First time we check for shutdown we do the prepare for shutdown
        prepare_runtime_shutdown();  
      }
      ShutdownManager *shutdown_manager = 
        new ShutdownManager(phase, this, source, 
                            LEGION_SHUTDOWN_RADIX, owner);
      if (shutdown_manager->attempt_shutdown())
        delete shutdown_manager;
    }

    //--------------------------------------------------------------------------
    void Runtime::confirm_runtime_shutdown(ShutdownManager *shutdown_manager, 
                                           bool phase_one)
    //--------------------------------------------------------------------------
    {
      if (has_outstanding_tasks())
      {
        shutdown_manager->record_outstanding_tasks();
#ifdef DEBUG_LEGION
        LG_TASK_DESCRIPTIONS(meta_task_names);
        AutoLock out_lock(outstanding_task_lock,1,false/*exclusive*/);
        for (std::map<std::pair<unsigned,bool>,unsigned>::const_iterator it =
              outstanding_task_counts.begin(); it != 
              outstanding_task_counts.end(); it++)
        {
          if (it->second == 0)
            continue;
          if (it->first.second)
            log_shutdown.info("RT %d: %d outstanding meta task(s) %s",
                              address_space, it->second, 
                              meta_task_names[it->first.first]);
          else                
            log_shutdown.info("RT %d: %d outstanding application task(s) %d",
                              address_space, it->second, it->first.first);
        }
#endif
      }
      // Check all our message managers for outstanding messages
      for (unsigned idx = 0; idx < LEGION_MAX_NUM_NODES; idx++)
      {
        MessageManager *manager = message_managers[idx].load();
        if (manager != NULL)
          manager->confirm_shutdown(shutdown_manager, phase_one);
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::prepare_runtime_shutdown(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!prepared_for_shutdown);
      assert(virtual_manager != NULL);
#endif
      // Search through all our distributed collectables and find any
      // futures which are leaking and therefore need to be finalized
      std::vector<FutureImpl*> leaked_futures;
      {
        // Also have any leaking futures force delete their instances 
        AutoLock d_lock(distributed_collectable_lock,1,false/*exclusive*/);
        for (std::map<DistributedID,DistributedCollectable*>::const_iterator it
              = dist_collectables.begin(); it != dist_collectables.end(); it++)
        {
          // See if this is a future
          if (LEGION_DISTRIBUTED_HELP_DECODE(it->second->did) != FUTURE_DC)
            continue;
#ifdef DEBUG_LEGION
          FutureImpl *impl = dynamic_cast<FutureImpl*>(it->second);
          assert(impl != NULL);
#else
          FutureImpl *impl = static_cast<FutureImpl*>(it->second);
#endif
          impl->add_base_resource_ref(RUNTIME_REF);
          leaked_futures.push_back(impl);
        }
      }
      for (std::vector<FutureImpl*>::const_iterator it =
            leaked_futures.begin(); it != leaked_futures.end(); it++)
      {
        (*it)->prepare_for_shutdown();
        if ((*it)->remove_base_resource_ref(RUNTIME_REF))
          delete (*it);
      }
      for (std::map<Memory,MemoryManager*>::const_iterator it = 
            memory_managers.begin(); it != memory_managers.end(); it++)
        it->second->prepare_for_shutdown();
      // Do processor managers after memory managers in case we need to
      // report any deleted instances back to the mappers
      for (std::map<Processor,ProcessorManager*>::const_iterator it = 
            proc_managers.begin(); it != proc_managers.end(); it++)
        it->second->prepare_for_shutdown();
      // Destroy any index slice spaces that we made during execution
      std::set<RtEvent> applied;
      for (std::map<std::pair<Domain,TypeTag>,IndexSpace>::const_iterator it =
            index_slice_spaces.begin(); it != index_slice_spaces.end(); it++)
        forest->destroy_index_space(it->second, address_space, applied);
      for (std::map<ProjectionID,ProjectionFunction*>::const_iterator it =
           projection_functions.begin(); it != projection_functions.end(); it++)
        it->second->prepare_for_shutdown();
      // If there are still any layout constraints that the application
      // failed to remove its references to then we can remove the reference
      // for them and make sure it's effects propagate
      if (!separate_runtime_instances)
      {
        std::vector<LayoutConstraints*> to_remove;
        {
          AutoLock l_lock(layout_constraints_lock,1,false/*exclusive*/);
          for (std::map<LayoutConstraintID,LayoutConstraints*>::const_iterator
                it = layout_constraints_table.begin(); it !=
                layout_constraints_table.end(); it++)
            if (it->second->is_owner() && !it->second->internal)
              to_remove.push_back(it->second);
        }
        if (!to_remove.empty())
        {
          for (std::vector<LayoutConstraints*>::const_iterator it = 
                to_remove.begin(); it != to_remove.end(); it++)
            if ((*it)->remove_base_gc_ref(APPLICATION_REF))
              delete (*it);
        }
      }
      if (!redop_fill_views.empty())
      {
        for (std::map<ReductionOpID,FillView*>::const_iterator it =
              redop_fill_views.begin(); it != redop_fill_views.end(); it++)
          if (it->second->remove_base_valid_ref(RUNTIME_REF))
            delete it->second;
        redop_fill_views.clear();
      }
      if (virtual_manager->remove_base_gc_ref(NEVER_GC_REF))
        delete virtual_manager;
      virtual_manager = NULL;
      if (!applied.empty())
      {
        const RtEvent wait_on = Runtime::merge_events(applied);
        if (wait_on.exists() && !wait_on.has_triggered())
          wait_on.wait();
      }
      prepared_for_shutdown = true;
    }

    //--------------------------------------------------------------------------
    bool Runtime::has_outstanding_tasks(void)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      AutoLock out_lock(outstanding_task_lock);
      return (total_outstanding_tasks > 0);
#else
      return total_outstanding_tasks.load();
#endif
    }

#ifdef DEBUG_LEGION
    //--------------------------------------------------------------------------
    void Runtime::increment_total_outstanding_tasks(unsigned tid, bool meta)
    //--------------------------------------------------------------------------
    {
      AutoLock out_lock(outstanding_task_lock); 
      total_outstanding_tasks++;
      std::pair<unsigned,bool> key(tid,meta);
      std::map<std::pair<unsigned,bool>,unsigned>::iterator finder = 
        outstanding_task_counts.find(key);
      if (finder == outstanding_task_counts.end())
        outstanding_task_counts[key] = 1;
      else
        finder->second++;
    }

    //--------------------------------------------------------------------------
    void Runtime::decrement_total_outstanding_tasks(unsigned tid, bool meta)
    //--------------------------------------------------------------------------
    {
      AutoLock out_lock(outstanding_task_lock);
      assert(total_outstanding_tasks > 0);
      total_outstanding_tasks--;
      std::pair<unsigned,bool> key(tid,meta);
      std::map<std::pair<unsigned,bool>,unsigned>::iterator finder = 
        outstanding_task_counts.find(key);
      assert(finder != outstanding_task_counts.end());
      assert(finder->second > 0);
      finder->second--;
    }
#endif

    //--------------------------------------------------------------------------
    IndividualTask* Runtime::get_available_individual_task(void)
    //--------------------------------------------------------------------------
    {
      IndividualTask *result = get_available<IndividualTask,
                     Predicated<IndividualTask> >(individual_task_lock, 
                                         available_individual_tasks);
#ifdef DEBUG_LEGION
      AutoLock i_lock(individual_task_lock);
      out_individual_tasks.insert(result);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    PointTask* Runtime::get_available_point_task(void)
    //--------------------------------------------------------------------------
    {
      PointTask *result = get_available<PointTask,Memoizable<PointTask> >(
                                    point_task_lock, available_point_tasks);
#ifdef DEBUG_LEGION
      AutoLock p_lock(point_task_lock);
      out_point_tasks.insert(result);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    IndexTask* Runtime::get_available_index_task(void)
    //--------------------------------------------------------------------------
    {
      IndexTask *result = get_available<IndexTask,Predicated<IndexTask> >(
                                    index_task_lock, available_index_tasks);
#ifdef DEBUG_LEGION
      AutoLock i_lock(index_task_lock);
      out_index_tasks.insert(result);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    SliceTask* Runtime::get_available_slice_task(void)
    //--------------------------------------------------------------------------
    {
      SliceTask *result = get_available<SliceTask,Memoizable<SliceTask> >(
                                    slice_task_lock, available_slice_tasks);
#ifdef DEBUG_LEGION
      AutoLock s_lock(slice_task_lock);
      out_slice_tasks.insert(result);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    MapOp* Runtime::get_available_map_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(map_op_lock, available_map_ops);
    }

    //--------------------------------------------------------------------------
    CopyOp* Runtime::get_available_copy_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<CopyOp,Predicated<CopyOp> >(
                        copy_op_lock, available_copy_ops);
    }

    //--------------------------------------------------------------------------
    IndexCopyOp* Runtime::get_available_index_copy_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<IndexCopyOp,Predicated<IndexCopyOp> >(
                            copy_op_lock, available_index_copy_ops);
    }

    //--------------------------------------------------------------------------
    PointCopyOp* Runtime::get_available_point_copy_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<PointCopyOp,Memoizable<PointCopyOp> >(
                    copy_op_lock, available_point_copy_ops);
    }

    //--------------------------------------------------------------------------
    template<>
    ApEvent Memoizable<FenceOp>::compute_sync_precondition(
                                              const TraceInfo &trace_info) const
    //--------------------------------------------------------------------------
    {
      return this->execution_fence_event;
    }

    //--------------------------------------------------------------------------
    FenceOp* Runtime::get_available_fence_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<FenceOp,Memoizable<FenceOp> >(
                      fence_op_lock, available_fence_ops);
    }

    //--------------------------------------------------------------------------
    FrameOp* Runtime::get_available_frame_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(frame_op_lock, available_frame_ops);
    }

    //--------------------------------------------------------------------------
    CreationOp* Runtime::get_available_creation_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(creation_op_lock, available_creation_ops);
    }

    //--------------------------------------------------------------------------
    DeletionOp* Runtime::get_available_deletion_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(deletion_op_lock, available_deletion_ops);
    }

    //--------------------------------------------------------------------------
    MergeCloseOp* Runtime::get_available_merge_close_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(merge_close_op_lock, available_merge_close_ops);
    }

    //--------------------------------------------------------------------------
    PostCloseOp* Runtime::get_available_post_close_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(post_close_op_lock, available_post_close_ops);
    }

    //--------------------------------------------------------------------------
    RefinementOp* Runtime::get_available_refinement_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(refinement_op_lock, available_refinement_ops);
    }

    //--------------------------------------------------------------------------
    ResetOp* Runtime::get_available_reset_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(reset_op_lock, available_reset_ops);
    }

    //--------------------------------------------------------------------------
    template<>
    ApEvent Memoizable<DynamicCollectiveOp>::compute_sync_precondition(
                                              const TraceInfo &trace_info) const
    //--------------------------------------------------------------------------
    {
      return this->execution_fence_event;
    }

    //--------------------------------------------------------------------------
    DynamicCollectiveOp* Runtime::get_available_dynamic_collective_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<DynamicCollectiveOp,
             Memoizable<DynamicCollectiveOp> >(dynamic_collective_op_lock, 
                           available_dynamic_collective_ops);
    }

    //--------------------------------------------------------------------------
    FuturePredOp* Runtime::get_available_future_pred_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(future_pred_op_lock, available_future_pred_ops);
    }

    //--------------------------------------------------------------------------
    NotPredOp* Runtime::get_available_not_pred_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(not_pred_op_lock, available_not_pred_ops);
    }

    //--------------------------------------------------------------------------
    AndPredOp* Runtime::get_available_and_pred_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(and_pred_op_lock, available_and_pred_ops);
    }

    //--------------------------------------------------------------------------
    OrPredOp* Runtime::get_available_or_pred_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(or_pred_op_lock, available_or_pred_ops);
    }

    //--------------------------------------------------------------------------
    AcquireOp* Runtime::get_available_acquire_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<AcquireOp,Predicated<AcquireOp> >(
                        acquire_op_lock, available_acquire_ops);
    }

    //--------------------------------------------------------------------------
    ReleaseOp* Runtime::get_available_release_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<ReleaseOp,Predicated<ReleaseOp> >(
                        release_op_lock, available_release_ops);
    }

    //--------------------------------------------------------------------------
    TraceBeginOp* Runtime::get_available_begin_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(begin_op_lock, available_begin_ops);
    }

    //--------------------------------------------------------------------------
    TraceCompleteOp* Runtime::get_available_complete_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(complete_op_lock, available_complete_ops);
    }

    //--------------------------------------------------------------------------
    TraceRecurrentOp* Runtime::get_available_recurrent_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(recurrent_op_lock, available_recurrent_ops);
    }

    //--------------------------------------------------------------------------
    MustEpochOp* Runtime::get_available_epoch_op(void)
    //--------------------------------------------------------------------------
    {
      MustEpochOp *result = get_available(epoch_op_lock, available_epoch_ops);
#ifdef DEBUG_LEGION
      AutoLock e_lock(epoch_op_lock);
      out_must_epoch.insert(result);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    PendingPartitionOp* Runtime::get_available_pending_partition_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(pending_partition_op_lock, 
                           available_pending_partition_ops);
    }

    //--------------------------------------------------------------------------
    DependentPartitionOp* Runtime::get_available_dependent_partition_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(dependent_partition_op_lock, 
                           available_dependent_partition_ops);
    }

    //--------------------------------------------------------------------------
    PointDepPartOp* Runtime::get_available_point_dep_part_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(dependent_partition_op_lock,
                           available_point_dep_part_ops);
    }

    //--------------------------------------------------------------------------
    FillOp* Runtime::get_available_fill_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<FillOp,Predicated<FillOp> >(
                        fill_op_lock, available_fill_ops);
    }

    //--------------------------------------------------------------------------
    IndexFillOp* Runtime::get_available_index_fill_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<IndexFillOp,Predicated<IndexFillOp> >( 
                      fill_op_lock, available_index_fill_ops);
    }

    //--------------------------------------------------------------------------
    PointFillOp* Runtime::get_available_point_fill_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<PointFillOp,Memoizable<PointFillOp> >(
                          fill_op_lock, available_point_fill_ops);
    }

    //--------------------------------------------------------------------------
    DiscardOp* Runtime::get_available_discard_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(discard_op_lock, available_discard_ops);
    }

    //--------------------------------------------------------------------------
    AttachOp* Runtime::get_available_attach_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(attach_op_lock, available_attach_ops);
    }

    //--------------------------------------------------------------------------
    IndexAttachOp* Runtime::get_available_index_attach_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(attach_op_lock, available_index_attach_ops);
    }

    //--------------------------------------------------------------------------
    PointAttachOp* Runtime::get_available_point_attach_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(attach_op_lock, available_point_attach_ops);
    }

    //--------------------------------------------------------------------------
    DetachOp* Runtime::get_available_detach_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(detach_op_lock, available_detach_ops);
    }

    //--------------------------------------------------------------------------
    IndexDetachOp* Runtime::get_available_index_detach_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(detach_op_lock, available_index_detach_ops);
    }

    //--------------------------------------------------------------------------
    PointDetachOp* Runtime::get_available_point_detach_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(detach_op_lock, available_point_detach_ops);
    }

    //--------------------------------------------------------------------------
    TimingOp* Runtime::get_available_timing_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(timing_op_lock, available_timing_ops);
    }

    //--------------------------------------------------------------------------
    TunableOp* Runtime::get_available_tunable_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(tunable_op_lock, available_tunable_ops);
    }

    //--------------------------------------------------------------------------
    template<>
    ApEvent Memoizable<AllReduceOp>::compute_sync_precondition(
                                              const TraceInfo &trace_info) const
    //--------------------------------------------------------------------------
    {
      return this->execution_fence_event;
    }

    //--------------------------------------------------------------------------
    AllReduceOp* Runtime::get_available_all_reduce_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<AllReduceOp, Memoizable<AllReduceOp> >(
                      all_reduce_op_lock, available_all_reduce_ops);
    }

    //--------------------------------------------------------------------------
    ReplIndividualTask* Runtime::get_available_repl_individual_task(void)
    //--------------------------------------------------------------------------
    {
      return get_available<ReplIndividualTask,Predicated<ReplIndividualTask> >(
                         individual_task_lock, available_repl_individual_tasks);
    }

    //--------------------------------------------------------------------------
    ReplIndexTask* Runtime::get_available_repl_index_task(void)
    //--------------------------------------------------------------------------
    {
      return get_available<ReplIndexTask,Predicated<ReplIndexTask> >(
                          index_task_lock, available_repl_index_tasks);
    }

    //--------------------------------------------------------------------------
    ReplMergeCloseOp* Runtime::get_available_repl_merge_close_op(void)
    //-------------------------------------------------------------------------- 
    {
      return get_available(merge_close_op_lock, available_repl_merge_close_ops);
    }

    //--------------------------------------------------------------------------
    ReplRefinementOp* Runtime::get_available_repl_refinement_op(void)
    //-------------------------------------------------------------------------- 
    {
      return get_available(refinement_op_lock, available_repl_refinement_ops);
    }

    //--------------------------------------------------------------------------
    ReplResetOp* Runtime::get_available_repl_reset_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(reset_op_lock, available_repl_reset_ops);
    }

    //--------------------------------------------------------------------------
    ReplFillOp* Runtime::get_available_repl_fill_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<ReplFillOp,Predicated<ReplFillOp> >(
                          fill_op_lock, available_repl_fill_ops);
    }

    //--------------------------------------------------------------------------
    ReplIndexFillOp* Runtime::get_available_repl_index_fill_op(void) 
    //--------------------------------------------------------------------------
    {
      return get_available<ReplIndexFillOp,Predicated<ReplIndexFillOp> >(
                              fill_op_lock, available_repl_index_fill_ops);
    }

    //--------------------------------------------------------------------------
    ReplCopyOp* Runtime::get_available_repl_copy_op(void) 
    //--------------------------------------------------------------------------
    {
      return get_available<ReplCopyOp,Predicated<ReplCopyOp> >(  
                          copy_op_lock, available_repl_copy_ops);
    }

    //--------------------------------------------------------------------------
    ReplIndexCopyOp* Runtime::get_available_repl_index_copy_op(void) 
    //--------------------------------------------------------------------------
    {
      return get_available<ReplIndexCopyOp,Predicated<ReplIndexCopyOp> >(
                              copy_op_lock, available_repl_index_copy_ops);
    }

    //--------------------------------------------------------------------------
    ReplDeletionOp* Runtime::get_available_repl_deletion_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(deletion_op_lock, available_repl_deletion_ops);
    }

    //--------------------------------------------------------------------------
    ReplPendingPartitionOp* 
                          Runtime::get_available_repl_pending_partition_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(pending_partition_op_lock,
                           available_repl_pending_partition_ops);
    }

    //--------------------------------------------------------------------------
    ReplDependentPartitionOp* 
                        Runtime::get_available_repl_dependent_partition_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(dependent_partition_op_lock,
                           available_repl_dependent_partition_ops);
    }

    //--------------------------------------------------------------------------
    ReplMustEpochOp* Runtime::get_available_repl_epoch_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(epoch_op_lock, available_repl_must_epoch_ops);
    }

    //--------------------------------------------------------------------------
    ReplTimingOp* Runtime::get_available_repl_timing_op(void) 
    //--------------------------------------------------------------------------
    {
      return get_available(timing_op_lock, available_repl_timing_ops);
    }

    //--------------------------------------------------------------------------
    ReplTunableOp* Runtime::get_available_repl_tunable_op(void) 
    //--------------------------------------------------------------------------
    {
      return get_available(tunable_op_lock, available_repl_tunable_ops);
    }

    //--------------------------------------------------------------------------
    template<>
    ApEvent Memoizable<ReplAllReduceOp>::compute_sync_precondition(
                                              const TraceInfo &trace_info) const
    //--------------------------------------------------------------------------
    {
      return this->execution_fence_event;
    }

    //--------------------------------------------------------------------------
    ReplAllReduceOp* Runtime::get_available_repl_all_reduce_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<ReplAllReduceOp, Memoizable<ReplAllReduceOp> >(
                        all_reduce_op_lock, available_repl_all_reduce_ops);
    }

    //--------------------------------------------------------------------------
    template<>
    ApEvent Memoizable<ReplFenceOp>::compute_sync_precondition(
                                              const TraceInfo &trace_info) const
    //--------------------------------------------------------------------------
    {
      return this->execution_fence_event;
    }

    //--------------------------------------------------------------------------
    ReplFenceOp* Runtime::get_available_repl_fence_op(void) 
    //--------------------------------------------------------------------------
    {
      return get_available<ReplFenceOp,Memoizable<ReplFenceOp> >(
                        fence_op_lock, available_repl_fence_ops);
    }

    //--------------------------------------------------------------------------
    ReplMapOp* Runtime::get_available_repl_map_op(void) 
    //--------------------------------------------------------------------------
    {
      return get_available(map_op_lock, available_repl_map_ops);
    }

    //--------------------------------------------------------------------------
    ReplDiscardOp* Runtime::get_available_repl_discard_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(discard_op_lock, available_repl_discard_ops);
    }

    //--------------------------------------------------------------------------
    ReplAttachOp* Runtime::get_available_repl_attach_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(attach_op_lock, available_repl_attach_ops);
    }

    //--------------------------------------------------------------------------
    ReplIndexAttachOp* Runtime::get_available_repl_index_attach_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(attach_op_lock, available_repl_index_attach_ops);
    }

    //--------------------------------------------------------------------------
    ReplDetachOp* Runtime::get_available_repl_detach_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(detach_op_lock, available_repl_detach_ops);
    }

    //--------------------------------------------------------------------------
    ReplIndexDetachOp* Runtime::get_available_repl_index_detach_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(detach_op_lock, available_repl_index_detach_ops);
    }

    //--------------------------------------------------------------------------
    ReplAcquireOp* Runtime::get_available_repl_acquire_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<ReplAcquireOp,Predicated<ReplAcquireOp> >(
                            acquire_op_lock, available_repl_acquire_ops);
    }

    //--------------------------------------------------------------------------
    ReplReleaseOp* Runtime::get_available_repl_release_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available<ReplReleaseOp,Predicated<ReplReleaseOp> >(
                          release_op_lock, available_repl_release_ops);
    }

    //--------------------------------------------------------------------------
    ReplTraceBeginOp* Runtime::get_available_repl_begin_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(begin_op_lock, available_repl_begin_ops);
    }

    //--------------------------------------------------------------------------
    ReplTraceCompleteOp* Runtime::get_available_repl_complete_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(complete_op_lock, available_repl_complete_ops);
    }

    //--------------------------------------------------------------------------
    ReplTraceRecurrentOp* Runtime::get_available_repl_recurrent_op(void)
    //--------------------------------------------------------------------------
    {
      return get_available(recurrent_op_lock, available_repl_recurrent_ops);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_individual_task(IndividualTask *task)
    //--------------------------------------------------------------------------
    {
      AutoLock i_lock(individual_task_lock);
      release_operation<false>(available_individual_tasks, task);
#ifdef DEBUG_LEGION
      out_individual_tasks.erase(task);
#endif
    }

    //--------------------------------------------------------------------------
    void Runtime::free_point_task(PointTask *task)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(point_task_lock);
#ifdef DEBUG_LEGION
      out_point_tasks.erase(task);
#endif
      // Note that we can safely delete point tasks because they are
      // never registered in the logical state of the region tree
      // as part of the dependence analysis. This does not apply
      // to all operation objects.
      release_operation<true>(available_point_tasks, task);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_index_task(IndexTask *task)
    //--------------------------------------------------------------------------
    {
      AutoLock i_lock(index_task_lock);
      release_operation<false>(available_index_tasks, task);
#ifdef DEBUG_LEGION
      out_index_tasks.erase(task);
#endif
    }

    //--------------------------------------------------------------------------
    void Runtime::free_slice_task(SliceTask *task)
    //--------------------------------------------------------------------------
    {
      AutoLock s_lock(slice_task_lock);
#ifdef DEBUG_LEGION
      out_slice_tasks.erase(task);
#endif
      // Note that we can safely delete slice tasks because they are
      // never registered in the logical state of the region tree
      // as part of the dependence analysis. This does not apply
      // to all operation objects.
      release_operation<true>(available_slice_tasks, task);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_map_op(MapOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock m_lock(map_op_lock);
      release_operation<false>(available_map_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_copy_op(CopyOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock c_lock(copy_op_lock);
      release_operation<false>(available_copy_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_index_copy_op(IndexCopyOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock c_lock(copy_op_lock);
      release_operation<false>(available_index_copy_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_point_copy_op(PointCopyOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock c_lock(copy_op_lock);
      release_operation<true>(available_point_copy_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_fence_op(FenceOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(fence_op_lock);
      release_operation<false>(available_fence_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_frame_op(FrameOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(frame_op_lock);
      release_operation<false>(available_frame_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_creation_op(CreationOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock d_lock(creation_op_lock);
      release_operation<false>(available_creation_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_deletion_op(DeletionOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock d_lock(deletion_op_lock);
      release_operation<false>(available_deletion_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_merge_close_op(MergeCloseOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock i_lock(merge_close_op_lock);
      release_operation<false>(available_merge_close_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_post_close_op(PostCloseOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(post_close_op_lock);
      release_operation<false>(available_post_close_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_refinement_op(RefinementOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock r_lock(refinement_op_lock);
      release_operation<false>(available_refinement_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_reset_op(ResetOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(reset_op_lock);
      release_operation<false>(available_reset_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_dynamic_collective_op(DynamicCollectiveOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock dc_lock(dynamic_collective_op_lock);
      release_operation<false>(available_dynamic_collective_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_future_predicate_op(FuturePredOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(future_pred_op_lock);
      release_operation<false>(available_future_pred_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_not_predicate_op(NotPredOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock n_lock(not_pred_op_lock);
      release_operation<false>(available_not_pred_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_and_predicate_op(AndPredOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(and_pred_op_lock);
      release_operation<false>(available_and_pred_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_or_predicate_op(OrPredOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock o_lock(or_pred_op_lock);
      release_operation<false>(available_or_pred_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_acquire_op(AcquireOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(acquire_op_lock);
      release_operation<false>(available_acquire_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_release_op(ReleaseOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock r_lock(release_op_lock);
      release_operation<false>(available_release_ops, op);
    } 

    //--------------------------------------------------------------------------
    void Runtime::free_begin_op(TraceBeginOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(begin_op_lock);
      release_operation<false>(available_begin_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_complete_op(TraceCompleteOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(complete_op_lock);
      release_operation<false>(available_complete_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_recurrent_op(TraceRecurrentOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(recurrent_op_lock);
      release_operation<false>(available_recurrent_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_epoch_op(MustEpochOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock e_lock(epoch_op_lock);
      release_operation<false>(available_epoch_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_pending_partition_op(PendingPartitionOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(pending_partition_op_lock);
      release_operation<false>(available_pending_partition_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_dependent_partition_op(DependentPartitionOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(dependent_partition_op_lock);
      release_operation<false>(available_dependent_partition_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_point_dep_part_op(PointDepPartOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(dependent_partition_op_lock);
      release_operation<true>(available_point_dep_part_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_fill_op(FillOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(fill_op_lock);
      release_operation<false>(available_fill_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_index_fill_op(IndexFillOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(fill_op_lock);
      release_operation<false>(available_index_fill_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_point_fill_op(PointFillOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(fill_op_lock);
      release_operation<true>(available_point_fill_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_discard_op(DiscardOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(discard_op_lock);
      release_operation<false>(available_discard_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_attach_op(AttachOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(attach_op_lock);
      release_operation<false>(available_attach_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_index_detach_op(IndexDetachOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock d_lock(detach_op_lock);
      release_operation<false>(available_index_detach_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_point_detach_op(PointDetachOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock d_lock(detach_op_lock);
      release_operation<true>(available_point_detach_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_detach_op(DetachOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock d_lock(detach_op_lock);
      release_operation<false>(available_detach_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_index_attach_op(IndexAttachOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(attach_op_lock);
      release_operation<false>(available_index_attach_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_point_attach_op(PointAttachOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(attach_op_lock);
      release_operation<true>(available_point_attach_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_timing_op(TimingOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(timing_op_lock);
      release_operation<false>(available_timing_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_individual_task(ReplIndividualTask *task)
    //--------------------------------------------------------------------------
    {
      AutoLock i_lock(individual_task_lock);
      release_operation<false>(available_repl_individual_tasks, task);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_index_task(ReplIndexTask *task)
    //--------------------------------------------------------------------------
    {
      AutoLock i_lock(index_task_lock);
      release_operation<false>(available_repl_index_tasks, task);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_merge_close_op(ReplMergeCloseOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock m_lock(merge_close_op_lock);
      release_operation<false>(available_repl_merge_close_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_refinement_op(ReplRefinementOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock m_lock(refinement_op_lock);
      release_operation<false>(available_repl_refinement_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_reset_op(ReplResetOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock m_lock(reset_op_lock);
      release_operation<false>(available_repl_reset_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_fill_op(ReplFillOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(fill_op_lock);
      release_operation<false>(available_repl_fill_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_index_fill_op(ReplIndexFillOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock f_lock(fill_op_lock);
      release_operation<false>(available_repl_index_fill_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_copy_op(ReplCopyOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock c_lock(copy_op_lock);
      release_operation<false>(available_repl_copy_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_index_copy_op(ReplIndexCopyOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock c_lock(copy_op_lock);
      release_operation<false>(available_repl_index_copy_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_deletion_op(ReplDeletionOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock d_lock(deletion_op_lock);
      release_operation<false>(available_repl_deletion_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_pending_partition_op(ReplPendingPartitionOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock p_lock(pending_partition_op_lock);
      release_operation<false>(available_repl_pending_partition_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_dependent_partition_op(ReplDependentPartitionOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock d_lock(dependent_partition_op_lock);
      release_operation<false>(available_repl_dependent_partition_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_epoch_op(ReplMustEpochOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock m_lock(epoch_op_lock);
      release_operation<false>(available_repl_must_epoch_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_timing_op(ReplTimingOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(timing_op_lock);
      release_operation<false>(available_repl_timing_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_tunable_op(ReplTunableOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(tunable_op_lock);
      release_operation<false>(available_repl_tunable_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_all_reduce_op(ReplAllReduceOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(all_reduce_op_lock);
      release_operation<false>(available_repl_all_reduce_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_fence_op(ReplFenceOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(fence_op_lock);
      release_operation<false>(available_repl_fence_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_map_op(ReplMapOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock m_lock(map_op_lock);
      release_operation<false>(available_repl_map_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_discard_op(ReplDiscardOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(discard_op_lock);
      release_operation<false>(available_repl_discard_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_attach_op(ReplAttachOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(attach_op_lock);
      release_operation<false>(available_repl_attach_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_index_attach_op(ReplIndexAttachOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(attach_op_lock);
      release_operation<false>(available_repl_index_attach_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_detach_op(ReplDetachOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock d_lock(detach_op_lock);
      release_operation<false>(available_repl_detach_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_index_detach_op(ReplIndexDetachOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock d_lock(detach_op_lock);
      release_operation<false>(available_repl_index_detach_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_acquire_op(ReplAcquireOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(acquire_op_lock);
      release_operation<false>(available_repl_acquire_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_release_op(ReplReleaseOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock r_lock(release_op_lock);
      release_operation<false>(available_repl_release_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_begin_op(ReplTraceBeginOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(begin_op_lock);
      release_operation<false>(available_repl_begin_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_complete_op(ReplTraceCompleteOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(complete_op_lock);
      release_operation<false>(available_repl_complete_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_repl_recurrent_op(ReplTraceRecurrentOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(recurrent_op_lock);
      release_operation<false>(available_repl_recurrent_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_tunable_op(TunableOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock t_lock(tunable_op_lock);
      release_operation<false>(available_tunable_ops, op);
    }

    //--------------------------------------------------------------------------
    void Runtime::free_all_reduce_op(AllReduceOp *op)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(all_reduce_op_lock);
      release_operation<false>(available_all_reduce_ops, op);
    }

    //--------------------------------------------------------------------------
    ContextID Runtime::allocate_region_tree_context(void)
    //--------------------------------------------------------------------------
    {
      // Try getting something off the list of available contexts
      AutoLock ctx_lock(context_lock);
      if (available_contexts.empty())
      {
        // Double the number of available contexts
        available_contexts.resize(total_contexts);
        total_contexts *= 2;
        for (unsigned idx = 0; idx < available_contexts.size(); idx++)
          available_contexts[idx] = total_contexts - (idx+1);
        // Tell all the processor managers about the additional contexts
        for (std::map<Processor,ProcessorManager*>::const_iterator it = 
              proc_managers.begin(); it != proc_managers.end(); it++)
          it->second->update_max_context_count(total_contexts);
      }
      ContextID result = available_contexts.back();
      available_contexts.pop_back();
      return result;
    }

    //--------------------------------------------------------------------------
    void Runtime::free_region_tree_context(ContextID context)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      forest->check_context_state(context);
#endif
      AutoLock ctx_lock(context_lock);
      available_contexts.push_back(context);
    }

    //--------------------------------------------------------------------------
    bool Runtime::is_local(Processor proc) const
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(proc.exists());
#endif
      if (separate_runtime_instances)
        return (local_procs.find(proc) != local_procs.end());
      else
        return (proc.address_space() == address_space);
    }

    //--------------------------------------------------------------------------
    bool Runtime::is_visible_memory(Processor proc, Memory memory)
    //--------------------------------------------------------------------------
    {
      // If we cached it locally for our processors, then just go
      // ahead and get the result
      std::map<Processor,ProcessorManager*>::const_iterator finder = 
        proc_managers.find(proc);
      if (finder != proc_managers.end())
        return finder->second->is_visible_memory(memory);
      // Otherwise look up the result
      Machine::MemoryQuery visible_memories(machine);
      // Have to handle the case where this is a processor group
      if (proc.kind() == Processor::PROC_GROUP)
      {
        std::vector<Processor> group_members;
        proc.get_group_members(group_members);
        for (std::vector<Processor>::const_iterator it =
              group_members.begin(); it != group_members.end(); it++)
          visible_memories.has_affinity_to(*it);
      }
      else
        visible_memories.has_affinity_to(proc);
      for (Machine::MemoryQuery::iterator it =
            visible_memories.begin(); it != visible_memories.end(); it++)
        if ((*it) == memory)
          return true;
      return false;
    }

    //--------------------------------------------------------------------------
    void Runtime::find_visible_memories(Processor proc, 
                                        std::set<Memory> &visible)
    //--------------------------------------------------------------------------
    {
      // If we cached it locally for our processors, then just go
      // ahead and get the result
      std::map<Processor,ProcessorManager*>::const_iterator finder = 
        proc_managers.find(proc);
      if (finder != proc_managers.end())
      {
        finder->second->find_visible_memories(visible);
        return;
      }
      // Otherwise look up the result
      Machine::MemoryQuery visible_memories(machine);
      // Have to handle the case where this is a processor group
      if (proc.kind() == Processor::PROC_GROUP)
      {
        std::vector<Processor> group_members;
        proc.get_group_members(group_members);
        for (std::vector<Processor>::const_iterator it = 
              group_members.begin(); it != group_members.end(); it++)
          visible_memories.has_affinity_to(*it);
      }
      else
        visible_memories.has_affinity_to(proc);
      for (Machine::MemoryQuery::iterator it = visible_memories.begin();
            it != visible_memories.end(); it++)
        visible.insert(*it);
    }

    //--------------------------------------------------------------------------
    Memory Runtime::find_local_memory(Processor proc, Memory::Kind mem_kind)
    //--------------------------------------------------------------------------
    {
      if ((mem_kind == Memory::SYSTEM_MEM) &&
          (proc.address_space() == address_space))
        return runtime_system_memory;
      // Check to see if this is a local processor in which case
      // we should be able to do this much faster
      std::map<Processor,ProcessorManager*>::const_iterator finder = 
        proc_managers.find(proc);
      if (finder != proc_managers.end())
        return finder->second->find_best_visible_memory(mem_kind);
      // Otherwise look up the result
      Machine::MemoryQuery visible_memories(machine);
      // Must be of the right kind
      visible_memories.only_kind(mem_kind);
      // Must not be empty
      visible_memories.has_capacity(1/*at least one byte*/);
      // Have to handle the case where this is a processor group
      if (proc.kind() == Processor::PROC_GROUP)
      {
        std::vector<Processor> group_members;
        proc.get_group_members(group_members);
        for (std::vector<Processor>::const_iterator it = 
              group_members.begin(); it != group_members.end(); it++)
          visible_memories.best_affinity_to(*it);
      }
      else
        visible_memories.best_affinity_to(proc);
      if (visible_memories.count() == 0)
      {
        const char *mem_names[] = {
#define MEM_NAMES(name, desc) desc,
          REALM_MEMORY_KINDS(MEM_NAMES) 
#undef MEM_NAMES
        };
        const char *proc_names[] = {
#define PROC_NAMES(name, desc) desc,
          REALM_PROCESSOR_KINDS(PROC_NAMES)
#undef PROC_NAMES
        };
        REPORT_LEGION_ERROR(ERROR_CONFUSED_USER,
            "%s Processor " IDFMT " has no %s memory",
            proc_names[proc.kind()], proc.id, mem_names[mem_kind])
      }
      return visible_memories.first();
    }

    //--------------------------------------------------------------------------
    IndexSpaceID Runtime::get_unique_index_space_id(void)
    //--------------------------------------------------------------------------
    {
      IndexSpaceID result = unique_index_space_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      // If we have overflow on the number of partitions created
      // then we are really in a bad place.
      assert(result <= unique_index_space_id); 
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    IndexPartitionID Runtime::get_unique_index_partition_id(void)
    //--------------------------------------------------------------------------
    {
      IndexPartitionID result =
        unique_index_partition_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      // If we have overflow on the number of partitions created
      // then we are really in a bad place.
      assert(result <= unique_index_partition_id); 
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    FieldSpaceID Runtime::get_unique_field_space_id(void)
    //--------------------------------------------------------------------------
    {
      FieldSpaceID result = unique_field_space_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      // If we have overflow on the number of field spaces
      // created then we are really in a bad place.
      assert(result <= unique_field_space_id);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    IndexTreeID Runtime::get_unique_index_tree_id(void)
    //--------------------------------------------------------------------------
    {
      IndexTreeID result = unique_index_tree_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      // If we have overflow on the number of region trees
      // created then we are really in a bad place.
      assert(result <= unique_index_tree_id);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    RegionTreeID Runtime::get_unique_region_tree_id(void)
    //--------------------------------------------------------------------------
    {
      RegionTreeID result = unique_region_tree_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      // If we have overflow on the number of region trees
      // created then we are really in a bad place.
      assert(result <= unique_region_tree_id);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    UniqueID Runtime::get_unique_operation_id(void)
    //--------------------------------------------------------------------------
    {
      UniqueID result = unique_operation_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      assert(result <= unique_operation_id);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    FieldID Runtime::get_unique_field_id(void)
    //--------------------------------------------------------------------------
    {
      FieldID result = unique_field_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      assert(result <= unique_field_id);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    CodeDescriptorID Runtime::get_unique_code_descriptor_id(void)
    //--------------------------------------------------------------------------
    {
      CodeDescriptorID result = 
        unique_code_descriptor_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      assert(result <= unique_code_descriptor_id);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    LayoutConstraintID Runtime::get_unique_constraint_id(void)
    //--------------------------------------------------------------------------
    {
      LayoutConstraintID result =
        unique_constraint_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      assert(result <= unique_constraint_id);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    IndexSpaceExprID Runtime::get_unique_index_space_expr_id(void)
    //--------------------------------------------------------------------------
    {
      IndexSpaceExprID result = unique_is_expr_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      assert(result <= unique_is_expr_id);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    uint64_t Runtime::get_unique_top_level_task_id(void)
    //--------------------------------------------------------------------------
    {
      uint64_t result = unique_top_level_task_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      assert(result < unique_top_level_task_id);
#endif
      return result;
    }

    //--------------------------------------------------------------------------
    uint64_t Runtime::get_unique_implicit_top_level_task_id(void)
    //--------------------------------------------------------------------------
    {
      // These count the same across all the nodes and don't need to be 
      // atomic since it's up to the caller to guard againt concurrency here
      uint64_t result = unique_implicit_top_level_task_id++;
#ifdef DEBUG_LEGION
      assert(result < unique_implicit_top_level_task_id);
#endif
      return result;
    }

#ifdef LEGION_SPY
    //--------------------------------------------------------------------------
    unsigned Runtime::get_unique_indirections_id(void)
    //--------------------------------------------------------------------------
    {
      unsigned result = unique_indirections_id.fetch_add(runtime_stride);
#ifdef DEBUG_LEGION
      // check for overflow
      assert(result <= unique_indirections_id);
#endif
      return result;
    }
#endif

    //--------------------------------------------------------------------------
    Provenance* Runtime::find_or_create_provenance(const char *prov,size_t size)
    //--------------------------------------------------------------------------
    {
      if ((prov == NULL) || (size == 0))
        return NULL;
      // Check to see if we can find it in read-only mode first
      {
        AutoLock prov_lock(provenance_lock,1,false/*exclusive*/);
        std::map<size_t,std::vector<Provenance*> >::const_iterator finder =
          provenances.find(size);
        if (finder != provenances.end())
        {
          for (std::vector<Provenance*>::const_iterator it =
                finder->second.begin(); it != finder->second.end(); it++)
          {
            if ((*it)->full.compare(0, size, prov) != 0)
              continue;
            (*it)->add_reference();
            return (*it);
          }
        }
      }
      // Retake the lock in exclusive mode
      AutoLock prov_lock(provenance_lock);
      // Check to make sure we didn't lose the race
      std::map<size_t,std::vector<Provenance*> >::iterator finder =
        provenances.find(size);
      if (finder != provenances.end())
      {
        for (std::vector<Provenance*>::const_iterator it =
              finder->second.begin(); it != finder->second.end(); it++)
        {
          if ((*it)->full.compare(0, size, prov) != 0)
            continue;
          (*it)->add_reference();
          return (*it);
        }
      }
      else
        finder = provenances.emplace(
            std::make_pair(size, std::vector<Provenance*>())).first;
      // Generate a new provenance object
      Provenance *result = new Provenance(unique_provenance_id, prov, size);
      result->add_reference(2); // one for ourself and one for the caller
      finder->second.push_back(result);
      // If we have a profiler, then record this provenance
      if (profiler != NULL)
        profiler->record_provenance(unique_provenance_id, prov, size);
      unique_provenance_id += runtime_stride;
      return result;
    }

    //--------------------------------------------------------------------------
    LegionErrorType Runtime::verify_requirement(
                               const RegionRequirement &req, FieldID &bad_field)
    //--------------------------------------------------------------------------
    {
      FieldSpace sp = (req.handle_type == LEGION_SINGULAR_PROJECTION) 
                      || (req.handle_type == LEGION_REGION_PROJECTION)
                        ? req.region.field_space : req.partition.field_space;
      // First make sure that all the privilege fields are valid for
      // the given field space of the region or partition
      for (std::set<FieldID>::const_iterator it = req.privilege_fields.begin();
            it != req.privilege_fields.end(); it++)
      {
        if (!forest->has_field(sp, *it))
        {
          bad_field = *it;
          return ERROR_FIELD_SPACE_FIELD_MISMATCH;
        }
      }
      // Make sure that the requested node is a valid request
      if ((req.handle_type == LEGION_SINGULAR_PROJECTION) || 
          (req.handle_type == LEGION_REGION_PROJECTION))
      {
        if (forest->get_tree(req.region.get_tree_id(),
              true/*can fail*/) == NULL)
          return ERROR_INVALID_REGION_HANDLE;
        if (forest->get_node(req.region.get_index_space(), 
              NULL/*do not defer*/, true/*can fail*/) == NULL)
          return ERROR_INVALID_REGION_HANDLE;
        if (req.region.get_tree_id() != req.parent.get_tree_id())
          return ERROR_INVALID_REGION_HANDLE;
      }
      else
      {
        if (forest->get_tree(req.partition.get_tree_id(), 
              true/*can fail*/) == NULL)
          return ERROR_INVALID_PARTITION_HANDLE;
        if (forest->get_node(req.partition.get_index_partition(),
              NULL/*do not defer*/, true/*can fail*/) == NULL)
          return ERROR_INVALID_PARTITION_HANDLE;
        if (req.partition.get_tree_id() != req.parent.get_tree_id())
          return ERROR_INVALID_PARTITION_HANDLE;
      }

      // Then check that any instance fields are included in the privilege 
      // fields.  Make sure that there are no duplicates in the instance fields
      std::set<FieldID> inst_duplicates;
      for (std::vector<FieldID>::const_iterator it = 
            req.instance_fields.begin(); it != 
            req.instance_fields.end(); it++)
      {
        if (req.privilege_fields.find(*it) == req.privilege_fields.end())
        {
          bad_field = *it;
          return ERROR_INVALID_INSTANCE_FIELD;
        }
        if (inst_duplicates.find(*it) != inst_duplicates.end())
        {
          bad_field = *it;
          return ERROR_DUPLICATE_INSTANCE_FIELD;
        }
        inst_duplicates.insert(*it);
      }

      // If this is a projection requirement and the child region selected will 
      // need to be in exclusive mode then the partition must be disjoint
      if ((req.handle_type == LEGION_PARTITION_PROJECTION) && 
          (IS_WRITE(req)))
      {
        if (!forest->is_disjoint(req.partition))
          return ERROR_NON_DISJOINT_PARTITION;
      }

      // Made it here, then there is no error
      return LEGION_NO_ERROR;
    }

    //--------------------------------------------------------------------------
    IndexSpace Runtime::help_create_index_space_handle(TypeTag type_tag)
    //--------------------------------------------------------------------------
    {
      IndexSpace handle(get_unique_index_space_id(),
                        get_unique_index_tree_id(), type_tag);
      return handle;
    }

    //--------------------------------------------------------------------------
    unsigned Runtime::generate_random_integer(void)
    //--------------------------------------------------------------------------
    {
      AutoLock r_lock(random_lock);
      unsigned result = nrand48(random_state);
      return result;
    }

#ifdef LEGION_TRACE_ALLOCATION 
    //--------------------------------------------------------------------------
    void Runtime::trace_allocation(AllocationType type, size_t size, int elems)
    //--------------------------------------------------------------------------
    {
      if (prepared_for_shutdown)
        return;
      AutoLock a_lock(allocation_lock);
      std::map<AllocationType,AllocationTracker>::iterator finder = 
        allocation_manager.find(type);
      size_t alloc_size = size * elems;
      finder->second.total_allocations += elems;
      finder->second.total_bytes += alloc_size;
      finder->second.diff_allocations += elems;
      finder->second.diff_bytes += alloc_size;
    }

    //--------------------------------------------------------------------------
    void Runtime::trace_free(AllocationType type, size_t size, int elems)
    //--------------------------------------------------------------------------
    {
      if (prepared_for_shutdown)
        return;
      AutoLock a_lock(allocation_lock);
      std::map<AllocationType,AllocationTracker>::iterator finder = 
        allocation_manager.find(type);
      size_t free_size = size * elems;
      finder->second.total_allocations -= elems;
      finder->second.total_bytes -= free_size;
      finder->second.diff_allocations -= elems;
      finder->second.diff_bytes -= free_size;
    }

    //--------------------------------------------------------------------------
    void Runtime::dump_allocation_info(void)
    //--------------------------------------------------------------------------
    {
      AutoLock a_lock(allocation_lock);
      for (std::map<AllocationType,AllocationTracker>::iterator it = 
            allocation_manager.begin(); it != allocation_manager.end(); it++)
      {
        // Skip anything that is empty
        if (it->second.total_allocations == 0)
          continue;
        // Skip anything that hasn't changed
        if (it->second.diff_allocations == 0)
          continue;
        log_allocation.info("%s on %d: "
            "total=%d total_bytes=%ld diff=%d diff_bytes=%lld",
            get_allocation_name(it->first), address_space,
            it->second.total_allocations, it->second.total_bytes,
            it->second.diff_allocations, (long long int)it->second.diff_bytes);
        it->second.diff_allocations = 0;
        it->second.diff_bytes = 0;
      }
      struct rusage usage;
      getrusage(RUSAGE_SELF, &usage);
      log_allocation.info("RSS: %ld", usage.ru_maxrss);
      log_allocation.info(" ");
    }

    //--------------------------------------------------------------------------
    /*static*/ const char* Runtime::get_allocation_name(AllocationType type)
    //--------------------------------------------------------------------------
    {
      switch (type)
      {
        case ARGUMENT_MAP_ALLOC:
          return "Argument Map";
        case ARGUMENT_MAP_STORE_ALLOC:
          return "Argument Map Store";
        case STORE_ARGUMENT_ALLOC:
          return "Store Argument";
        case MPI_HANDSHAKE_ALLOC:
          return "MPI Handshake";
        case GRANT_ALLOC:
          return "Grant";
        case FUTURE_ALLOC:
          return "Future";
        case FUTURE_MAP_ALLOC:
          return "Future Map";
        case PHYSICAL_REGION_ALLOC:
          return "Physical Region";
        case OUTPUT_REGION_ALLOC:
          return "Output Region";
        case EXTERNAL_RESOURCES_ALLOC:
          return "External Resources";
        case STATIC_TRACE_ALLOC:
          return "Static Trace";
        case DYNAMIC_TRACE_ALLOC:
          return "Dynamic Trace";
        case ALLOC_MANAGER_ALLOC:
          return "Allocation Manager";
        case ALLOC_INTERNAL_ALLOC:
          return "Allocation Internal";
        case TASK_ARGS_ALLOC:
          return "Task Arguments";
        case REDUCTION_ALLOC:
          return "Reduction Result";
        case PREDICATE_ALLOC:
          return "Default Predicate";
        case FUTURE_RESULT_ALLOC:
          return "Future Result";
        case PHYSICAL_MANAGER_ALLOC:
          return "Physical Manager";
        case TREE_CLOSE_ALLOC:
          return "Tree Close List";
        case TREE_CLOSE_IMPL_ALLOC:
          return "Tree Close Impl";
        case MATERIALIZED_VIEW_ALLOC:
          return "Materialized View";
        case REDUCTION_VIEW_ALLOC:
          return "Reduction View";
        case REPLICATED_VIEW_ALLOC:
          return "Replicated View";
        case ALLREDUCE_VIEW_ALLOC:
          return "Allreduce View";
        case FILL_VIEW_ALLOC:
          return "Fill View";
        case PHI_VIEW_ALLOC:
          return "Phi View";
        case INDIVIDUAL_TASK_ALLOC:
          return "Individual Task";
        case POINT_TASK_ALLOC:
          return "Point Task";
        case INDEX_TASK_ALLOC:
          return "Index Task";
        case SLICE_TASK_ALLOC:
          return "Slice Task";
        case TOP_TASK_ALLOC:
          return "Top Level Task";
        case REMOTE_TASK_ALLOC:
          return "Remote Task";
        case INLINE_TASK_ALLOC:
          return "Inline Task";
        case MAP_OP_ALLOC:
          return "Map Op";
        case COPY_OP_ALLOC:
          return "Copy Op";
        case FENCE_OP_ALLOC:
          return "Fence Op";
        case FRAME_OP_ALLOC:
          return "Frame Op";
        case CREATION_OP_ALLOC:
          return "Creation Op";
        case DELETION_OP_ALLOC:
          return "Deletion Op";
        case CLOSE_OP_ALLOC:
          return "Close Op";
        case REFINEMENT_OP_ALLOC:
          return "Refinement Op";
        case DYNAMIC_COLLECTIVE_OP_ALLOC:
          return "Dynamic Collective Op";
        case FUTURE_PRED_OP_ALLOC:
          return "Future Pred Op";
        case NOT_PRED_OP_ALLOC:
          return "Not Pred Op";
        case AND_PRED_OP_ALLOC:
          return "And Pred Op";
        case OR_PRED_OP_ALLOC:
          return "Or Pred Op";
        case ACQUIRE_OP_ALLOC:
          return "Acquire Op";
        case RELEASE_OP_ALLOC:
          return "Release Op";
        case TRACE_BEGIN_OP_ALLOC:
          return "Trace Begin";
        case TRACE_RECURRENT_OP_ALLOC:
          return "Trace Recurrent";
        case TRACE_COMPLETE_OP_ALLOC:
          return "Trace Complete Op";
        case MUST_EPOCH_OP_ALLOC:
          return "Must Epoch Op";
        case PENDING_PARTITION_OP_ALLOC:
          return "Pending Partition Op";
        case DEPENDENT_PARTITION_OP_ALLOC:
          return "Dependent Partition Op";
        case FILL_OP_ALLOC:
          return "Fill Op";
        case DISCARD_OP_ALLOC:
          return "Discard Op";
        case ATTACH_OP_ALLOC:
          return "Attach Op";
        case DETACH_OP_ALLOC:
          return "Detach Op";
        case MESSAGE_BUFFER_ALLOC:
          return "Message Buffer";
        case LOGICAL_VIEW_ALLOC:
          return "Logical Views";
        case LOGICAL_FIELD_VERSIONS_ALLOC:
          return "Logical Field Versions";
        case LOGICAL_FIELD_STATE_ALLOC:
          return "Logical Field States";
        case CURR_LOGICAL_ALLOC:
          return "Current Logical Users";
        case PREV_LOGICAL_ALLOC:
          return "Previous Logical Users";
        case VERSION_ID_ALLOC:
          return "Version IDs";
        case LOGICAL_REC_ALLOC:
          return "Recorded Logical Users";
        case CLOSE_LOGICAL_ALLOC:
          return "Close Logical Users";
        case VALID_VIEW_ALLOC:
          return "Valid Instance Views";
        case VALID_REDUCTION_ALLOC:
          return "Valid Reduction Views";
        case PENDING_UPDATES_ALLOC:
          return "Pending Updates";
        case LAYOUT_DESCRIPTION_ALLOC:
          return "Layout Description";
        case PHYSICAL_USER_ALLOC:
          return "Physical Users";
        case PHYSICAL_VERSION_ALLOC:
          return "Physical Versions";
        case MEMORY_INSTANCES_ALLOC:
          return "Memory Manager Instances";
        case MEMORY_GARBAGE_ALLOC:
          return "Memory Garbage Instances";
        case PROCESSOR_GROUP_ALLOC:
          return "Processor Groups";
        case RUNTIME_DISTRIBUTED_ALLOC:
          return "Runtime Distributed IDs";
        case RUNTIME_DIST_COLLECT_ALLOC:
          return "Distributed Collectables";
        case RUNTIME_GC_EPOCH_ALLOC:
          return "Runtime Garbage Collection Epochs";
        case RUNTIME_FUTURE_ALLOC:
          return "Runtime Futures";
        case RUNTIME_REMOTE_ALLOC:
          return "Runtime Remote Contexts";
        case TASK_INLINE_REGION_ALLOC:
          return "Task Inline Regions";
        case TASK_TRACES_ALLOC:
          return "Task Traces";
        case TASK_RESERVATION_ALLOC:
          return "Task Reservations";
        case TASK_BARRIER_ALLOC:
          return "Task Barriers";
        case TASK_LOCAL_FIELD_ALLOC:
          return "Task Local Fields";
        case SEMANTIC_INFO_ALLOC:
          return "Semantic Information";
        case DIRECTORY_ALLOC:
          return "State Directory";
        case DENSE_INDEX_ALLOC:
          return "Dense Index Set";
        case CURRENT_STATE_ALLOC:
          return "Current State";
        case VERSION_MANAGER_ALLOC:
          return "Version Manager";
        case PHYSICAL_STATE_ALLOC:
          return "Physical State";
        case EQUIVALENCE_SET_ALLOC:
          return "Equivalence Set";
        case AGGREGATE_VERSION_ALLOC:
          return "Aggregate Version";
        case TASK_IMPL_ALLOC:
          return "Task Implementation";
        case VARIANT_IMPL_ALLOC:
          return "Variant Implementation";
        case LAYOUT_CONSTRAINTS_ALLOC:
          return "Layout Constraints";
        case COPY_FILL_AGGREGATOR_ALLOC:
          return "Copy Fill Aggregator";
        case UNION_EXPR_ALLOC:
          return "Union Index Space Expression";
        case INTERSECTION_EXPR_ALLOC:
          return "Intersection Index Space Expression";
        case DIFFERENCE_EXPR_ALLOC:
          return "Difference Index Space Expression";
        case INSTANCE_EXPR_ALLOC:
          return "Instance Index Space Expression";
        case REMOTE_EXPR_ALLOC:
          return "Remote Index Space Expression";
        default:
          assert(false); // should never get here
      }
      return NULL;
    }
#endif

#ifdef DEBUG_LEGION
    //--------------------------------------------------------------------------
    void Runtime::print_out_individual_tasks(FILE *f, int cnt /*= -1*/)
    //--------------------------------------------------------------------------
    {
      // Build a map of the tasks based on their task IDs
      // so we can print them out in the order that they were created.
      // No need to hold the lock because we'll only ever call this
      // in the debugger.
      std::map<UniqueID,IndividualTask*> out_tasks;
      for (std::set<IndividualTask*>::const_iterator it = 
            out_individual_tasks.begin(); it !=
            out_individual_tasks.end(); it++)
      {
        out_tasks[(*it)->get_unique_id()] = *it;
      }
      for (std::map<UniqueID,IndividualTask*>::const_iterator it = 
            out_tasks.begin(); (it != out_tasks.end()); it++)
      {
        ApEvent completion = it->second->get_completion_event();
        fprintf(f,"Outstanding Individual Task %lld: %p %s (" IDFMT ")\n",
                it->first, it->second, it->second->get_task_name(),
                completion.id); 
        if (cnt > 0)
          cnt--;
        else if (cnt == 0)
          break;
      }
      fflush(f);
    }

    //--------------------------------------------------------------------------
    void Runtime::print_out_index_tasks(FILE *f, int cnt /*= -1*/)
    //--------------------------------------------------------------------------
    {
      // Build a map of the tasks based on their task IDs
      // so we can print them out in the order that they were created.
      // No need to hold the lock because we'll only ever call this
      // in the debugger.
      std::map<UniqueID,IndexTask*> out_tasks;
      for (std::set<IndexTask*>::const_iterator it = 
            out_index_tasks.begin(); it !=
            out_index_tasks.end(); it++)
      {
        out_tasks[(*it)->get_unique_id()] = *it;
      }
      for (std::map<UniqueID,IndexTask*>::const_iterator it = 
            out_tasks.begin(); (it != out_tasks.end()); it++)
      {
        ApEvent completion = it->second->get_completion_event();
        fprintf(f,"Outstanding Index Task %lld: %p %s (" IDFMT ")\n",
                it->first, it->second, it->second->get_task_name(),
                completion.id); 
        if (cnt > 0)
          cnt--;
        else if (cnt == 0)
          break;
      }
      fflush(f);
    }

    //--------------------------------------------------------------------------
    void Runtime::print_out_slice_tasks(FILE *f, int cnt /*= -1*/)
    //--------------------------------------------------------------------------
    {
      // Build a map of the tasks based on their task IDs
      // so we can print them out in the order that they were created.
      // No need to hold the lock because we'll only ever call this
      // in the debugger.
      std::map<UniqueID,SliceTask*> out_tasks;
      for (std::set<SliceTask*>::const_iterator it = 
            out_slice_tasks.begin(); it !=
            out_slice_tasks.end(); it++)
      {
        out_tasks[(*it)->get_unique_id()] = *it;
      }
      for (std::map<UniqueID,SliceTask*>::const_iterator it = 
            out_tasks.begin(); (it != out_tasks.end()); it++)
      {
        ApEvent completion = it->second->get_completion_event();
        fprintf(f,"Outstanding Slice Task %lld: %p %s (" IDFMT ")\n",
                it->first, it->second, it->second->get_task_name(),
                completion.id); 
        if (cnt > 0)
          cnt--;
        else if (cnt == 0)
          break;
      }
      fflush(f);
    }

    //--------------------------------------------------------------------------
    void Runtime::print_out_point_tasks(FILE *f, int cnt /*= -1*/)
    //--------------------------------------------------------------------------
    {
      // Build a map of the tasks based on their task IDs
      // so we can print them out in the order that they were created.
      // No need to hold the lock because we'll only ever call this
      // in the debugger.
      std::map<UniqueID,PointTask*> out_tasks;
      for (std::set<PointTask*>::const_iterator it = 
            out_point_tasks.begin(); it !=
            out_point_tasks.end(); it++)
      {
        out_tasks[(*it)->get_unique_id()] = *it;
      }
      for (std::map<UniqueID,PointTask*>::const_iterator it = 
            out_tasks.begin(); (it != out_tasks.end()); it++)
      {
        ApEvent completion = it->second->get_completion_event();
        fprintf(f,"Outstanding Point Task %lld: %p %s (" IDFMT ")\n",
                it->first, it->second, it->second->get_task_name(),
                completion.id); 
        if (cnt > 0)
          cnt--;
        else if (cnt == 0)
          break;
      }
      fflush(f);
    }

    //--------------------------------------------------------------------------
    void Runtime::print_outstanding_tasks(FILE *f, int cnt /*= -1*/)
    //--------------------------------------------------------------------------
    {
      std::map<UniqueID,TaskOp*> out_tasks;
      for (std::set<IndividualTask*>::const_iterator it = 
            out_individual_tasks.begin(); it !=
            out_individual_tasks.end(); it++)
      {
        out_tasks[(*it)->get_unique_id()] = *it;
      }
      for (std::set<IndexTask*>::const_iterator it = 
            out_index_tasks.begin(); it !=
            out_index_tasks.end(); it++)
      {
        out_tasks[(*it)->get_unique_id()] = *it;
      }
      for (std::set<SliceTask*>::const_iterator it = 
            out_slice_tasks.begin(); it !=
            out_slice_tasks.end(); it++)
      {
        out_tasks[(*it)->get_unique_id()] = *it;
      }
      for (std::set<PointTask*>::const_iterator it = 
            out_point_tasks.begin(); it !=
            out_point_tasks.end(); it++)
      {
        out_tasks[(*it)->get_unique_id()] = *it;
      }
      for (std::map<UniqueID,TaskOp*>::const_iterator it = 
            out_tasks.begin(); it != out_tasks.end(); it++)
      {
        ApEvent completion = it->second->get_completion_event();
        switch (it->second->get_task_kind())
        {
          case TaskOp::INDIVIDUAL_TASK_KIND:
            {
              fprintf(f,"Outstanding Individual Task %lld: %p %s (" 
                        IDFMT ")\n",
                it->first, it->second, it->second->get_task_name(),
                completion.id);
              break;
            }
          case TaskOp::POINT_TASK_KIND:
            {
              fprintf(f,"Outstanding Point Task %lld: %p %s (" 
                        IDFMT ")\n",
                it->first, it->second, it->second->get_task_name(),
                completion.id);
              break;
            }
          case TaskOp::INDEX_TASK_KIND:
            {
              fprintf(f,"Outstanding Index Task %lld: %p %s (" 
                        IDFMT ")\n",
                it->first, it->second, it->second->get_task_name(),
                completion.id);
              break;
            }
          case TaskOp::SLICE_TASK_KIND:
            {
              fprintf(f,"Outstanding Slice Task %lld: %p %s (" 
                        IDFMT ")\n",
                it->first, it->second, it->second->get_task_name(),
                completion.id);
              break;
            }
          default:
            assert(false);
        }
        if (cnt > 0)
          cnt--;
        else if (cnt == 0)
          break;
      }
      fflush(f);
    }
#endif

    //--------------------------------------------------------------------------
    LayoutConstraintID Runtime::register_layout(
                                const LayoutConstraintRegistrar &registrar,
                                LayoutConstraintID layout_id, DistributedID did,
                                CollectiveMapping *collective_mapping)
    //--------------------------------------------------------------------------
    {
      if (layout_id == LEGION_AUTO_GENERATE_ID)
        layout_id = get_unique_constraint_id();
      // Now make our entry and then return the result
      LayoutConstraints *constraints = 
        new LayoutConstraints(layout_id, this, registrar,
            false/*internal*/, did, collective_mapping);
      if (!register_layout(constraints))
        // If someone else already registered this ID then we delete our object
        delete constraints;
      return layout_id;
    }

    //--------------------------------------------------------------------------
    LayoutConstraints* Runtime::register_layout(FieldSpace handle,
                                 const LayoutConstraintSet &cons, bool internal)
    //--------------------------------------------------------------------------
    {
      LayoutConstraints *constraints = new LayoutConstraints(
          get_unique_constraint_id(), this, cons, handle, internal);
      register_layout(constraints);
      return constraints;
    }

    //--------------------------------------------------------------------------
    bool Runtime::register_layout(LayoutConstraints *new_constraints)
    //--------------------------------------------------------------------------
    {
      new_constraints->add_base_resource_ref(RUNTIME_REF);
      // If we're not internal and we're the owner then we also
      // add an application reference to prevent early collection
      if (!new_constraints->internal && new_constraints->is_owner())
        new_constraints->add_base_gc_ref(APPLICATION_REF);
      AutoLock l_lock(layout_constraints_lock);
      std::map<LayoutConstraintID,LayoutConstraints*>::const_iterator finder =
        layout_constraints_table.find(new_constraints->layout_id);
      if (finder != layout_constraints_table.end())
        return false;
      layout_constraints_table[new_constraints->layout_id] = new_constraints;
      // Remove any pending requests
      pending_constraint_requests.erase(new_constraints->layout_id);
      // Now we can do the registration with the runtime
      new_constraints->register_with_runtime();
      return true;
    }

    //--------------------------------------------------------------------------
    void Runtime::release_layout(LayoutConstraintID layout_id)
    //--------------------------------------------------------------------------
    {
      LayoutConstraints *constraints = find_layout_constraints(layout_id);
#ifdef DEBUG_LEGION
      assert(!constraints->internal);
#endif
      // Check to see if this is the owner
      if (constraints->is_owner())
      {
        if (constraints->remove_base_gc_ref(APPLICATION_REF))
          delete constraints;
      }
      else
      {
        // Send a message to the owner asking it to do the release
        Serializer rez;
        {
          RezCheck z(rez);
          rez.serialize(layout_id);
        }
        send_constraint_release(constraints->owner_space, rez);
      }
    }

    //--------------------------------------------------------------------------
    void Runtime::unregister_layout(LayoutConstraintID layout_id)
    //--------------------------------------------------------------------------
    {
      LayoutConstraints *constraints = NULL;
      {
        AutoLock l_lock(layout_constraints_lock);
        std::map<LayoutConstraintID,LayoutConstraints*>::iterator finder = 
          layout_constraints_table.find(layout_id);
        if (finder != layout_constraints_table.end())
        {
          constraints = finder->second;
          layout_constraints_table.erase(finder);
        }
      }
      if ((constraints != NULL) && 
          constraints->remove_base_resource_ref(RUNTIME_REF))
        delete (constraints);
    }

    //--------------------------------------------------------------------------
    /*static*/ LayoutConstraintID Runtime::preregister_layout(
                                     const LayoutConstraintRegistrar &registrar,
                                     LayoutConstraintID layout_id)
    //--------------------------------------------------------------------------
    { 
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'preregister_layout' after "
                      "the runtime has started!");
      std::map<LayoutConstraintID,LayoutConstraintRegistrar> 
        &pending_constraints = get_pending_constraint_table();
      // See if we have to generate an ID
      if (layout_id == LEGION_AUTO_GENERATE_ID)
      {
        // Find the first available layout ID
        if (!pending_constraints.empty())
        {
          std::map<LayoutConstraintID,
            LayoutConstraintRegistrar>::const_reverse_iterator finder = 
              pending_constraints.crbegin();
          if (finder->first <= LEGION_MAX_APPLICATION_LAYOUT_ID)
            layout_id = LEGION_MAX_APPLICATION_LAYOUT_ID + 1;
          else
            layout_id = finder->first + 1;
        }
        else
          layout_id = LEGION_MAX_APPLICATION_LAYOUT_ID + 1;
      }
      else
      {
        if (layout_id == 0)
          REPORT_LEGION_ERROR(ERROR_RESERVED_CONSTRAINT_ID, 
                        "Illegal use of reserved constraint ID 0")
        else if (LEGION_MAX_APPLICATION_LAYOUT_ID < layout_id)
          REPORT_LEGION_ERROR(ERROR_RESERVED_CONSTRAINT_ID,
              "Illegal application-provided layout constraint ID %ld "
              "which exceeds the LEGION_MAX_APPLICATION_LAYOUT_ID of %d "
              "configured in legion_config.h.", layout_id,
              LEGION_MAX_APPLICATION_LAYOUT_ID)
        // Check to make sure it is not already used
        std::map<LayoutConstraintID,LayoutConstraintRegistrar>::const_iterator
          finder = pending_constraints.find(layout_id);
        if (finder != pending_constraints.end())
          REPORT_LEGION_ERROR(ERROR_DUPLICATE_CONSTRAINT_ID, 
                        "Duplicate use of constraint ID %ld", layout_id);
      }
      pending_constraints[layout_id] = registrar;
      return layout_id;
    }

    //--------------------------------------------------------------------------
    FieldSpace Runtime::get_layout_constraint_field_space(
                                                   LayoutConstraintID layout_id)
    //--------------------------------------------------------------------------
    {
      LayoutConstraints *constraints = find_layout_constraints(layout_id);
      return constraints->get_field_space();
    }

    //--------------------------------------------------------------------------
    void Runtime::get_layout_constraints(LayoutConstraintID layout_id,
                                        LayoutConstraintSet &layout_constraints)
    //--------------------------------------------------------------------------
    {
      LayoutConstraints *constraints = find_layout_constraints(layout_id);
      layout_constraints = *constraints;
    }

    //--------------------------------------------------------------------------
    const char* Runtime::get_layout_constraints_name(
                                                   LayoutConstraintID layout_id)
    //--------------------------------------------------------------------------
    {
      LayoutConstraints *constraints = find_layout_constraints(layout_id);
      return constraints->get_name();
    }

    //--------------------------------------------------------------------------
    LayoutConstraints* Runtime::find_layout_constraints(
                      LayoutConstraintID layout_id, bool can_fail /*= false*/, 
                      RtEvent *wait_for /*=NULL*/)
    //--------------------------------------------------------------------------
    {
      // See if we can find it first
      RtEvent wait_on;
      {
        AutoLock l_lock(layout_constraints_lock);
        std::map<LayoutConstraintID,LayoutConstraints*>::const_iterator
          finder = layout_constraints_table.find(layout_id);
        if (finder != layout_constraints_table.end())
        {
          return finder->second;
        }
        else
        {
          // See if a request has already been issued
          std::map<LayoutConstraintID,RtEvent>::const_iterator
            wait_on_finder = pending_constraint_requests.find(layout_id);
          if (can_fail || 
              (wait_on_finder == pending_constraint_requests.end()))
          {
            // Ask for the constraints
            AddressSpaceID target = 
              LayoutConstraints::get_owner_space(layout_id, this); 
            if (target == address_space)
            {
              if (can_fail)
                return NULL;
              REPORT_LEGION_ERROR(ERROR_INVALID_CONSTRAINT_ID,
                  "Unable to find layout constraint %ld", layout_id);
            }
            RtUserEvent to_trigger = Runtime::create_rt_user_event();
            Serializer rez;
            {
              RezCheck z(rez);
              rez.serialize(layout_id);
              rez.serialize(to_trigger);
              rez.serialize(can_fail);
            }
            // Send the message
            send_constraint_request(target, rez);
            // Only save the event to wait on if this can't fail
            if (!can_fail)
              pending_constraint_requests[layout_id] = to_trigger;
            wait_on = to_trigger;
          }
          else
            wait_on = wait_on_finder->second;
        }
      }
      // If we want the wait event, just return
      if (wait_for != NULL)
      {
        *wait_for = wait_on;
        return NULL;
      }
      // If we didn't find it send a remote request for the constraints
      wait_on.wait();
      // When we wake up, the result should be there
      AutoLock l_lock(layout_constraints_lock);
      std::map<LayoutConstraintID,LayoutConstraints*>::const_iterator
          finder = layout_constraints_table.find(layout_id);
      if (finder == layout_constraints_table.end())
      {
        if (can_fail)
          return NULL;
#ifdef DEBUG_LEGION
        assert(finder != layout_constraints_table.end());
#endif
      }
      return finder->second;
    }

    /*static*/ TaskID Runtime::legion_main_id = 0;
    /*static*/ MapperID Runtime::legion_main_mapper_id = 0;
    /*static*/ bool Runtime::legion_main_set = false;
    /*static*/ bool Runtime::runtime_initialized = false;
    /*static*/ bool Runtime::runtime_cmdline_parsed = false;
    /*static*/ bool Runtime::runtime_started = false;
    /*static*/ bool Runtime::runtime_backgrounded = false;
    /*static*/ Runtime* Runtime::the_runtime = NULL;
    /*static*/ std::atomic<Realm::Event::id_t> Runtime::startup_event = {0};
    /*static*/ Realm::Barrier::timestamp_t Runtime::startup_timestamp = 0;
    /*static*/ std::atomic<bool> Runtime::background_wait = {0};
    /*static*/ int Runtime::return_code = 0;
    /*static*/ int Runtime::mpi_rank = -1;

    //--------------------------------------------------------------------------
    /*static*/ int Runtime::start(int argc, char **argv, bool background,
                                  bool supply_default_mapper, bool filter)
    //--------------------------------------------------------------------------
    {
      // Some static asserts that need to hold true for the runtime to work
      static_assert(LEGION_MAX_RETURN_SIZE > 0, 
          "Need a positive and non-zero value for LEGION_MAX_RETURN_SIZE");
      static_assert((1 << LEGION_FIELD_LOG2) == LEGION_MAX_FIELDS,
          "LEGION_MAX_FIELDS must be a pwoer of 2");
      static_assert(LEGION_MAX_NUM_NODES > 0,
          "Need a positive and non-zero value for LEGION_MAX_NUM_NODES");
      static_assert(LEGION_MAX_NUM_PROCS > 0,
          "Need a positive and non-zero value for LEGION_MAX_NUM_PROCS");
      static_assert(LEGION_DEFAULT_MAX_TASK_WINDOW > 0,
          "Need a positive and non-zero value for "
          "LEGION_DEFAULT_MAX_TASK_WINDOW");
      static_assert(LEGION_DEFAULT_MIN_TASKS_TO_SCHEDULE > 0,
          "Need a positive and non-zero value for "
          "LEGION_DEFAULT_MIN_TASKS_TO_SCHEDULE");
      static_assert(LEGION_DEFAULT_MAX_MESSAGE_SIZE > 0,
          "Need a positive and non-zero value for "
          "LEGION_DEFAULT_MAX_MESSAGE_SIZE"); 
#ifdef LEGION_SPY
      static_assert(
          Realm::Logger::REALM_LOGGING_MIN_LEVEL <= Realm::Logger::LEVEL_INFO,
        "Legion Spy requires a COMPILE_TIME_MIN_LEVEL of at most LEVEL_INFO.");
#endif
#ifdef LEGION_GC
      static_assert(
          Realm::Logger::REALM_LOGGING_MIN_LEVEL <= Realm::Logger::LEVEL_INFO,
          "Legion GC requires a COMPILE_TIME_MIN_LEVEL of at most LEVEL_INFO.");
#endif
#ifdef DEBUG_SHUTDOWN_HANG
      static_assert(
          Realm::Logger::REALM_LOGGING_MIN_LEVEL <= Realm::Logger::LEVEL_INFO,
          "DEBUG_SHUTDOWN_HANG requires a COMPILE_TIME_MIN_LEVEL "
          "of at most LEVEL_INFO.");
#endif
      // Register builtin reduction operators
      register_builtin_reduction_operators();
      // Need to pass argc and argv to low-level runtime before we can record 
      // their values as they might be changed by GASNet or MPI or whatever.
      // Note that the logger isn't initialized until after this call returns 
      // which means any logging that occurs before this has undefined behavior.
      const LegionConfiguration &config = 
        initialize(&argc, &argv, !runtime_cmdline_parsed, filter);
      RealmRuntime realm = RealmRuntime::get_runtime();
      // Finish configuring the machine so we can start querying the machine
      // model and setting up our data structures before we start Realm
      realm.finish_configure();

      // Perform any waits that the user requested before starting
      if (config.delay_start > 0)
          sleep(config.delay_start);
      // Check for any slow configurations
      if (!config.slow_config_ok)
        perform_slow_config_checks(config);
      // Configure legion spy if necessary
      if (config.legion_spy_enabled)
        LegionSpy::log_legion_spy_config();
      // Construct our runtime objects 
      std::set<Processor> local_procs;
      std::map<Processor,Runtime*> processor_mapping;
      const Processor first_proc = configure_runtime(argc, argv,
          config, realm, local_procs, processor_mapping, background,
          supply_default_mapper);
#ifdef DEBUG_LEGION
      // Startup kind should be a CPU or a Utility processor
      assert((first_proc.kind() == Processor::LOC_PROC) ||
          (first_proc.kind() == Processor::UTIL_PROC));
      // First processor should be on node zero
      assert(first_proc.address_space() == 0);
      assert(!local_procs.empty());
#endif 
      // Configure MPI Interoperability
      const std::vector<LegionHandshake> &pending_handshakes =
        get_pending_handshake_table();
      if ((mpi_rank >= 0) || (!pending_handshakes.empty()))
        configure_interoperability(config.separate_runtime_instances);
      // We have to set these prior to starting Realm as once we start
      // Realm it might fork child processes so they all need to see
      // the same values for these static variables
      runtime_started = true;
      runtime_backgrounded = background;

      // Now that we have everything setup we can tell Realm to
      // start the processors. It is at this point which fork
      // can be called to spawn subprocesses.
      realm.start();

      Realm::Barrier startup_barrier = Realm::Barrier::NO_BARRIER;
      if ((the_runtime->total_address_spaces > 1) && 
          !config.separate_runtime_instances)
      {
        // First we do a collective spawn to make sure that Realm is
        // started and all of our meta-tasks have been registered
        // across all of the nodes
        // Very important, do NOT pass in any event preconditions to
        // this task and do not use the postcondition as it comes from
        // node zero and we don't want all the nodes to subscribe to
        // node zero unnecessarily.
        realm.collective_spawn(first_proc, LG_STARTUP_TASK_ID, NULL, 0);
        // Now get the start-up barrier that will be set by the
        // start-up task as it broadcasts through the nodes
        startup_barrier = find_or_wait_for_startup_barrier();
      }
      // We also need to run a nop task on every processor to make sure
      // that Realm has finished initializing that processor. This is
      // especially important for things like Python processors which 
      // might still be loading modules and we want to ensure that they
      // are completely done doing that before we try to do anything
      std::vector<RtEvent> nop_events;
      nop_events.reserve(local_procs.size());
      for (std::set<Processor>::const_iterator it =
            local_procs.begin(); it != local_procs.end(); it++)
        nop_events.push_back(RtEvent(it->spawn(
                  Processor::TASK_ID_PROCESSOR_NOP, NULL, 0)));
      // Now we can initialize the Legion runtime(s) on this node
      TopLevelContext *top_context = NULL;
      if (config.separate_runtime_instances)
      {
        for (std::map<Processor,Runtime*>::const_iterator it =
              processor_mapping.begin(); it != processor_mapping.end(); it++)
          if (top_context == NULL)
            top_context = it->second->initialize_runtime(first_proc);
          else
            it->second->initialize_runtime(first_proc);
      }
      else
        top_context = the_runtime->initialize_runtime(first_proc);
      if (startup_barrier.exists())
      {
        // Make sure all the nodes are done
        startup_barrier.arrive(1/*count*/, Runtime::merge_events(nop_events));
        // Wait for all the nodes to be done with the initialization
        startup_barrier.wait();
      }
      else
      {
        const RtEvent initialized = Runtime::merge_events(nop_events);
        initialized.wait();
      }

      // Launch the top-level task if we have a main set
      if (the_runtime->address_space == 0)
      {
        if (legion_main_set)
        {
#ifdef DEBUG_LEGION
          assert(top_context != NULL);
#endif
          TaskLauncher launcher(Runtime::legion_main_id,
              UntypedBuffer(&the_runtime->input_args, sizeof(InputArgs)),
                            Predicate::TRUE_PRED, legion_main_mapper_id);
          the_runtime->launch_top_level_task(launcher, top_context);
        }
        // Cleanup the start-up barrier
        if (startup_barrier.exists())
          startup_barrier.destroy_barrier();
      }
      // If we are supposed to background this thread, then we wait
      // for the runtime to shutdown, otherwise we can now return
      if (background)
        return 0;
      // Decrement the total outstanding top-level tasks to reflect that
      // this node is ready to shutdown when everything is done
      the_runtime->decrement_outstanding_top_level_tasks();
      // Wait for Realm shutdown to be complete
      return realm.wait_for_shutdown();
    }

    //--------------------------------------------------------------------------
    /*static*/ const Runtime::LegionConfiguration& Runtime::initialize(
                               int *argc, char ***argv, bool parse, bool filter)
    //--------------------------------------------------------------------------
    {
      static LegionConfiguration config;
      RealmRuntime realm = RealmRuntime::get_runtime();
      if (!runtime_initialized)
      {
#ifndef NDEBUG
        bool ok = 
#endif
          realm.network_init(argc, argv);
        assert(ok);
#ifndef NDEBUG
        ok =
#endif
          realm.create_configs(*argc, *argv);
        assert(ok);
        runtime_initialized = true;
      }
      if (runtime_cmdline_parsed || !parse)
        return config;
      // Next we configure the realm runtime after which we can access the
      // machine model and make events and reservations and do reigstrations
      std::vector<std::string> cmdline;
      // Check to see if there are any Legion default args from the environment
      const char *e = getenv("LEGION_DEFAULT_ARGS");
      if (e)
      {
        // This code is borrowed from Realm for parsing default arguments
        // Prepend any default args so they can still be overridden 
        // by actual flags on the command line
        while (*e) 
        {
          if (isspace(*e)) 
          { 
            e++;
            continue; 
          }
          const char *starts = NULL;
          if (*e == '\'') 
          {
            // single quoted string
            e++;
            assert(*e);
            starts = e;
            // read until next single quote
            while (*e && (*e != '\''))
              e++;
            cmdline.emplace_back(std::string(starts, size_t(e++ - starts))); 
            assert(!*e || isspace(*e));
            continue;
          }
          if (*e == '\"')
          {
            // double quoted string
            e++;
            assert(*e);
            starts = e;
            // read until next double quote
            while (*e && (*e != '\"'))
              e++;
            cmdline.emplace_back(std::string(starts, size_t(e++ - starts)));
            assert(!*e || isspace(*e));
            continue;
          }
          // no quotes - just take until next whitespace
          starts = e;
          while (*e && !isspace(*e))
            e++;
          cmdline.emplace_back(std::string(starts, size_t(e - starts)));
        }
      }
      size_t num_args = *argc;
      cmdline.reserve(cmdline.size() + ((num_args > 0) ? num_args-1 : 0));
      for (unsigned i = 1; i < num_args; i++)
        cmdline.emplace_back((*argv)[i]);
      realm.parse_command_line(cmdline, filter);
      Realm::CommandLineParser cp; 
      cp.add_option_bool("-lg:warn_backtrace",
                         config.warnings_backtrace, !filter)
        .add_option_bool("-lg:warn", config.runtime_warnings, !filter)
        .add_option_bool("-lg:werror", config.warnings_are_errors, !filter)
        .add_option_bool("-lg:leaks", config.report_leaks, !filter)
        .add_option_bool("-lg:separate",
                         config.separate_runtime_instances, !filter)
        .add_option_bool("-lg:registration",config.record_registration,!filter)
        .add_option_bool("-lg:nosteal",config.stealing_disabled,!filter)
        .add_option_bool("-lg:resilient",config.resilient_mode,!filter)
        .add_option_bool("-lg:unsafe_launch",config.unsafe_launch,!filter)
        .add_option_bool("-lg:unsafe_mapper",config.unsafe_mapper,!filter)
        .add_option_bool("-lg:safe_mapper",config.safe_mapper,!filter)
        .add_option_bool("-lg:safe_tracing", config.safe_tracing, !filter)
        .add_option_int("-lg:safe_ctrlrepl",
                         config.safe_control_replication, !filter)
        .add_option_bool("-lg:inorder",config.program_order_execution,!filter)
        .add_option_bool("-lg:dump_physical_traces",
                         config.dump_physical_traces, !filter)
        .add_option_bool("-lg:no_tracing",config.no_tracing, !filter)
        .add_option_bool("-lg:no_physical_tracing",
                         config.no_physical_tracing, !filter)
        .add_option_bool("-lg:no_trace_optimization",
                         config.no_trace_optimization, !filter)
        .add_option_bool("-lg:no_fence_elision",
                         config.no_fence_elision, !filter)
        .add_option_bool("-lg:no_transitive_reduction",
                         config.no_transitive_reduction, !filter)
        .add_option_bool("-lg:inline_transitive_reduction",
                         config.inline_transitive_reduction, !filter)
        .add_option_bool("-lg:replay_on_cpus",
                         config.replay_on_cpus, !filter)
        .add_option_bool("-lg:disjointness",
                         config.verify_partitions, !filter)
        .add_option_bool("-lg:partcheck",
                         config.verify_partitions, !filter)
        .add_option_int("-lg:window", config.initial_task_window_size, !filter)
        .add_option_int("-lg:hysteresis", 
                        config.initial_task_window_hysteresis, !filter)
        .add_option_int("-lg:sched", 
                        config.initial_tasks_to_schedule, !filter)
        .add_option_int("-lg:vector", 
                        config.initial_meta_task_vector_width, !filter)
        .add_option_int("-lg:eager_alloc_percentage",
                        config.eager_alloc_percentage, !filter)
        .add_option_method("-lg:eager_alloc_percentage_override",
                           &config,
                           &LegionConfiguration::parse_alloc_percentage_override_argument,
                           !filter)
        .add_option_bool("-lg:dump_free_ranges",
                         config.dump_free_ranges, !filter)
        .add_option_int("-lg:message",config.max_message_size, !filter)
        .add_option_int("-lg:epoch", config.gc_epoch_size, !filter)
        .add_option_int("-lg:local", config.max_local_fields, !filter)
        .add_option_int("-lg:parallel_replay", 
                        config.max_replay_parallelism, !filter)
        .add_option_bool("-lg:no_dyn",config.disable_independence_tests,!filter)
        .add_option_bool("-lg:spy",config.legion_spy_enabled, !filter)
        .add_option_bool("-lg:test",config.enable_test_mapper, !filter)
        .add_option_int("-lg:delay", config.delay_start, !filter)
        .add_option_string("-lg:replay", config.replay_file, !filter)
        .add_option_string("-lg:ldb", config.ldb_file, !filter)
#ifdef DEBUG_LEGION
        .add_option_bool("-lg:tree",config.logging_region_tree_state, !filter)
        .add_option_bool("-lg:verbose",config.verbose_logging, !filter)
        .add_option_bool("-lg:logical_only",config.logical_logging_only,!filter)
        .add_option_bool("-lg:physical_only",
                         config.physical_logging_only,!filter)
#endif
        .add_option_int("-lg:prof", config.num_profiling_nodes, !filter)
        .add_option_string("-lg:serializer", config.serializer_type, !filter)
        .add_option_string("-lg:prof_logfile", config.prof_logfile, !filter)
        .add_option_int("-lg:prof_footprint", 
                        config.prof_footprint_threshold, !filter)
        .add_option_int("-lg:prof_latency",config.prof_target_latency, !filter)
        .add_option_int("-lg:prof_call_threshold",
                        config.prof_call_threshold, !filter)
        .add_option_bool("-lg:prof_self", config.prof_self_profile, !filter)
        .add_option_bool("-lg:prof_no_critical_paths",
                        config.prof_no_critical_paths, !filter)
        .add_option_bool("-lg:prof_all_critical_arrivals",
                        config.prof_all_critical_arrivals, !filter)
        .add_option_bool("-lg:debug_ok",config.slow_config_ok, !filter)
        // These are all the deprecated versions of these flag
        .add_option_bool("-hl:separate",
                         config.separate_runtime_instances, !filter)
        .add_option_bool("-hl:registration",config.record_registration, !filter)
        .add_option_bool("-hl:nosteal",config.stealing_disabled, !filter)
        .add_option_bool("-hl:resilient",config.resilient_mode, !filter)
        .add_option_bool("-hl:unsafe_launch",config.unsafe_launch, !filter)
        .add_option_bool("-hl:unsafe_mapper",config.unsafe_mapper, !filter)
        .add_option_bool("-hl:safe_mapper",config.safe_mapper, !filter)
        .add_option_bool("-hl:inorder",config.program_order_execution, !filter)
        .add_option_bool("-hl:disjointness",config.verify_partitions, !filter)
        .add_option_int("-hl:window", config.initial_task_window_size, !filter)
        .add_option_int("-hl:hysteresis", 
                        config.initial_task_window_hysteresis, !filter)
        .add_option_int("-hl:sched", config.initial_tasks_to_schedule, !filter)
        .add_option_int("-hl:message",config.max_message_size, !filter)
        .add_option_int("-hl:epoch", config.gc_epoch_size, !filter)
        .add_option_bool("-hl:no_dyn",config.disable_independence_tests,!filter)
        .add_option_bool("-hl:spy",config.legion_spy_enabled, !filter)
        .add_option_bool("-hl:test",config.enable_test_mapper, !filter)
        .add_option_int("-hl:delay", config.delay_start, !filter)
        .add_option_string("-hl:replay", config.replay_file, !filter)
        .add_option_string("-hl:ldb", config.ldb_file, !filter)
#ifdef DEBUG_LEGION
        .add_option_bool("-hl:tree",config.logging_region_tree_state,!filter)
        .add_option_bool("-hl:verbose",config.verbose_logging,!filter)
        .add_option_bool("-hl:logical_only",config.logical_logging_only,!filter)
        .add_option_bool("-hl:physical_only",
                         config.physical_logging_only,!filter)
#endif
        .add_option_int("-hl:prof", config.num_profiling_nodes, !filter)
        .add_option_string("-hl:serializer", config.serializer_type, !filter)
        .add_option_string("-hl:prof_logfile", config.prof_logfile, !filter)
        .parse_command_line(cmdline);
      // If we asked to filter the arguments, now we need to go back in
      // and update the arguments so that they reflect the pruned data
      if (filter)
      {
        if (!cmdline.empty())
        {
          unsigned arg_index = 1;
          for (unsigned idx = 0; idx < cmdline.size(); idx++)
          {
            const char *str = cmdline[idx].c_str();
            // Find the location of this string in the original
            // arguments to so that we can get its original pointer 
            assert(arg_index < num_args);
            while (strcmp(str, (*argv)[arg_index]) != 0)
            {
              arg_index++;
              assert(arg_index < num_args);
            }
            // Now that we've got it's original pointer we can move
            // it to the new location in the outputs
            if (arg_index == (idx+1))
              arg_index++; // already in the right place 
            else
              (*argv)[idx+1] = (*argv)[arg_index++];
          }
          *argc = (1 + cmdline.size());
        }
        else
          *argc = 1;
      }
#ifdef DEBUG_LEGION
      if (config.logging_region_tree_state)
        REPORT_LEGION_WARNING(LEGION_WARNING_REGION_TREE_STATE_LOGGING,
            "Region tree state logging is disabled.  To enable region "
            "tree state logging compile in debug mode.")
#endif
      if (config.initial_task_window_hysteresis > 100)
        REPORT_LEGION_ERROR(ERROR_LEGION_CONFIGURATION,
            "Illegal task window hysteresis value of %d which is not a value "
            "between 0 and 100.", config.initial_task_window_hysteresis)
      if (config.max_local_fields > LEGION_MAX_FIELDS)
        REPORT_LEGION_ERROR(ERROR_LEGION_CONFIGURATION,
            "Illegal max local fields value %d which is larger than the "
            "value of LEGION_MAX_FIELDS (%d).", config.max_local_fields,
            LEGION_MAX_FIELDS)
      const Realm::Logger::LoggingLevel compile_time_min_level =
            Realm::Logger::REALM_LOGGING_MIN_LEVEL;
      if (config.legion_spy_enabled && 
          (Realm::Logger::LEVEL_INFO < compile_time_min_level))
        REPORT_LEGION_ERROR(ERROR_LEGION_CONFIGURATION,
            "Legion Spy logging requires a COMPILE_TIME_MIN_LEVEL "
            "of at most LEVEL_INFO, but current setting is %s",
            (compile_time_min_level == Realm::Logger::LEVEL_PRINT) ? 
              "LEVEL_PRINT" : 
            (compile_time_min_level == Realm::Logger::LEVEL_WARNING) ?
              "LEVEL_WARNING" : 
            (compile_time_min_level == Realm::Logger::LEVEL_ERROR) ?
              "LEVEL_ERROR" :
            (compile_time_min_level == Realm::Logger::LEVEL_FATAL) ?
              "LEVEL_FATAL" : "LEVEL_NONE")
      if ((config.num_profiling_nodes > 0) &&
          (strcmp(config.serializer_type.c_str(), "ascii") == 0) &&
          (Realm::Logger::LEVEL_INFO < compile_time_min_level))
        REPORT_LEGION_ERROR(ERROR_LEGION_CONFIGURATION,
            "Legion Prof 'ascii' logging requires a COMPILE_TIME_MIN_LEVEL "
            "of at most LEVEL_INFO, but current setting is %s",
            (compile_time_min_level == Realm::Logger::LEVEL_PRINT) ? 
              "LEVEL_PRINT" : 
            (compile_time_min_level == Realm::Logger::LEVEL_WARNING) ?
              "LEVEL_WARNING" : 
            (compile_time_min_level == Realm::Logger::LEVEL_ERROR) ?
              "LEVEL_ERROR" :
            (compile_time_min_level == Realm::Logger::LEVEL_FATAL) ?
              "LEVEL_FATAL" : "LEVEL_NONE")
      if (config.record_registration &&
          (Realm::Logger::LEVEL_PRINT < compile_time_min_level))
        REPORT_LEGION_ERROR(ERROR_LEGION_CONFIGURATION,
            "Legion registration logging requires a COMPILE_TIME_MIN_LEVEL "
            "of at most LEVEL_PRINT, but current setting is %s",
            (compile_time_min_level == Realm::Logger::LEVEL_WARNING) ?
              "LEVEL_WARNING" : 
            (compile_time_min_level == Realm::Logger::LEVEL_ERROR) ?
              "LEVEL_ERROR" :
            (compile_time_min_level == Realm::Logger::LEVEL_FATAL) ?
              "LEVEL_FATAL" : "LEVEL_NONE")
      if (config.dump_physical_traces &&
          (Realm::Logger::LEVEL_INFO < compile_time_min_level))
        REPORT_LEGION_ERROR(ERROR_LEGION_CONFIGURATION,
            "Legion physical trace logging requires a COMPILE_TIME_MIN_LEVEL "
            "of at most LEVEL_INFO, but current setting is %s",
            (compile_time_min_level == Realm::Logger::LEVEL_PRINT) ? 
              "LEVEL_PRINT" : 
            (compile_time_min_level == Realm::Logger::LEVEL_WARNING) ?
              "LEVEL_WARNING" : 
            (compile_time_min_level == Realm::Logger::LEVEL_ERROR) ?
              "LEVEL_ERROR" :
            (compile_time_min_level == Realm::Logger::LEVEL_FATAL) ?
              "LEVEL_FATAL" : "LEVEL_NONE")
      runtime_cmdline_parsed = true;
      return config;
    }

    //--------------------------------------------------------------------------
    bool Runtime::LegionConfiguration::parse_alloc_percentage_override_argument(
        const std::string &s) {
    //--------------------------------------------------------------------------
      // Some of this code is borrowed from Realm's logger initialization.
      const char *p1 = s.c_str();
      while (true) {
        // Skip commas.
        while(*p1 == ',') p1++;
        if(!*p1) break;

        // We follow a similar format as the logger's -level arguments, where
        // users can specify for particular memory kinds the amount of eager
        // allocation space should be used. For example:
        // -lg:eager_alloc_percentage_overrides socket_mem=35,system_mem=20.
        std::string mem_kind_name;
        if (!isdigit(*p1)) {
          const char *p2 = p1;
          while (*p2 != '=') {
            if (!*p2) {
              fprintf(stderr, "ERROR: memory kind in "
                              "-lg:eager_alloc_percentage_override "
                              "must be followed by =.\n");
              return false;
            }
            p2++;
          }
          mem_kind_name.assign(p1, p2 - p1);
          p1 = p2 + 1;
        }
        // Parse the memory kind now. First, convert the memory
        // string to all upper case.
        std::transform(
            mem_kind_name.begin(),
            mem_kind_name.end(),
            mem_kind_name.begin(),
            ::toupper
        );
        Realm::Memory::Kind mem_kind = Memory::NO_MEMKIND;
        #define MEM_STR_EQ(name, desc) \
          if (strcmp(mem_kind_name.c_str(), #name) == 0) { \
            mem_kind = Realm::Memory::name;                \
          }
          REALM_MEMORY_KINDS(MEM_STR_EQ)
        #undef MEM_STR_EQ
        if (mem_kind == Realm::Memory::NO_MEMKIND) {
          fprintf(stderr, "ERROR: unable to parse memory kind %s.\n",
                  mem_kind_name.c_str());
          return false;
        }

        // Advance until we don't see any more numbers.
        const char* p2 = p1;
        while (*p2 && isdigit(*p2)) p2++;
        if (!*p2 || (*p2 == ',')) {
          std::string percentage_str(p1, p2);
          char* pos;
          errno = 0; // No errors from before.
          long percentage = strtol(percentage_str.c_str(), &pos, 10);
          if (errno != 0) {
            fprintf(stderr, "ERROR: unable to parse percentage value.\n");
            return false;
          }
          this->eager_alloc_percentage_overrides[mem_kind] = percentage;
          p1 = p2;
        }
      }
      return true;
    }

    //--------------------------------------------------------------------------
    /*static*/ unsigned Runtime::initialize_outstanding_top_level_tasks(
        AddressSpaceID local_space, size_t total_spaces, unsigned radix)
    //--------------------------------------------------------------------------
    {
      // We always have at least one top-level task in the count as a guard
      // that will be removed once we know that we aren't launching anymore
      // new top-level tasks on this node
      unsigned result = 1;
      // Now count how many notifications we expect to see and add that to
      // our count to act as an additional guard. This will allow us to do
      // a tree reduction down from each node towards node 0 which will
      // start the shutdown quiescence test
      AddressSpaceID offset = local_space * radix;
      for (unsigned idx = 1; idx <= radix; idx++)
      {
        AddressSpaceID target = offset + idx;
        if (target < total_spaces)
          result++;
      }
      return result;
    }

    //--------------------------------------------------------------------------
    Future Runtime::launch_top_level_task(const TaskLauncher &launcher,
                                          TopLevelContext *top_context)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(!local_procs.empty());
#endif 
      // Find a target processor, we'll prefer a CPU processor for
      // backwards compatibility, but will take anything we get
      Processor target = Processor::NO_PROC;
      for (std::set<Processor>::const_iterator it = 
            local_procs.begin(); it != local_procs.end(); it++)
      {
        if (it->kind() == Processor::LOC_PROC)
        {
          target = *it;
          break;
        }
        else if (!target.exists())
          target = *it;
      }
#ifdef DEBUG_LEGION
      assert(target.exists());
#endif
      if (top_context == NULL)
        top_context = new TopLevelContext(this, target,
            get_unique_top_level_task_id(), 0/*implicit*/);
      // Save the current context if there is one and restore it later
      TaskContext *previous_implicit = implicit_context;
      // Save the context in the implicit context
      implicit_context = top_context;
      implicit_runtime = this;
      if ((profiler != NULL) && (implicit_profiler == NULL))
        implicit_profiler = profiler->find_or_create_profiling_instance();
      // Add a reference to the top level context
      top_context->add_base_gc_ref(RUNTIME_REF);
      // Get an individual task to be the top-level task
      IndividualTask *top_task = get_available_individual_task();
      AutoProvenance provenance(launcher.provenance);
      // Mark that this task is the top-level task
      Future result = top_task->initialize_task(top_context, launcher,
          provenance, true/*top level task*/);
      // Set this to be the current processor
      top_task->set_current_proc(target);
      top_task->select_task_options(false/*prioritize*/);
      increment_outstanding_top_level_tasks();
      // Launch a task to deactivate the top-level context
      // when the top-level task is done
      TopFinishArgs args(top_context);
      RtEvent pre = top_task->get_commit_event();
      issue_runtime_meta_task(args, LG_LATENCY_WORK_PRIORITY, pre);
      add_to_ready_queue(target, top_task);
      // Now we can restore the previous implicit context
      implicit_context = previous_implicit;
      return result;
    }

    //--------------------------------------------------------------------------
    IndividualTask* Runtime::create_implicit_top_level(TaskID top_task_id,
                              MapperID top_mapper_id, Processor proxy,
                              const char *task_name, CollectiveMapping *mapping)
    //--------------------------------------------------------------------------
    {
      // Get an individual task to be the top-level task
      IndividualTask *top_task = get_available_individual_task();
      // Get a remote task to serve as the top of the top-level task
      TopLevelContext *top_context = new TopLevelContext(this, proxy,
          0/*id*/, get_unique_implicit_top_level_task_id(), 0/*did*/, mapping);
      // Add a reference to the top level context
      top_context->add_base_gc_ref(RUNTIME_REF);
      TaskLauncher launcher(top_task_id, UntypedBuffer(),
                            Predicate::TRUE_PRED, top_mapper_id);
      // Mark that this task is the top-level task
      top_task->initialize_task(top_context, launcher, NULL/*provenance*/,
          true/*top level task*/);
      increment_outstanding_top_level_tasks();
      // Launch a task to deactivate the top-level context
      // when the top-level task is done
      TopFinishArgs args(top_context);
      RtEvent pre = top_task->get_commit_event();
      issue_runtime_meta_task(args, LG_LATENCY_WORK_PRIORITY, pre);
      return top_task;
    }

    //--------------------------------------------------------------------------
    ImplicitShardManager* Runtime::find_implicit_shard_manager(
                  TaskID top_task_id, MapperID mapper_id, Processor::Kind kind,
                  unsigned shards_per_address_space)
    //--------------------------------------------------------------------------
    {
      AutoLock s_lock(shard_lock);
      std::map<TaskID,ImplicitShardManager*>::iterator finder = 
        implicit_shard_managers.find(top_task_id);
      if (finder != implicit_shard_managers.end())
        return finder->second;
      ImplicitShardManager *result = new ImplicitShardManager(this,
          top_task_id, mapper_id, kind, shards_per_address_space);
      implicit_shard_managers[top_task_id] = result;
      result->add_reference(shards_per_address_space);
      return result;
    }

    //--------------------------------------------------------------------------
    void Runtime::unregister_implicit_shard_manager(TaskID top_task_id)
    //--------------------------------------------------------------------------
    {
      AutoLock s_lock(shard_lock);
      std::map<TaskID,ImplicitShardManager*>::iterator finder = 
        implicit_shard_managers.find(top_task_id);
#ifdef DEBUG_LEGION
      assert(finder != implicit_shard_managers.end());
#endif
      implicit_shard_managers.erase(finder);
    }

    //--------------------------------------------------------------------------
    Context Runtime::begin_implicit_task(TaskID top_task_id,
                                         MapperID top_mapper_id,
                                         Processor::Kind proc_kind,
                                         const char *task_name,
                                         bool control_replicable,
                                         unsigned shards_per_address_space,
                                         int shard_id, const DomainPoint &point)
    //--------------------------------------------------------------------------
    {
      if (!runtime_started)
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_IMPLICIT_TOP_LEVEL_TASK,
            "Implicit top-level tasks are not allowed to be started before "
            "the Legion runtime is started.")
      // Check that we're not inside a task
      if (implicit_context != NULL)
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_IMPLICIT_TOP_LEVEL_TASK,
            "Implicit top-level tasks are not allowed to be started inside "
            "of Legion tasks. Only external computations are permitted "
            "to create new implicit top-level tasks.")
      // Save the top-level task name if necessary
      // Record a fake variant if we're profiling
      if (task_name != NULL)
      {
        attach_semantic_information(top_task_id,
            LEGION_NAME_SEMANTIC_TAG, task_name,
            strlen(task_name) + 1, true/*mutable*/, false/*send to owner*/);
        if (profiler != NULL)
          profiler->register_task_variant(top_task_id, 0/*variant ID*/,
                                          task_name);
      }
      else if (profiler != NULL)
      {
        char implicit_name[64];
        snprintf(implicit_name, 64, "implicit_variant_%d", top_task_id);
        profiler->register_task_variant(top_task_id, 0/*variant ID*/,
                                        implicit_name);
      }
      // Find a proxy processor for us to use for this task 
      // We might already even be on a Realm processor
      Processor proxy = Processor::get_executing_processor();
      if (!proxy.exists())
      {
#ifdef DEBUG_LEGION
        assert(!local_procs.empty());
#endif
        for (std::set<Processor>::const_iterator it =
              local_procs.begin(); it != local_procs.end(); it++)
        {
          if (it->kind() == proc_kind)
          {
            proxy = *it;
            break;
          }
        }
      }
#ifdef DEBUG_LEGION
      // TODO: remove this once realm supports drafting this thread
      // as a new kind of processor to use
      assert(proxy.exists());
#endif
      SingleTask *local_task = NULL;
      // Now that the runtime is started we can make our context
      if (control_replicable && (total_address_spaces > 1))
      {
        // Either find or make an implicit shard manager for hooking up
        ImplicitShardManager *implicit_shard_manager = 
          find_implicit_shard_manager(top_task_id, top_mapper_id, proc_kind, 
                                      shards_per_address_space);
        local_task = 
          implicit_shard_manager->create_shard(shard_id,point,proxy,task_name);
        if (implicit_shard_manager->remove_reference())
          delete implicit_shard_manager;
      }
      else
      {
        local_task = create_implicit_top_level(top_task_id, top_mapper_id,
                                               proxy, task_name);
        // Increment the pending count here
        local_task->get_context()->increment_pending();
      }
#ifdef DEBUG_LEGION
      increment_total_outstanding_tasks(top_task_id, false);
#else
      increment_total_outstanding_tasks();
#endif
      InnerContext *execution_context = local_task->create_implicit_context();
      execution_context->begin_task(proxy);
      return execution_context;
    }

    //--------------------------------------------------------------------------
    void Runtime::unbind_implicit_task_from_external_thread(TaskContext *ctx)
    //--------------------------------------------------------------------------
    {
      if (!ctx->implicit_task)
        REPORT_LEGION_ERROR(ERROR_CONFUSED_USER,
            "Illegal call to unbind a context for task %s (UID %lld) that "
            "is not an implicit top-level task",
            ctx->get_task_name(), ctx->get_unique_id())
      ctx->begin_wait(LgEvent::NO_LG_EVENT, true/*from application*/);
      implicit_context = NULL;
      implicit_profiler = NULL;
      implicit_fevent = LgEvent::NO_LG_EVENT;
      implicit_provenance = 0;
    }

    //--------------------------------------------------------------------------
    void Runtime::bind_implicit_task_to_external_thread(TaskContext *ctx)
    //--------------------------------------------------------------------------
    {
      if (!ctx->implicit_task)
        REPORT_LEGION_ERROR(ERROR_CONFUSED_USER,
            "Illegal call to bind a context for task %s (UID %lld) that "
            "is not an implicit top-level task",
            ctx->get_task_name(), ctx->get_unique_id())
      ctx->end_wait(LgEvent::NO_LG_EVENT, true/*from application*/);
      if (implicit_runtime == NULL)
        implicit_runtime = this;
      if ((profiler != NULL) && (implicit_profiler == NULL))
        implicit_profiler = profiler->find_or_create_profiling_instance();
      implicit_context = ctx;
      implicit_provenance = ctx->owner_task->get_unique_op_id();
    }

    //--------------------------------------------------------------------------
    void Runtime::finish_implicit_task(TaskContext *ctx, ApEvent effects)
    //--------------------------------------------------------------------------
    {
      if (!ctx->implicit_task)
        REPORT_LEGION_ERROR(ERROR_CONFUSED_USER,
            "Illegal call to finish an implicit task for task %s (UID %lld) "
            "that is not an implicit top-level task",
            ctx->get_task_name(), ctx->get_unique_id())
      // this is just a normal finish operation
      ctx->end_task(NULL, 0, false/*owned*/, PhysicalInstance::NO_INST, 
          NULL/*callback functor*/, NULL/*resource*/,  NULL/*freefunc*/,
          NULL/*metadataptr*/, 0/*metadatasize*/, effects);
      implicit_context = NULL;
      implicit_profiler = NULL;
      implicit_fevent = LgEvent::NO_LG_EVENT;
      implicit_provenance = 0;
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::perform_slow_config_checks(
                                              const LegionConfiguration &config)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      if (config.num_profiling_nodes > 0)
      {
        // Give a massive warning about profiling with debug enabled
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"!!! YOU ARE PROFILING IN DEBUG MODE           !!!\n");
        fprintf(stderr,"!!! SERIOUS PERFORMANCE DEGRADATION WILL OCCUR!!!\n");
        fprintf(stderr,"!!! COMPILE WITH DEBUG=0 FOR PROFILING        !!!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"\n");
        fprintf(stderr,"SLEEPING FOR 5 SECONDS SO YOU READ THIS WARNING...\n");
        fflush(stderr);
        sleep(5);
      }
#endif
#ifdef LEGION_SPY
      if (config.num_profiling_nodes > 0)
      {
        // Give a massive warning about profiling with Legion Spy enabled
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"!!! YOU ARE PROFILING WITH LegionSpy ENABLED  !!!\n");
        fprintf(stderr,"!!! SERIOUS PERFORMANCE DEGRADATION WILL OCCUR!!!\n");
        fprintf(stderr,"!!! COMPILE WITHOUT -DLEGION_SPY FOR PROFILING!!!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"\n");
        fprintf(stderr,"SLEEPING FOR 5 SECONDS SO YOU READ THIS WARNING...\n");
        fflush(stderr);
        sleep(5);
      }
#else
      if (config.legion_spy_enabled && (config.num_profiling_nodes > 0))
      {
        // Give a massive warning about profiling with Legion Spy enabled
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"!!! YOU ARE PROFILING WITH LegionSpy ENABLED  !!!\n");
        fprintf(stderr,"!!! SERIOUS PERFORMANCE DEGRADATION WILL OCCUR!!!\n");
        fprintf(stderr,"!!! RUN WITHOUT -lg:spy flag FOR PROFILING    !!!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"\n");
        fprintf(stderr,"SLEEPING FOR 5 SECONDS SO YOU READ THIS WARNING...\n");
        fflush(stderr);
        sleep(5);
      }
#endif
#ifdef LEGION_BOUNDS_CHECKS
      if (config.num_profiling_nodes > 0)
      {
        // Give a massive warning about profiling with bounds checks enabled
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"!!! YOU ARE PROFILING WITH LEGION_BOUNDS_CHECKS!!!\n");
        fprintf(stderr,"!!! SERIOUS PERFORMANCE DEGRADATION WILL OCCUR !!!\n");
        fprintf(stderr,"!!! PLEASE COMPILE WITHOUT LEGION_BOUNDS_CHECKS!!!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"\n");
        fprintf(stderr,"SLEEPING FOR 5 SECONDS SO YOU READ THIS WARNING...\n");
        fflush(stderr);
        sleep(5);
      }
#endif
#ifdef LEGION_PRIVILEGE_CHECKS
      if (config.num_profiling_nodes > 0)
      {
        // Give a massive warning about profiling with privilege checks enabled
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"!!!YOU ARE PROFILING WITH LEGION_PRIVILEGE_CHECKS!!\n");
        fprintf(stderr,"!!!SERIOUS PERFORMANCE DEGRADATION WILL OCCUR!!!\n");
        fprintf(stderr,"!!!PLEASE COMPILE WITHOUT LEGION_PRIVILEGE_CHECKS!!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"\n");
        fprintf(stderr,"SLEEPING FOR 5 SECONDS SO YOU READ THIS WARNING...\n");
        fflush(stderr);
        sleep(5);
      }
#endif
      if (config.verify_partitions && (config.num_profiling_nodes > 0))
      {
        // Give a massive warning about profiling with partition checks enabled
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"!!! YOU ARE PROFILING WITH PARTITION CHECKS ON!!!\n");
        fprintf(stderr,"!!! SERIOUS PERFORMANCE DEGRADATION WILL OCCUR!!!\n");
        fprintf(stderr,"!!! DO NOT USE -lg:partcheck WITH PROFILING   !!!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        for (int i = 0; i < 4; i++)
          fprintf(stderr,"!WARNING WARNING WARNING WARNING WARNING WARNING!\n");
        for (int i = 0; i < 2; i++)
          fprintf(stderr,"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n");
        fprintf(stderr,"\n");
        fprintf(stderr,"SLEEPING FOR 5 SECONDS SO YOU READ THIS WARNING...\n");
        fflush(stderr);
        sleep(5);
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::configure_interoperability(
                                                bool separate_runtime_instances)
    //--------------------------------------------------------------------------
    {
      if (separate_runtime_instances && (mpi_rank > 0))
        REPORT_LEGION_ERROR(ERROR_MPI_INTEROP_MISCONFIGURATION,
            "Legion-MPI Interoperability is not supported when running "
            "with separate runtime instances for each processor")
      const std::vector<LegionHandshake> &pending_handshakes = 
        get_pending_handshake_table();
      if (!pending_handshakes.empty())
      {
        for (std::vector<LegionHandshake>::const_iterator it = 
              pending_handshakes.begin(); it != pending_handshakes.end(); it++)
          it->impl->initialize(the_runtime);
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ Processor Runtime::configure_runtime(int argc, char **argv,
                         const LegionConfiguration &config, RealmRuntime &realm,
                         std::set<Processor> &local_procs,
                         std::map<Processor,Runtime*> &processor_mapping,
                         bool background, bool supply_default_mapper)
    //--------------------------------------------------------------------------
    {
      Processor first_proc = Processor::NO_PROC;
      // Do some error checking in case we are running with separate instances
      Machine machine = Machine::get_machine();
      // Compute the data structures necessary for constructing a runtime 
      std::set<Processor> local_util_procs;
      Processor::Kind startup_kind = Processor::NO_KIND;
      // First we find all our local processors
      {
        Machine::ProcessorQuery local_proc_query(machine);
        local_proc_query.local_address_space();
        // Check for exceeding the local number of processors
        if (local_proc_query.count() > LEGION_MAX_NUM_PROCS)
          REPORT_LEGION_ERROR(ERROR_MAXIMUM_PROCS_EXCEEDED, 
                        "Maximum number of local processors %zd exceeds "
                        "compile-time maximum of %d.  Change the value "
                        "LEGION_MAX_NUM_PROCS in legion_config.h and recompile."
                        , local_proc_query.count(), LEGION_MAX_NUM_PROCS)
        for (Machine::ProcessorQuery::iterator it = 
              local_proc_query.begin(); it != local_proc_query.end(); it++)
        {
          if (it->kind() == Processor::UTIL_PROC)
          {
            local_util_procs.insert(*it);
            // Startup can also be a utility processor if nothing else
            if (startup_kind == Processor::NO_KIND)
              startup_kind = Processor::UTIL_PROC;
          }
          else
          {
            local_procs.insert(*it);
            // Prefer CPUs for the startup kind
            if (it->kind() == Processor::LOC_PROC)
              startup_kind = Processor::LOC_PROC;
          }
        }
        if (local_procs.empty())
          REPORT_LEGION_ERROR(ERROR_NO_STARTUP_RESOURCES, 
                        "Machine model contains no local processors!")
      }
      // Check to make sure we have something to do startup
      if (startup_kind == Processor::NO_KIND)
        REPORT_LEGION_ERROR(ERROR_NO_STARTUP_RESOURCES, "Machine model contains"
            " no CPU processors and no utility processors! At least one "
            "CPU or one utility processor is required for Legion.")
      // Find the local system memory for our runtime
      Memory system_memory;
      {
        Machine::MemoryQuery local_sysmems(machine);
        local_sysmems.local_address_space();
        local_sysmems.only_kind(Memory::SYSTEM_MEM);
        if (local_sysmems.count() == 0)
          REPORT_LEGION_ERROR(ERROR_NO_STARTUP_RESOURCES, "Machine model "
              "contains no local system memories! At least one system memory "
              "must exist in each process for Legion.")
        system_memory = local_sysmems.first();
      }
      // Now build the data structures for all processors 
      if (config.separate_runtime_instances)
      {
#ifdef LEGION_TRACE_ALLOCATION
        REPORT_LEGION_FATAL(LEGION_FATAL_SEPARATE_RUNTIME_INSTANCES, 
                      "Memory tracing not supported with "
                      "separate runtime instances.")
#endif
        if (!local_util_procs.empty())
          REPORT_LEGION_FATAL(LEGION_FATAL_SEPARATE_RUNTIME_INSTANCES, 
                        "Separate runtime instances are not "
                        "supported when running with explicit "
                        "utility processors")
        std::set<AddressSpaceID> address_spaces;
        std::map<Processor,AddressSpaceID> proc_spaces;
        // If we are doing separate runtime instances then each
        // processor effectively gets its own address space
        Machine::ProcessorQuery all_procs(machine);
        AddressSpaceID sid = 0;
        for (Machine::ProcessorQuery::iterator it = 
              all_procs.begin(); it != all_procs.end(); it++,sid++)
        {
          if (it->address_space() != 0)
            REPORT_LEGION_FATAL(LEGION_FATAL_SEPARATE_RUNTIME_INSTANCES, 
                        "Separate runtime instances are not "
                        "supported when running with multiple nodes ")
          address_spaces.insert(sid);
          proc_spaces[*it] = sid;
          if (!first_proc.exists() && (it->kind() == startup_kind))
            first_proc = *it;
        }
        // Now we make runtime instances for each of the local processors
        for (std::set<Processor>::const_iterator it =
              local_procs.begin(); it != local_procs.end(); it++)
        {
          // Make a separate copy of the input arguments for each runtime
          InputArgs input_args;
          input_args.argc = argc;
          if (argc > 0)
          {
            input_args.argv = (char**)malloc(argc*sizeof(char*));
            for (int i = 0; i < argc; i++)
            {
              if (argv[i] != NULL)
                input_args.argv[i] = strdup(argv[i]);
              else
                input_args.argv[i] = NULL;
            }
          }
          else
            input_args.argv = NULL;
          const AddressSpace local_space = proc_spaces[*it];
          // Only one local processor here
          std::set<Processor> fake_local_procs;
          fake_local_procs.insert(*it);
          Runtime *runtime = new Runtime(machine, config, background,
                                         input_args, local_space, system_memory,
                                         fake_local_procs, local_util_procs,
                                         address_spaces, proc_spaces,
                                         supply_default_mapper);
          processor_mapping[*it] = runtime;
          // Save the the_runtime as the first one we make
          // just so that things will work in the multi-processor case
          if (the_runtime == NULL)
            the_runtime = runtime;
        }
      }
      else
      {
        // The normal path
        std::set<AddressSpaceID> address_spaces;
        std::map<Processor,AddressSpaceID> proc_spaces;
        Machine::ProcessorQuery all_procs(machine);
        for (Machine::ProcessorQuery::iterator it = 
              all_procs.begin(); it != all_procs.end(); it++)
        {
          AddressSpaceID sid = it->address_space();
          address_spaces.insert(sid);
          proc_spaces[*it] = sid;
          if (!first_proc.exists() && (sid == 0) && 
              (it->kind() == startup_kind))
            first_proc = *it;
        }
        // Make one runtime instance and record it with all the processors
        const AddressSpace local_space = local_procs.begin()->address_space();
        // Make a separate copy of the input arguments for the runtime
        InputArgs input_args;
        input_args.argc = argc;
        if (argc > 0)
        {
          input_args.argv = (char**)malloc(argc*sizeof(char*));
          for (int i = 0; i < argc; i++)
          {
            if (argv[i] != NULL)
              input_args.argv[i] = strdup(argv[i]);
            else
              input_args.argv[i] = NULL;
          }
        }
        else
          input_args.argv = NULL;
        Runtime *runtime = new Runtime(machine, config, background,
                                       input_args, local_space, system_memory,
                                       local_procs, local_util_procs,
                                       address_spaces, proc_spaces,
                                       supply_default_mapper);
        // Save THE runtime 
        the_runtime = runtime;
        for (std::set<Processor>::const_iterator it = 
              local_procs.begin(); it != local_procs.end(); it++)
          processor_mapping[*it] = runtime;
        for (std::set<Processor>::const_iterator it = 
              local_util_procs.begin(); it != local_util_procs.end(); it++)
          processor_mapping[*it] = runtime;
      }
      Realm::ProfilingRequestSet no_requests;
      // Keep track of all the registration events
      std::set<RtEvent> registered_events;
      // Make the code descriptors for our tasks
      CodeDescriptor startup_task(Runtime::startup_runtime_task);
      CodeDescriptor shutdown_task(Runtime::shutdown_runtime_task);
      CodeDescriptor lg_task(Runtime::legion_runtime_task);
      CodeDescriptor rt_profiling_task(Runtime::profiling_runtime_task);
      CodeDescriptor endpoint_task(Runtime::endpoint_runtime_task); 
      CodeDescriptor app_proc_task(Runtime::application_processor_runtime_task);
      for (std::map<Processor,Runtime*>::const_iterator it = 
            processor_mapping.begin(); it != processor_mapping.end(); it++)
      {
        // These tasks get registered on startup_kind processors
        if (it->first.kind() == startup_kind)
          registered_events.insert(RtEvent(
              it->first.register_task(LG_STARTUP_TASK_ID, startup_task,
                no_requests, &it->second, sizeof(it->second))));
        // Register these tasks on utility processors if we have
        // them otherwise register them on all the processor kinds
        if (local_util_procs.empty() || 
            (it->first.kind() == Processor::UTIL_PROC))
        {
          registered_events.insert(RtEvent(
                it->first.register_task(LG_SHUTDOWN_TASK_ID, shutdown_task,
                  no_requests, &it->second, sizeof(it->second))));
#ifdef LEGION_SEPARATE_META_TASKS
          for (unsigned idx = 0; idx < LG_LAST_TASK_ID; idx++)
          {
            if (idx == LG_MESSAGE_ID)
            {
              for (unsigned msg = 0; msg < LAST_SEND_KIND; msg++)
                registered_events.insert(RtEvent(
                    it->first.register_task(LG_TASK_ID+idx+msg, lg_task,
                        no_requests, &it->second, sizeof(it->second))));
            }
            else
              registered_events.insert(RtEvent(
                    it->first.register_task(LG_TASK_ID+idx, lg_task,
                      no_requests, &it->second, sizeof(it->second))));
          }
#else
          registered_events.insert(RtEvent(
                it->first.register_task(LG_TASK_ID, lg_task,
                  no_requests, &it->second, sizeof(it->second))));
#endif
          registered_events.insert(RtEvent(
                it->first.register_task(LG_ENDPOINT_TASK_ID, endpoint_task,
                  no_requests, &it->second, sizeof(it->second))));
        }
        // Register profiling return meta-task on all processor kinds
        registered_events.insert(RtEvent(
            it->first.register_task(LG_LEGION_PROFILING_ID, rt_profiling_task,
              no_requests, &it->second, sizeof(it->second))));
        // Application processor tasks get registered on all
        // processors which are not utility processors
#ifdef LEGION_SEPARATE_META_TASKS
        if (it->first.kind() != Processor::UTIL_PROC)
        {
          for (unsigned idx = 0; idx < LG_LAST_TASK_ID; idx++)
            registered_events.insert(RtEvent(
                it->first.register_task(LG_APP_PROC_TASK_ID+idx, app_proc_task,
                      no_requests, &it->second, sizeof(it->second))));
        }
#else
        if (it->first.kind() != Processor::UTIL_PROC)
          registered_events.insert(RtEvent(
                it->first.register_task(LG_APP_PROC_TASK_ID, app_proc_task,
                  no_requests, &it->second, sizeof(it->second))));
#endif
      }
      // Lastly do any other registrations we might have
      ReductionOpTable& red_table = get_reduction_table(true/*safe*/);
      red_table[BarrierArrivalReduction::REDOP] =
        Realm::ReductionOpUntyped::create_reduction_op<
                            BarrierArrivalReduction>();
#ifdef DEBUG_LEGION_COLLECTIVES
      red_table[CollectiveCheckReduction::REDOP] =
        Realm::ReductionOpUntyped::create_reduction_op<
                                CollectiveCheckReduction>();
      red_table[CloseCheckReduction::REDOP]=
        Realm::ReductionOpUntyped::create_reduction_op<
                                CloseCheckReduction>();
#endif
      for(ReductionOpTable::const_iterator it = red_table.begin();
          it != red_table.end();
          it++)
        realm.register_reduction(it->first, it->second);

      const SerdezOpTable &serdez_table = get_serdez_table(true/*safe*/);
      for (SerdezOpTable::const_iterator it = serdez_table.begin();
            it != serdez_table.end(); it++)
        realm.register_custom_serdez(it->first, it->second);
      
      if (config.record_registration)
      {
        log_run.print("Legion startup task has Realm ID %d",
                      LG_STARTUP_TASK_ID);
        log_run.print("Legion runtime shutdown task has Realm ID %d", 
                      LG_SHUTDOWN_TASK_ID);
        log_run.print("Legion runtime meta-task has Realm ID %d", 
                      LG_TASK_ID);
        log_run.print("Legion runtime profiling task Realm ID %d",
                      LG_LEGION_PROFILING_ID);
        log_run.print("Legion endpoint task has Realm ID %d",
                      LG_ENDPOINT_TASK_ID);
#ifdef LEGION_SEPARATE_META_TASKS
        LG_TASK_DESCRIPTIONS(descs);
        for (unsigned idx = 0; idx < LG_LAST_TASK_ID; idx++)
        {
          if (idx == LG_MESSAGE_ID)
          {
            LG_MESSAGE_DESCRIPTIONS(msg_descs);
            for (unsigned msg = 0; msg < LAST_SEND_KIND; msg++)
              log_run.print("Legion message %s meta-task has Realm ID %d",
                  msg_descs[msg], LG_TASK_ID+idx+msg);
          }
          else
          {
            log_run.print("Legion runtime %s meta-task has Realm ID %d",
                descs[idx], LG_TASK_ID+idx);
            log_run.print("Legion application %s meta-task has Realm ID %d",
                descs[idx], LG_APP_PROC_TASK_ID+idx);
          }
        }
#endif
      }
      // Make sure that we are done registering before we return
      RtEvent ready = Runtime::merge_events(registered_events);
      if (ready.exists())
        ready.wait();
      return first_proc;
    }

    //--------------------------------------------------------------------------
    /*static*/ int Runtime::wait_for_shutdown(void)
    //--------------------------------------------------------------------------
    {
      if (!runtime_backgrounded)
        REPORT_LEGION_ERROR(ERROR_ILLEGAL_WAIT_FOR_SHUTDOWN, 
                      "Illegal call to wait_for_shutdown when runtime was "
                      "not launched in background mode!");
      // If this is the first time we've called this on this node then 
      // we need to remove our reference to allow shutdown to proceed
      if (!background_wait.exchange(true))
        the_runtime->decrement_outstanding_top_level_tasks();
      return RealmRuntime::get_runtime().wait_for_shutdown();
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::set_return_code(int code)
    //--------------------------------------------------------------------------
    {
      return_code = code;
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::set_top_level_task_id(TaskID top_id)
    //--------------------------------------------------------------------------
    {
      legion_main_id = top_id;
      legion_main_set = true;
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::set_top_level_task_mapper_id(MapperID mapper_id)
    //--------------------------------------------------------------------------
    {
      legion_main_mapper_id = mapper_id;
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::configure_MPI_interoperability(int rank)
    //--------------------------------------------------------------------------
    {
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'configure_MPI_interoperability' after "
                      "the runtime has been started!");
#ifdef DEBUG_LEGION
      assert(rank >= 0);
#endif
      // Check to see if it was already set
      if (mpi_rank >= 0)
      {
        if (rank != mpi_rank)
          REPORT_LEGION_ERROR(ERROR_DUPLICATE_MPI_CONFIG, 
              "multiple calls to "
              "configure_MPI_interoperability with different ranks "
              "%d and %d on the same Legion runtime!", mpi_rank, rank)
        else
          REPORT_LEGION_WARNING(LEGION_WARNING_DUPLICATE_MPI_CONFIG,
                                "duplicate calls to configure_"
                                "MPI_interoperability on rank %d!", rank);
      }
      mpi_rank = rank;
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::register_handshake(LegionHandshake &handshake)
    //--------------------------------------------------------------------------
    {
      // See if the runtime is started or not
      if (runtime_started)
      {
        // If it's started, we can just do the initialization now
        handshake.impl->initialize(the_runtime);
      }
      else
      {
        std::vector<LegionHandshake> &pending_handshakes = 
          get_pending_handshake_table();
        pending_handshakes.push_back(handshake);
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ const ReductionOp* Runtime::get_reduction_op(
                                                        ReductionOpID redop_id,
                                                        bool has_lock/*=false*/)
    //--------------------------------------------------------------------------
    {
      if (redop_id == 0)
        REPORT_LEGION_ERROR(ERROR_RESERVED_REDOP_ID, 
                      "ReductionOpID zero is reserved.")
      if (!runtime_started || has_lock)
      {
        ReductionOpTable &red_table = 
          Runtime::get_reduction_table(true/*safe*/);
#ifdef DEBUG_LEGION
        if (red_table.find(redop_id) == red_table.end())
          REPORT_LEGION_ERROR(ERROR_INVALID_REDOP_ID, 
                        "Invalid ReductionOpID %d",redop_id)
#endif
        return red_table[redop_id];
      }
      else
        return the_runtime->get_reduction(redop_id);
    }

    //--------------------------------------------------------------------------
    const ReductionOp* Runtime::get_reduction(ReductionOpID redop_id)
    //--------------------------------------------------------------------------
    {
      AutoLock r_lock(redop_lock);
      return get_reduction_op(redop_id, true/*has lock*/); 
    }

    //--------------------------------------------------------------------------
    FillView* Runtime::find_or_create_reduction_fill_view(ReductionOpID redop)
    //--------------------------------------------------------------------------
    {
      {
        AutoLock r_lock(redop_lock,1,false/*exclusive*/);
        std::map<ReductionOpID,FillView*>::const_iterator finder =
          redop_fill_views.find(redop);
        if (finder != redop_fill_views.end())
          return finder->second;
      }
      AutoLock r_lock(redop_lock);
      // Check to see if we lost the race
      std::map<ReductionOpID,FillView*>::const_iterator finder =
        redop_fill_views.find(redop);
      if (finder != redop_fill_views.end())
        return finder->second;
      const ReductionOp *reduction_op =
        get_reduction_op(redop, true/*has lock*/);
#ifdef DEBUG_LEGION
      assert(reduction_op->identity != NULL);
#endif
      FillView *fill_view = new FillView(this, get_available_distributed_id(),
#ifdef LEGION_SPY
                                         0/*no creator*/,
#endif
                                         reduction_op->identity,
                                         reduction_op->sizeof_rhs,
                                         true/*register now*/);
      fill_view->add_base_valid_ref(RUNTIME_REF);
      redop_fill_views[redop] = fill_view;
      return fill_view;
    }

    //--------------------------------------------------------------------------
    /*static*/ const SerdezOp* Runtime::get_serdez_op(CustomSerdezID serdez_id,
                                                      bool has_lock/*=false*/)
    //--------------------------------------------------------------------------
    {
      if (serdez_id == 0)
        REPORT_LEGION_ERROR(ERROR_RESERVED_SERDEZ_ID, 
                      "CustomSerdezID zero is reserved.")
      if (!runtime_started || has_lock)
      {
        SerdezOpTable &serdez_table = Runtime::get_serdez_table(true/*safe*/);
#ifdef DEBUG_LEGION
        if (serdez_table.find(serdez_id) == serdez_table.end())
          REPORT_LEGION_ERROR(ERROR_INVALID_SERDEZ_ID, 
                        "Invalid CustomSerdezOpID %d", serdez_id)
#endif
        return serdez_table[serdez_id];
      }
      else
        return the_runtime->get_serdez(serdez_id);
    }

    //--------------------------------------------------------------------------
    const SerdezOp* Runtime::get_serdez(CustomSerdezID serdez_id)
    //--------------------------------------------------------------------------
    {
      AutoLock s_lock(serdez_lock);
      return get_serdez_op(serdez_id, true/*has lock*/);
    }

    //--------------------------------------------------------------------------
    /*static*/ const SerdezRedopFns* Runtime::get_serdez_redop_fns(
                                                       ReductionOpID redop_id,
                                                       bool has_lock/*= false*/)
    //--------------------------------------------------------------------------
    {
      if (!runtime_started || has_lock)
      {
        SerdezRedopTable &serdez_table = get_serdez_redop_table(true/*safe*/); 
        SerdezRedopTable::const_iterator finder = serdez_table.find(redop_id);
        if (finder != serdez_table.end())
          return &(finder->second);
        return NULL;
      }
      else
        return the_runtime->get_serdez_redop(redop_id);
    }

    //--------------------------------------------------------------------------
    const SerdezRedopFns* Runtime::get_serdez_redop(ReductionOpID redop_id)
    //--------------------------------------------------------------------------
    {
      AutoLock r_lock(redop_lock);
      return get_serdez_redop_fns(redop_id, true/*has lock*/);
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::add_registration_callback(
                                             RegistrationCallbackFnptr callback,
                                             bool deduplicate, size_t dedup_tag)
    //--------------------------------------------------------------------------
    {
      if (!runtime_started)
      {
        std::vector<RegistrationCallback> &registration_callbacks = 
          get_pending_registration_callbacks();
        registration_callbacks.resize(registration_callbacks.size() + 1);
        RegistrationCallback &reg = registration_callbacks.back();
        reg.callback.withoutargs = callback;
        reg.deduplicate = deduplicate;
        reg.dedup_tag = dedup_tag;
        reg.has_args = false;
      }
      else
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'add_registration_callback' after "
                      "the runtime has been started! Please use "
                      "'perform_registration_callback' for registration "
                      "calls to be done after the runtime has started.")
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::add_registration_callback(
                                  RegistrationWithArgsCallbackFnptr callback,
                                  const UntypedBuffer &buffer, 
                                  bool deduplicate, size_t dedup_tag)
    //--------------------------------------------------------------------------
    {
      if (!runtime_started)
      {
        std::vector<RegistrationCallback> &registration_callbacks = 
          get_pending_registration_callbacks();
        registration_callbacks.resize(registration_callbacks.size() + 1);
        RegistrationCallback &reg = registration_callbacks.back();
        reg.callback.withargs = callback;
        reg.deduplicate = deduplicate;
        reg.dedup_tag = dedup_tag;
        reg.has_args = true;
        const size_t size = buffer.get_size();
        if (size > 0)
        {
          void *copy = malloc(size);
          memcpy(copy, buffer.get_ptr(), size);
          reg.buffer = UntypedBuffer(copy, size);
        }
      }
      else
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'add_registration_callback' after "
                      "the runtime has been started! Please use "
                      "'perform_registration_callback' for registration "
                      "calls to be done after the runtime has started.")
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::perform_dynamic_registration_callback(
                                RegistrationCallbackFnptr callback, bool global,
                                bool deduplicate, size_t dedup_tag)
    //--------------------------------------------------------------------------
    {
      if (runtime_started)
      {
        if (the_runtime->separate_runtime_instances)
            REPORT_LEGION_FATAL(LEGION_FATAL_SEPARATE_RUNTIME_INSTANCES,
                "Dynamic registration callbacks cannot be registered after "
                "the runtime has been started with multiple runtime instances.") 
        const RtEvent done_event = the_runtime->perform_registration_callback(
            (void*)callback, NULL/*buffer*/, 0/*size*/, false/*withargs*/,
            global, false/*preregistered*/, deduplicate, dedup_tag);
        if (done_event.exists() && !done_event.has_triggered())
        {
          // Block waiting for these to finish currently since we need
          // to guarantee that all the resources are registered before
          // we proceed any further
          if (Processor::get_executing_processor().exists())
            done_event.wait();
          else
            done_event.external_wait();
        }
      }
      else // can safely ignore global as this call must be done everywhere
        add_registration_callback(callback, deduplicate, dedup_tag);
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::perform_dynamic_registration_callback(
                                     RegistrationWithArgsCallbackFnptr callback,
                                     const UntypedBuffer &buffer, bool global,
                                     bool deduplicate, size_t dedup_tag)
    //--------------------------------------------------------------------------
    {
      if (runtime_started)
      {
        if (the_runtime->separate_runtime_instances)
            REPORT_LEGION_FATAL(LEGION_FATAL_SEPARATE_RUNTIME_INSTANCES,
                "Dynamic registration callbacks cannot be registered after "
                "the runtime has been started with multiple runtime instances.") 
        const RtEvent done_event = the_runtime->perform_registration_callback(
            (void*)callback, buffer.get_ptr(), buffer.get_size(), 
            true/*withargs*/, global, false/*preregistered*/,
            deduplicate, dedup_tag);
        if (done_event.exists() && !done_event.has_triggered())
        {
          // Block waiting for these to finish currently since we need
          // to guarantee that all the resources are registered before
          // we proceed any further
          if (Processor::get_executing_processor().exists())
            done_event.wait();
          else
            done_event.external_wait();
        }
      }
      else // can safely ignore global as this call must be done everywhere
        add_registration_callback(callback, buffer, deduplicate, dedup_tag);
    }

    //--------------------------------------------------------------------------
    /*static*/ ReductionOpTable& Runtime::get_reduction_table(bool safe)
    //--------------------------------------------------------------------------
    {
      static ReductionOpTable table;
      if (!safe && runtime_started)
        assert(false);
      return table;
    }

    //--------------------------------------------------------------------------
    /*static*/ SerdezOpTable& Runtime::get_serdez_table(bool safe)
    //--------------------------------------------------------------------------
    {
      static SerdezOpTable table;
      if (!safe && runtime_started)
        assert(false);
      return table;
    }
    
    //--------------------------------------------------------------------------
    /*static*/ SerdezRedopTable& Runtime::get_serdez_redop_table(bool safe)
    //--------------------------------------------------------------------------
    {
      static SerdezRedopTable table;
      if (!safe && runtime_started)
        assert(false);
      return table;
    }

#if defined(LEGION_USE_CUDA) || defined(LEGION_USE_HIP)
    // Define a free function for Runtime::register_reduction_op because
    //  legion_redop.cu cannot include runtime.h
    //--------------------------------------------------------------------------
    void runtime_register_reduction_op(ReductionOpID redop_id,
                                       ReductionOp *redop,
                                       SerdezInitFnptr init_fnptr,
                                       SerdezFoldFnptr fold_fnptr,
                                       bool permit_duplicates,
                                       bool has_lock = false)
    //--------------------------------------------------------------------------
    {
      Runtime::register_reduction_op(redop_id, redop, init_fnptr, fold_fnptr,
                                     permit_duplicates, has_lock);
    }
#endif

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::register_reduction_op(ReductionOpID redop_id,
                                                   ReductionOp *redop,
                                                   SerdezInitFnptr init_fnptr,
                                                   SerdezFoldFnptr fold_fnptr,
                                                   bool permit_duplicates,
                                                   bool has_lock/*= false*/)
    //--------------------------------------------------------------------------
    {
      if (!runtime_started || has_lock)
      {
        if (redop_id == 0)
          REPORT_LEGION_ERROR(ERROR_RESERVED_REDOP_ID, 
                              "ERROR: ReductionOpID zero is reserved.")
        // TODO: figure out a way to make this safe with dynamic registration
#if 0
        if (redop_id >= LEGION_MAX_APPLICATION_REDOP_ID)
          REPORT_LEGION_ERROR(ERROR_RESERVED_REDOP_ID,
                         "ERROR: ReductionOpID %d is greater than or equal "
                         "to the LEGION_MAX_APPLICATION_REDOP_ID of %d "
                         "set in legion_config.h.", redop_id, 
                         LEGION_MAX_APPLICATION_REDOP_ID)
#endif
        if (redop->identity == NULL)
          REPORT_LEGION_ERROR(ERROR_RESERVED_REDOP_ID,
              "ERROR: Legion does not support reduction operators "
              "without identity values. All reduction operators must "
              "have an identity value to support fold operations.")
        ReductionOpTable &red_table = 
          Runtime::get_reduction_table(true/*safe*/);
        // Check to make sure we're not overwriting a prior reduction op 
        if (!permit_duplicates &&
            (red_table.find(redop_id) != red_table.end()))
          REPORT_LEGION_ERROR(ERROR_DUPLICATE_REDOP_ID, "ERROR: ReductionOpID "
                    "%d has already been used in the reduction table",redop_id)
        red_table[redop_id] = redop;
        if ((init_fnptr != NULL) || (fold_fnptr != NULL))
        {
#ifdef DEBUG_LEGION
          assert((init_fnptr != NULL) && (fold_fnptr != NULL));
#endif
          SerdezRedopTable &serdez_red_table = 
            Runtime::get_serdez_redop_table(true/*safe*/);
          SerdezRedopFns &fns = serdez_red_table[redop_id];
          fns.init_fn = init_fnptr;
          fns.fold_fn = fold_fnptr;
        }
      }
      else
        the_runtime->register_reduction(redop_id, redop, init_fnptr,
              fold_fnptr, permit_duplicates, false/*preregistered*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::register_reduction(ReductionOpID redop_id,
                                     ReductionOp *redop,
                                     SerdezInitFnptr init_fnptr,
                                     SerdezFoldFnptr fold_fnptr,
                                     bool permit_duplicates,
                                     bool preregistered)
    //--------------------------------------------------------------------------
    {
      if (!preregistered && !inside_registration_callback)
        REPORT_LEGION_WARNING(LEGION_WARNING_NON_CALLBACK_REGISTRATION,
            "Reduction operator %d was dynamically registered outside of a "
            "registration callback invocation. In the near future this will "
            "become an error in order to support task subprocesses. Please "
            "use 'perform_registration_callback' to generate a callback where "
            "it will be safe to perform dynamic registrations.", redop_id)
      // Dynamic registration so do it with realm too
      RealmRuntime realm = RealmRuntime::get_runtime();
      realm.register_reduction(redop_id, redop);
      AutoLock r_lock(redop_lock);
      Runtime::register_reduction_op(redop_id, redop, init_fnptr,
                fold_fnptr, permit_duplicates, true/*has locks*/);
    }

    //--------------------------------------------------------------------------
    void Runtime::register_serdez(CustomSerdezID serdez_id, SerdezOp *serdez_op, 
                                  bool permit_duplicates, bool preregistered)
    //--------------------------------------------------------------------------
    {
      if (!preregistered && !inside_registration_callback)
        REPORT_LEGION_WARNING(LEGION_WARNING_NON_CALLBACK_REGISTRATION,
            "Custom serdez operator %d was dynamically registered outside of a "
            "registration callback invocation. In the near future this will "
            "become an error in order to support task subprocesses. Please "
            "use 'perform_registration_callback' to generate a callback where "
            "it will be safe to perform dynamic registrations.", serdez_id)
      // Dynamic registration so do it with realm too
      RealmRuntime realm = RealmRuntime::get_runtime();
      realm.register_custom_serdez(serdez_id, serdez_op);
      AutoLock s_lock(serdez_lock);
      Runtime::register_serdez_op(serdez_id, serdez_op, 
                                  permit_duplicates, true/*has lock*/);
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::register_serdez_op(CustomSerdezID serdez_id,
                                                SerdezOp *serdez_op,
                                                bool permit_duplicates,
                                                bool has_lock/*= false*/)
    //--------------------------------------------------------------------------
    {
      if (!runtime_started || has_lock)
      {
        if (serdez_id == 0)
          REPORT_LEGION_ERROR(ERROR_RESERVED_SERDEZ_ID,
                              "ERROR: Custom Serdez ID zero is reserved.\n")
        // TODO: figure out a way to make this safe with dynamic registration
#if 0
        if (serdez_id >= LEGION_MAX_APPLICATION_SERDEZ_ID)
          REPORT_LEGION_ERROR(ERROR_RESERVED_SERDEZ_ID,
                         "ERROR: ReductionOpID %d is greater than or equal "
                         "to the LEGION_MAX_APPLICATION_SERDEZ_ID of %d set "
                         "in legion_config.h.", serdez_id, 
                         LEGION_MAX_APPLICATION_SERDEZ_ID)
#endif
        SerdezOpTable &serdez_table = Runtime::get_serdez_table(true/*safe*/);
        // Check to make sure we're not overwriting a prior serdez op
        if (!permit_duplicates &&
            (serdez_table.find(serdez_id) != serdez_table.end()))
          REPORT_LEGION_ERROR(ERROR_DUPLICATE_SERDEZ_ID,
                         "ERROR: CustomSerdezID %d has already been used "
                         "in the serdez operation table", serdez_id)
        serdez_table[serdez_id] = serdez_op;
      }
      else
        the_runtime->register_serdez(serdez_id, serdez_op, 
                                     permit_duplicates, false/*preregistered*/);
    }

    //--------------------------------------------------------------------------
    /*static*/ std::deque<PendingVariantRegistration*>& 
                                       Runtime::get_pending_variant_table(void)
    //--------------------------------------------------------------------------
    {
      static std::deque<PendingVariantRegistration*> pending_variant_table;
      return pending_variant_table;
    }

    //--------------------------------------------------------------------------
    /*static*/ std::map<LayoutConstraintID,LayoutConstraintRegistrar>&
                                    Runtime::get_pending_constraint_table(void)
    //--------------------------------------------------------------------------
    {
      static std::map<LayoutConstraintID,LayoutConstraintRegistrar>
                                                    pending_constraint_table;
      return pending_constraint_table;
    }

    //--------------------------------------------------------------------------
    /*static*/ std::map<ProjectionID,ProjectionFunctor*>&
                                     Runtime::get_pending_projection_table(void)
    //--------------------------------------------------------------------------
    {
      static std::map<ProjectionID,ProjectionFunctor*> pending_projection_table;
      return pending_projection_table;
    }

    //--------------------------------------------------------------------------
    /*static*/ std::map<ShardingID,ShardingFunctor*>&
                                       Runtime::get_pending_sharding_table(void)
    //--------------------------------------------------------------------------
    {
      static std::map<ShardingID,ShardingFunctor*> pending_sharding_table;
      return pending_sharding_table;
    }

    //--------------------------------------------------------------------------
    /*static*/ std::vector<LegionHandshake>& 
                                      Runtime::get_pending_handshake_table(void)
    //--------------------------------------------------------------------------
    {
      static std::vector<LegionHandshake> pending_handshakes_table;
      return pending_handshakes_table;
    }

    //--------------------------------------------------------------------------
    /*static*/ std::vector<Runtime::RegistrationCallback>&
                               Runtime::get_pending_registration_callbacks(void)
    //--------------------------------------------------------------------------
    {
      static std::vector<RegistrationCallback> pending_callbacks;
      return pending_callbacks;
    }

    //--------------------------------------------------------------------------
    /*static*/ TaskID& Runtime::get_current_static_task_id(void)
    //--------------------------------------------------------------------------
    {
      static TaskID current_task_id = LEGION_MAX_APPLICATION_TASK_ID;
      return current_task_id;
    }

    //--------------------------------------------------------------------------
    /*static*/ TaskID Runtime::generate_static_task_id(void)
    //--------------------------------------------------------------------------
    {
      TaskID &next_task = get_current_static_task_id(); 
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'generate_static_task_id' after "
                      "the runtime has been started!")
      return next_task++;
    }

    //--------------------------------------------------------------------------
    /*static*/ ReductionOpID& Runtime::get_current_static_reduction_id(void)
    //--------------------------------------------------------------------------
    {
      // Make sure to reserve space for the built-in reduction operators
      static ReductionOpID current_redop_id = 
        LEGION_MAX_APPLICATION_REDOP_ID + LEGION_REDOP_LAST;
      return current_redop_id;
    }

    //--------------------------------------------------------------------------
    /*static*/ ReductionOpID Runtime::generate_static_reduction_id(void)
    //--------------------------------------------------------------------------
    {
      ReductionOpID &next_redop = get_current_static_reduction_id();
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'generate_static_reduction_id' after "
                      "the runtime has been started!")
      return next_redop++;
    }

    //--------------------------------------------------------------------------
    /*static*/ CustomSerdezID& Runtime::get_current_static_serdez_id(void)
    //--------------------------------------------------------------------------
    {
      static CustomSerdezID current_serdez_id =LEGION_MAX_APPLICATION_SERDEZ_ID;
      return current_serdez_id;
    }

    //--------------------------------------------------------------------------
    /*static*/ CustomSerdezID Runtime::generate_static_serdez_id(void)
    //--------------------------------------------------------------------------
    {
      CustomSerdezID &next_serdez = get_current_static_serdez_id();
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'generate_static_serdez_id' after "
                      "the runtime has been started!")
      return next_serdez++;
    }

    //--------------------------------------------------------------------------
    /*static*/ VariantID Runtime::preregister_variant(
                          const TaskVariantRegistrar &registrar,
                          const void *user_data, size_t user_data_size,
                          const CodeDescriptor &code_desc, 
                          size_t return_size, bool has_return_size, 
                          const char *task_name, VariantID vid, bool check_id)
    //--------------------------------------------------------------------------
    {
      // Report an error if the runtime has already started
      if (runtime_started)
        REPORT_LEGION_ERROR(ERROR_STATIC_CALL_POST_RUNTIME_START, 
                      "Illegal call to 'preregister_task_variant' after "
                      "the runtime has been started!")
      if (check_id && (registrar.task_id >= get_current_static_task_id()))
        REPORT_LEGION_ERROR(ERROR_MAX_APPLICATION_TASK_ID_EXCEEDED, 
                      "Error preregistering task with ID %d. Exceeds the "
                      "statically set bounds on application task IDs of %d. "
                      "See %s in legion_config.h.", 
                      registrar.task_id, LEGION_MAX_APPLICATION_TASK_ID, 
                      LEGION_MACRO_TO_STRING(LEGION_MAX_APPLICATION_TASK_ID))
      std::deque<PendingVariantRegistration*> &pending_table = 
        get_pending_variant_table();
      // See if we need to pick a variant
      if (vid == LEGION_AUTO_GENERATE_ID)
        vid = pending_table.size() + 1;
      else if (vid == 0)
        REPORT_LEGION_ERROR(ERROR_RESERVED_VARIANT_ID,
                      "Error preregistering variant for task ID %d with "
                      "variant ID 0. Variant ID 0 is reserved for task "
                      "generators.", registrar.task_id)
      // Offset by the runtime tasks
      pending_table.push_back(new PendingVariantRegistration(vid, return_size,
                              has_return_size, registrar, user_data,
                              user_data_size, code_desc, task_name));
      return vid;
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::report_fatal_message(int id,
                                          const char *file_name, const int line,
                                                  const char *message)
    //--------------------------------------------------------------------------
    {
      log_run.fatal(id, "LEGION FATAL: %s (from file %s:%d)",
                    message, file_name, line);
      abort();
    }
    
    //--------------------------------------------------------------------------
    /*static*/ void Runtime::report_error_message(int id,
                                          const char *file_name, const int line,
                                                  const char *message)
    //--------------------------------------------------------------------------
    {
      log_run.error(id, "LEGION ERROR: %s (from file %s:%d)",
                    message, file_name, line);
      abort();
    }
    
    //--------------------------------------------------------------------------
    /*static*/ void Runtime::report_warning_message(
                                         int id,
                                         const char *file_name, const int line,
                                         const char *message)
    //--------------------------------------------------------------------------
    {
      log_run.warning(id, "LEGION WARNING: %s (from file %s:%d)",
                      message, file_name, line);
      if (Runtime::the_runtime && Runtime::the_runtime->warnings_backtrace)
      {
        Realm::Backtrace bt;
        bt.capture_backtrace();
        bt.lookup_symbols();
        log_run.warning() << bt;
      }
#ifndef LEGION_WARNINGS_FATAL
      if (the_runtime->warnings_are_errors)
#endif
        abort();
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::shutdown_runtime_task(const void *args, 
               size_t arglen, const void *userdata, size_t userlen, Processor p)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(userlen == sizeof(Runtime**));
#endif
      Runtime *runtime = *((Runtime**)userdata); 
      if (implicit_runtime == NULL)
        implicit_runtime = runtime;
      // We don't profile this task
      implicit_profiler = NULL;
      implicit_fevent = LgEvent::NO_LG_EVENT;
      // Finalize the runtime and then delete it
      std::vector<RtEvent> shutdown_events;
      runtime->finalize_runtime(shutdown_events);
      delete runtime;
      // If we have any shutdown events we need to wait for them to have
      // finished before we return and end up marking ourselves finished
      if (!shutdown_events.empty())
      {
        const RtEvent wait_on = Runtime::merge_events(shutdown_events);
        wait_on.wait();
      }
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::legion_runtime_task(
                                  const void *args, size_t arglen, 
				  const void *userdata, size_t userlen,
				  Processor p)
    //--------------------------------------------------------------------------
    {
      Runtime *runtime = *((Runtime**)userdata);
#ifdef DEBUG_LEGION
      assert(userlen == sizeof(Runtime**));
#if (!defined(LEGION_MALLOC_INSTANCES) && !defined(LEGION_USE_CUDA)) || \
      (!defined(LEGION_MALLOC_INSTANCES) && !defined(LEGION_USE_HIP))
      // Meta-tasks can run on application processors only when there
      // are no utility processors for us to use
      if (!runtime->local_utils.empty())
        assert(implicit_context == NULL); // this better hold
#endif
      assert(implicit_reference_tracker == NULL);
#endif
      if (implicit_runtime == NULL)
        implicit_runtime = runtime;
      // We immediately bump the priority of all meta-tasks once they start
      // up to the highest level to ensure that they drain once they begin
      Processor::set_current_task_priority(LG_RUNNING_PRIORITY);
      const char *data = (const char*)args;
      implicit_provenance = *((const UniqueID*)data);
      data += sizeof(implicit_provenance);
      arglen -= sizeof(implicit_provenance);
#ifdef DEBUG_LEGION_CALLERS
      implicit_task_caller = *((const LgTaskID*)data);
      data += sizeof(implicit_task_caller);
      arglen -= sizeof(implicit_task_caller);
#endif
      LgTaskID tid = *((const LgTaskID*)data);
#ifdef DEBUG_LEGION_CALLERS
      implicit_task_kind = tid;
#endif
      data += sizeof(tid);
      arglen -= sizeof(tid);
      if (runtime->profiler != NULL)
      {
        implicit_fevent = LgEvent(Processor::get_current_finish_event());
        // If this is a message task, then we need to initialize the
        // implicit_fevent before doing anything that can block
        if (tid == LG_MESSAGE_ID)
          runtime->profiler->increment_outstanding_message_request();
        if (implicit_profiler == NULL)
          implicit_profiler = 
            runtime->profiler->find_or_create_profiling_instance();
      }
      switch (tid)
      {
        case LG_SCHEDULER_ID:
          {
            const ProcessorManager::SchedulerArgs *sched_args = 
              (const ProcessorManager::SchedulerArgs*)args;
            runtime->process_schedule_request(sched_args->proc);
            break;
          }
        case LG_MESSAGE_ID:
          {
            runtime->process_message_task(data, arglen);
            break;
          }
        case LG_TRIGGER_READY_ID:
          {
            InnerContext::handle_ready_queue(args);
            break;
          }
        case LG_TRIGGER_COMMIT_ID:
          {
            InnerContext::handle_trigger_commit_queue(args);
            break;
          }
        case LG_DEFERRED_EXECUTION_ID:
          {
            InnerContext::handle_deferred_execution_queue(args);
            break;
          }
        case LG_TRIGGER_EXECUTION_ID:
          {
            InnerContext::handle_trigger_execution_queue(args);
            break;
          }
        case LG_DEFERRED_COMPLETION_ID:
          {
            InnerContext::handle_deferred_completion_queue(args);
            break;
          } 
        case LG_DEFERRED_COMMIT_ID:
          {
            InnerContext::handle_deferred_commit_queue(args);
            break;
          }
        case LG_PRE_PIPELINE_ID:
          {
            InnerContext::handle_prepipeline_stage(args);
            break;
          }
        case LG_TRIGGER_DEPENDENCE_ID:
          {
            InnerContext::handle_dependence_stage(args);
            break;
          }
        case LG_DEFERRED_MAPPED_ID:
          {
            InnerContext::handle_deferred_mapped_queue(args);
            break;
          }
        case LG_TRIGGER_OP_ID:
          {
            // Key off of args here instead of data
            const Operation::TriggerOpArgs *trigger_args = 
                            (const Operation::TriggerOpArgs*)args;
            trigger_args->op->trigger_mapping();
            break;
          }
        case LG_TRIGGER_TASK_ID:
          {
            // Key off of args here instead of data
            const TaskOp::TriggerTaskArgs *trigger_args = 
                          (const TaskOp::TriggerTaskArgs*)args;
            trigger_args->op->trigger_mapping(); 
            break;
          }
        case LG_DEFER_MAPPER_SCHEDULER_TASK_ID:
          {
            ProcessorManager::handle_defer_mapper(args);
            break;
          }
        case LG_MUST_INDIV_ID:
          {
            MustEpochOp::handle_trigger_individual(args);
            break;
          }
        case LG_MUST_INDEX_ID:
          {
            MustEpochOp::handle_trigger_index(args);
            break;
          }
        case LG_MUST_MAP_ID:
          {
            MustEpochOp::handle_map_task(args);
            break;
          }
        case LG_MUST_DIST_ID:
          {
            MustEpochOp::handle_distribute_task(args);
            break;
          }
        case LG_MUST_LAUNCH_ID:
          {
            MustEpochOp::handle_launch_task(args);
            break;
          }
        case LG_CONTRIBUTE_COLLECTIVE_ID:
          {
            FutureImpl::handle_contribute_to_collective(args);
            break;
          }
        case LG_FUTURE_BROADCAST_TASK_ID:
          {
            FutureImpl::handle_broadcast(args);
            break;
          }
        case LG_TOP_FINISH_TASK_ID:
          {
            TopFinishArgs *fargs = (TopFinishArgs*)args; 
            if (fargs->ctx->remove_base_gc_ref(RUNTIME_REF))
              delete fargs->ctx;
            // Finally tell the runtime that we have one less top level task
            runtime->decrement_outstanding_top_level_tasks();
            break;
          }
        case LG_MAPPER_TASK_ID:
          {
            MapperTaskArgs *margs = (MapperTaskArgs*)args;
            runtime->process_mapper_task_result(margs);
            // Now indicate that we are done with the future
            if (margs->future->remove_base_gc_ref(META_TASK_REF))
              delete margs->future;
            // We can also deactivate the enclosing context 
            if (margs->ctx->remove_nested_gc_ref(RUNTIME_REF))
              delete margs->ctx;
            // Finally tell the runtime we have one less top level task
            runtime->decrement_outstanding_top_level_tasks();
            break;
          }
        case LG_DISJOINTNESS_TASK_ID:
          {
            RegionTreeForest *forest = runtime->forest;
            IndexPartNode::handle_disjointness_computation(args, forest);
            break;
          }
        case LG_DEFER_TIMING_MEASUREMENT_TASK_ID:
          {
            TimingOp::handle_deferred_measurement(args);
            break;
          }
        case LG_TASK_IMPL_SEMANTIC_INFO_REQ_TASK_ID:
          {
            TaskImpl::SemanticRequestArgs *req_args = 
              (TaskImpl::SemanticRequestArgs*)args;
            req_args->proxy_this->process_semantic_request(
                          req_args->tag, req_args->source, 
                          false, false, RtUserEvent::NO_RT_USER_EVENT);
            break;
          }
        case LG_INDEX_SPACE_SEMANTIC_INFO_REQ_TASK_ID:
          {
            IndexSpaceNode::SemanticRequestArgs *req_args = 
              (IndexSpaceNode::SemanticRequestArgs*)args;
            req_args->proxy_this->process_semantic_request(
                          req_args->tag, req_args->source, 
                          false, false, RtUserEvent::NO_RT_USER_EVENT);
            break;
          }
        case LG_INDEX_PART_SEMANTIC_INFO_REQ_TASK_ID:
          {
            IndexPartNode::SemanticRequestArgs *req_args = 
              (IndexPartNode::SemanticRequestArgs*)args;
            req_args->proxy_this->process_semantic_request(
                          req_args->tag, req_args->source, 
                          false, false, RtUserEvent::NO_RT_USER_EVENT);
            break;
          }
        case LG_FIELD_SPACE_SEMANTIC_INFO_REQ_TASK_ID:
          {
            FieldSpaceNode::SemanticRequestArgs *req_args = 
              (FieldSpaceNode::SemanticRequestArgs*)args;
            req_args->proxy_this->process_semantic_request(
                          req_args->tag, req_args->source, 
                          false, false, RtUserEvent::NO_RT_USER_EVENT);
            break;
          }
        case LG_FIELD_SEMANTIC_INFO_REQ_TASK_ID:
          {
            FieldSpaceNode::SemanticFieldRequestArgs *req_args = 
              (FieldSpaceNode::SemanticFieldRequestArgs*)args;
            req_args->proxy_this->process_semantic_field_request(
                  req_args->fid, req_args->tag, req_args->source, 
                  false, false, RtUserEvent::NO_RT_USER_EVENT);
            break;
          }
        case LG_DEFER_FIELD_INFOS_TASK_ID:
          {
            FieldSpaceNode::handle_defer_infos_request(args);
            break;
          }
        case LG_REGION_SEMANTIC_INFO_REQ_TASK_ID:
          {
            RegionNode::SemanticRequestArgs *req_args = 
              (RegionNode::SemanticRequestArgs*)args;
            req_args->proxy_this->process_semantic_request(
                          req_args->tag, req_args->source, 
                          false, false, RtUserEvent::NO_RT_USER_EVENT);
            break;
          }
        case LG_PARTITION_SEMANTIC_INFO_REQ_TASK_ID:
          {
            PartitionNode::SemanticRequestArgs *req_args = 
              (PartitionNode::SemanticRequestArgs*)args;
            req_args->proxy_this->process_semantic_request(
                          req_args->tag, req_args->source, 
                          false, false, RtUserEvent::NO_RT_USER_EVENT);
            break;
          }
        case LG_INDEX_SPACE_DEFER_CHILD_TASK_ID:
          {
            IndexSpaceNode::defer_node_child_request(args);
            break;
          }
        case LG_INDEX_PART_DEFER_CHILD_TASK_ID:
          {
            IndexPartNode::defer_node_child_request(args);
            break;
          }
        case LG_INDEX_PART_DEFER_SHARD_RECTS_TASK_ID:
          {
            IndexPartNode::defer_find_local_shard_rects(args);
            break;
          }
        case LG_DEFERRED_ENQUEUE_TASK_ID:
          {
            InnerContext::handle_enqueue_task_queue(args);
            break;
          }
        case LG_DEFER_MAPPER_MESSAGE_TASK_ID:
          {
            MapperManager::handle_deferred_message(args);
            break;
          }
        case LG_DEFER_MAPPER_COLLECTION_TASK_ID:
          {
            MapperManager::handle_deferred_collection(args);
            break;
          }
        case LG_REMOTE_VIEW_CREATION_TASK_ID:
          {
            PhysicalManager::handle_top_view_creation(args, runtime);
            break;
          }
        case LG_DEFERRED_DISTRIBUTE_TASK_ID:
          {
            InnerContext::handle_distribute_task_queue(args);
            break;
          }
        case LG_DEFER_PERFORM_MAPPING_TASK_ID:
          {
            const TaskOp::DeferMappingArgs *margs = 
              (const TaskOp::DeferMappingArgs*)args;
            const RtEvent deferred = 
              margs->proxy_this->perform_mapping(margs->must_op, margs);
            // Once we've no longer been deferred then we can trigger
            // the done event to signal we are done
            if (!deferred.exists())
              Runtime::trigger_event(margs->done_event);
            break;
          }
        case LG_FINALIZE_OUTPUT_TREE_TASK_ID:
          {
            const TaskOp::FinalizeOutputEqKDTreeArgs *fargs =
              (const TaskOp::FinalizeOutputEqKDTreeArgs*)args;
            fargs->proxy_this->finalize_output_region_trees();
            break;
          }
        case LG_DEFERRED_LAUNCH_TASK_ID:
          {
            InnerContext::handle_launch_task_queue(args);
            break;
          }
        case LG_MISPREDICATION_TASK_ID:
          {
            const SingleTask::MispredicationTaskArgs *targs = 
              (const SingleTask::MispredicationTaskArgs*)args;
            targs->task->handle_mispredication();
            break;
          }
        case LG_DEFER_TRIGGER_CHILDREN_COMMIT_TASK_ID:
          {
            TaskOp::handle_deferred_children_commit(args);
            break;
          }
        case LG_ORDER_CONCURRENT_LAUNCH_TASK_ID:
          {
            SingleTask::order_concurrent_task_launch(args);
            break;
          }
        case LG_DEFER_MATERIALIZED_VIEW_TASK_ID:
          {
            MaterializedView::handle_defer_materialized_view(args, runtime);
            break;
          }
        case LG_DEFER_REDUCTION_VIEW_TASK_ID:
          {
            ReductionView::handle_defer_reduction_view(args, runtime);
            break;
          }
        case LG_DEFER_PHI_VIEW_REGISTRATION_TASK_ID:
          {
            PhiView::handle_deferred_view_registration(args);
            break;
          }
        case LG_TIGHTEN_INDEX_SPACE_TASK_ID:
          {
            IndexSpaceExpression::handle_tighten_index_space(args);
            break;
          }
        case LG_REPLAY_SLICE_TASK_ID:
          {
            PhysicalTemplate::handle_replay_slice(args);
            break;
          }
        case LG_TRANSITIVE_REDUCTION_TASK_ID:
          {
            PhysicalTemplate::handle_transitive_reduction(args);
            break;
          }
        case LG_DELETE_TEMPLATE_TASK_ID:
          {
            PhysicalTemplate::handle_delete_template(args);
            break;
          }
        case LG_DEFER_MAKE_OWNER_TASK_ID:
          {
            EquivalenceSet::handle_make_owner(args);
            break;
          }
        case LG_DEFER_APPLY_STATE_TASK_ID:
          {
            EquivalenceSet::handle_apply_state(args);
            break;
          }
        case LG_COPY_FILL_AGGREGATION_TASK_ID:
          {
            CopyFillAggregator::handle_aggregation(args);
            break;
          }
        case LG_COPY_FILL_DELETION_TASK_ID:
          {
            CopyFillGuard::handle_deletion(args);
            break;
          }
        case LG_FINALIZE_EQ_SETS_TASK_ID:
          {
            EqSetTracker::handle_finalize_eq_sets(args, runtime);
            break;
          }
        case LG_FINALIZE_OUTPUT_EQ_SET_TASK_ID:
          {
            VersionManager::handle_finalize_output_eq_set(args);
            break;
          }
        case LG_DEFERRED_COPY_ACROSS_TASK_ID:
          {
            CopyOp::handle_deferred_across(args);
            break;
          }
        case LG_DEFER_REMOTE_OP_DELETION_TASK_ID:
          {
            RemoteOp::handle_deferred_deletion(args);
            break;
          }
        case LG_DEFER_PERFORM_TRAVERSAL_TASK_ID:
          {
            PhysicalAnalysis::handle_deferred_traversal(args);
            break;
          }
        case LG_DEFER_PERFORM_ANALYSIS_TASK_ID:
          {
            PhysicalAnalysis::handle_deferred_analysis(args);
            break;
          }
        case LG_DEFER_PERFORM_REMOTE_TASK_ID:
          {
            PhysicalAnalysis::handle_deferred_remote(args);
            break;
          }
        case LG_DEFER_PERFORM_UPDATE_TASK_ID:
          {
            PhysicalAnalysis::handle_deferred_update(args);
            break;
          }
        case LG_DEFER_PERFORM_REGISTRATION_TASK_ID:
          {
            PhysicalAnalysis::handle_deferred_registration(args);
            break;
          }
        case LG_DEFER_PERFORM_OUTPUT_TASK_ID:
          {
            PhysicalAnalysis::handle_deferred_output(args);
            break;
          }
        case LG_DEFER_PHYSICAL_MANAGER_TASK_ID:
          {
            PhysicalManager::handle_defer_manager(args, runtime);
            break;
          }
        case LG_DEFER_DELETE_PHYSICAL_MANAGER_TASK_ID:
          {
            PhysicalManager::handle_defer_perform_deletion(args, runtime);
            break;
          }
        case LG_DEFER_VERIFY_PARTITION_TASK_ID:
          {
            InnerContext::handle_partition_verification(args);
            break;
          }
        case LG_DEFER_RELEASE_ACQUIRED_TASK_ID:
          {
            Operation::handle_deferred_release(args);
            break;
          }
        case LG_DEFER_COPY_ACROSS_TASK_ID:
          {
            CopyAcrossExecutor::handle_deferred_copy_across(args);
            break;
          }
        case LG_FREE_EAGER_INSTANCE_TASK_ID:
          {
            MemoryManager::handle_free_eager_instance(args);
            break;
          }
        case LG_FINALIZE_OUTPUT_ID:
          {
            OutputRegionImpl::handle_finalize_output(args);
            break;
          } 
#ifdef LEGION_MALLOC_INSTANCES
        // LG_MALLOC_INSTANCE_TASK_ID should always run app processor
        case LG_FREE_INSTANCE_TASK_ID:
          {
            MemoryManager::handle_free_instance(args);
            break;
          }
#endif
        case LG_DEFER_TRACE_UPDATE_TASK_ID:
          {
            ShardedPhysicalTemplate::handle_deferred_trace_update(args,runtime);
            break;
          }
        case LG_DEFER_CONSENSUS_MATCH_TASK_ID:
          {
            ConsensusMatchBase::handle_consensus_match(args);
            break;
          }
        case LG_DEFER_COLLECTIVE_TASK_ID:
          {
            ShardCollective::handle_deferred_collective(args);
            break;
          }
        case LG_DEFER_ISSUE_FILL_TASK_ID:
          {
            FillView::handle_defer_issue_fill(args);
            break;
          }
        case LG_DEFER_MUST_EPOCH_RETURN_TASK_ID:
          {
            ReplMustEpochOp::handle_defer_return_resources(args);
            break;
          }
        case LG_DEFER_DELETE_FUTURE_INSTANCE_TASK_ID:
          {
            FutureInstance::handle_defer_deletion(args);
            break;
          }
        case LG_FREE_EXTERNAL_TASK_ID:
          {
            FutureInstance::handle_free_external(args);
            break;
          }
        case LG_DEFER_DELETION_COMMIT_TASK_ID:
          {
            ReplDeletionOp::handle_defer_commit(args);
            break;
          }
        case LG_YIELD_TASK_ID:
          break; // nothing to do here
        case LG_AUTO_TRACE_PROCESS_REPEATS_TASK_ID:
          {
            TraceRecognizer::find_repeats(args);
            break;
          }
        case LG_RETRY_SHUTDOWN_TASK_ID:
          {
            const ShutdownManager::RetryShutdownArgs *shutdown_args = 
              (const ShutdownManager::RetryShutdownArgs*)args;
            runtime->initiate_runtime_shutdown(runtime->address_space,
                                               shutdown_args->phase);
            break;
          }
        default:
          assert(false); // should never get here
      }
      if (implicit_reference_tracker != NULL)
      {
        delete implicit_reference_tracker;
        implicit_reference_tracker = NULL;
      }
#ifdef DEBUG_LEGION
      if (tid < LG_BEGIN_SHUTDOWN_TASK_IDS)
        runtime->decrement_total_outstanding_tasks(tid, true/*meta*/);
#else
      if (tid < LG_BEGIN_SHUTDOWN_TASK_IDS)
        runtime->decrement_total_outstanding_tasks();
#endif
#ifdef DEBUG_SHUTDOWN_HANG
      runtime->outstanding_counts[tid].fetch_sub(1);
#endif
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::profiling_runtime_task(
                                   const void *args, size_t arglen, 
				   const void *userdata, size_t userlen,
				   Processor p)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(userlen == sizeof(Runtime**));
#endif
      Runtime *runtime = *((Runtime**)userdata);
      if (implicit_runtime == NULL)
        implicit_runtime = runtime;
      if (runtime->profiler != NULL) 
      {
        implicit_fevent = LgEvent(Processor::get_current_finish_event());
        if (implicit_profiler == NULL)
          implicit_profiler = 
            runtime->profiler->find_or_create_profiling_instance();
      }
      Realm::ProfilingResponse response(args, arglen);
      const ProfilingResponseBase *base = 
        static_cast<const ProfilingResponseBase*>(response.user_data());
      LgEvent fevent;
      if (base->handler == NULL)
      {
        // This is the remote message case
#ifdef DEBUG_LEGION
        assert(runtime->profiler != NULL);
#endif
        const long long t_start = Realm::Clock::current_time_in_nanoseconds();
        // Check to see if should report this profiling
        if (runtime->profiler->handle_profiling_response(response, args,
                                                         arglen, fevent))
        {
          const long long t_stop = Realm::Clock::current_time_in_nanoseconds();
          const LgEvent finish_event(Processor::get_current_finish_event());
          implicit_profiler->process_proc_desc(p);
          implicit_profiler->record_proftask(p, base->op_id, t_start, t_stop,
              fevent, finish_event, base->completion);
        }
      }
      else if (runtime->profiler != NULL)
      {
        const long long t_start = Realm::Clock::current_time_in_nanoseconds();
        // Check to see if should report this profiling
        if (base->handler->handle_profiling_response(response, args, arglen, 
                                                     fevent))
        {
          const long long t_stop = Realm::Clock::current_time_in_nanoseconds();
          const LgEvent finish_event(Processor::get_current_finish_event());
          implicit_profiler->process_proc_desc(p);
          implicit_profiler->record_proftask(p, base->op_id, t_start, t_stop,
              fevent, finish_event, base->completion);
        }
      }
      else
        base->handler->handle_profiling_response(response, args, arglen,fevent);
    }

    //--------------------------------------------------------------------------
    void Runtime::broadcast_startup_barrier(RtBarrier startup_barrier)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(startup_barrier.exists());
#endif
      // Make sure the representation of the barriers haven't changed
      static_assert(sizeof(startup_barrier) == 
          (sizeof(startup_event) + sizeof(startup_timestamp)),
          "Realm Barrier representation changed");
      // Tree broadcast it out to any downstream nodes
      AddressSpaceID offset = address_space * legion_collective_radix;
      for (int idx = 1; idx <= legion_collective_radix; idx++)
      {
        AddressSpaceID target = offset + idx;
        if (target < total_address_spaces)
        {
          Serializer rez;
          rez.serialize(startup_barrier);
          send_startup_barrier(target, rez);
        }
      }
      // Write the timestamp first
      startup_timestamp = startup_barrier.timestamp;
      // Then set the ID locally
      RtUserEvent to_trigger;
      to_trigger.id = startup_event.exchange(startup_barrier.id);
      if (to_trigger.exists())
        Runtime::trigger_event(to_trigger);
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::startup_runtime_task(
                                   const void *args, size_t arglen, 
				   const void *userdata, size_t userlen,
				   Processor p)
    //--------------------------------------------------------------------------
    {
#ifdef DEBUG_LEGION
      assert(userlen == sizeof(Runtime**));
#endif
      Runtime *runtime = *((Runtime**)userdata);
      if (implicit_runtime == NULL)
        implicit_runtime = runtime;
      // We don't profile this task
      implicit_profiler = NULL;
      implicit_fevent = LgEvent::NO_LG_EVENT;
      // Create the startup barrier and send it out
      // Note we don't profile this for critical paths
      RtBarrier startup_barrier(
        Realm::Barrier::create_barrier(runtime->total_address_spaces));
      runtime->broadcast_startup_barrier(startup_barrier);
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::endpoint_runtime_task(
                                   const void *args, size_t arglen, 
				   const void *userdata, size_t userlen,
				   Processor p)
    //--------------------------------------------------------------------------
    {
      Runtime *runtime = *((Runtime**)userdata);
#ifdef DEBUG_LEGION
      assert(userlen == sizeof(Runtime**));
#endif
      Deserializer derez(args, arglen);
      if (implicit_runtime == NULL)
        implicit_runtime = runtime;
      // We don't profile this task
      implicit_profiler = NULL;
      implicit_fevent = LgEvent::NO_LG_EVENT;
      runtime->handle_endpoint_creation(derez);
    }

    //--------------------------------------------------------------------------
    /*static*/ void Runtime::application_processor_runtime_task(
                                   const void *args, size_t arglen, 
				   const void *userdata, size_t userlen,
				   Processor p)
    //--------------------------------------------------------------------------
    {
      Runtime *runtime = *((Runtime**)userdata);
#ifdef DEBUG_LEGION
      assert(userlen == sizeof(Runtime**));
      assert(implicit_reference_tracker == NULL);
#endif
      if (implicit_runtime == NULL)
        implicit_runtime = runtime;
      if (runtime->profiler != NULL)
      {
        implicit_fevent = LgEvent(Processor::get_current_finish_event());
        if (implicit_profiler == NULL)
          implicit_profiler =
            runtime->profiler->find_or_create_profiling_instance();
      }
      // We immediately bump the priority of all meta-tasks once they start
      // up to the highest level to ensure that they drain once they begin
      Processor::set_current_task_priority(LG_RUNNING_PRIORITY);
      const char *data = (const char*)args;
      implicit_provenance = *((const UniqueID*)data);
      data += sizeof(implicit_provenance);
      arglen -= sizeof(implicit_provenance);
#ifdef DEBUG_LEGION_CALLERS
      implicit_task_caller = *((const LgTaskID*)data);
      data += sizeof(implicit_task_caller);
      arglen -= sizeof(implicit_task_caller);
#endif
      LgTaskID tid = *((const LgTaskID*)data);
      data += sizeof(tid);
      arglen -= sizeof(tid);
#ifdef DEBUG_LEGION_CALLERS
      implicit_task_kind = tid;
#endif
      switch (tid)
      {
        case LG_FUTURE_CALLBACK_TASK_ID:
          {
            FutureImpl::handle_callback(args);
            break;
          }
        case LG_CALLBACK_RELEASE_TASK_ID:
          {
            FutureImpl::handle_release(args);
            break;
          } 
        case LG_REPLAY_SLICE_TASK_ID:
          {
            PhysicalTemplate::handle_replay_slice(args);
            break;
          }
        case LG_FREE_EXTERNAL_TASK_ID:
          {
            FutureInstance::handle_free_external(args);
            break;
          }
#ifdef LEGION_MALLOC_INSTANCES
        case LG_MALLOC_INSTANCE_TASK_ID:
          {
            MemoryManager::handle_malloc_instance(args);
            break;
          }
        case LG_FREE_INSTANCE_TASK_ID:
          {
            MemoryManager::handle_free_instance(args);
            break;
          }
#endif
        default:
          assert(false); // should never get here
      }
      if (implicit_reference_tracker != NULL)
      {
        delete implicit_reference_tracker;
        implicit_reference_tracker = NULL;
      }
#ifdef DEBUG_LEGION
      runtime->decrement_total_outstanding_tasks(tid, true/*meta*/);
#else
      runtime->decrement_total_outstanding_tasks();
#endif
#ifdef DEBUG_SHUTDOWN_HANG
      runtime->outstanding_counts[tid].fetch_sub(1);
#endif
    }

    //--------------------------------------------------------------------------
    /*static*/ RtBarrier Runtime::find_or_wait_for_startup_barrier(void)
    //--------------------------------------------------------------------------
    {
      RtBarrier result;
      result.id = startup_event.load();
      if (result.exists())
      {
        result.timestamp = startup_timestamp;
        return result;
      }
      // Barrier isn't ready yet so make an event to wait on and try to
      // swap it into the startup event
      const RtUserEvent ready = Runtime::create_rt_user_event();
      if (startup_event.compare_exchange_strong(result.id, ready.id))
      {
        ready.wait();
        result.id = startup_event.load();
      }
      else // Was already set
        Runtime::trigger_event(ready);
      // Get the timestamp
      result.timestamp = startup_timestamp;
      return result;
    }

#ifdef LEGION_TRACE_ALLOCATION
    //--------------------------------------------------------------------------
    /*static*/ void LegionAllocation::trace_allocation(
                                       AllocationType a, size_t size, int elems)
    //--------------------------------------------------------------------------
    {
      Runtime *rt = Runtime::the_runtime;
      if (rt != NULL)
        rt->trace_allocation(a, size, elems);
    }

    //--------------------------------------------------------------------------
    /*static*/ void LegionAllocation::trace_free(AllocationType a, 
                                                 size_t size, int elems)
    //--------------------------------------------------------------------------
    {
      Runtime *rt = Runtime::the_runtime;
      if (rt != NULL)
        rt->trace_free(a, size, elems);
    }

    //--------------------------------------------------------------------------
    /*static*/ Runtime* LegionAllocation::find_runtime(void)
    //--------------------------------------------------------------------------
    {
      return Runtime::the_runtime;
    }

    //--------------------------------------------------------------------------
    /*static*/ void LegionAllocation::trace_allocation(Runtime *&runtime,
                                       AllocationType a, size_t size, int elems)
    //--------------------------------------------------------------------------
    {
      if (runtime == NULL)
      {
        runtime = LegionAllocation::find_runtime();
        // Only happens during initialization
        if (runtime == NULL)
          return;
      }
      runtime->trace_allocation(a, size, elems);
    }

    //--------------------------------------------------------------------------
    /*static*/ void LegionAllocation::trace_free(Runtime *&runtime,
                                       AllocationType a, size_t size, int elems)
    //--------------------------------------------------------------------------
    {
      if (runtime == NULL)
      {
        runtime = LegionAllocation::find_runtime();
        // Only happens during intialization
        if (runtime == NULL)
          return;
      }
      runtime->trace_free(a, size, elems);
    }
#endif 

  }; // namespace Internal 
}; // namespace Legion 

// EOF
